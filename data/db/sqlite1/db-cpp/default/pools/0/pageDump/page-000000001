BloomPulldown"BloomPulldown"20971520x00200000BalancedMerge"BalancedMerge"0x00400000ReleaseReg"ReleaseReg"83886080x00800000FlttnUnionAll"FlttnUnionAll"IndexedEXpr"IndexedEXpr"33554432Coroutines"Coroutines"671088640x04000000NullUnusedCols"NullUnusedCols"134217728OnePass"OnePass"268435456OrderBySubq"OrderBySubq"536870912StarQuery"StarQuery"All"All"curOptnewOptmnOffuseLabel'+'jjArraySize(aLabel)Error: no such optimization: "%s"
"Error: no such optimization: \"%s\"\n"Should be one of:"Should be one of:" %s" %s"+All"+All" -%s" -%s"-All"-All" +%s" +%s"opt"random"sizeof(ii)-- random seed: %d
"-- random seed: %d\n"u64 *unsigned long long *%llu
"%llu\n"kkbShowHelpstatus"status"faultsim.iId:       %d
"faultsim.iId:       %d\n"faultsim.iErr:      %d
"faultsim.iErr:      %d\n"faultsim.iCnt:      %d
"faultsim.iCnt:      %d\n"faultsim.nHit:      %d
"faultsim.nHit:      %d\n"faultsim.iInterval: %d
"faultsim.iInterval: %d\n"faultsim.eVerbose:  %d
"faultsim.eVerbose:  %d\n"faultsim.nRepeat:   %d
"faultsim.nRepeat:   %d\n"faultsim.nSkip:     %d
"faultsim.nSkip:     %d\n"-q"-q"-id"-id"-errcode"-errcode"-interval"-interval"-repeat"-repeat"-?"-?"*help*"*help*"Unrecognized fault_install argument: "%s"
"Unrecognized fault_install argument: \"%s\"\n"Usage: .testctrl fault_install ARGS
Possible arguments:
   off               Disable faultsim
   on                Activate faultsim
   reset             Reset the trigger counter
   status            Show current status
   -v                Increase verbosity
   -q                Decrease verbosity
   --errcode N       When triggered, return N as error code
   --id ID           Trigger only for the ID specified
   --interval N      Trigger only after every N-th call
   --repeat N        Turn off after N hits.  0 means never
   --skip N          Skip the first N encounters
"Usage: .testctrl fault_install ARGS\n"
               "Possible arguments:\n"
               "   off               Disable faultsim\n"
               "   on                Activate faultsim\n"
               "   reset             Reset the trigger counter\n"
               "   status            Show current status\n"
               "   -v                Increase verbosity\n"
               "   -q                Decrease verbosity\n"
               "   --errcode N       When triggered, return N as error code\n"
               "   --id ID           Trigger only for the ID specified\n"
               "   --interval N      Trigger only after every N-th call\n"
               "   --repeat N        Turn off after N hits.  0 means never\n"
               "   --skip N          Skip the first N encounters\n"char[581]Usage: .testctrl %s %s
"Usage: .testctrl %s %s\n"0x%08x
"0x%08x\n"timeout"timeout"timer"timer"HAS_TIMER!HAS_TIMERError: timer not available on this system.
Usage: .timer on|off
mTypeexpanded"expanded"SHELL_TRACE_EXPANDEDplain"plain"SHELL_TRACE_PLAINprofile"profile"row"row"Unknown option "%s" on ".trace"
"Unknown option \"%s\" on \".trace\"\n"'v'"version"zPtrSzsizeof(void*)sizeof(void*)==864-bit"64-bit"32-bit"32-bit"SQLite %s %s
"SQLite %s %s\n"zlib version %s
"zlib version %s\n"gcc-EDG gcc 13.3 mode (%s)
"gcc-" __VERSION__ " (%s)\n"vfsinfo"vfsinfo"sqlite3_vfs **vfs.zName      = "%s"
"vfs.zName      = \"%s\"\n"vfs.iVersion   = %d
"vfs.iVersion   = %d\n"vfs.szOsFile   = %d
"vfs.szOsFile   = %d\n"vfs.mxPathname = %d
"vfs.mxPathname = %d\n"vfslist"vfslist"vfs.zName      = "%s"%s
"vfs.zName      = \"%s\"%s\n"  <--- CURRENT"  <--- CURRENT"-----------------------------------
"-----------------------------------\n"vfsname"vfsname"wheretrace"wheretrace"sizeof(int)Error: unknown command or invalid arguments:  "%s". Enter ".help" for help
"Error: unknown command or invalid arguments: "
          " \"%s\". Enter \".help\" for help\n"char[76]meta_command_exitfaultsim_callbackFAULT-SIM id=%d no-fault (cnt=%d)
"FAULT-SIM id=%d no-fault (cnt=%d)\n"FAULT-SIM id=%d returns %d
"FAULT-SIM id=%d returns %d\n"outputDumpWarningSELECT 1 FROM sqlite_schema o WHERE sql LIKE 'CREATE VIRTUAL TABLE%%' AND %s"SELECT 1 FROM sqlite_schema o WHERE "
    "sql LIKE 'CREATE VIRTUAL TABLE%%' AND %s"char[77]/* WARNING: Script requires that SQLITE_DBCONFIG_DEFENSIVE be disabled */
"/* WARNING: "
          "Script requires that SQLITE_DBCONFIG_DEFENSIVE be disabled */\n"char[75]zAutoColumnzTabMakezTabFillzHasDupeszSetRepszColDigitszRenameRankzCollectVarzRenamesDonepDb!=0*pDb!=0db_int(*pDb, "%s", zHasDupes)==0zColsSpechasDupesnDigitsSELECT group_concat( printf('"%w" to "%w"',name,printf('%!.*s%s', nlen-chop, name, suff)), ','||x'0a')FROM ColNames WHERE suff<>'' OR chop!=0"SELECT group_concat("
    " printf('\"%w\" to \"%w\"',name,printf('%!.*s%s', nlen-chop, name, suff)),"
    " ','||x'0a')"
    "FROM ColNames WHERE suff<>'' OR chop!=0"char[142]SELECT '('||x'0a' || group_concat(  cname||' TEXT',  ','||iif((cpos-1)%4>0, ' ', x'0a'||' ')) ||')' AS ColsSpec FROM ( SELECT cpos, printf('"%w"',printf('%!.*s%s', nlen-chop,name,suff)) AS cname  FROM ColNames ORDER BY cpos)"\
SELECT\
 '('||x'0a'\
 || group_concat(\
  cname||' TEXT',\
  ','||iif((cpos-1)%4>0, ' ', x'0a'||' '))\
 ||')' AS ColsSpec \
FROM (\
 SELECT cpos, printf('\"%w\"',printf('%!.*s%s', nlen-chop,name,suff)) AS cname \
 FROM ColNames ORDER BY cpos\
)"char[225]WITH Lzn(nlz) AS (  SELECT 0 AS nlz  UNION  SELECT nlz+1 AS nlz FROM Lzn  WHERE EXISTS(   SELECT 1   FROM ColNames t, ColNames o   WHERE    iif(t.name IN (SELECT * FROM RepeatedNames),     printf('%s_%s',      t.name, substring(printf('%.*c%0.*d',nlz+1,'0',$1,t.cpos),2)),     t.name    )    =    iif(o.name IN (SELECT * FROM RepeatedNames),     printf('%s_%s',      o.name, substring(printf('%.*c%0.*d',nlz+1,'0',$1,o.cpos),2)),     o.name    )    COLLATE NOCASE    AND o.cpos<>t.cpos   GROUP BY t.cpos  )) UPDATE Colnames AS t SET chop = 0, suff = iif(name IN (SELECT * FROM RepeatedNames),  printf('_%s', substring(   printf('%.*c%0.*d',(SELECT max(nlz) FROM Lzn)+1,'0',1,t.cpos),2)),  '' )"WITH Lzn(nlz) AS (" /* Find minimum extraneous leading 0's for uniqueness */
"  SELECT 0 AS nlz"
"  UNION"
"  SELECT nlz+1 AS nlz FROM Lzn"
"  WHERE EXISTS("
"   SELECT 1"
"   FROM ColNames t, ColNames o"
"   WHERE"
"    iif(t.name IN (SELECT * FROM RepeatedNames),"
"     printf('%s"AUTOCOLUMN_SEP"%s',"
"      t.name, substring(printf('%.*c%0.*d',nlz+1,'0',$1,t.cpos),2)),"
"     t.name"
"    )"
"    ="
"    iif(o.name IN (SELECT * FROM RepeatedNames),"
"     printf('%s"AUTOCOLUMN_SEP"%s',"
"      o.name, substring(printf('%.*c%0.*d',nlz+1,'0',$1,o.cpos),2)),"
"     o.name"
"    )"
"    COLLATE NOCASE"
"    AND o.cpos<>t.cpos"
"   GROUP BY t.cpos"
"  )"
") UPDATE Colnames AS t SET"
" chop = 0," /* No chopping, never touch incoming names. */
" suff = iif(name IN (SELECT * FROM RepeatedNames),"
"  printf('"AUTOCOLUMN_SEP"%s', substring("
"   printf('%.*c%0.*d',(SELECT max(nlz) FROM Lzn)+1,'0',1,t.cpos),2)),"
"  ''"
" )"char[694]SELECT CAST(ceil(log(count(*)+0.5)) AS INT) FROM ColNames "\
SELECT CAST(ceil(log(count(*)+0.5)) AS INT) FROM ColNames \
"UPDATE ColNames AS t SET reps=(SELECT count(*) FROM ColNames d  WHERE substring(t.name,1,t.nlen-t.chop)=substring(d.name,1,d.nlen-d.chop) COLLATE NOCASE)"\
UPDATE ColNames AS t SET reps=\
(SELECT count(*) FROM ColNames d \
 WHERE substring(t.name,1,t.nlen-t.chop)=substring(d.name,1,d.nlen-d.chop)\
 COLLATE NOCASE\
)\
"char[154]SELECT count(DISTINCT (substring(name,1,nlen-chop)||suff) COLLATE NOCASE) <count(name) FROM ColNames"\
SELECT count(DISTINCT (substring(name,1,nlen-chop)||suff) COLLATE NOCASE)\
 <count(name) FROM ColNames\
"char[101]INSERT INTO ColNames(name,nlen,chop,reps,suff) VALUES(iif(length(?1)>0,?1,'?'),max(length(?1),1),0,0,'')"\
INSERT INTO ColNames(name,nlen,chop,reps,suff)\
 VALUES(iif(length(?1)>0,?1,'?'),max(length(?1),1),0,0,'')\
"char[105]CREATE TABLE ColNames( cpos INTEGER PRIMARY KEY, name TEXT, nlen INT, chop INT, reps INT, suff TEXT);CREATE VIEW RepeatedNames AS SELECT DISTINCT t.name FROM ColNames t WHERE t.name COLLATE NOCASE IN ( SELECT o.name FROM ColNames o WHERE o.cpos<>t.cpos);"\
CREATE TABLE ColNames(\
 cpos INTEGER PRIMARY KEY,\
 name TEXT, nlen INT, chop INT, reps INT, suff TEXT);\
CREATE VIEW RepeatedNames AS \
SELECT DISTINCT t.name FROM ColNames t \
WHERE t.name COLLATE NOCASE IN (\
 SELECT o.name FROM ColNames o WHERE o.cpos<>t.cpos\
);\
"char[255]rc_err_oom_dierc==SQLITE_OK||rc==SQLITE_DONEintckDatabaseCmdsqlite3_intck *sqlite3_intck **nStepnErrorzErrzMsg%lld steps, %lld errors
"%lld steps, %lld errors\n"recoverDatabaseCmdzRecoveryDbzLAFlost_and_found"lost_and_found"bFreelistbRowidssqlite3_recover *-ignore-freelist"-ignore-freelist"-recovery-db"-recovery-db"-lost-and-found"-lost-and-found"-no-rowids"-no-rowids"unexpected option: %s
"unexpected option: %s\n"789SQLITE_RECOVER_LOST_AND_FOUNDSQLITE_RECOVER_ROWIDSSQLITE_RECOVER_FREELIST_CORRUPTerrCodesql error: %s (%d)
"sql error: %s (%d)\n"recoverSqlCbpStatearDotCommandcmdArCommand *sizeof(cmd)cmd.eCmd==AR_CMD_UPDATEeDbTypeAR_CMD_EXTRACTAR_CMD_LISTzipfile(%Q)"zipfile(%Q)"AR_CMD_CREATEAR_CMD_INSERTAR_CMD_REMOVEAR_CMD_UPDATE-- open database '%s'%s
"-- open database '%s'%s\n" using 'apndvfs'" using 'apndvfs'"cannot open file: %s (%s)
"cannot open file: %s (%s)\n"shell_putsnl"shell_putsnl"AR_CMD_HELPzColNewpzRenamednStepPerUnlockfromCmdLinesqlar"sqlar""name"database does not contain an 'sqlar' table
"database does not contain an 'sqlar' table\n"end_ar_commandarCreateOrUpdateCommandCREATE TABLE IF NOT EXISTS sqlar(
  name TEXT PRIMARY KEY,  -- name of the file
  mode INT,               -- access permissions
  mtime INT,              -- last modification time
  sz INT,                 -- original file size
  data BLOB               -- compressed content
)"CREATE TABLE IF NOT EXISTS sqlar(\n"
      "  name TEXT PRIMARY KEY,  -- name of the file\n"
      "  mode INT,               -- access permissions\n"
      "  mtime INT,              -- last modification time\n"
      "  sz INT,                 -- original file size\n"
      "  data BLOB               -- compressed content\n"
      ")"char[278]zDropDROP TABLE IF EXISTS sqlar"DROP TABLE IF EXISTS sqlar"const char *[2]zInsertFmtREPLACE INTO %s(name,mode,mtime,sz,data)
  SELECT
    %s,
    mode,
    mtime,
    CASE substr(lsmode(mode),1,1)
      WHEN '-' THEN length(data)
      WHEN 'd' THEN 0
      ELSE -1 END,
    sqlar_compress(data)
  FROM fsdir(%Q,%Q) AS disk
  WHERE lsmode(mode) NOT LIKE '?%%'%s;"REPLACE INTO %s(name,mode,mtime,sz,data)\n"
     "  SELECT\n"
     "    %s,\n"
     "    mode,\n"
     "    mtime,\n"
     "    CASE substr(lsmode(mode),1,1)\n"
     "      WHEN '-' THEN length(data)\n"
     "      WHEN 'd' THEN 0\n"
     "      ELSE -1 END,\n"
     "    sqlar_compress(data)\n"
     "  FROM fsdir(%Q,%Q) AS disk\n"
     "  WHERE lsmode(mode) NOT LIKE '?%%'%s;"char[279]REPLACE INTO %s(name,mode,mtime,data)
  SELECT
    %s,
    mode,
    mtime,
    data
  FROM fsdir(%Q,%Q) AS disk
  WHERE lsmode(mode) NOT LIKE '?%%'%s;"REPLACE INTO %s(name,mode,mtime,data)\n"
     "  SELECT\n"
     "    %s,\n"
     "    mode,\n"
     "    mtime,\n"
     "    data\n"
     "  FROM fsdir(%Q,%Q) AS disk\n"
     "  WHERE lsmode(mode) NOT LIKE '?%%'%s;"zTempzExistsPRAGMA page_size=512"PRAGMA page_size=512"SAVEPOINT ar;"SAVEPOINT ar;"sizeof(r)sqlite3_uint64 *sizeof(zTemp)zip%016llx"zip%016llx"CREATE VIRTUAL TABLE temp.%s USING zipfile(%Q)"CREATE VIRTUAL TABLE temp.%s USING zipfile(%Q)" AND NOT EXISTS(SELECT 1 FROM %s AS mem WHERE mem.name=disk.name AND mem.mtime=disk.mtime AND mem.mode=disk.mode)" AND NOT EXISTS("
          "SELECT 1 FROM %s AS mem"
          " WHERE mem.name=disk.name"
          " AND mem.mtime=disk.mtime"
          " AND mem.mode=disk.mode)"zSql2shell_putsnl(name)"shell_putsnl(name)"end_ar_transactionROLLBACK TO ar; RELEASE ar;"ROLLBACK TO ar; RELEASE ar;"RELEASE ar;"RELEASE ar;"DROP TABLE %s"DROP TABLE %s"arExecSqlERROR: %s
"ERROR: %s\n"arExtractCommandzSql1SELECT  ($dir || name), writefile(($dir || name), %s, mode, mtime) FROM %s WHERE (%s) AND (data IS NULL OR $dirOnly = 0) AND name NOT GLOB '*..[/\]*'"SELECT "
    " ($dir || name),"
    " writefile(($dir || name), %s, mode, mtime) "
    "FROM %s WHERE (%s) AND (data IS NULL OR $dirOnly = 0)"
    " AND name NOT GLOB '*..[/\\]*'"char[150]azExtraArgsqlar_uncompress(data, sz)"sqlar_uncompress(data, sz)""data"pSqlzDirzWhere%s/"%s/"$dir"$dir"$dirOnly"$dirOnly"arRemoveCommandDELETE FROM %s WHERE %s;"DELETE FROM %s WHERE %s;"arListCommandSELECT %s FROM %s WHERE %s"SELECT %s FROM %s WHERE %s"azColslsmode(mode), sz, datetime(mtime, 'unixepoch'), name"lsmode(mode), sz, datetime(mtime, 'unixepoch'), name"%s % 10d  %s  %s
"%s % 10d  %s  %s\n"arWhereClausezSameOpGLOB"GLOB"="=""1"%z%s name %s '%q' OR substr(name,1,%d) %s '%q/'"%z%s name %s '%q' OR substr(name,1,%d) %s '%q/'" OR " OR "arCheckEntriespTestzSelSELECT name FROM %s WHERE glob($name,name)"SELECT name FROM %s WHERE glob($name,name)"SELECT name FROM %s WHERE name=$name"SELECT name FROM %s WHERE name=$name"$name"$name"bOknot found in archive: %s
"not found in archive: %s\n"arParseCommandArSwitch[]aSwitchArSwitch[13]create"create"extract"extract""remove"update"update"'u'verbose"verbose"AR_SWITCH_VERBOSE"file"AR_SWITCH_FILEAR_SWITCH_APPENDdirectory"directory"'C'AR_SWITCH_DIRECTORYdryrun"dryrun"AR_SWITCH_DRYRUNglob"glob"AR_SWITCH_GLOBnSwitchsizeof(aSwitch)sizeof(struct ArSwitch)sizeof(aSwitch) / sizeof(struct ArSwitch)ArSwitch *pEndWrong number of arguments.  Usage:
"Wrong number of arguments.  Usage:\n" 2zArgpOptunrecognized option: %c"unrecognized option: %c"option requires an argument: %c"option requires an argument: %c"pMatchzLongambiguous option: %s"ambiguous option: %s"unrecognized option: %s"unrecognized option: %s"option requires an argument: %s"option requires an argument: %s"Required argument missing.  Usage:
"Required argument missing.  Usage:\n"arProcessSwitchmultiple command options"multiple command options"arErrorMsgapzFmtUse "-A" for more help
"Use \"-A\" for more help\n"Use ".archive --help" for more help
"Use \".archive --help\" for more help\n"arUsageshellResetSQL error: %s
"SQL error: %s\n"shellFinalizeshellPreparePrintfshellPreparelintDotCommandpArbUpdatebOnlyIfChangedpRcpzWhereeSwitchffkey-indexes"fkey-indexes"Usage %s sub-command ?switches...?
"Usage %s sub-command ?switches...?\n"Where sub-commands are:
"Where sub-commands are:\n"    fkey-indexes
"    fkey-indexes\n"lintFkeyIndexesbGroupByParentzIndentSELECT      'EXPLAIN QUERY PLAN SELECT 1 FROM ' || quote(s.name) || ' WHERE '  || group_concat(quote(s.name) || '.' || quote(f.[from]) || '=?'   || fkey_collate_clause(       f.[table], COALESCE(f.[to], p.[name]), s.name, f.[from]),' AND '),      'SEARCH ' || s.name || ' USING COVERING INDEX*('  || group_concat('*=?', ' AND ') || ')',      s.name  || '(' || group_concat(f.[from],  ', ') || ')',      f.[table] || '(' || group_concat(COALESCE(f.[to], p.[name])) || ')',      'CREATE INDEX ' || quote(s.name ||'_'|| group_concat(f.[from], '_'))  || ' ON ' || quote(s.name) || '('  || group_concat(quote(f.[from]) ||        fkey_collate_clause(          f.[table], COALESCE(f.[to], p.[name]), s.name, f.[from]), ', ')  || ');',      f.[table] FROM sqlite_schema AS s, pragma_foreign_key_list(s.name) AS f LEFT JOIN pragma_table_info AS p ON (pk-1=seq AND p.arg=f.[table]) GROUP BY s.name, f.id ORDER BY (CASE WHEN ? THEN f.[table] ELSE s.name END)"SELECT "
    "     'EXPLAIN QUERY PLAN SELECT 1 FROM ' || quote(s.name) || ' WHERE '"
    "  || group_concat(quote(s.name) || '.' || quote(f.[from]) || '=?' "
    "  || fkey_collate_clause("
    "       f.[table], COALESCE(f.[to], p.[name]), s.name, f.[from]),' AND ')"
    ", "
    "     'SEARCH ' || s.name || ' USING COVERING INDEX*('"
    "  || group_concat('*=?', ' AND ') || ')'"
    ", "
    "     s.name  || '(' || group_concat(f.[from],  ', ') || ')'"
    ", "
    "     f.[table] || '(' || group_concat(COALESCE(f.[to], p.[name])) || ')'"
    ", "
    "     'CREATE INDEX ' || quote(s.name ||'_'|| group_concat(f.[from], '_'))"
    "  || ' ON ' || quote(s.name) || '('"
    "  || group_concat(quote(f.[from]) ||"
    "        fkey_collate_clause("
    "          f.[table], COALESCE(f.[to], p.[name]), s.name, f.[from]), ', ')"
    "  || ');'"
    ", "
    "     f.[table] "
    "FROM sqlite_schema AS s, pragma_foreign_key_list(s.name) AS f "
    "LEFT JOIN pragma_table_info AS p ON (pk-1=seq AND p.arg=f.[table]) "
    "GROUP BY s.name, f.id "
    "ORDER BY (CASE WHEN ? THEN f.[table] ELSE s.name END)"char[948]zGlobIPKSEARCH * USING INTEGER PRIMARY KEY (rowid=?)"SEARCH * USING INTEGER PRIMARY KEY (rowid=?)"-verbose"-verbose"-groupbyparent"-groupbyparent"    "    "Usage: %s %s ?-verbose? ?-groupbyparent?
"Usage: %s %s ?-verbose? ?-groupbyparent?\n"fkey_collate_clause"fkey_collate_clause"zPrevrespExplainzEQPzFromzTargetzCIzParentzPlanError: internal error"Error: internal error"-- Parent table %s
"-- Parent table %s\n"%s%s --> %s
"%s%s --> %s\n"%s/* no extra indexes required for %s -> %s */
"%s/* no extra indexes required for %s -> %s */\n"shellFkeyCollateClausezParentColzParentSeqzChildzChildColzChildSeqnVal==4 COLLATE %s" COLLATE %s"newTempFileTEMP"TEMP"TMP"TMP"/tmp%s/temp%llx.%s"%s/temp%llx.%s"%z.%s"%z.%s"clearTempFileshellDeleteFileoptionMatchtestcase_globc2invertseen(unsigned char)c((unsigned char)c)*z(unsigned char)*z((unsigned char)*z)*zGlob(unsigned char)*zGlob((unsigned char)*zGlob)prior_c'^'shellDatabaseErrorshellEmitErrorshell_dbtotxt_commandpgSzzTailunsigned char[256]bShowsizeof(bShow)'~''{''}'PRAGMA page_size"PRAGMA page_size"PRAGMA page_count"PRAGMA page_count"PRAGMA databases"PRAGMA databases"unk.db"unk.db"zFilename| size %lld pagesize %d filename %s
"| size %lld pagesize %d filename %s\n"SELECT pgno, data FROM sqlite_dbpage ORDER BY pgno"SELECT pgno, data FROM sqlite_dbpage ORDER BY pgno"pgnoconst u8const u8 *aDataseenPageLabelaLine| page %lld offset %lld
"| page %lld offset %lld\n"|  %5d:"|  %5d:" %02x" %02x"   "   "%c"%c"| end %s
"| end %s\n"dbtotxt_errorshell_dbinfo_commandaFieldaQueryiDataVersionzSchemaTabunsigned char[100]aHdrSELECT data FROM sqlite_dbpage(?1) WHERE pgno=1"SELECT data FROM sqlite_dbpage(?1) WHERE pgno=1"error: %s
"error: %s\n"pbunable to read database header
"unable to read database header\n"%-20s %d
"%-20s %d\n"database page size:"database page size:"write format:"write format:"read format:"read format:"reserved bytes:"reserved bytes:"ArraySize(aField)ofst%-20s %u"%-20s %u" (utf8)" (utf8)" (utf16le)" (utf16le)" (utf16be)" (utf16be)"main.sqlite_schema"main.sqlite_schema"temp"temp""%w".sqlite_schema"\"%w\".sqlite_schema"const struct <unnamed>[5]struct <unnamed>[5]ArraySize(aQuery)nValapValzSuffixzOpt%-20s %u
"%-20s %u\n"data version"data version"number of tables:"number of tables:"SELECT count(*) FROM %s WHERE type='table'"SELECT count(*) FROM %s WHERE type='table'"number of indexes:"number of indexes:"SELECT count(*) FROM %s WHERE type='index'"SELECT count(*) FROM %s WHERE type='index'"number of triggers:"number of triggers:"SELECT count(*) FROM %s WHERE type='trigger'"SELECT count(*) FROM %s WHERE type='trigger'"number of views:"number of views:"SELECT count(*) FROM %s WHERE type='view'"SELECT count(*) FROM %s WHERE type='view'"schema size:"schema size:"SELECT total(length(sql)) FROM %s"SELECT total(length(sql)) FROM %s"file change counter:"file change counter:"database page count:"database page count:"freelist page count:"freelist page count:"schema cookie:"schema cookie:"schema format:"schema format:"default cache size:"default cache size:"autovacuum top root:"autovacuum top root:"incremental vacuum:"incremental vacuum:"text encoding:"text encoding:"user version:"user version:"application id:"application id:"software version:"software version:"get4byteIntget2byteIntdb_intoutput_reset</PRE></BODY></HTML>
"</PRE></BODY></HTML>\n"zXdgOpenCmdxdg-open"xdg-open"%s %s"%s %s"Failed: [%s]
"Failed: [%s]\n"output_redirOutput already redirected.
"Output already redirected.\n"<!DOCTYPE html>
<HTML><BODY><PRE>
"<!DOCTYPE html>\n"
        "<HTML><BODY><PRE>\n"tryToClonenewDbFile "%s" already exists.
"File \"%s\" already exists.\n"Cannot create output database: %s
"Cannot create output database: %s\n"PRAGMA writable_schema=ON;"PRAGMA writable_schema=ON;"BEGIN EXCLUSIVE;"BEGIN EXCLUSIVE;"type='table'"type='table'"type!='table'"type!='table'"COMMIT;"COMMIT;"tryToCloneSchemapQuerySELECT name, sql FROM sqlite_schema WHERE %s ORDER BY rowid ASC"SELECT name, sql FROM sqlite_schema"
                           " WHERE %s ORDER BY rowid ASC"Error: (%d) %s on [%s]
"Error: (%d) %s on [%s]\n""done\n"%s... "%s... "Error: %s
SQL: [%s]
"Error: %s\nSQL: [%s]\n"done
SELECT name, sql FROM sqlite_schema WHERE %s ORDER BY rowid DESC"SELECT name, sql FROM sqlite_schema"
                             " WHERE %s ORDER BY rowid DESC"end_schema_xfertryToCloneDatapInsertzInsertnTablecntconst intspinRate10000 10000SELECT * FROM "%w""SELECT * FROM \"%w\""Error %d: %s on [%s]
"Error %d: %s on [%s]\n"INSERT OR IGNORE INTO "%s" VALUES(?"INSERT OR IGNORE INTO \"%s\" VALUES(?",?",?");");"Error %d: %s
"Error %d: %s\n"%c"%c\b"|/-\"|/-\\"SELECT * FROM "%w" ORDER BY rowid DESC;"SELECT * FROM \"%w\" ORDER BY rowid DESC;"Warning: cannot step "%s" backwards"Warning: cannot step \"%s\" backwards"end_data_xferascii_read_one_fieldcSeprSepcsv_read_one_fieldpcppccQuote'\r'%s:%d: unescaped %c character
"%s:%d: unescaped %c character\n"%s:%d: unterminated %c-quoted field
"%s:%d: unterminated %c-quoted field\n"0xff2390xef0xbb0xbfimport_append_charimport_cleanuptest_breakpointnCallMany .breakpoints have run
"Many .breakpoints have run\n"sql_trace_callbackp->traceOut"-- closing database connection\n"-- closing database connection
1000000000%.*s;
"%.*s;\n"nNanosec%.*s; -- %lld ns
"%.*s; -- %lld ns\n"output_file_open"stderr"output_file_closesetOrClearFlagmFlagbooleanValue'9'yes"yes"ERROR: Not a boolean value: "%s". Assuming "no".
"ERROR: Not a boolean value: \"%s\". Assuming \"no\".\n"resolve_backslashespfNewzNewDbxForEachpPpX'\a''\b''\t''\v''\f'nhdhdvhv'7'close_dbError: sqlite3_close() returns %d: %s
"Error: sqlite3_close() returns %d: %s\n"open_dbzDbFilenameSHELL_OPEN_UNSPECSHELL_OPEN_NORMALError: unable to open database "%s": %s
"Error: unable to open database \"%s\": %s\n"char[41]Also: unable to open substitute in-memory database.
"Also: unable to open substitute in-memory database.\n"Notice: using substitute in-memory database instead of "%s"
"Notice: using substitute in-memory database instead of \"%s\"\n"(int)0testmode_on"strtod"dtostr"dtostr"shell_add_schema"shell_add_schema"shell_module_schema"shell_module_schema""usleep"edit"edit"CREATE VIRTUAL TABLE zip USING zipfile(%Q);"CREATE VIRTUAL TABLE zip USING zipfile(%Q);"nDataError: sqlite3_deserialize() returns %d
"Error: sqlite3_deserialize() returns %d\n"shellUSleepFuncreadHexDbpgszunsigned int[16]char[1000]cannot open "%s" for reading
"cannot open \"%s\" for reading\n"| size %d pagesize %d"| size %d pagesize %d"invalid pagesize
"invalid pagesize\n"| page %d offset %d"| page %d offset %d"| end "| end "| %d: %x %x %x %x %x %x %x %x %x %x %x %x %x %x %x %x"| %d: %x %x %x %x %x %x %x %x %x %x %x %x %x %x %x %x"readHexDb_errorError on line %d of --hexdb input
"Error on line %d of --hexdb input\n"deduceDatabaseType%.zip"%.zip"SQLite format 3"SQLite format 3"-25Start-Of-SQLite3-"Start-Of-SQLite3-"-220x500x4b0x050x06readFilenInnReadError: '%s' not seekable
"Error: '%s' not seekable\n"Error: out of memory
"Error: out of memory\n"Error: cannot read '%s'
"Error: cannot read '%s'\n"showHelpzPatazHelp-a"-a"-all"-all"--all"--all"hwhhHW_NoCull|HW_Undocconst char *[211]char *[211]1688211ArraySize(azHelp)HH_Summary|HH_Undoc4294967294~HH_Summary.%s
".%s\n".%s*".%s*"openFlagscontextargcUnusedpnDatadfltZippnBytezPattern%%%s%%"%%%s%%"run_schema_dump_queryzQ2/****** CORRUPTION ERROR *******/
"/****** CORRUPTION ERROR *******/\n"/****** %s ******/
"/****** %s ******/\n"%s ORDER BY rowid DESC"%s ORDER BY rowid DESC"/****** ERROR: %s ******/
"/****** ERROR: %s ******/\n"dump_callbackzTypedataOnlynoSysazNotUsedsqlite_stat?"sqlite_stat?"CREATE VIRTUAL TABLE"CREATE VIRTUAL TABLE"zInsPRAGMA writable_schema=ON;
"PRAGMA writable_schema=ON;\n"INSERT INTO sqlite_schema(type,name,tbl_name,rootpage,sql)VALUES('table','%q','%q',0,'%q');"INSERT INTO sqlite_schema(type,name,tbl_name,rootpage,sql)"
       "VALUES('table','%q','%q',0,'%q');"char[92];
";\n"sTableazColsavedDestTablesavedMode)")" FROM " FROM "toggleSelectOrderiSettingzStmtPRAGMA reverse_unordered_selects"PRAGMA reverse_unordered_selects"sizeof(zStmt)PRAGMA reverse_unordered_selects(%d)"PRAGMA reverse_unordered_selects(%d)"tableColumnListnPKisIPKpreserveRowidPRAGMA table_info=%Q"PRAGMA table_info=%Q"sizeof(azCol[0])INTEGER"INTEGER"SELECT 1 FROM pragma_index_list(%Q) WHERE origin='pk'"SELECT 1 FROM pragma_index_list(%Q)"
                           " WHERE origin='pk'"char *[3]rowid"rowid"_rowid_"_rowid_"oid"oid"azRowidfreeColumnListshell_execzLeftoverzSql[0](unsigned char)zSql[0]((unsigned char)zSql[0])zStmtSql[0](unsigned char)zStmtSql[0]((unsigned char)zStmtSql[0])sqlite3_stmt_isexplain(pExplain)==1zStmtSqlin prepare"in prepare"triggerEQPzEQPLineiEqpIdiParentIdbIsExplainMODE_EQPstepping"stepping"expertDotCommandiSamplepState->expert.pExpert==0ExpertInfo *sizeof(ExpertInfo)-sample"-sample"option requires an argument: %s
"option requires an argument: %s\n"value out of range: %s
"value out of range: %s\n"sqlite3_expert_new: %s
"sqlite3_expert_new: %s\n"out of memory"out of memory"EXPERT_CONFIG_SAMPLEexpertFinishbCancel || pzErr==0 || *pzErr==0nQueryzCandEXPERT_REPORT_CANDIDATES-- Candidates -----------------------------
"-- Candidates -----------------------------\n"EXPERT_REPORT_SQLzIdxEXPERT_REPORT_INDEXESEXPERT_REPORT_PLAN(no new indexes)
"(no new indexes)\n"-- Query %d --------------------------------
%s

"-- Query %d --------------------------------\n"
              "%s\n\n"bCancelpzErr%s
%s
"%s\n%s\n"expertHandleSQLpState->expert.pExpertpzErr==0 || *pzErr==0exec_prepared_stmtsizeof(int) <= sizeof(char *)sizeof(const char*)azValsaiTypes]
"]\n"</TABLE>
<PRE>
"</TABLE>\n<PRE>\n"char[200]%llu row%s
"%llu row%s\n"exec_prepared_stmt_columnarnColumnazDataabRowDivuzazQuotednTotalcolSeprowSepconst unsigned char **azNextLinebNextLinebMultiLineRowExistsbwzEmptyzShowNullzNotUsedwxu8 *useNextLine | " | " |
" |\n"+"+"| "| "%*s%s%*s"%*s%s%*s""|" â " " BOX_13 " " â
" " BOX_13 "\n"âBOX_23â¬BOX_234âBOX_34â %*s%s%*s%s"%*s%s%*s%s"" "BOX_13"\n"" "BOX_13" "âBOX_123â¼BOX_1234â¤BOX_134âBOX_12â´BOX_124âBOX_14columnar_endInterrupt
"Interrupt\n"quoted_columnpStrx'"x'"%02x"%02x"'"'"translateForDisplayAndDup10000000xc0uz[k-1](z[k-1])z[k](z[k])mxWidthbWordWrapprint_box_row_separatorprint_box_linezDashââââââââââââââââââââBOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24
      BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24 BOX_24nDashconst char[61]sizeof(zDash)sizeof(zDash) - 1bind_prepared_stmtnVarpQsqlite_parameters"sqlite_parameters"key"key"SELECT value FROM temp.sqlite_parameters WHERE key=?1"SELECT value FROM temp.sqlite_parameters"
            " WHERE key=?1"zNumzVarsizeof(zNum)?%d"?%d"_NAN"_NAN"__builtin_nanfNaN_INF"_INF"__builtin_inff+Infinity$int_"$int_"$text_"$text_"szVarbind_table_initwrSchemadefensiveModeCREATE TABLE IF NOT EXISTS temp.sqlite_parameters(
  key TEXT PRIMARY KEY,
  value
) WITHOUT ROWID;"CREATE TABLE IF NOT EXISTS temp.sqlite_parameters(\n"
    "  key TEXT PRIMARY KEY,\n"
    "  value\n"
    ") WITHOUT ROWID;"restore_debug_trace_modesdisable_debug_trace_modeszerodisplay_scanstatsexplain_data_deleteexplain_data_prepareabYieldiOpazNextconst char *[7]char *[7]Next"Next"Prev"Prev"VPrev"VPrev"VNext"VNext"SorterNext"SorterNext"Return"Return"azYieldconst char *[6]char *[6]Yield"Yield"SeekLT"SeekLT"SeekGT"SeekGT"RowSetRead"RowSetRead"Rewind"Rewind"azGotoGoto"Goto"sqlite3_column_count(pSql)>=40==sqlite3_stricmp( sqlite3_column_name(pSql, 0), "addr" )0==sqlite3_stricmp( sqlite3_column_name(pSql, 1), "opcode" )0==sqlite3_stricmp( sqlite3_column_name(pSql, 2), "p1" )0==sqlite3_stricmp( sqlite3_column_name(pSql, 3), "p2" )iAddrp2opstr_in_arraydisplay_statsiCuriHiwtr%-36s %d
"%-36s %d\n"Number of output columns:"Number of output columns:"sizeof(z)Column %d %nname:"Column %d %nname:"%-36s %s
"%-36s %s\n"declared type:"declared type:"VM-steps: %d
"VM-steps: %d\n"Memory Used:"Memory Used:"%lld (max %lld) bytes"%lld (max %lld) bytes"Number of Outstanding Allocations:"Number of Outstanding Allocations:"%lld (max %lld)"%lld (max %lld)"Number of Pcache Pages Used:"Number of Pcache Pages Used:"%lld (max %lld) pages"%lld (max %lld) pages"Number of Pcache Overflow Bytes:"Number of Pcache Overflow Bytes:"Largest Allocation:"Largest Allocation:"%lld bytes"%lld bytes"Largest Pcache Allocation:"Largest Pcache Allocation:"Lookaside Slots Used:                %d (max %d)
"Lookaside Slots Used:                %d (max %d)\n"Successful lookaside attempts:       %d
"Successful lookaside attempts:       %d\n"Lookaside failures due to size:      %d
"Lookaside failures due to size:      %d\n"Lookaside failures due to OOM:       %d
"Lookaside failures due to OOM:       %d\n"Pager Heap Usage:                    %d bytes
"Pager Heap Usage:                    %d bytes\n"Page cache hits:                     %d
"Page cache hits:                     %d\n"Page cache misses:                   %d
"Page cache misses:                   %d\n"Page cache writes:                   %d
"Page cache writes:                   %d\n"Page cache spills:                   %d
"Page cache spills:                   %d\n"Schema Heap Usage:                   %d bytes
"Schema Heap Usage:                   %d bytes\n"Statement Heap/Lookaside Usage:      %d bytes
"Statement Heap/Lookaside Usage:      %d bytes\n"iHitiMissFullscan Steps:                      %d
"Fullscan Steps:                      %d\n"Sort Operations:                     %d
"Sort Operations:                     %d\n"Autoindex Inserts:                   %d
"Autoindex Inserts:                   %d\n"Bloom filter bypass taken:           %d/%d
"Bloom filter bypass taken:           %d/%d\n"Virtual Machine Steps:               %d
"Virtual Machine Steps:               %d\n"Reprepare operations:                %d
"Reprepare operations:                %d\n"Number of times run:                 %d
"Number of times run:                 %d\n"Memory used by prepared stmt:        %d
"Memory used by prepared stmt:        %d\n"displayStatLinenPercent'%'displayLinuxIoStats/proc/%d/io"/proc/%d/io"aTransconst struct <unnamed>[7]struct <unnamed>[7]rchar: "rchar: "Bytes received by read():"Bytes received by read():"wchar: "wchar: "Bytes sent to write():"Bytes sent to write():"syscr: "syscr: "Read() system calls:"Read() system calls:"syscw: "syscw: "Write() system calls:"Write() system calls:"read_bytes: "read_bytes: "Bytes read from storage:"Bytes read from storage:"write_bytes: "write_bytes: "Bytes written to storage:"Bytes written to storage:"cancelled_write_bytes: "cancelled_write_bytes: "Cancelled write bytes:"Cancelled write bytes:"ArraySize(aTrans)%-36s %s"%-36s %s"save_err_msgzContext%s, %s"%s, %s" (%d)" (%d)"run_table_dump_querypSelectnResult/**** ERROR: (%d) %s *****/
%s"/**** ERROR: (%d) %s *****/\n%s",%s",%s"zSep1zSep2zSep3azArraybResetiStatusCtrlzPhasezSelect
;
"\n;\n"/**** ERROR: (%d) %s *****/
"/**** ERROR: (%d) %s *****/\n"shell_error_contextzCodezSql[i](unsigned char)zSql[i]((unsigned char)zSql[i])
  %z
  %*s^--- error here"\n  %z\n  %*s^--- error here"
  %z
  %*serror here ---^"\n  %z\n  %*serror here ---^"set_table_namecreateSelftestTableSAVEPOINT selftest_init;
CREATE TABLE IF NOT EXISTS selftest(
  tno INTEGER PRIMARY KEY,
  op TEXT,
  cmd TEXT,
  ans TEXT
);CREATE TEMP TABLE [_shell$self](op,cmd,ans);
INSERT INTO [_shell$self](rowid,op,cmd)
  VALUES(coalesce((SELECT (max(tno)+100)/10 FROM selftest),10),
         'memo','Tests generated by --init');
INSERT INTO [_shell$self]
  SELECT 'run',
    'SELECT hex(sha3_query(''SELECT type,name,tbl_name,sql FROM sqlite_schema ORDER BY 2'',224))',
    hex(sha3_query('SELECT type,name,tbl_name,sql FROM sqlite_schema ORDER BY 2',224));
INSERT INTO [_shell$self]
  SELECT 'run',    'SELECT hex(sha3_query(''SELECT * FROM "' ||        printf('%w',name) || '" NOT INDEXED'',224))',
    hex(sha3_query(printf('SELECT * FROM "%w" NOT INDEXED',name),224))
  FROM (
    SELECT name FROM sqlite_schema
     WHERE type='table'
       AND name<>'selftest'
       AND coalesce(rootpage,0)>0
  )
 ORDER BY name;
INSERT INTO [_shell$self]
  VALUES('run','PRAGMA integrity_check','ok');
INSERT INTO selftest(tno,op,cmd,ans)  SELECT rowid*10,op,cmd,ans FROM [_shell$self];
DROP TABLE [_shell$self];"SAVEPOINT selftest_init;\n"
    "CREATE TABLE IF NOT EXISTS selftest(\n"
    "  tno INTEGER PRIMARY KEY,\n"   /* Test number */
    "  op TEXT,\n"                   /* Operator:  memo run */
    "  cmd TEXT,\n"                  /* Command text */
    "  ans TEXT\n"                   /* Desired answer */
    ");"
    "CREATE TEMP TABLE [_shell$self](op,cmd,ans);\n"
    "INSERT INTO [_shell$self](rowid,op,cmd)\n"
    "  VALUES(coalesce((SELECT (max(tno)+100)/10 FROM selftest),10),\n"
    "         'memo','Tests generated by --init');\n"
    "INSERT INTO [_shell$self]\n"
    "  SELECT 'run',\n"
    "    'SELECT hex(sha3_query(''SELECT type,name,tbl_name,sql "
                                 "FROM sqlite_schema ORDER BY 2'',224))',\n"
    "    hex(sha3_query('SELECT type,name,tbl_name,sql "
                          "FROM sqlite_schema ORDER BY 2',224));\n"
    "INSERT INTO [_shell$self]\n"
    "  SELECT 'run',"
    "    'SELECT hex(sha3_query(''SELECT * FROM \"' ||"
    "        printf('%w',name) || '\" NOT INDEXED'',224))',\n"
    "    hex(sha3_query(printf('SELECT * FROM \"%w\" NOT INDEXED',name),224))\n"
    "  FROM (\n"
    "    SELECT name FROM sqlite_schema\n"
    "     WHERE type='table'\n"
    "       AND name<>'selftest'\n"
    "       AND coalesce(rootpage,0)>0\n"
    "  )\n"
    " ORDER BY name;\n"
    "INSERT INTO [_shell$self]\n"
    "  VALUES('run','PRAGMA integrity_check','ok');\n"
    "INSERT INTO selftest(tno,op,cmd,ans)"
    "  SELECT rowid*10,op,cmd,ans FROM [_shell$self];\n"
    "DROP TABLE [_shell$self];"char[1097]SELFTEST initialization failure: %s
"SELFTEST initialization failure: %s\n"RELEASE selftest_init"RELEASE selftest_init"captureOutputCallbackazshell_callbackaExplainWidthaScanExpWidthnArg==1z[i](unsigned char)z[i]((unsigned char)z[i])z[j-1](unsigned char)z[j-1]((unsigned char)z[j-1])z[i+1](unsigned char)z[i+1]((unsigned char)z[i+1])_O_BINARY 5%*s = %s%s"%*s = %s%s"MODE_ScanExpconst int[10]int[10]const int[8]int[8]const int[]int[]aExplainMapaScanExpMapconst int *aWidthaMapnWidthArraySize(aExplainWidth)iIndentArraySize(aScanExpWidth)zVal%*.s"%*.s"nParencEndCREATE VIEW%"CREATE VIEW%"CREATE TRIG%"CREATE TRIG%"
  "\n  "%s%s"%s%s"</PRE>
<TABLE border='1' cellspacing='0' cellpadding='2'>
"</PRE>\n"
          "<TABLE border='1' cellspacing='0' cellpadding='2'>\n"<TR>"<TR>"<TH>"<TH>"</TH>
"</TH>\n"</TR>
"</TR>\n"<TD>"<TD>"</TD>
"</TD>\n"INSERT INTO %s"INSERT INTO %s" VALUES(" VALUES("ur92188684372274053120x7ff0000000000000LL9.0e+999"9.0e+999"184422404740821811200xfff0000000000000LL-9.0e+999"-9.0e+999"ir%lld.0"%lld.0"%!.20g"%!.20g"pBlobnBlob);
");\n"[{"[{",
{",\n{"aiType:":"null"null"}"}"print_row_separatorprint_dashes--------------------------------------------------"--------------------------------------------------"const char[51]progress_handlerProgress limit reached (%u)
"Progress limit reached (%u)\n"Progress %u
"Progress %u\n"eqp_renderEQPGraphRow *pRowQUERY PLAN (cycles=%lld [100%%])
"QUERY PLAN (cycles=%lld [100%%])\n"QUERY PLAN
"QUERY PLAN\n"eqp_render_level%s%s%s
"%s%s%s\n"|--"|--"`--"`--"(i64)sizeof(p->sGraph.zPrefix)(i64)sizeof(p->sGraph.zPrefix)-7|  "|  "eqp_next_roweqp_resetEQPGraph *sizeof(p->sGraph)eqp_appendpNewnText%d,%d,%s
"%d,%d,%s\n"sizeof(*pNew)wsToEolprintSchemaLineNprintSchemaLinezToFreeazTerm--"--"const char *[3]*/"*/"zOrigArraySize(azTerm)zNew%s%s;"%s%s;"CREATE TABLE ['"]*"CREATE TABLE ['\"]*"CREATE TABLE IF NOT EXISTS %s%s"CREATE TABLE IF NOT EXISTS %s%s"shellAuthazActionauthorizer: %s"authorizer: %s"const char *[34]char *[34]CREATE_INDEX"CREATE_INDEX"CREATE_TABLE"CREATE_TABLE"CREATE_TEMP_INDEX"CREATE_TEMP_INDEX"CREATE_TEMP_TABLE"CREATE_TEMP_TABLE"CREATE_TEMP_TRIGGER"CREATE_TEMP_TRIGGER"CREATE_TEMP_VIEW"CREATE_TEMP_VIEW"CREATE_TRIGGER"CREATE_TRIGGER"CREATE_VIEW"CREATE_VIEW"DELETE"DELETE"DROP_INDEX"DROP_INDEX"DROP_TABLE"DROP_TABLE"DROP_TEMP_INDEX"DROP_TEMP_INDEX"DROP_TEMP_TABLE"DROP_TEMP_TABLE"DROP_TEMP_TRIGGER"DROP_TEMP_TRIGGER"DROP_TEMP_VIEW"DROP_TEMP_VIEW"DROP_TRIGGER"DROP_TRIGGER"DROP_VIEW"DROP_VIEW"INSERT"INSERT"PRAGMA"PRAGMA"READ"READ"SELECT"SELECT"TRANSACTION"TRANSACTION"UPDATE"UPDATE"ATTACH"ATTACH"DETACH"DETACH"ALTER_TABLE"ALTER_TABLE"REINDEX"REINDEX"ANALYZE"ANALYZE"CREATE_VTABLE"CREATE_VTABLE"DROP_VTABLE"DROP_VTABLE"FUNCTION"FUNCTION"SAVEPOINT"SAVEPOINT"RECURSIVE"RECURSIVE"safeModeAuthazProhibitedFunctionszA1zA3zA4cannot run ATTACH in safe mode"cannot run ATTACH in safe mode"ArraySize(azProhibitedFunctions)cannot use the %s() function in safe mode"cannot use the %s() function in safe mode"readfile"readfile"writefile"writefile"zipfile"zipfile"zipfile_cds"zipfile_cds"interrupt_handlerNotUsedoutput_csvconst char[256]zQuotedoutput_html_string'<''&''>''\"'&lt;"&lt;"&amp;"&amp;"&gt;"&gt;"&quot;"&quot;"&#39;"&#39;"output_json_stringzqctrlMaskzDQBSpcLimitace\?"\\?"cbsSaypcDQBSpcPastpcEnd0x1f\u%04x"\\u%04x""\"\"\\"0L~0L""\""output_c_stringzDQBSROc&0xff(c&0xff)pcDQBSRO(size_t)0~(size_t)0\%03o"\\%03o""\"\"\\\x7f"zSkipValidUtf8ngz!=00x201L0xC0zt0x40ctanyOfInStrpcFirstoutput_quoted_escaped_stringnCyclepOldzA2bSepnAcceptccmzAnyns'%s'"'%s'"zNLzCRnNLnCRzBuf1zBuf2replace("replace("\n"\\n"\012"\\012"\r"\\r"\015"\\015",'%s',char(13))",'%s',char(13))",'%s',char(10))",'%s',char(10))"output_quoted_stringunused_string(%s%u)"(%s%u)"output_hex_blobaBlobconst char[16]'1''2''3''4''5''6''8'aHex0x0FX'%s'"X'%s'"setCrlfModeoutputModePopoutputModePusheditFunczEditorzTempFilebBinhasCRLFVISUAL"VISUAL"no editor for edit()"no editor for edit()"NULL input to edit()"NULL input to edit()"temp%llx"temp%llx"wb"wb"edit() cannot open temp file"edit() cannot open temp file""\r\n"edit() could not write the whole file"edit() could not write the whole file"%s "%s""%s \"%s\""EDITOR returned non-zero"EDITOR returned non-zero"edit() cannot reopen temp file after edit"edit() cannot reopen temp file after edit"could not read back the whole file"could not read back the whole file"edit_func_endfailIfSafeModeline %d: %s
"line %d: %s\n"shellPutsFuncshellLog(%d) %s
"(%d) %s\n"sqlite3_recover_finishEND"END"sqlite3_recover_runsqlite3_recover_stepRECOVER_STATE_DONEsqlite3_recover_configRECOVER_STATE_INITSQLITE_RECOVER_SLOWINDEXESsqlite3_recover_errcodesqlite3_recover_errmsgsqlite3_recover_init_sqlsqlite3_recover_initrecoverInitpRetnDbnUri328sizeof(sqlite3_recover)RECOVER_ROWID_DEFAULTrecoverStepp && p->errCode==SQLITE_OKPRAGMA writable_schema = on"PRAGMA writable_schema = on"SELECT 1 FROM sqlite_schema"SELECT 1 FROM sqlite_schema"RECOVER_STATE_WRITINGRECOVER_STATE_LOSTANDFOUND1RECOVER_STATE_SCHEMA2RecoverBitmap *RECOVER_STATE_LOSTANDFOUND2RECOVER_STATE_LOSTANDFOUND3PRAGMA writable_schema = off"PRAGMA writable_schema = off"recoverUninstallWrapperpFdsqlite3_file **recoverInstallWrapperrecover_g.pMethods==0pFd==0 || pFd->pMethods!=&recover_methodsrecoverVfsUnfetchrecoverVfsFetchrecoverVfsShmUnmappFd->pMethods->xShmUnmap(pFd, deleteFlag)recoverVfsShmBarrierrecoverVfsShmLockpFd->pMethods->xShmLock(pFd, offset, n, flags)recoverVfsShmMappFd->pMethods->xShmMap(pFd, iPg, pgsz, bExtend, pp)recoverVfsDeviceCharacteristicspFd->pMethods->xDeviceCharacteristics(pFd)recoverVfsSectorSizepFd->pMethods->xSectorSize(pFd)recoverVfsFileControl(pFd->pMethods ? pFd->pMethods->xFileControl(pFd, op, pArg) : SQLITE_NOTFOUND)(pFd->pMethods ? pFd->pMethods->xFileControl(pFd, op, pArg) : 12)recoverVfsCheckReservedLockpFd->pMethods->xCheckReservedLock(pFd, pResOut)recoverVfsUnlockpFd->pMethods->xUnlock(pFd, eLock)recoverVfsLockpFd->pMethods->xLock(pFd, eLock)recoverVfsFileSizepFd->pMethods->xFileSize(pFd, pSize)zAzBxSqlpSqlCtxzUriiOffiAmtppdeleteFlagoffsetiPgbExtendpResOuteLockpSizerecoverVfsSyncpFd->pMethods->xSync(pFd, flags)recoverVfsTruncatepFd->pMethods->xTruncate(pFd, size)recoverVfsWritepFd->pMethods->xWrite(pFd, aBuf, nByte, iOff)recoverVfsReadaPreserveconst int[6]int[6]u8[108]unsigned char[108]nReserveencdbszdbFileSizei64 *sizeof(aPreserve)sizeof(aPreserve[0])sizeof(aPreserve)/sizeof(aPreserve[0])(int)(sizeof(aPreserve)/sizeof(aPreserve[0]))sizeof(aHdr)recoverVfsDetectPagesizenMin 512nMax 65536nMaxBlk 4iBlkaPgaTmpnBlk2*nMaxpgsz2recoverPutU320x00FFrecoverPutU16recoverVfsClosepFd->pMethods!=&recover_methodsrecoverIsValidPageaUsednFragnActualiFreenCelliCellOffiContenteType0x0A0x0D0xFFiNextiBytenPayloaddummyXMKrecoverGetVarintrecoverGetU32recoverGetU16recoverFinalCleanupRecoverTable *pTabres==SQLITE_OKrecoverLostAndFoundCleanuprecoverLostAndFound2StepRecoverStateLAF *pLafiChildrecoverLostAndFound2Initp->laf.pAllAndParent==0p->laf.pMapInsert==0p->laf.pMaxField==0p->laf.nMaxField==0INSERT OR IGNORE INTO recovery.map(pgno, parent) VALUES(?, ?)"INSERT OR IGNORE INTO recovery.map(pgno, parent) VALUES(?, ?)"WITH RECURSIVE seq(ii) AS (  SELECT 1 UNION ALL SELECT ii+1 FROM seq WHERE ii<%lld)SELECT pgno, child FROM sqlite_dbptr('getpage()')  UNION ALL SELECT NULL, ii FROM seq"WITH RECURSIVE seq(ii) AS ("
      "  SELECT 1 UNION ALL SELECT ii+1 FROM seq WHERE ii<%lld"
      ")"
      "SELECT pgno, child FROM sqlite_dbptr('getpage()') "
      " UNION ALL "
      "SELECT NULL, ii FROM seq"SELECT max(field)+1 FROM sqlite_dbdata('getpage') WHERE pgno = ?"SELECT max(field)+1 FROM sqlite_dbdata('getpage') WHERE pgno = ?"recoverLostAndFound1SteprecoverLostAndFound1Initp->laf.pUsed==0WITH trunk(pgno) AS (  SELECT read_i32(getpage(1), 8) AS x WHERE x>0    UNION  SELECT read_i32(getpage(trunk.pgno), 0) AS x FROM trunk WHERE x>0),trunkdata(pgno, data) AS (  SELECT pgno, getpage(pgno) FROM trunk),freelist(data, n, freepgno) AS (  SELECT data, min(16384, read_i32(data, 1)-1), pgno FROM trunkdata    UNION ALL  SELECT data, n-1, read_i32(data, 2+n) FROM freelist WHERE n>=0),roots(r) AS (  SELECT 1 UNION ALL  SELECT rootpage FROM recovery.schema WHERE rootpage>0),used(page) AS (  SELECT r FROM roots    UNION  SELECT child FROM sqlite_dbptr('getpage()'), used     WHERE pgno=page) SELECT page FROM used UNION ALL SELECT freepgno FROM freelist WHERE NOT ?"WITH trunk(pgno) AS ("
      "  SELECT read_i32(getpage(1), 8) AS x WHERE x>0"
      "    UNION"
      "  SELECT read_i32(getpage(trunk.pgno), 0) AS x FROM trunk WHERE x>0"
      "),"
      "trunkdata(pgno, data) AS ("
      "  SELECT pgno, getpage(pgno) FROM trunk"
      "),"
      "freelist(data, n, freepgno) AS ("
      "  SELECT data, min(16384, read_i32(data, 1)-1), pgno FROM trunkdata"
      "    UNION ALL"
      "  SELECT data, n-1, read_i32(data, 2+n) FROM freelist WHERE n>=0"
      "),"
      ""
      "roots(r) AS ("
      "  SELECT 1 UNION ALL"
      "  SELECT rootpage FROM recovery.schema WHERE rootpage>0"
      "),"
      "used(page) AS ("
      "  SELECT r FROM roots"
      "    UNION"
      "  SELECT child FROM sqlite_dbptr('getpage()'), used "
      "    WHERE pgno=page"
      ") "
      "SELECT page FROM used"
      " UNION ALL "
      "SELECT freepgno FROM freelist WHERE NOT ?"char[673]recoverWriteDataStepRecoverStateW1 *pSeliRootDELETE FROM sqlite_sequence"DELETE FROM sqlite_sequence"p->errCode!=SQLITE_OK || p1->pTabbNewCell==0 || (iField==-1 || iField==0)bNewCell || iField==p1->nVal || p1->nVal==pTab->nColp->errCode || pInsertp1->nVal==-1apVal[iField]==0iPageiCelliFieldbNewCellRecoverColumn *pColiBindrecoverWriteDataCleanupsizeof(*p1)recoverWriteDataInitpTblp1->nMax==0sizeof(sqlite3_value*)SELECT rootpage FROM recovery.schema   WHERE type='table' AND (sql NOT LIKE 'create virtual%')  ORDER BY (tbl_name='sqlite_sequence') ASC"SELECT rootpage FROM recovery.schema "
      "  WHERE type='table' AND (sql NOT LIKE 'create virtual%')"
      "  ORDER BY (tbl_name='sqlite_sequence') ASC"char[138]WITH RECURSIVE pages(page) AS (  SELECT ?1    UNION  SELECT child FROM sqlite_dbptr('getpage()'), pages     WHERE pgno=page) SELECT page, cell, field, value FROM sqlite_dbdata('getpage()') d, pages p WHERE p.page=d.pgno UNION ALL SELECT 0, 0, 0, 0"WITH RECURSIVE pages(page) AS ("
      "  SELECT ?1"
      "    UNION"
      "  SELECT child FROM sqlite_dbptr('getpage()'), pages "
      "    WHERE pgno=page"
      ") "
      "SELECT page, cell, field, value "
      "FROM sqlite_dbdata('getpage()') d, pages p WHERE p.page=d.pgno "
      "UNION ALL "
      "SELECT 0, 0, 0, 0"char[248]recoverLostAndFound3InitWITH RECURSIVE seq(ii) AS (  SELECT 1 UNION ALL SELECT ii+1 FROM seq WHERE ii<%lld)SELECT ii FROM seq"WITH RECURSIVE seq(ii) AS ("
        "  SELECT 1 UNION ALL SELECT ii+1 FROM seq WHERE ii<%lld"
        ")"
        "SELECT ii FROM seq"char[102]SELECT cell, field, value FROM sqlite_dbdata('getpage()') d WHERE d.pgno=? UNION ALL SELECT -1, -1, -1"SELECT cell, field, value "
        "FROM sqlite_dbdata('getpage()') d WHERE d.pgno=? "
        "UNION ALL "
        "SELECT -1, -1, -1"char[103]aBufnSzrecoverLostAndFound3SteprecoverLostAndFoundOnePagepPageDataiPrevCellbHaveRowidnVal==-1iField==nVal || (nVal==-1 && iField==0)recoverLostAndFoundFindRootWITH RECURSIVE p(pgno) AS (  SELECT ?    UNION  SELECT parent FROM recovery.map AS m, p WHERE m.pgno=p.pgno) SELECT p.pgno FROM p, recovery.map m WHERE m.pgno=p.pgno     AND m.parent IS NULL"WITH RECURSIVE p(pgno) AS ("
        "  SELECT ?"
        "    UNION"
        "  SELECT parent FROM recovery.map AS m, p WHERE m.pgno=p.pgno"
        ") "
        "SELECT p.pgno FROM p, recovery.map m WHERE m.pgno=p.pgno "
        "    AND m.parent IS NULL"char[191]recoverLostAndFoundInsertzBind%z%s?"%z%s?", ", "INSERT INTO %s VALUES(%s)"INSERT INTO %s VALUES(%s)"%z%squote(?)"%z%squote(?)"|| ', ' ||"|| ', ' ||"SELECT 'INSERT INTO %s VALUES(' || %s || ')'"SELECT 'INSERT INTO %s VALUES(' || %s || ')'"recoverLostAndFoundCreatezTblpProbeSELECT 1 FROM sqlite_schema WHERE name=?"SELECT 1 FROM sqlite_schema WHERE name=?"bFail%s_%d"%s_%d"zFieldrootpgno INTEGER, pgno INTEGER, nfield INTEGER, id INTEGER, "rootpgno INTEGER, pgno INTEGER, nfield INTEGER, id INTEGER, "%z%sc%d"%z%sc%d"CREATE TABLE %s(%s)"CREATE TABLE %s(%s)"failed to create %s output table"failed to create %s output table"recoverFindTablerecoverInsertStmtzSqlSepzFinalbSqlnField<=pTab->nColINSERT OR IGNORE INTO %Q("INSERT OR IGNORE INTO %Q("pTab->bIntkey%z_rowid_"%z_rowid_"%zquote(?%d)"%zquote(?%d)"%z?%d"%z?%d"||', '||"||', '||"pTab->aCol[ii].iField>=0 && pTab->aCol[ii].iBind>=1eHiddenRECOVER_EHIDDEN_VIRTUALRECOVER_EHIDDEN_STORED%z%s%Q"%z%s%Q"%z%sescape_crlf(quote(?%d))"%z%sescape_crlf(quote(?%d))"%z%s?%d"%z%s?%d"SELECT %Q || ') VALUES (' || %s || ')'"SELECT %Q || ') VALUES (' || %s || ')'"%s) VALUES (%s)"%s) VALUES (%s)"recoverWriteSchema2SELECT rootpage, sql FROM recovery.schema   WHERE type!='table' AND type!='index'"SELECT rootpage, sql FROM recovery.schema "
      "  WHERE type!='table' AND type!='index'"SELECT rootpage, sql FROM recovery.schema   WHERE type!='table' AND (type!='index' OR sql NOT LIKE '%unique%')"SELECT rootpage, sql FROM recovery.schema "
      "  WHERE type!='table' AND (type!='index' OR sql NOT LIKE '%unique%')"char[111]recoverWriteSchema1pTblnameWITH dbschema(rootpage, name, sql, tbl, isVirtual, isIndex) AS (  SELECT rootpage, name, sql,     type='table',     sql LIKE 'create virtual%',    (type='index' AND (sql LIKE '%unique%' OR ?1))  FROM recovery.schema)SELECT rootpage, tbl, isVirtual, name, sql FROM dbschema   WHERE tbl OR isIndex  ORDER BY tbl DESC, name=='sqlite_sequence' DESC"WITH dbschema(rootpage, name, sql, tbl, isVirtual, isIndex) AS ("
      "  SELECT rootpage, name, sql, "
      "    type='table', "
      "    sql LIKE 'create virtual%',"
      "    (type='index' AND (sql LIKE '%unique%' OR ?1))"
      "  FROM recovery.schema"
      ")"
      "SELECT rootpage, tbl, isVirtual, name, sql"
      " FROM dbschema "
      "  WHERE tbl OR isIndex"
      "  ORDER BY tbl DESC, name=='sqlite_sequence' DESC"char[345]SELECT name FROM sqlite_schema WHERE type='table' ORDER BY rowid DESC LIMIT 1"SELECT name FROM sqlite_schema "
      "WHERE type='table' ORDER BY rowid DESC LIMIT 1"char[78]bTablebVirtualzFreeINSERT INTO sqlite_schema VALUES('table', %Q, %Q, 0, %Q)"INSERT INTO sqlite_schema VALUES('table', %Q, %Q, 0, %Q)"recoverAddTablePRAGMA table_xinfo(%Q)"PRAGMA table_xinfo(%Q)"iCol<pNew->nColiPksizeof(RecoverTable)sizeof(RecoverColumn)csriPKFinteger"integer"PRAGMA index_xinfo(%Q)"PRAGMA index_xinfo(%Q)"recoverOpenRecoveryATTACH %Q AS recovery;"ATTACH %Q AS recovery;"PRAGMA writable_schema = 1;CREATE TABLE recovery.map(pgno INTEGER PRIMARY KEY, parent INT);CREATE TABLE recovery.schema(type, name, tbl_name, rootpage, sql);"PRAGMA writable_schema = 1;"
      "CREATE TABLE recovery.map(pgno INTEGER PRIMARY KEY, parent INT);" 
      "CREATE TABLE recovery.schema(type, name, tbl_name, rootpage, sql);"char[158]recoverOpenOutputFuncFunc[]aFuncFunc[4]getpage"getpage"page_is_used"page_is_used"read_i32"read_i32"escape_crlf"escape_crlf"p->dbOut==0sizeof(aFunc)Func *sizeof(aFunc[0])sizeof(aFunc)/sizeof(aFunc[0])(int)(sizeof(aFunc)/sizeof(aFunc[0]))recoverTransferSettingsaPragmaconst char *[5]char *[5]"encoding"page_size"page_size"auto_vacuum"auto_vacuum"user_version"user_version"application_id"application_id"db2sizeof(aPragma)sizeof(aPragma[0])sizeof(aPragma)/sizeof(aPragma[0])(int)(sizeof(aPragma)/sizeof(aPragma[0]))zPragPRAGMA %Q.%s"PRAGMA %Q.%s"z2PRAGMA %s = %Q"PRAGMA %s = %Q"CREATE TABLE t1(a); DROP TABLE t1;"CREATE TABLE t1(a); DROP TABLE t1;"recoverSqlCallbackcallback returned an error - %d"callback returned an error - %d"recoverCacheSchemaWITH RECURSIVE pages(p) AS (  SELECT 1    UNION  SELECT child FROM sqlite_dbptr('getpage()'), pages WHERE pgno=p)INSERT INTO recovery.schema SELECT  max(CASE WHEN field=0 THEN value ELSE NULL END),  max(CASE WHEN field=1 THEN value ELSE NULL END),  max(CASE WHEN field=2 THEN value ELSE NULL END),  max(CASE WHEN field=3 THEN value ELSE NULL END),  max(CASE WHEN field=4 THEN value ELSE NULL END)FROM sqlite_dbdata('getpage()') WHERE pgno IN (  SELECT p FROM pages) GROUP BY pgno, cell"WITH RECURSIVE pages(p) AS ("
    "  SELECT 1"
    "    UNION"
    "  SELECT child FROM sqlite_dbptr('getpage()'), pages WHERE pgno=p"
    ")"
    "INSERT INTO recovery.schema SELECT"
    "  max(CASE WHEN field=0 THEN value ELSE NULL END),"
    "  max(CASE WHEN field=1 THEN value ELSE NULL END),"
    "  max(CASE WHEN field=2 THEN value ELSE NULL END),"
    "  max(CASE WHEN field=3 THEN value ELSE NULL END),"
    "  max(CASE WHEN field=4 THEN value ELSE NULL END)"
    "FROM sqlite_dbdata('getpage()') WHERE pgno IN ("
    "  SELECT p FROM pages"
    ") GROUP BY pgno, cell"char[486]recoverEscapeCrlfiOutreplace(replace("replace(replace(",'",'"', char(10))"', char(10))"', char(13))"', char(13))"recoverUnusedStringrecoverGetPagep->errCode==SQLITE_OKnPgSELECT data FROM sqlite_dbpage(%Q) WHERE pgno=?"SELECT data FROM sqlite_dbpage(%Q) WHERE pgno=?"piRootnFieldapArgrecoverPageIsUsedrecoverReadI32iIntargc==2655350xFFFFiValrecoverPageCountPRAGMA %Q.page_count"PRAGMA %Q.page_count"recoverMPrintfrecoverBindValuerecoverExecrecoverFinalizerecoverResetrecoverPreparePrintfrecoverPreparerecoverDbErrorrecoverBitmapQueryretiElemiBitu32[1]unsigned int[1]u32 *(u32)1((u32)1)recoverBitmapSetrecoverBitmapFreerecoverBitmapAllocnElemsizeof(RecoverBitmap)sizeof(u32)recoverErrorrecoverMallocnByte>0recoverStrlenrecoverLeaveMutexrecoverEnterMutexsqlite3_dbdata_initsqlite3DbdataRegisterdbdata_modulesqlite_dbdata"sqlite_dbdata"sqlite_dbptr"sqlite_dbptr"(void*)1sqlite_int64 *dbdataRowidDbdataCursor *pCsrdbdataColumnDbdataTable *DBPTR_COLUMN_PGNODBPTR_COLUMN_CHILDDBDATA_COLUMN_PGNODBDATA_COLUMN_CELLDBDATA_COLUMN_FIELDDBDATA_COLUMN_VALUEiTypedbdataFilterpCsr->iPgno==1nFuncSELECT %.*s(?2)"SELECT %.*s(?2)"SELECT data FROM sqlite_dbpage(?) WHERE pgno=?"SELECT data FROM sqlite_dbpage(?) WHERE pgno=?"dbdataGetEncodingnPg1aPg1u8 **56+4(56+4)dbdataDbsizeSELECT %.*s(0)"SELECT %.*s(0)"dbdataIsFunctiondbdataEofdbdataNextiOff+3+2<=pCsr->nPagepCsr->nPagepCsr->rec.aBuf!=0 || pCsr->nRec==0pCsr->rec.aBuf!=0nPayload!=0rc!=SQLITE_OK || aOvfl==0 || nOvfl==pCsr->nPagebNextPagebHasRowidnPointernHdriHdrUnLocal0x0a0x0diCellPtr21474833920x7fffff00163830x3fffDbdataBuffer *DBDATA_PADDING_BYTESnRempgnoOvflaOvflnOvflnCopy32676DBDATA_MX_FIELDszField!"can't get here"dbdataValuedbdataValueBytesdbdataGetVarintU32nRet0xFFFFFFFFdbdataGetVarintpMappApipCursorpRowidctxdbdataLoadPagepPagepCopyget_uint32get_uint16dbdataClosedbdataResetCursordbdataOpensizeof(DbdataCursor)dbdataBestIndexiPgnocolSchemaDBPTR_COLUMN_SCHEMADBDATA_COLUMN_SCHEMA100.0100000000100000000.00x00dbdataDisconnectdbdataConnectCREATE TABLE x(  pgno INTEGER,  child INTEGER,  schema TEXT HIDDEN)DBPTR_SCHEMACREATE TABLE x(  pgno INTEGER,  cell INTEGER,  field INTEGER,  value ANY,  schema TEXT HIDDEN)DBDATA_SCHEMAchar[95]sizeof(DbdataTable)dbdataBufferFreesizeof(*pBuf)dbdataBufferSizenNewaNewvfstrace_unregistervfstrace_registerpRootvfstrace_info *pInfosizeof(*pInfo)sizeof(*pNew) + sizeof(*pInfo)sizeof(vfstrace_file)%s.enabled_for("%s")
"%s.enabled_for(\"%s\")\n"vfstraceNextSystemCallvfstraceGetSystemCallvfstraceSetSystemCallvfstraceGetLastErrorVTR_LASTERR%s.xGetLastError(%d,zBuf)"%s.xGetLastError(%d,zBuf)" -> zBuf[] = "%s", rc = %d
" -> zBuf[] = \"%s\", rc = %d\n"vfstraceCurrentTimeInt64VTR_CURTIME%s.xCurrentTimeInt64()"%s.xCurrentTimeInt64()" -> %lld
" -> %lld\n"vfstraceCurrentTime%s.xCurrentTime()"%s.xCurrentTime()" -> %.17g
" -> %.17g\n"vfstraceSleepVTR_SLEEP%s.xSleep(%d)
"%s.xSleep(%d)\n"vfstraceRandomnessVTR_RAND%s.xRandomness(%d)
"%s.xRandomness(%d)\n"vfstraceDlCloseVTR_DLCLOSE%s.xDlClose()
"%s.xDlClose()\n"vfstraceDlSym%s.xDlSym("%s")
"%s.xDlSym(\"%s\")\n"vfstraceDlErrorVTR_DLERR%s.xDlError(%d)"%s.xDlError(%d)" -> "%s"" -> \"%s\""vfstraceDlOpenVTR_DLOPEN%s.xDlOpen("%s")
"%s.xDlOpen(\"%s\")\n"vfstraceFullPathnameVTR_FULLPATH%s.xFullPathname("%s")"%s.xFullPathname(\"%s\")" -> %s" -> %s", out="%.*s"
", out=\"%.*s\"\n"vfstraceAccessVTR_ACCESS%s.xAccess("%s",%d)"%s.xAccess(\"%s\",%d)", out=%d
", out=%d\n"vfstraceDeleteVTR_DELETE%s.xDelete("%s",%d)"%s.xDelete(\"%s\",%d)" -> %s
" -> %s\n"vfstraceOpenvfstrace_file *<temp>"<temp>"VTR_OPEN%s.xOpen(%s,flags=0x%x)"%s.xOpen(%s,flags=0x%x)"pSub, outFlags=0x%x
", outFlags=0x%x\n"vfstraceUnfetchVTR_FETCH%s.xUnfetch(%s,iOff=%lld,p=%p)"%s.xUnfetch(%s,iOff=%lld,p=%p)"vfstraceFetch%s.xFetch(%s,iOff=%lld,nAmt=%d,p=%p)"%s.xFetch(%s,iOff=%lld,nAmt=%d,p=%p)"vfstraceShmUnmapVTR_SHMUNMAP%s.xShmUnmap(%s,delFlag=%d)"%s.xShmUnmap(%s,delFlag=%d)"vfstraceShmBarrierVTR_SHMBAR%s.xShmBarrier(%s)
"%s.xShmBarrier(%s)\n"vfstraceShmMapVTR_SHMMAP%s.xShmMap(%s,iRegion=%d,szRegion=%d,isWrite=%d,*)"%s.xShmMap(%s,iRegion=%d,szRegion=%d,isWrite=%d,*)"vfstraceShmLockazLockNamezLckVTR_SHMLOCK|0"|0"|UNLOCK"|UNLOCK"|LOCK"|LOCK"|SHARED"|SHARED"|EXCLUSIVE"|EXCLUSIVE"0xf(0xf)-16~(0xf)sizeof(zLck)|0x%x"|0x%x"const char *[8]char *[8]sizeof(azLockName)sizeof(azLockName[0])sizeof(azLockName)/sizeof(azLockName[0])(int)(sizeof(azLockName)/sizeof(azLockName[0]))%s.xShmLock(%s,ofst=%d(%s),n=%d,%s)"%s.xShmLock(%s,ofst=%d(%s),n=%d,%s)"%s.xShmLock(%s,ofst=5d,n=%d,%s)"%s.xShmLock(%s,ofst=5d,n=%d,%s)"WRITE"WRITE"CKPT"CKPT"RECOVER"RECOVER"READ0"READ0"READ1"READ1"READ2"READ2"READ3"READ3"READ4"READ4"vfstraceDeviceCharacteristicsVTR_DEVCHAR%s.xDeviceCharacteristics(%s)"%s.xDeviceCharacteristics(%s)" -> 0x%08x
" -> 0x%08x\n"vfstraceSectorSizeVTR_SECSZ%s.xSectorSize(%s)"%s.xSectorSize(%s)" -> %d
" -> %d\n"vfstraceFileControlzRValVTR_FCTRLzArg[0](zArg[0])zArg[1](zArg[1])zArg[n](zArg[n])LOCKSTATE"LOCKSTATE"GET_LOCKPROXYFILE"GET_LOCKPROXYFILE"SET_LOCKPROXYFILE"SET_LOCKPROXYFILE"LAST_ERRNO"LAST_ERRNO"SIZE_HINT,%lld"SIZE_HINT,%lld"CHUNK_SIZE,%d"CHUNK_SIZE,%d"FILE_POINTER"FILE_POINTER"WIN32_AV_RETRY"WIN32_AV_RETRY"PERSIST_WAL,%d"PERSIST_WAL,%d"OVERWRITE"OVERWRITE"VFSNAME"VFSNAME"POWERSAFE_OVERWRITE"POWERSAFE_OVERWRITE"vfstrace"vfstrace"const struct <unnamed>[31]struct <unnamed>[31]all"all"VTR_CLOSEVTR_READ"write"VTR_WRITE"truncate"VTR_TRUNC"sync"VTR_SYNCfilesize"filesize"VTR_FSIZElock"lock"VTR_LOCKunlock"unlock"VTR_UNLOCKcheckreservedlock"checkreservedlock"VTR_CRLfilecontrol"filecontrol"sectorsize"sectorsize"devicecharacteristics"devicecharacteristics"shmlock"shmlock"ppPagepnPagepVTabppCursortabpIdxpAuxppVtabzTraceNamezOldVfsNamexOutpOutArgmakeDefaultpFuncpTimeOutnMicrozBufOutpHandlezSymzPathnOutdirSyncpFilepOutFlagsptrnAmtpptrdelFlagiRegionszRegionisWriteshmmap"shmmap"shmummap"shmummap"shmbarrier"shmbarrier"delete"delete""access"fullpathname"fullpathname"dlopen"dlopen"dlerror"dlerror"dlsym"dlsym"VTR_DLSYMdlclose"dlclose"randomness"randomness""sleep"currenttime"currenttime"currenttimeint64"currenttimeint64"getlasterror"getlasterror"fetch"fetch"aKwonOff496sizeof(aKw)sizeof(aKw[0])sizeof(aKw)/sizeof(aKw[0])(int)(sizeof(aKw)/sizeof(aKw[0]))PRAGMA,[%s,%s]"PRAGMA,[%s,%s]"BUSYHANDLER"BUSYHANDLER"TEMPFILENAME"TEMPFILENAME"iMMapMMAP_SIZE,%lld"MMAP_SIZE,%lld"TRACE"TRACE"HAS_MOVED"HAS_MOVED"SYNC"SYNC"COMMIT_PHASETWO"COMMIT_PHASETWO"WIN32_SET_HANDLE"WIN32_SET_HANDLE"WAL_BLOCK"WAL_BLOCK"ZIPVFS"ZIPVFS"RBU"RBU"VFS_POINTER"VFS_POINTER"JOURNAL_POINTER"JOURNAL_POINTER"WIN32_GET_HANDLE"WIN32_GET_HANDLE"PDB"PDB"BEGIN_ATOMIC_WRITE"BEGIN_ATOMIC_WRITE"COMMIT_ATOMIC_WRITE"COMMIT_ATOMIC_WRITE"ROLLBACK_ATOMIC_WRITE"ROLLBACK_ATOMIC_WRITE"LOCK_TIMEOUT,%d"LOCK_TIMEOUT,%d"DATA_VERSION"DATA_VERSION"SIZE_LIMIT"SIZE_LIMIT"CKPT_DONE"CKPT_DONE"RESERVED_BYTES"RESERVED_BYTES"CKPT_START"CKPT_START"EXTERNAL_READER"EXTERNAL_READER"CKSM_FILE"CKSM_FILE"RESET_CACHE"RESET_CACHE"33896037440xca093fa0-905363552DB_UNCHANGED"DB_UNCHANGED"sizeof zBuf%s.xFileControl(%s,%s)"%s.xFileControl(%s,%s)"vfstrace.%s/%z"vfstrace.%s/%z"sizeof(zBuf2), %s
", %s\n"vfstraceCheckReservedLock%s.xCheckReservedLock(%s,%d)"%s.xCheckReservedLock(%s,%d)"vfstraceUnlock%s.xUnlock(%s,%s)"%s.xUnlock(%s,%s)"vfstraceLock%s.xLock(%s,%s)"%s.xLock(%s,%s)"lockNameazLockNamesNONE"NONE"SHARED"SHARED"RESERVED"RESERVED"PENDING"PENDING"EXCLUSIVE"EXCLUSIVE"sizeof(azLockNames)sizeof(azLockNames[0])sizeof(azLockNames)/sizeof(azLockNames[0])(int)(sizeof(azLockNames)/sizeof(azLockNames[0]))???"???"vfstraceFileSize%s.xFileSize(%s)"%s.xFileSize(%s)" -> %s," -> %s," size=%lld
" size=%lld\n"vfstraceSync|FULL"|FULL"|NORMAL"|NORMAL"|DATAONLY"|DATAONLY"(SQLITE_SYNC_FULL|SQLITE_SYNC_DATAONLY)~(SQLITE_SYNC_FULL|SQLITE_SYNC_DATAONLY)%s.xSync(%s,%s)"%s.xSync(%s,%s)"vfstraceTruncate%s.xTruncate(%s,%lld)"%s.xTruncate(%s,%lld)"vfstraceWrite%s.xWrite(%s,n=%d,ofst=%lld)"%s.xWrite(%s,n=%d,ofst=%lld)"vfstraceRead%s.xRead(%s,n=%d,ofst=%lld)"%s.xRead(%s,n=%d,ofst=%lld)"vfstraceClose%s.xClose(%s)"%s.xClose(%s)"vfstraceOnOffstrappendvfstrace_print_errcode%s | 0x%x"%s | 0x%x"167769600xffff00%d (0x%x)"%d (0x%x)"vfstrace_errcode_name"SQLITE_OK""SQLITE_INTERNAL""SQLITE_ERROR""SQLITE_PERM""SQLITE_ABORT""SQLITE_BUSY""SQLITE_LOCKED""SQLITE_NOMEM""SQLITE_READONLY""SQLITE_INTERRUPT""SQLITE_IOERR""SQLITE_CORRUPT""SQLITE_NOTFOUND""SQLITE_FULL""SQLITE_CANTOPEN""SQLITE_PROTOCOL""SQLITE_EMPTY""SQLITE_SCHEMA""SQLITE_TOOBIG""SQLITE_CONSTRAINT""SQLITE_MISMATCH""SQLITE_MISUSE""SQLITE_NOLFS"266"SQLITE_IOERR_READ"522"SQLITE_IOERR_SHORT_READ"778"SQLITE_IOERR_WRITE"1034"SQLITE_IOERR_FSYNC"12801290"SQLITE_IOERR_DIR_FSYNC"15361546"SQLITE_IOERR_TRUNCATE"17921802"SQLITE_IOERR_FSTAT"2058"SQLITE_IOERR_UNLOCK"23042314"SQLITE_IOERR_RDLOCK"25602570"SQLITE_IOERR_DELETE"28162826"SQLITE_IOERR_BLOCKED"30723082"SQLITE_IOERR_NOMEM"33283338"SQLITE_IOERR_ACCESS"35843594"SQLITE_IOERR_CHECKRESERVEDLOCK"38403850"SQLITE_IOERR_LOCK"4106"SQLITE_IOERR_CLOSE"43524362"SQLITE_IOERR_DIR_CLOSE"46084618"SQLITE_IOERR_SHMOPEN"48644874"SQLITE_IOERR_SHMSIZE"51205130"SQLITE_IOERR_SHMLOCK"53765386"SQLITE_IOERR_SHMMAP"56325642"SQLITE_IOERR_SEEK"64006410"SQLITE_IOERR_GETTEMPPATH"66566666"SQLITE_IOERR_CONVPATH"1032"SQLITE_READONLY_DBMOVED"262"SQLITE_LOCKED_SHAREDCACHE"261"SQLITE_BUSY_RECOVERY"270"SQLITE_CANTOPEN_NOTEMPDIR"vfstrace_printffileTailsqlite3_stmtrand_initstmtrand"stmtrand"stmtrandFuncStmtrand *4418371-4418371STMTRAND_KEYseedsizeof(*p)34896609290xd0000001110351524512345sqlite3_intck_test_sqlsqlite3_intck_unlockp->zKey==0 && p->nKeyVal>0sqlite3_intck_errorsqlite3_intck_messagep->pCheck==0 || p->zMessage==0sqlite3_intck_stepp->rc==SQLITE_OKcorruption found while reading database schema"corruption found while reading database schema"corruption found while scanning database object %s"corruption found while scanning database object %s"sqlite3_intck_closeparse_create_index"parse_create_index"sqlite3_intck_openiOfstmMaskpIzAppendzObjzDbArgintckCheckObjectSqlzRetbAutoIndexbIsIndexzCommon, without_rowid(b) AS (  SELECT EXISTS (    SELECT 1 FROM tabname, pragma_index_list(tab, db) AS l      WHERE origin='pk'       AND NOT EXISTS (SELECT 1 FROM sqlite_schema WHERE name=l.name)  )), idx_cols(idx_name, idx_ispk, col_name, col_expr, col_alias) AS (  SELECT l.name, (l.origin=='pk' AND w.b), i.name, COALESCE((    SELECT parse_create_index(sql, i.seqno) FROM     sqlite_schema WHERE name = l.name  ), format('"%w"', i.name) || ' COLLATE ' || quote(i.coll)),  'c' || row_number() OVER ()  FROM       tabname t,      without_rowid w,      pragma_index_list(t.tab, t.db) l,      pragma_index_xinfo(l.name) i      WHERE i.key  UNION ALL  SELECT '', 1, '_rowid_', '_rowid_', 'r1' FROM without_rowid WHERE b=0), tabpk(db, tab, idx, o_pk, i_pk, q_pk, eq_pk, ps_pk, pk_pk, n_pk) AS (    WITH pkfields(f, a) AS (      SELECT i.col_name, i.col_alias FROM idx_cols i WHERE i.idx_ispk    )    SELECT t.db, t.tab, t.idx,            group_concat(a, ', '),            group_concat('i.'||quote(f), ', '),            group_concat('quote(o.'||a||')', ' || '','' || '),             format('(%s)==(%s)',               group_concat('o.'||a, ', '),                group_concat(format('"%w"', f), ', ')           ),           group_concat('%s', ','),           group_concat('quote('||a||')', ', '),             count(*)    FROM tabname t, pkfields), idx(name, match_expr, partial, partial_alias, idx_ps, idx_idx) AS (  SELECT idx_name,    format('(%s,%s) IS (%s,%s)',            group_concat(i.col_expr, ', '), i_pk,           group_concat('o.'||i.col_alias, ', '), o_pk    ),     parse_create_index(        (SELECT sql FROM sqlite_schema WHERE name=idx_name), -1    ),    'cond' || row_number() OVER ()    , group_concat('%s', ',')    , group_concat('quote('||i.col_alias||')', ', ')  FROM tabpk t,        without_rowid w,       idx_cols i  WHERE i.idx_ispk==0   GROUP BY idx_name), wrapper_with(s) AS (  SELECT 'intck_wrapper AS (
  SELECT
    ' || (      WITH f(a, b) AS (        SELECT col_expr, col_alias FROM idx_cols          UNION ALL         SELECT partial, partial_alias FROM idx WHERE partial IS NOT NULL      )      SELECT group_concat(format('%s AS %s', a, b), ',
    ') FROM f    )    || format('
  FROM %Q.%Q ', t.db, t.tab)    || CASE WHEN t.idx IS NULL THEN         'NOT INDEXED'       ELSE        format('INDEXED BY %Q%s', t.idx, ' WHERE '||i.partial)       END    || '
)'    FROM tabname t LEFT JOIN idx i ON (i.name=t.idx))", without_rowid(b) AS ("
      "  SELECT EXISTS ("
      "    SELECT 1 FROM tabname, pragma_index_list(tab, db) AS l"
      "      WHERE origin='pk' "
      "      AND NOT EXISTS (SELECT 1 FROM sqlite_schema WHERE name=l.name)"
      "  )"
      ")"
      ""
      /* Table idx_cols contains 1 row for each column in each index on the
      ** table being checked. Columns are:
      **
      **   idx_name: Name of the index.
      **   idx_ispk: True if this index is the PK of a WITHOUT ROWID table.
      **   col_name: Name of indexed column, or NULL for index on expression.
      **   col_expr: Indexed expression, including COLLATE clause.
      **   col_alias: Alias used for column in 'intck_wrapper' table.
      */
      ", idx_cols(idx_name, idx_ispk, col_name, col_expr, col_alias) AS ("
      "  SELECT l.name, (l.origin=='pk' AND w.b), i.name, COALESCE(("
      "    SELECT parse_create_index(sql, i.seqno) FROM "
      "    sqlite_schema WHERE name = l.name"
      "  ), format('\"%w\"', i.name) || ' COLLATE ' || quote(i.coll)),"
      "  'c' || row_number() OVER ()"
      "  FROM "
      "      tabname t,"
      "      without_rowid w,"
      "      pragma_index_list(t.tab, t.db) l,"
      "      pragma_index_xinfo(l.name) i"
      "      WHERE i.key"
      "  UNION ALL"
      "  SELECT '', 1, '_rowid_', '_rowid_', 'r1' FROM without_rowid WHERE b=0"
      ")"
      ""
      ""
      /*
      ** For a PK declared as "PRIMARY KEY(a, b) ... WITHOUT ROWID", where
      ** the intck_wrapper aliases of "a" and "b" are "c1" and "c2":
      **
      **   o_pk:   "o.c1, o.c2"
      **   i_pk:   "i.'a', i.'b'"
      **   ...
      **   n_pk:   2
      */ 
      ", tabpk(db, tab, idx, o_pk, i_pk, q_pk, eq_pk, ps_pk, pk_pk, n_pk) AS ("
      "    WITH pkfields(f, a) AS ("
      "      SELECT i.col_name, i.col_alias FROM idx_cols i WHERE i.idx_ispk"
      "    )"
      "    SELECT t.db, t.tab, t.idx, "
      "           group_concat(a, ', '), "
      "           group_concat('i.'||quote(f), ', '), "
      "           group_concat('quote(o.'||a||')', ' || '','' || '),  "
      "           format('(%s)==(%s)',"
      "               group_concat('o.'||a, ', '), "
      "               group_concat(format('\"%w\"', f), ', ')"
      "           ),"
      "           group_concat('%s', ','),"
      "           group_concat('quote('||a||')', ', '),  "
      "           count(*)"
      "    FROM tabname t, pkfields"
      ")"
      ""
      ", idx(name, match_expr, partial, partial_alias, idx_ps, idx_idx) AS ("
      "  SELECT idx_name,"
      "    format('(%s,%s) IS (%s,%s)', "
      "           group_concat(i.col_expr, ', '), i_pk,"
      "           group_concat('o.'||i.col_alias, ', '), o_pk"
      "    ), "
      "    parse_create_index("
      "        (SELECT sql FROM sqlite_schema WHERE name=idx_name), -1"
      "    ),"
      "    'cond' || row_number() OVER ()"
      "    , group_concat('%s', ',')"
      "    , group_concat('quote('||i.col_alias||')', ', ')"
      "  FROM tabpk t, "
      "       without_rowid w,"
      "       idx_cols i"
      "  WHERE i.idx_ispk==0 "
      "  GROUP BY idx_name"
      ")"
      ""
      ", wrapper_with(s) AS ("
      "  SELECT 'intck_wrapper AS (\n  SELECT\n    ' || ("
      "      WITH f(a, b) AS ("
      "        SELECT col_expr, col_alias FROM idx_cols"
      "          UNION ALL "
      "        SELECT partial, partial_alias FROM idx WHERE partial IS NOT NULL"
      "      )"
      "      SELECT group_concat(format('%s AS %s', a, b), ',\n    ') FROM f"
      "    )"
      "    || format('\n  FROM %Q.%Q ', t.db, t.tab)"
           /* If the object being checked is a table, append "NOT INDEXED".
           ** Otherwise, append "INDEXED BY <index>", and then, if the index 
           ** is a partial index " WHERE <condition>".  */
      "    || CASE WHEN t.idx IS NULL THEN "
      "        'NOT INDEXED'"
      "       ELSE"
      "        format('INDEXED BY %Q%s', t.idx, ' WHERE '||i.partial)"
      "       END"
      "    || '\n)'"
      "    FROM tabname t LEFT JOIN idx i ON (i.name=t.idx)"
      ")"
      ""char[2432]PRAGMA automatic_index = 0"PRAGMA automatic_index = 0"WITH tabname(db, tab, idx) AS (  SELECT %Q, (SELECT tbl_name FROM %Q.sqlite_schema WHERE name=%Q), %Q ), whereclause(w_c) AS (%s)%s, case_statement(c) AS (  SELECT     'CASE WHEN (' || group_concat(col_alias, ', ') || ', 1) IS (
'     || '      SELECT ' || group_concat(col_expr, ', ') || ', 1 FROM '    || format('%%Q.%%Q NOT INDEXED WHERE %%s
', t.db, t.tab, p.eq_pk)    || '    )
  THEN NULL
    '    || 'ELSE format(''surplus entry ('    ||   group_concat('%%s', ',') || ',' || p.ps_pk    || ') in index ' || t.idx || ''', '     ||   group_concat('quote('||i.col_alias||')', ', ') || ', ' || p.pk_pk    || ')'    || '
  END AS error_message'  FROM tabname t, tabpk p, idx_cols i WHERE i.idx_name=t.idx), thiskey(k, n) AS (    SELECT group_concat(i.col_alias, ', ') || ', ' || p.o_pk,            count(*) + p.n_pk     FROM tabpk p, idx_cols i WHERE i.idx_name=p.idx), main_select(m, n) AS (  SELECT format(      'WITH %%s
' ||      ', idx_checker AS (
' ||      '  SELECT %%s,
' ||      '  %%s
' ||       '  FROM intck_wrapper AS o
' ||      ')
',      ww.s, c, t.k  ), t.n  FROM case_statement, wrapper_with ww, thiskey t)SELECT m ||     group_concat('SELECT * FROM idx_checker ' || w_c, ' UNION ALL '), n FROM main_select, whereclause "WITH tabname(db, tab, idx) AS ("
      "  SELECT %Q, (SELECT tbl_name FROM %Q.sqlite_schema WHERE name=%Q), %Q "
      ")"
      ""
      ", whereclause(w_c) AS (%s)"
      ""
      "%s" /* zCommon */
      ""
      ", case_statement(c) AS ("
      "  SELECT "
      "    'CASE WHEN (' || group_concat(col_alias, ', ') || ', 1) IS (\n' "
      "    || '      SELECT ' || group_concat(col_expr, ', ') || ', 1 FROM '"
      "    || format('%%Q.%%Q NOT INDEXED WHERE %%s\n', t.db, t.tab, p.eq_pk)"
      "    || '    )\n  THEN NULL\n    '"
      "    || 'ELSE format(''surplus entry ('"
      "    ||   group_concat('%%s', ',') || ',' || p.ps_pk"
      "    || ') in index ' || t.idx || ''', ' "
      "    ||   group_concat('quote('||i.col_alias||')', ', ') || ', ' || p.pk_pk"
      "    || ')'"
      "    || '\n  END AS error_message'"
      "  FROM tabname t, tabpk p, idx_cols i WHERE i.idx_name=t.idx"
      ")"
      ""
      ", thiskey(k, n) AS ("
      "    SELECT group_concat(i.col_alias, ', ') || ', ' || p.o_pk, "
      "           count(*) + p.n_pk "
      "    FROM tabpk p, idx_cols i WHERE i.idx_name=p.idx"
      ")"
      ""
      ", main_select(m, n) AS ("
      "  SELECT format("
      "      'WITH %%s\n' ||"
      "      ', idx_checker AS (\n' ||"
      "      '  SELECT %%s,\n' ||"
      "      '  %%s\n' || "
      "      '  FROM intck_wrapper AS o\n' ||"
      "      ')\n',"
      "      ww.s, c, t.k"
      "  ), t.n"
      "  FROM case_statement, wrapper_with ww, thiskey t"
      ")"

      "SELECT m || "
      "    group_concat('SELECT * FROM idx_checker ' || w_c, ' UNION ALL '), n"
      " FROM "
      "main_select, whereclause "char[1241]VALUES('')"VALUES('')"WITH tabname(db, tab, idx, prev) AS (SELECT %Q, %Q, NULL, %Q)%s, expr(e, p) AS (  SELECT format('CASE WHEN EXISTS 
    (SELECT 1 FROM %%Q.%%Q AS i INDEXED BY %%Q WHERE %%s%%s)
    THEN NULL
    ELSE format(''entry (%%s,%%s) missing from index %%s'', %%s, %%s)
  END
'    , t.db, t.tab, i.name, i.match_expr, ' AND (' || partial || ')',      i.idx_ps, t.ps_pk, i.name, i.idx_idx, t.pk_pk),    CASE WHEN partial IS NULL THEN NULL ELSE i.partial_alias END  FROM tabpk t, idx i), numbered(ii, cond, e) AS (  SELECT 0, 'n.ii=0', 'NULL'    UNION ALL   SELECT row_number() OVER (),      '(n.ii='||row_number() OVER ()||COALESCE(' AND '||p||')', ')'), e  FROM expr), counter_with(w) AS (    SELECT 'WITH intck_counter(ii) AS (
  ' ||        group_concat('SELECT '||ii, ' UNION ALL
  ')     || '
)' FROM numbered), case_statement(c) AS (    SELECT 'CASE ' ||     group_concat(format('
  WHEN %%s THEN (%%s)', cond, e), '') ||    '
END AS error_message'    FROM numbered), thiskey(k, n) AS (    SELECT o_pk || ', ii', n_pk+1 FROM tabpk), whereclause(w_c) AS (    SELECT CASE WHEN prev!='' THEN     '
WHERE (' || o_pk ||', n.ii) > ' || prev    ELSE ''    END    FROM tabpk, tabname), main_select(m, n) AS (  SELECT format(      '%%s, %%s
SELECT %%s,
%%s
FROM intck_wrapper AS o, intck_counter AS n%%s
ORDER BY %%s',       w, ww.s, c, thiskey.k, whereclause.w_c, t.o_pk  ), thiskey.n  FROM case_statement, tabpk t, counter_with,        wrapper_with ww, thiskey, whereclause)SELECT m, n FROM main_select"WITH tabname(db, tab, idx, prev) AS (SELECT %Q, %Q, NULL, %Q)"
      ""
      "%s" /* zCommon */

      /* expr(e) contains one row for each index on table zObj. Value e
      ** is set to an expression that evaluates to NULL if the required
      ** entry is present in the index, or an error message otherwise.  */
      ", expr(e, p) AS ("
      "  SELECT format('CASE WHEN EXISTS \n"
      "    (SELECT 1 FROM %%Q.%%Q AS i INDEXED BY %%Q WHERE %%s%%s)\n"
      "    THEN NULL\n"
      "    ELSE format(''entry (%%s,%%s) missing from index %%s'', %%s, %%s)\n"
      "  END\n'"
      "    , t.db, t.tab, i.name, i.match_expr, ' AND (' || partial || ')',"
      "      i.idx_ps, t.ps_pk, i.name, i.idx_idx, t.pk_pk),"
      "    CASE WHEN partial IS NULL THEN NULL ELSE i.partial_alias END"
      "  FROM tabpk t, idx i"
      ")"

      ", numbered(ii, cond, e) AS ("
      "  SELECT 0, 'n.ii=0', 'NULL'"
      "    UNION ALL "
      "  SELECT row_number() OVER (),"
      "      '(n.ii='||row_number() OVER ()||COALESCE(' AND '||p||')', ')'), e"
      "  FROM expr"
      ")"

      ", counter_with(w) AS ("
      "    SELECT 'WITH intck_counter(ii) AS (\n  ' || "
      "       group_concat('SELECT '||ii, ' UNION ALL\n  ') "
      "    || '\n)' FROM numbered"
      ")"
      ""
      ", case_statement(c) AS ("
      "    SELECT 'CASE ' || "
      "    group_concat(format('\n  WHEN %%s THEN (%%s)', cond, e), '') ||"
      "    '\nEND AS error_message'"
      "    FROM numbered"
      ")"
      ""

      /* This table contains a single row consisting of a single value -
      ** the text of an SQL expression that may be used by the main SQL
      ** statement to output an SQL literal that can be used to resume
      ** the scan if it is suspended. e.g. for a rowid table, an expression
      ** like:
      **
      **     format('(%d,%d)', _rowid_, n.ii)
      */
      ", thiskey(k, n) AS ("
      "    SELECT o_pk || ', ii', n_pk+1 FROM tabpk"
      ")"
      ""
      ", whereclause(w_c) AS ("
      "    SELECT CASE WHEN prev!='' THEN "
      "    '\nWHERE (' || o_pk ||', n.ii) > ' || prev"
      "    ELSE ''"
      "    END"
      "    FROM tabpk, tabname"
      ")"
      ""
      ", main_select(m, n) AS ("
      "  SELECT format("
      "      '%%s, %%s\nSELECT %%s,\n%%s\nFROM intck_wrapper AS o"
               ", intck_counter AS n%%s\nORDER BY %%s', "
      "      w, ww.s, c, thiskey.k, whereclause.w_c, t.o_pk"
      "  ), thiskey.n"
      "  FROM case_statement, tabpk t, counter_with, "
      "       wrapper_with ww, thiskey, whereclause"
      ")"

      "SELECT m, n FROM main_select"char[1491]PRAGMA automatic_index = 1"PRAGMA automatic_index = 1"intckIsIndexbRetSELECT 1 FROM %Q.sqlite_schema WHERE name=%Q AND type='index'"SELECT 1 FROM %Q.sqlite_schema WHERE name=%Q AND type='index'"intckGetAutoIndexPRAGMA automatic_index"PRAGMA automatic_index"intckParseCreateIndexFuncnResnVal==2intckParseCreateIndexiThisColiStartnOpeniEndOfColz[iOff]=='('zTokennTokeniEndASC"ASC"DESC"DESC"where"where"intckIsSpaceintckGetTokeniRet'A''Z''z'intckFindObjectp->pCheck==0WITH tables(table_name) AS (  SELECT name  FROM %Q.sqlite_schema WHERE (type='table' OR type='index') AND rootpage  UNION ALL   SELECT 'sqlite_schema')SELECT table_name FROM tables WHERE ?1 IS NULL OR table_name%s?1 ORDER BY 1"WITH tables(table_name) AS (" 
    "  SELECT name"
    "  FROM %Q.sqlite_schema WHERE (type='table' OR type='index') AND rootpage"
    "  UNION ALL "
    "  SELECT 'sqlite_schema'"
    ")"
    "SELECT table_name FROM tables "
    "WHERE ?1 IS NULL OR table_name%s?1 "
    "ORDER BY 1"char[227]>=">=">">"intckSaveKeypXinfop->pCheckp->zKey==0SELECT group_concat(desc, '') FROM %Q.sqlite_schema s, pragma_index_xinfo(%Q, %Q) WHERE s.type='index' AND s.name=%Q"SELECT group_concat(desc, '') FROM %Q.sqlite_schema s, "
      "pragma_index_xinfo(%Q, %Q) "
      "WHERE s.type='index' AND s.name=%Q"char[117]p->nKeyVal>1SELECT '(' || "SELECT '(' || " || ', ' || " || ', ' || "%z || ')'"%z || ')'"bLastIsDescbLastIsNullzLastzLhszRhs'%s IS NOT NULL'"'%s IS NOT NULL'"<"<"'%s %s ' || quote(?%d)"'%s %s ' || quote(?%d)"zLhsSepzRhsSepzAlias%z%s%s"%z%s%s"%z%squote(?%d)"%z%squote(?%d)" || ',' || " || ',' || "'(%z) IS (' || %z || ') AND ' || %z"'(%z) IS (' || %z || ') AND ' || %z"'WHERE ' || %z"'WHERE ' || %z"%z%s(quote( %z ) )"%z%s(quote( %z ) )"VALUES"VALUES",
      ",\n      "WITH wc(q) AS (
%z
)SELECT 'VALUES' || group_concat('(' || q || ')', ',
      ') FROM wc"WITH wc(q) AS (\n%z\n)"
        "SELECT 'VALUES' || group_concat('(' || q || ')', ',\n      ') FROM wc"intckMprintfintckExecintckStepintckFinalizeintckPrepareFmtintckPreparepRet==0intckSaveErrmsgsqlite3_expert_destroyIdxScan *IdxStatement *IdxTable *IdxWrite *IdxHash *sqlite3_expert_reportsqlite3_expert_countsqlite3_expert_analyzeIdxHashEntry *pEntry773Cannot find a unique index name to propose."Cannot find a unique index name to propose."%s;%s%s
"%s;%s%s\n" -- stat1: " -- stat1: "sqlite3_expert_sqlpScanOrigpStmtOrigsizeof(IdxStatement)sqlite3_expert_configsqlite3_expert_new8288sizeof(sqlite3expert)SELECT sql, name, substr(sql,1,14)=='create virtual' COLLATE nocase FROM sqlite_schema WHERE substr(name,1,7)!='sqlite_' COLLATE nocase ORDER BY 3 DESC, rowid"SELECT sql, name, substr(sql,1,14)=='create virtual' COLLATE nocase"
        " FROM sqlite_schema WHERE substr(name,1,7)!='sqlite_' COLLATE nocase"
        " ORDER BY 3 DESC, rowid"char[159]bExistsregisterUDFsSELECT name,type,enc,narg,flags FROM pragma_function_list() WHERE builtin==0"SELECT name,type,enc,narg,flags "
            "FROM pragma_function_list() "
            "WHERE builtin==0"nargsienc SQLITE_UTF8rcf SQLITE_ERRORutf16le"utf16le"utf16be"utf16be"526336(SQLITE_DETERMINISTIC|SQLITE_DIRECTONLY)"a"dummyUDFvaluedummyUDFuseDummyCSdummyCompareidxPopulateStat1IdxRemCtx *samplectxiPrev-100000pAllIndexpIndexXInfopWritezAllIndexSELECT s.rowid, s.name, l.name FROM   sqlite_schema AS s,   pragma_index_list(s.name) AS l WHERE s.type = 'table'"SELECT s.rowid, s.name, l.name FROM "
    "  sqlite_schema AS s, "
    "  pragma_index_list(s.name) AS l "
    "WHERE s.type = 'table'"zIndexXInfoSELECT name, coll FROM pragma_index_xinfo(?) WHERE key"SELECT name, coll FROM pragma_index_xinfo(?) WHERE key"char[55]zWriteINSERT INTO sqlite_stat1 VALUES(?, ?, ?)"INSERT INTO sqlite_stat1 VALUES(?, ?, ?)"ANALYZE; PRAGMA writable_schema=1"ANALYZE; PRAGMA writable_schema=1"sizeof(struct IdxRemCtx)sizeof(struct IdxRemSlot)dbremsqlite_expert_rem"sqlite_expert_rem"sqlite_expert_sample"sqlite_expert_sample"IdxSampleCtx *pnKeyValiStmteReportdbSrcdbDstup1up2up3etrup4up5DROP TABLE IF EXISTS temp.t592690916721053953805701627921227776"DROP TABLE IF EXISTS temp." UNIQUE_TABLE_NAMEIdxRemSlot[1]IdxRemSlot *ANALYZE sqlite_schema"ANALYZE sqlite_schema""DROP TABLE IF EXISTS temp."UNIQUE_TABLE_NAMEidxBuildSampleTableCREATE TABLE temp.t592690916721053953805701627921227776 AS SELECT * FROM %Q"CREATE TABLE temp." UNIQUE_TABLE_NAME " AS SELECT * FROM %Q"idxPopulateOneStat1zColszOrderaStatp->iSample>0zCommazColl%sx.%Q IS sqlite_expert_rem(%d, x.%Q) COLLATE %s"%sx.%Q IS sqlite_expert_rem(%d, x.%Q) COLLATE %s"%s%d"%s%d"SELECT %s FROM %Q x ORDER BY %s"SELECT %s FROM %Q x ORDER BY %s"SELECT %s FROM temp.t592690916721053953805701627921227776 x ORDER BY %s"SELECT %s FROM temp."UNIQUE_TABLE_NAME" x ORDER BY %s"pEntry->zVal2==0zStats0 %d" %d"idxLargestIndexzMaxSELECT max(i.seqno) FROM   sqlite_schema AS s,   pragma_index_list(s.name) AS l,   pragma_index_info(l.name) AS i WHERE s.type = 'table'"SELECT max(i.seqno) FROM "
    "  sqlite_schema AS s, "
    "  pragma_index_list(s.name) AS l, "
    "  pragma_index_info(l.name) AS i "
    "WHERE s.type = 'table'"pMaxidxRemFuncpSlotiSlotiSlot<p->nSlotidxSampleFuncargc==0rnd1.0idxCreateVtabSchemapSchemaSELECT type, name, sql, 1,        substr(sql,1,14)=='create virtual' COLLATE nocase FROM sqlite_schema WHERE type IN ('table','view') AND       substr(name,1,7)!='sqlite_' COLLATE nocase  UNION ALL SELECT type, name, sql, 2, 0 FROM sqlite_schema WHERE type = 'trigger'  AND tbl_name IN(SELECT name FROM sqlite_schema WHERE type = 'view') ORDER BY 4, 5 DESC, 1"SELECT type, name, sql, 1, "
      "       substr(sql,1,14)=='create virtual' COLLATE nocase "
      "FROM sqlite_schema "
      "WHERE type IN ('table','view') AND "
      "      substr(name,1,7)!='sqlite_' COLLATE nocase "
      " UNION ALL "
      "SELECT type, name, sql, 2, 0 FROM sqlite_schema "
      "WHERE type = 'trigger'"
      "  AND tbl_name IN(SELECT name FROM sqlite_schema WHERE type = 'view') "
      "ORDER BY 4, 5 DESC, 1"char[360]pTab!=0IdxTable **zInnerzOuterCREATE TABLE x("CREATE TABLE x("%s%Q COLLATE %s"%s%Q COLLATE %s"IdxColumn *CREATE VIRTUAL TABLE %Q USING expert(%Q)"CREATE VIRTUAL TABLE %Q USING expert(%Q)"expertSchemaSqlno such module:"no such module:"expertDbContainsObjectSELECT 1 FROM sqlite_schema WHERE name = ?"SELECT 1 FROM sqlite_schema WHERE name = ?"idxProcessTriggerspFirstpIteridxProcessOneTriggerzIntSELECT 'CREATE TEMP' || substr(sql, 7) FROM sqlite_schema WHERE tbl_name = %Q AND type IN ('table', 'trigger') ORDER BY type;"SELECT 'CREATE TEMP' || substr(sql, 7) FROM sqlite_schema "
    "WHERE tbl_name = %Q AND type IN ('table', 'trigger') "
    "ORDER BY type;"char[126]ALTER TABLE temp.%Q RENAME TO %Q"ALTER TABLE temp.%Q RENAME TO %Q"pWrite->eOp==SQLITE_DELETEINSERT INTO %Q VALUES("INSERT INTO %Q VALUES("%s?"%s?"UPDATE %Q SET "UPDATE %Q SET "%s%Q=?"%s%Q=?"DELETE FROM %Q"DELETE FROM %Q"DROP TABLE t592690916721053953805701627921227776"DROP TABLE " UNIQUE_TABLE_NAMEt592690916721053953805701627921227776UNIQUE_TABLE_NAMEidxAuthCallbacksizeof(IdxWrite)idxFindIndexesdbmhIdxEXPLAIN QUERY PLAN %s"EXPLAIN QUERY PLAN %s"zDetailnDetail USING INDEX " USING INDEX " USING COVERING INDEX " USING COVERING INDEX "nIdxfind_indexes_outidxWriteFreeidxTableFreeidxStatementFreeidxScanFreeIdxConstraint *idxConstraintFreeidxCreateCandidatesidxCreateFromWherepConpCon->pLink==0idxFindConstraintpCmpidxCreateFromConsrc==SQLITE_OKpConsquoteTablecollisionszFind%s_idx_%08x"%s_idx_%08x"SELECT count(*) FROM sqlite_schema WHERE name=%Q AND type in ('index','table','view')"SELECT count(*) FROM sqlite_schema WHERE name=%Q"
          " AND type in ('index','table','view')"char[86]CREATE INDEX "%w" ON "%w"(%s)"CREATE INDEX \"%w\" ON \"%w\"(%s)"CREATE INDEX %s ON %s(%s)"CREATE INDEX %s ON %s(%s)"countNonzerospWriteStatpnMaxpbContainseOpz3z4zTriggerpStatementpLastpScanpConstraintpTailpListpEqpCountncazResultsazColumnsidxFindCompatiblepIdxListnEqPRAGMA index_list=%Q"PRAGMA index_list=%Q"bMatchpTPRAGMA index_xInfo=%Q"PRAGMA index_xInfo=%Q"iIdxidxAppendColDefn COLLATE %Q" COLLATE %Q" DESC" DESC"idxIdentifierRequiresQuotesnId'_'idxAppendTextnAppendidxGetTableInfonTabnPksizeof(IdxTable)PRAGMA table_xinfo=%Q"PRAGMA table_xinfo=%Q"zColSeqsizeof(IdxColumn)pNew!=0pNew->zName!=0idxFinalizeidxRegisterVtabexpertModuleexpertFilterExpertCsr *ExpertVtab *pExpertSELECT * FROM main.%Q WHERE sqlite_expert_sample()"SELECT * FROM main.%Q WHERE sqlite_expert_sample()"expertColumnexpertRowidexpertNextpCsr->pDataexpertEofexpertCloseexpertOpensizeof(ExpertCsr)expertUpdateexpertBestIndexopmasksizeof(IdxScan)1000000.0expertDisconnectexpertConnectsqlite3_stricmp(p->pTab->zName, argv[2])==0internal error!"internal error!"zCreateTablesizeof(ExpertVtab)expertDequotezIn[0]=='\''zIn[n-1]=='\''zIn[iIn+1]=='\''iInidxPrintfPrepareStmtidxPrepareStmtidxDatabaseErroridxNewConstraintnColl*pRc==SQLITE_OKsizeof(IdxConstraint)idxHashSearchidxHashFindiHashiHash>=0IdxHashEntry *[1023]1023IDX_HASH_SIZEIdxHashEntry **idxHashAddnKeysizeof(IdxHashEntry)idxHashStringidxHashClearsizeof(IdxHash)idxHashInitidxMallocsqlite3_sqlar_initsqlar_compress"sqlar_compress"2097153sqlar_uncompress"sqlar_uncompress"sqlarUncompressFuncszferror in uncompress()"error in uncompress()"sqlarCompressFuncargc==1error in compress()"error in compress()"sqlite3_zipfile_initzipfileRegisterzipfileModulesizeof(i64)==8sizeof(u32)==4sizeof(u16)==2sizeof(u8)==1zipfileFinalZipfileCtx *eocdnZipaZipsizeof(ZipfileCtx)ZipfileEOCD *sizeof(eocd)ZIPFILE_EOCD_FIXED_SZzipfileStepepNamepModepMtimepMethodbIsDiriMethodszUncompressedaFreeiCrc32ZipfileEntry *sizeof(e)wrong number of arguments to function zipfile()"wrong number of arguments to function zipfile()"first argument to zipfile() must be non-NULL"first argument to zipfile() must be non-NULL"illegal method value: %d"illegal method value: %d"non-directory name must not end with /"non-directory name must not end with /"zIdcurpIdxInfopHash798ZIPFILE_NEWENTRY_MADEBYZIPFILE_NEWENTRY_REQUIREDZIPFILE_NEWENTRY_FLAGSZipfileCDS *ZIPFILE_LFH_FIXED_SZZipfileBuffer *ZIPFILE_CDS_FIXED_SZzipfile_step_outzipfileBufferGrownReqzipfileFindFunctionzipfileFunctionCdsZipfileCsr *ZipfileTab *argc>0{"version-made-by" : %u, "version-to-extract" : %u, "flags" : %u, "compression" : %u, "time" : %u, "date" : %u, "crc32" : %u, "compressed-size" : %u, "uncompressed-size" : %u, "file-name-length" : %u, "extra-field-length" : %u, "file-comment-length" : %u, "disk-number-start" : %u, "internal-attr" : %u, "external-attr" : %u, "offset" : %u }"{"
        "\"version-made-by\" : %u, "
        "\"version-to-extract\" : %u, "
        "\"flags\" : %u, "
        "\"compression\" : %u, "
        "\"time\" : %u, "
        "\"date\" : %u, "
        "\"crc32\" : %u, "
        "\"compressed-size\" : %u, "
        "\"uncompressed-size\" : %u, "
        "\"file-name-length\" : %u, "
        "\"extra-field-length\" : %u, "
        "\"file-comment-length\" : %u, "
        "\"disk-number-start\" : %u, "
        "\"internal-attr\" : %u, "
        "\"external-attr\" : %u, "
        "\"offset\" : %u }"char[342]zipfileFindCursorzipfileRollbackzipfileCommitnEntryzipfileSerializeCDSpCDSZIPFILE_SIGNATURE_CDS0x02014b5033639248pCDS->iVersionMadeBypCDS->iVersionExtractpCDS->flagspCDS->iCompressionpCDS->mTimepCDS->mDatepCDS->crc32pCDS->szCompressedpCDS->szUncompresseda==&aBuf[ZIPFILE_CDS_NFILE_OFF]pCDS->nFilepCDS->nExtrapCDS->nCommentpCDS->iDiskStartpCDS->iInternalAttrpCDS->iExternalAttrpCDS->iOffsetpCDS->nExtra==9ZIPFILE_EXTRA_TIMESTAMP0x5455pEntry->mUnixTime21589zipfileAppendEOCDnBufnBuf==ZIPFILE_EOCD_FIXED_SZzipfileSerializeEOCDZIPFILE_SIGNATURE_EOCD0x06054b50101010256p->iDiskp->iFirstDiskp->nEntryp->nEntryTotalp->nSizep->iOffsetzipfileUpdatemTimenPathpFreepOld2pOld->pNextzDeletenDeletezUpdatesz must be NULL"sz must be NULL"rawdata must be NULL"rawdata must be NULL"aInbAutounknown compression method: %d"unknown compression method: %d"nCmpduplicate name: "%s""duplicate name: \"%s\""zipfile_update_donezipfileRemoveEntryFromListzipfileGetTimezipfileTime24405875(i64)244058758640210866760000(i64)24405875 * 8640((i64)24405875 * 8640)day2440587.58640086400.0zipfileBeginpTab->pWriteFd==0zipfile: missing filename"zipfile: missing filename"ab+"ab+"zipfile: failed to open file %s for writing"zipfile: failed to open file %s for writing"zipfileComparePathnAzipfileGetMode493075516877(S_IFDIR + 0755)420064433188(S_IFREG + 0644)const char[11]zTemplate-rwxrwxrwx"-rwxrwxrwx"40960zipfile: mode does not match data"zipfile: mode does not match data"parse_errorzipfile: parse error in mode: %s"zipfile: parse error in mode: %s"zipfileAppendEntryzipfileSerializeLFHpCdsZIPFILE_SIGNATURE_LFH0x04034b5067324752pCds->iVersionExtractpCds->flagspCds->iCompressionpCds->mTimepCds->mDatepCds->crc32pCds->szCompressedpCds->szUncompressed(u16)pCds->nFilepCds->nExtraa==&aBuf[ZIPFILE_LFH_FIXED_SZ]zipfileNewEntrysizeof(ZipfileEntry)zipfileBestIndexunusableconst sqlite3_index_constraintconst sqlite3_index_constraint *ZIPFILE_F_COLUMN_IDX1000.0zipfileFilterbInMemorypTab->pFirstEntry==0zipfile() function requires an argument"zipfile() function requires an argument"aEmptyBlobcannot open file: %s"cannot open file: %s"zipfileLoadDirectoryZipfileEntry **zipfileAddEntry(pTab->pFirstEntry==0)==(pTab->pLastEntry==0)pNew->pNext==0pTab->pLastEntry->pNext==0zipfileReadEOCDaReadsizeof(ZipfileEOCD)szFileZIPFILE_BUFFER_SIZE(64*1024)cannot find end of central directory record"cannot find end of central directory record"zipfileEofzipfileColumni==7pxFuncppArgiIdnBpBeforepEOCDszFinalzipfileDeflateaOutsizeof(str)&str-151.3zipfile: deflate() error"zipfile: deflate() error"zipfileInflateaResByte *inflateInit2() failed (%d)"inflateInit2() failed (%d)"inflate() failed (%d)"inflate() failed (%d)"zipfileFreezipfileNextiEofzipfileGetEntrynFileZIPFILE_CDS_NFILE_OFFnExtraZIPFILE_CDS_SZCOMPRESSED_OFFfailed to read CDS at offset %lld"failed to read CDS at offset %lld"ptszFixlfhZipfileLFH *failed to read LFH at offset %d"failed to read LFH at offset %d"zipfileMtimeToDosJD2440588(i64)2440588144024*6024*60*60(24*60*60)ABDEyrmonhrminsec1867216.2536524.251524122.0999999999999943122.1365.253652530.6001000000000011930.600147164715360060*60(60*60)1980mUnixTime<315507600 || mUnixTime==zipfileMtime(pCds) || ((mUnixTime % 2) && mUnixTime-1==zipfileMtime(pCds))zipfileMtimeYX1X2JDsec0x7F0x1F0x3F3060011524.5(i64)8640(i64)24405875*(i64)8640zipfileScanExtrazipfileReadLFHsigzipfileReadCDSaRead==&aBuf[ZIPFILE_CDS_NFILE_OFF]aRead==&aBuf[ZIPFILE_CDS_FIXED_SZ]zipfilePutU32zipfilePutU16zipfileGetU32zipfileGetU16zipfileAppendDataerror in fwrite()"error in fwrite()"zipfileReadDataerror in fread()"error in fread()"zipfileCursorErrzipfileTableErrzipfileCloseZipfileCsr **zipfileResetCursorzipfileOpensizeof(*pCsr)zipfileDisconnectzipfileCleanupTransactionzipfileEntryFreezipfileConnectsizeof(ZipfileTab)65640sizeof(ZipfileTab) + ZIPFILE_BUFFER_SIZE0==sqlite3_stricmp(argv[0], "zipfile")zipfile constructor requires one argument"zipfile constructor requires one argument"const char[91]char[91]zipfileDequotezIn[iIn]zipfileCtxErrorMsgsqlite3_appendvfs_initpOrigsizeof(ApndFile)apndNextSystemCallapndGetSystemCallapndSetSystemCallapndCurrentTimeInt64apndGetLastErrorapndCurrentTimeapndSleepapndRandomnessapndDlCloseapndDlSymapndDlErrorapndDlOpenapndFullPathnameapndAccessapndDeleteapndOpenApndFile *pApndFilepBaseFilepApndVfspBaseVfsAPND_MARK_SIZE4095-4096apndIsOrdinaryDatabaseFilezHdr5110x1ffsizeof(zHdr)apndIsAppendvfsDatabaseiMarkpnOutppEntrymUnixTimeaExtrapmTimeaBufferpLFHaWritenWriteppCsrpCall537512+APND_MARK_SIZEapndReadMarkmsbsAPND_MARK_FOS_SZ(APND_MARK_FOS_SZ-1)8 * (APND_MARK_FOS_SZ-1)unsigned char[25]APND_MARK_PREFIXAPND_MARK_PREFIX_SZapndUnfetchapndFetchapndShmUnmapapndShmBarrierapndShmLockapndShmMapapndDeviceCharacteristicsapndSectorSizeapndFileControlpafapnd(%lld)/%z"apnd(%lld)/%z"apndCheckReservedLockapndUnlockapndLockapndFileSizeapndSyncapndTruncateapndWriteiWriteEnd1073741824APND_MAX_SIZEapndWriteMarkiPgOne APND_MARK_FOS_SZpFile == ORIGFILE(paf)apndReadapndClosesqlite3_completion_initsqlite3CompletionVtabInitcompletion"completion"completionBestIndexprefixIdxwholelineIdxCOMPLETION_COLUMN_PREFIXCOMPLETION_COLUMN_WHOLELINE50005000.0(double)5000500completionFiltercompletion_cursor *pCur->zLine[i-1](pCur->zLine[i-1])COMPLETION_FIRST_PHASEcompletionEofCOMPLETION_EOFcompletionRowidcompletionColumnCOMPLETION_COLUMN_CANDIDATECOMPLETION_COLUMN_PHASEcompletionNexteNextPhaseCOMPLETION_KEYWORDSCOMPLETION_DATABASESCOMPLETION_TABLESpS2%z%sSELECT name FROM "%w".sqlite_schema"%z%s"
               "SELECT name FROM \"%w\".sqlite_schema" UNION " UNION "COMPLETION_COLUMNS%z%sSELECT pti.name FROM "%w".sqlite_schema AS sm JOIN pragma_table_xinfo(sm.name,%Q) AS pti WHERE sm.type='table'"%z%s"
               "SELECT pti.name FROM \"%w\".sqlite_schema AS sm"
                       " JOIN pragma_table_xinfo(sm.name,%Q) AS pti"
               " WHERE sm.type='table'"char[115]completionClosecompletionCursorResetcompletionOpensizeof(*pCur)completion_vtab *completionDisconnectcompletionConnectCREATE TABLE x(  candidate TEXT,  prefix TEXT HIDDEN,  wholeline TEXT HIDDEN,  phase INT HIDDEN)"CREATE TABLE x("
      "  candidate TEXT,"
      "  prefix TEXT HIDDEN,"
      "  wholeline TEXT HIDDEN,"
      "  phase INT HIDDEN"        /* Used for debugging only */
      ")"char[97]sqlite3_fileio_init524289lsmode"lsmode"fsdirRegisterfsdirModulefsdir"fsdir"fsdirBestIndexidxPathidxDirseenPathseenDirFSDIR_COLUMN_PATHFSDIR_COLUMN_DIR10.0fsdirFilterfsdir_cursor *table function fsdir requires an argument"table function fsdir requires an argument"argc==idxNum && (argc==1 || argc==2)table function fsdir requires a non-NULL argument"table function fsdir requires a non-NULL argument"%s/%s"%s/%s"cannot stat file: %s"cannot stat file: %s"fsdirEoffsdirRowidfsdirColumn(m)FSDIR_COLUMN_NAMEFSDIR_COLUMN_MODEFSDIR_COLUMN_MTIMEFSDIR_COLUMN_DATA61440aStaticfsdirNextiNewFsdirLevel *pLvlsizeof(FsdirLevel)cannot read directory: %s"cannot read directory: %s"fsdirSetErrmsgfsdirClosefsdirResetCursorfsdirOpenfsdirDisconnectfsdirConnectfsdir_tab *CREATE TABLE x(name,mode,mtime,data,path HIDDEN,dir HIDDEN)"CREATE TABLE x" FSDIR_SCHEMAlsModeFunciMode(iMode)0x40x20x1writefileFuncmtimewrong number of arguments to function writefile()"wrong number of arguments to function writefile()"(mode)failed to create symlink: %s"failed to create symlink: %s"failed to create directory: %s"failed to create directory: %s"failed to write file: %s"failed to write file: %s"writeFilesStat.st_mode(sStat.st_mode)zTosStat0777timesmakeDirectoryzCopypVtabCursorfileLinkStatfileStatctxErrorMsgreadfileFuncreadFileContentsmxBlobsqlite3_regexp_initregexp"regexp"2099201regexpi"regexpi"re_sql_funcReCompiled *pResetAuxReCompiled **sqlite3re_compilesizeof(*pRe)ReInput *RE_OP_ANYSTARRE_OP_ACCEPTunrecognized character"unrecognized character"unsigned char[12](int)sizeof(pRe->zInit)(int)sizeof(pRe->zInit)-2RE_OP_MATCH20470x7ff0x3f0xffff0xe0sqlite3re_freere_subcompile_stringunmatched '('"unmatched '('"RE_OP_ANY'*' without operand"'*' without operand"RE_OP_GOTORE_OP_FORK'+' without operand"'+' without operand"'?' without operand"'?' without operand"'$'RE_EOFRE_OP_ATSTART'{m,n}' without operand"'{m,n}' without operand"unmatched '{'"unmatched '{'"n less than m in '{m,n}'"n less than m in '{m,n}'"both m and n are zero in '{m,n}'"both m and n are zero in '{m,n}'"iFirstRE_OP_CC_EXCRE_OP_CC_INC':'POSIX character classes not supported"POSIX character classes not supported"RE_OP_CC_RANGERE_OP_CC_VALUEunclosed '['"unclosed '['"specialOpRE_OP_BOUNDARYRE_OP_DIGIT'D'RE_OP_NOTDIGITRE_OP_SPACE'S'RE_OP_NOTSPACERE_OP_WORD'W'RE_OP_NOTWORDre_subcompile_reiGotorePeekre_esc_charzEscafnrtv\()*.+?[$^{|}]"afnrtv\\()*.+?[$^{|}]"zTrans
	"\a\f\n\r\t\v"const char[21]const char[7]unknown \ escape"unknown \\ escape"re_hex'a' - 10'F''A' - 10re_copysizeof(p->aOp[0])sizeof(p->aArg[0])re_appendre_insertre_resizeaOpaArgsqlite3re_matchReStateSet[2]aStateSetReStateSet *pThisReStateNumber[100]unsigned short[100]aSpaceReStateNumber *pToFreeiSwap268435455 RE_STARTcPrevRE_START268435454sizeof(aSpace)sizeof(aSpace[0])sizeof(aSpace[0])*2(sizeof(aSpace[0])*2)sizeof(aSpace)/(sizeof(aSpace[0])*2)(sizeof(aSpace)/(sizeof(aSpace[0])*2))sizeof(ReStateNumber)sizeof(ReStateNumber)*2re_op_cc_inchitre_match_endre_space_charre_digit_charre_word_charre_next_char_nocase'a' - 'A're_next_char655330xfffd2400xf00x0f552960xd800573430xdfff2480xf80x0711141110x10ffffre_add_statesqlite3_series_init3008012generate_series() requires SQLite 3.8.12 or later"generate_series() requires SQLite 3.8.12 or later"generate_series"generate_series"seriesBestIndexbStartSeenunusableMaskint[7]aIdxSERIES_COLUMN_STOP == SERIES_COLUMN_START+1SERIES_COLUMN_STEP == SERIES_COLUMN_START+2op==SQLITE_INDEX_CONSTRAINT_OFFSETiCol>=0 && iCol<=2iMaskSERIES_COLUMN_STARTSERIES_COLUMN_VALUE0x0080130560x3300-13057~0x33000x01000x0200-513~0x0200-257~0x01000x10000x2000-8193~0x2000-4097~0x10000x60-97~0x60SQLITE_SERIES_CONSTRAINT_VERIFY!SQLITE_SERIES_CONSTRAINT_VERIFYfirst argument to "generate_series()" missing or unusable"first argument to \"generate_series()\" missing or unusable"0x030x212500seriesFilterseries_cursor *returnNoRowsiMin92233720325598085129223372036854775807-9223372036854775808SMALLEST_INT64iMaxLARGEST_INT648960x0380124160x3080szStep>0131840x33800x0300122880x3000pStatBufppRenoCasepVargiBeforepSetnewStateidxStrUnusedszStepdiTermSequenceSpec *seriesEofseriesRowid18446744069414584320LARGEST_UINT64seriesColumnSERIES_COLUMN_STOPSERIES_COLUMN_STEPseriesNextseriesCloseseriesOpenseriesDisconnectseriesConnectCREATE TABLE x(value,start hidden,stop hidden,step hidden)"CREATE TABLE x(value,start hidden,stop hidden,step hidden)"progressSequencesetupSequencebSameSignsnuspan18446744073709551614-9223372036854775807puspangenSeqMemberconst sqlite3_uint64mxI644611686018427387903mxI64/2(mxI64/2)4611686018427387904mxI64 - mxI64/2(mxI64 - mxI64/2)ix2(sqlite3_uint64)0x7fffffff((sqlite3_uint64)0x7fffffff)((sqlite3_uint64)0x7fffffff)<<32((sqlite3_uint64)0x7fffffff)<<32 | 0xffffffffsqlite3_ieee_initieee754"ieee754"ieee754_mantissa"ieee754_mantissa"ieee754_exponent"ieee754_exponent"ieee754_to_blob"ieee754_to_blob"ieee754_from_blob"ieee754_from_blob"ieee754_inc"ieee754_inc"ieee754incm1m2r2ieee754func_to_blobunsigned char[8]ieee754func_from_blobsizeof(double)ieee754funcsizeof(m)==sizeof(r)isNegzResultsizeof(a)(sqlite3_int64)1((sqlite3_int64)1)4503599627370496((sqlite3_int64)1)<<52(((sqlite3_int64)1)<<52)4503599627370495(((sqlite3_int64)1)<<52)-1((((sqlite3_int64)1)<<52)-1)1075sizeof(zResult)ieee754(%lld,%d)"ieee754(%lld,%d)"-10000-100042928701440xffe0000042939187200xfff00000(sqlite3_uint64)1((sqlite3_uint64)1)9223372036854775808((sqlite3_uint64)1)<<63sqlite3_base85_initbase85"base85"209920026234882623489sqlite3_value *[]nbnvnvMaxcBufbBufna==1blob expanded to base85 too big"blob expanded to base85 too big"blob from base85 may be too big"blob from base85 may be too big"base85 accepts only blob or text."base85 accepts only blob or text."memFailbase85 OOM"base85 OOM"fromBase85signed char[6]signed char[]nboipUseqvntinbosigned char *cdou8[5]unsigned char[5]toBase85dvncoqbvnqv85ULB85_DARK_MAXnbeputcsskipNonB85sqlite3_base64_initbase64"base64"2/3B64_DARK_MAX(B64_DARK_MAX-1)blob expanded to base64 too big"blob expanded to base64 too big"blob from base64 may be too big"blob from base64 may be too big"base64 accepts only blob or text"base64 accepts only blob or text"base64 OOM"base64 OOM"fromBase64PAD_CHARsigned char[5]nacconst char[65]64+1bdpconst u8[128]unsigned char[128]NDWSPCskipNonB64BX_DV_PROTO(c)((((u8)(c))<0x80)? (u8)(b64DigitValues[(u8)(c)]) : 0x80)toBase64pIn[0]>>2((pIn[0]<<4)|(pIn[1]>>4))&0x3f((pIn[1]&0xf)<<2)|(pIn[2]>>6)pIn[2]&0x3f(u8)(qv & 0x3f)cesqlite3_percentile_initconst PercentileFuncconst PercentileFunc[4]PercentileFunc[4]sizeof(aPercentFunc)const PercentileFunc *PercentileFunc *sizeof(aPercentFunc[0])sizeof(aPercentFunc)/sizeof(aPercentFunc[0])35651585percentValuepercentFinalpercentComputePercentile *i1i2v1v2ixvxp->nUsed>1percentInverseyargc==2 || argc==1p!=0sizeof(p->a[0])percentSortiLtiGtrPivotn>=2a[0]a[n-1]ttta[i]a[iGt]a[iLt]pUnusedargvUnusedpzErrUnusedpsssmBasesmStepnaavpInncInnbInpSepbIsFinalpercentSteprPctthe fraction argument to %%s() is not between 0.0 and %.1f"the fraction argument to %%s()"
                        " is not between 0.0 and %.1f"the fraction argument to %%s() is not the same for all input rows"the fraction argument to %%s()"
                      " is not the same for all input rows"input to %%s() is not numeric"input to %%s() is not numeric"Inf input to %%s()"Inf input to %%s()"250percentErrorzMsg1zMsg2percentBinarySearchiLastiMidpercentSameValue0.0010000000000000000210.001-0.001000000000000000021-0.001percentIsInfinitysizeof(u)==sizeof(r)sizeof(u)sqlite3_decimal_initdecimal_sum"decimal_sum"decimal"decimal"decimal_exp"decimal_exp"decimal_cmp"decimal_cmp"decimal_add"decimal_add"decimal_sub"decimal_sub"decimal_mul"decimal_mul"decimal_pow2"decimal_pow2"decimalPow2FuncDecimal *pAdecimalMulFuncpBmul_enddecimalSumFinalizedecimalSumValuedecimalSumInversedecimalSumStepdecimalSubFuncdecimalAddFuncdecimalCollFuncnotUsedconst Decimalconst Decimal *decimalFuncdecimalFromDouble971decimalPow220000-20000"1.0"2.0"2.0""0.5"pow2_faultdecimalMulaccminFraccarrynSignFracnDigitaAaBborrowdecimal_expandnAddSignAddFracdecimalCmpFunc+1cmp_donenASignBSigpTempdecimal_result_scinZeroe%+03d"e%+03d"decimal_resultdecimal_newnew_faileddecimalNewFromTextiExpzIn[i](zIn[i])'E'negnew_from_text_faileddecimal_freedecimal_clearsqlite3_uint_init"uint"uintCollFunczA[i](zA[i])zB[j](zB[j])zA[i+k](zA[i+k])zB[j+k](zB[j+k])sqlite3_sha_initonesha1"sha1"sha1b"sha1b"sha1_query"sha1_query"sha1QueryFunccxSHA1Context *error SQL statement [%s]: %s"error SQL statement [%s]: %s"non-query: [%s]"non-query: [%s]"S%d:"S%d:"R"R""N"unsigned char[9]'I'T%d:"T%d:"B%d:"B%d:"sha1Funchash_finishfinalcountunsigned char[20]digestzEncode0123456789abcdef"0123456789abcdef"unsigned int[2]"\200"504448 "\0"unsigned int[5]bExactnKey1pKey1nKey2pKey2bTextOnlybAsBinaryconst char[17]hash_step_vformathash_stepunsigned char[64]hash_init17325841930x6745230140232334170xEFCDAB8925623831020x98BADCFE2717338780x1032547632853775200xC3D2E1F0SHA1Transformconst unsigned char[64]qqblocksizeof(unsigned int)5*sizeof(unsigned int)qq[0]qq[1]qq[2]qq[3]qq[4]block[0]32-(8)32-(5)32-(2)block[1]block[2]block[3]block[4]block[5]block[6]block[7]block[8]block[9]block[10]block[11]block[12]block[13]block[14]block[15]4278255360167119351518500249bufferblock[(16+13)&15]^block[(16+8)&15] ^block[(16+2)&15]^block[16&15]32-(1)block[(17+13)&15]^block[(17+8)&15] ^block[(17+2)&15]^block[17&15]block[(18+13)&15]^block[(18+8)&15] ^block[(18+2)&15]^block[18&15]block[(19+13)&15]^block[(19+8)&15] ^block[(19+2)&15]^block[19&15]block[(20+13)&15]^block[(20+8)&15] ^block[(20+2)&15]^block[20&15]1859775393block[(21+13)&15]^block[(21+8)&15] ^block[(21+2)&15]^block[21&15]block[(22+13)&15]^block[(22+8)&15] ^block[(22+2)&15]^block[22&15]block[(23+13)&15]^block[(23+8)&15] ^block[(23+2)&15]^block[23&15]block[(24+13)&15]^block[(24+8)&15] ^block[(24+2)&15]^block[24&15]block[(25+13)&15]^block[(25+8)&15] ^block[(25+2)&15]^block[25&15]block[(26+13)&15]^block[(26+8)&15] ^block[(26+2)&15]^block[26&15]block[(27+13)&15]^block[(27+8)&15] ^block[(27+2)&15]^block[27&15]block[(28+13)&15]^block[(28+8)&15] ^block[(28+2)&15]^block[28&15]block[(29+13)&15]^block[(29+8)&15] ^block[(29+2)&15]^block[29&15]block[(30+13)&15]^block[(30+8)&15] ^block[(30+2)&15]^block[30&15]block[(31+13)&15]^block[(31+8)&15] ^block[(31+2)&15]^block[31&15]block[(32+13)&15]^block[(32+8)&15] ^block[(32+2)&15]^block[32&15]block[(33+13)&15]^block[(33+8)&15] ^block[(33+2)&15]^block[33&15]block[(34+13)&15]^block[(34+8)&15] ^block[(34+2)&15]^block[34&15]block[(35+13)&15]^block[(35+8)&15] ^block[(35+2)&15]^block[35&15]block[(36+13)&15]^block[(36+8)&15] ^block[(36+2)&15]^block[36&15]block[(37+13)&15]^block[(37+8)&15] ^block[(37+2)&15]^block[37&15]block[(38+13)&15]^block[(38+8)&15] ^block[(38+2)&15]^block[38&15]block[(39+13)&15]^block[(39+8)&15] ^block[(39+2)&15]^block[39&15]block[(40+13)&15]^block[(40+8)&15] ^block[(40+2)&15]^block[40&15]2400959708block[(41+13)&15]^block[(41+8)&15] ^block[(41+2)&15]^block[41&15]block[(42+13)&15]^block[(42+8)&15] ^block[(42+2)&15]^block[42&15]block[(43+13)&15]^block[(43+8)&15] ^block[(43+2)&15]^block[43&15]block[(44+13)&15]^block[(44+8)&15] ^block[(44+2)&15]^block[44&15]block[(45+13)&15]^block[(45+8)&15] ^block[(45+2)&15]^block[45&15]block[(46+13)&15]^block[(46+8)&15] ^block[(46+2)&15]^block[46&15]block[(47+13)&15]^block[(47+8)&15] ^block[(47+2)&15]^block[47&15]block[(48+13)&15]^block[(48+8)&15] ^block[(48+2)&15]^block[48&15]block[(49+13)&15]^block[(49+8)&15] ^block[(49+2)&15]^block[49&15]block[(50+13)&15]^block[(50+8)&15] ^block[(50+2)&15]^block[50&15]block[(51+13)&15]^block[(51+8)&15] ^block[(51+2)&15]^block[51&15]block[(52+13)&15]^block[(52+8)&15] ^block[(52+2)&15]^block[52&15]block[(53+13)&15]^block[(53+8)&15] ^block[(53+2)&15]^block[53&15]block[(54+13)&15]^block[(54+8)&15] ^block[(54+2)&15]^block[54&15]block[(55+13)&15]^block[(55+8)&15] ^block[(55+2)&15]^block[55&15]block[(56+13)&15]^block[(56+8)&15] ^block[(56+2)&15]^block[56&15]block[(57+13)&15]^block[(57+8)&15] ^block[(57+2)&15]^block[57&15]block[(58+13)&15]^block[(58+8)&15] ^block[(58+2)&15]^block[58&15]block[(59+13)&15]^block[(59+8)&15] ^block[(59+2)&15]^block[59&15]block[(60+13)&15]^block[(60+8)&15] ^block[(60+2)&15]^block[60&15]3395469782block[(61+13)&15]^block[(61+8)&15] ^block[(61+2)&15]^block[61&15]block[(62+13)&15]^block[(62+8)&15] ^block[(62+2)&15]^block[62&15]block[(63+13)&15]^block[(63+8)&15] ^block[(63+2)&15]^block[63&15]block[(64+13)&15]^block[(64+8)&15] ^block[(64+2)&15]^block[64&15]block[(65+13)&15]^block[(65+8)&15] ^block[(65+2)&15]^block[65&15]block[(66+13)&15]^block[(66+8)&15] ^block[(66+2)&15]^block[66&15]block[(67+13)&15]^block[(67+8)&15] ^block[(67+2)&15]^block[67&15]block[(68+13)&15]^block[(68+8)&15] ^block[(68+2)&15]^block[68&15]block[(69+13)&15]^block[(69+8)&15] ^block[(69+2)&15]^block[69&15]block[(70+13)&15]^block[(70+8)&15] ^block[(70+2)&15]^block[70&15]block[(71+13)&15]^block[(71+8)&15] ^block[(71+2)&15]^block[71&15]block[(72+13)&15]^block[(72+8)&15] ^block[(72+2)&15]^block[72&15]block[(73+13)&15]^block[(73+8)&15] ^block[(73+2)&15]^block[73&15]block[(74+13)&15]^block[(74+8)&15] ^block[(74+2)&15]^block[74&15]block[(75+13)&15]^block[(75+8)&15] ^block[(75+2)&15]^block[75&15]block[(76+13)&15]^block[(76+8)&15] ^block[(76+2)&15]^block[76&15]block[(77+13)&15]^block[(77+8)&15] ^block[(77+2)&15]^block[77&15]block[(78+13)&15]^block[(78+8)&15] ^block[(78+2)&15]^block[78&15]block[(79+13)&15]^block[(79+8)&15] ^block[(79+2)&15]^block[79&15]sqlite3_shathree_initsha3"sha3"sha3_agg"sha3_agg"sha3_query"sha3_query"sha3AggFinalSHA3Context *1616sha3AggStep 256384sha3QueryFuncSHA3 size should be one of: 224 256 384 512"SHA3 size should be one of: 224 256 "
                                    "384 512"sha3UpdateFromValuesha3_step_vformatsha3FuncSHA3Finalc10x86c3unsigned char[1600]1600SHA3Update(const unsigned char*)0u64[25]unsigned long long[25]SHA3Init-32~312*25610881600 - 2*256(1600 - 2*256)(1600 - 2*256)/8KeccakF1600Stepb0b1b2b3b4c0c4d0d1d2d3d4const u64const u64[]unsigned long long[]RC(a11^d1)((p->u.s[6])^d1)(a22^d2)((p->u.s[12])^d2)(a33^d3)((p->u.s[18])^d3)(a44^d4)((p->u.s[24])^d4)(a20^d0)((p->u.s[10])^d0)(a31^d1)((p->u.s[16])^d1)(a42^d2)((p->u.s[22])^d2)(a03^d3)((p->u.s[3])^d3)(a14^d4)((p->u.s[9])^d4)(a40^d0)((p->u.s[20])^d0)(a01^d1)((p->u.s[1])^d1)(a12^d2)((p->u.s[7])^d2)(a23^d3)((p->u.s[13])^d3)(a34^d4)((p->u.s[19])^d4)(a10^d0)((p->u.s[5])^d0)(a21^d1)((p->u.s[11])^d1)(a32^d2)((p->u.s[17])^d2)(a43^d3)((p->u.s[23])^d3)(a04^d4)((p->u.s[4])^d4)(a30^d0)((p->u.s[15])^d0)(a41^d1)((p->u.s[21])^d1)(a02^d2)((p->u.s[2])^d2)(a13^d3)((p->u.s[8])^d3)(a24^d4)((p->u.s[14])^d4)const u64[24]unsigned long long[24]const u64 *0x0000000000000001ULL328980x0000000000008082ULL92233720368548087140x800000000000808aULL92233720390022922240x8000000080008000ULL329070x000000000000808bULL21474836490x0000000080000001ULL92233720390022923530x8000000080008081ULL92233720368548085850x8000000000008009ULL0x000000000000008aULL0x0000000000000088ULL21475164250x0000000080008009ULL21474836580x000000008000000aULL21475165550x000000008000808bULL92233720368547759470x800000000000008bULL92233720368548087130x8000000000008089ULL92233720368548085790x8000000000008003ULL92233720368548085780x8000000000008002ULL92233720368547759360x8000000000000080ULL327780x000000000000800aULL92233720390022594660x800000008000000aULL92233720368548087040x8000000000008080ULL92233720390022922320x8000000080008008ULLsqlite3PcacheTraceDeactivatesqlite3_pcache_methods2 *sizeof(pcacheBase)sqlite3PcacheTraceActivatepcachetraceShrinkPCACHETRACE: xShrink(%p)
"PCACHETRACE: xShrink(%p)\n"pcachetraceDestroyPCACHETRACE: xDestroy(%p)
"PCACHETRACE: xDestroy(%p)\n"pcachetraceTruncatePCACHETRACE: xTruncate(%p, %u)
"PCACHETRACE: xTruncate(%p, %u)\n"pcachetraceRekeyPCACHETRACE: xRekey(%p, %p, %u, %u)
"PCACHETRACE: xRekey(%p, %p, %u, %u)\n"pcachetraceUnpinPCACHETRACE: xUnpin(%p, %p, %d)
"PCACHETRACE: xUnpin(%p, %p, %d)\n"pcachetraceFetchpResPCACHETRACE: xFetch(%p,%u,%d)
"PCACHETRACE: xFetch(%p,%u,%d)\n"PCACHETRACE: xFetch(%p,%u,%d) -> %p
"PCACHETRACE: xFetch(%p,%u,%d) -> %p\n"pcachetracePagecountPCACHETRACE: xPagecount(%p)
"PCACHETRACE: xPagecount(%p)\n"PCACHETRACE: xPagecount(%p) -> %d
"PCACHETRACE: xPagecount(%p) -> %d\n"pcachetraceCachesizePCACHETRACE: xCachesize(%p, %d)
"PCACHETRACE: xCachesize(%p, %d)\n"pcachetraceCreatePCACHETRACE: xCreate(%d,%d,%d)
"PCACHETRACE: xCreate(%d,%d,%d)\n"PCACHETRACE: xCreate(%d,%d,%d) -> %p
"PCACHETRACE: xCreate(%d,%d,%d) -> %p\n"pcachetraceShutdownPCACHETRACE: xShutdown(%p)
"PCACHETRACE: xShutdown(%p)\n"pcachetraceInitPCACHETRACE: xInit(%p)
"PCACHETRACE: xInit(%p)\n"PCACHETRACE: xInit(%p) -> %d
"PCACHETRACE: xInit(%p) -> %d\n"sqlite3MemTraceDeactivatesqlite3_mem_methods *sizeof(memtraceBase)sqlite3MemTraceActivatememtraceShutdownmemtraceInitmemtraceRoundupmemtraceSizememtraceReallocMEMTRACE: resize %d -> %d bytes
"MEMTRACE: resize %d -> %d bytes\n"memtraceFreeMEMTRACE: free %d bytes
"MEMTRACE: free %d bytes\n"memtraceMallocMEMTRACE: allocate %d bytes
"MEMTRACE: allocate %d bytes\n"shellAddSchemaNameaPrefixCREATE "CREATE "ArraySize(aPrefix)zFake%.*s "%w".%s"%.*s \"%w\".%s"%.*s %s.%s"%.*s %s.%s"'V'%s
/* %s */"%s\n/* %s */"%z
/* %s */"%z\n/* %s */"INDEX"INDEX"UNIQUE INDEX"UNIQUE INDEX"VIEW"VIEW"TRIGGER"TRIGGER"VIRTUAL TABLE"VIRTUAL TABLE"shellModuleSchema/* %s */"/* %s */"shellDtostrchar[400]400350%#+.*e"%#+.*e"shellStrtodshellFakeSchemaPRAGMA "%w".table_info=%Q;"PRAGMA \"%w\".table_info=%Q;"."."quoteChar(unsigned char)zName[0]((unsigned char)zName[0])(unsigned char)zName[i]((unsigned char)zName[i])appendTextzCsrfreeTextinitTextintegerValueaMult(unsigned char)zArg[0]((unsigned char)zArg[0])ArraySize(aMult)KiB"KiB"MiB"MiB"1024*1024GiB"GiB"1024*1024*1024KB"KB"MB"MB"GB"GB""K""M"G"G"hexDigitValueone_input_linezPromptlocal_getlineopenChrSourcex.st_mode(x.st_mode)strlenCharstrlen3010737418230x3fffffffisNumberutf8_width_printaw%*s%s"%*s%s"%s%*s"%s%*s"decodeUtf8cli_wcwidth0x300const struct <unnamed>[305]struct <unnamed>[305]2440sizeof(aUWidth)sizeof(aUWidth[0])305sizeof(aUWidth)/sizeof(aUWidth[0])304sizeof(aUWidth)/sizeof(aUWidth[0]) - 1cMidshell_check_oomshell_out_of_memorydynamicContinuePromptncpndp(.."(..")x!")x!"(x."(x."setLexemeOpentrackParenLevelshell_strcpyshell_strncpyendTimersEndRun Time: real %.3f user %f sys %f
"Run Time: real %.3f user %f sys %f\n"timeDiff9.999999999999999547e-070.000001beginTimertimeOfDayclockVfst86400000.0cli_strncmppPgoldKeynewKeybDiscardcrFgnCachesizeszPageszExtrabPurgezPriorisContinuationrealnumzUtfpUnisrcpStartcli_strcmpQuickScanState1<<CHAR_BIT2<<CHAR_BITQSS_CharMask(1<<CHAR_BIT)(1<<CHAR_BIT)-1QSS_ScanMask3<<CHAR_BITArCommandImportCtxShellStateAuxDbColModeOptsEQPGraphEQPGraphRowExpertInfoRecoverGlobalDbdataCursorDbdataBufferDbdataTablesqlite3_recoverRecoverStateLAFRecoverBitmapRecoverStateW1RecoverTableRecoverColumnvfstrace_filevfstrace_infoStmtrandsqlite3_intckIdxRemCtxIdxRemSlotIdxSampleCtxExpertCsrExpertVtabsqlite3expertIdxHashIdxHashEntryIdxStatementIdxWriteIdxScanIdxConstraintIdxTableIdxColumnZipfileCtxZipfileBufferZipfileTabZipfileCsrZipfileEntryZipfileLFHZipfileCDSZipfileEOCDApndFileApndVfscompletion_cursorcompletion_vtabfsdir_tabfsdir_cursorFsdirLevelReCompiledReInputReStateSetReStateNumberseries_cursorSequenceSpecPercentileFuncPercentileDecimalSHA1ContextSHA3ContextShellTextt_DynaPromptRefDynaPromptu8u64i64u16u32bDsplymaskzUsageunSafectrlCodezCtrlNamelimitCodezLimitNamebArgcShortzDesciAuxzFNameiMultnRepeatnHitiIntervaliCntiErrzSrcTablebAppendbDryRunbZipeCmdcRowSepcColSepcTermbNotFirstxClosersGraphzNoncenIndentaiIndentpAuxDbaAuxDbzFreeOnClosepLogoutfilenullValueactualWidthcolWidthrowSepPriorcolSepPriorrowSeparatorcolSeparatorzTestcasezDestTableszMaxpriorShFlgsshellFlgsflgProgressmxProgressnProgressnCheckshowHeaderwritableSchemanormalModecModemodePriortraceOutlinenooutCountinputNestingmEqpLinesstatsOncrlfModeeRestoreStatebSafeModePersistbSafeModeeTraceTypenEqpLeveldoXdgOpenscanstatsOnautoEQPtraceautoEQPtestautoEQPautoExplainbQuoteiWrapiIntkeypPtrpHdrPtrnRecrecbOnePageaPagebasebPtrpTblListpGetPagedbOutlafnMaxFieldpAllPagepFindRootpUsedPagespMaxFieldpMapInsertpAllAndParentpUsedaElemw1iPrevPageiRowidBindbIntkeyaColbIPKnInsertpTblsbCloseTransactioneStatepPage1CachepPage1Diskdetected_pgszbSlowIndexesbRecoverRowidbFreelistCorruptzLostAndFoundzStateDbdbInpRealpTraceVfsbOnmTracepRootVfszTestSqlbCorruptSchemazMessagenKeyValpCheckaSlotnSlotrValtargetiTargetzCandidatesaHashpHashNextzVal2bRunpNextScanpRangepOrderpLinkbDescbFlagbRangecoveringiDbpTabledbvcdsbodyszOrigszCurrentpWriteFdpLastEntrypFirstEntryiNextCsridpCsrListpCsrNextpFreeEntryiNextOffbNoopbEofiDataOffszCompressedmDateiCompressioniVersionExtractiExternalAttriInternalAttriDiskStartnCommentiVersionMadeBynSizenEntryTotaliFirstDiskiDiskePhaseszRowzCurrentRownPrefixnBasezBaseaLvlpDiriLvlnLvlnStatenInitzInitxNextCharsInmxaStatessisReversingisNotEOFiValueNowuSeqIndexNowuSeqIndexMaxiStepiBaseiOTermiOBasebDiscretemxFracbPctValidbKeepSortedbSortednUsedisInitisNulloomsignixMasknLoadednRatezScannerAwaitsinParenLevelacAwaitdynamicPromptzOptions   --                   treat no subsequent arguments as options
   -A ARGS...           run ".archive ARGS" and exit
   -append              append the database to the end of the file
   -ascii               set output mode to 'ascii'
   -bail                stop after hitting an error
   -batch               force batch I/O
   -box                 set output mode to 'box'
   -column              set output mode to 'column'
   -cmd COMMAND         run "COMMAND" before reading stdin
   -csv                 set output mode to 'csv'
   -deserialize         open the database using sqlite3_deserialize()
   -echo                print inputs before execution
   -init FILENAME       read/process named file
   -[no]header          turn headers on or off
   -help                show this message
   -html                set output mode to HTML
   -interactive         force interactive I/O
   -json                set output mode to 'json'
   -line                set output mode to 'line'
   -list                set output mode to 'list'
   -lookaside SIZE N    use N entries of SZ bytes for lookaside memory
   -markdown            set output mode to 'markdown'
   -maxsize N           maximum size for a --deserialize database
   -memtrace            trace all memory allocations and deallocations
   -mmap N              default mmap size set to N
   -newline SEP         set output row separator. Default: '\n'
   -nofollow            refuse to open symbolic links to database files
   -nonce STRING        set the safe-mode escape nonce
   -no-rowid-in-view    Disable rowid-in-view using sqlite3_config()
   -nullvalue TEXT      set text string for NULL values. Default ''
   -pagecache SIZE N    use N slots of SZ bytes each for page cache memory
   -pcachetrace         trace all page cache operations
   -quote               set output mode to 'quote'
   -readonly            open the database read-only
   -safe                enable safe-mode
   -separator SEP       set output column separator. Default: '|'
   -stats               print memory stats before each finalize
   -table               set output mode to 'table'
   -tabs                set output mode to 'tabs'
   -unsafe-testing      allow unsafe commands and modes for testing
   -version             show SQLite version
   -vfs NAME            use NAME as the default VFS
   -vfstrace            enable tracing of all VFS calls
   -zip                 open the file as a ZIP Archive
"   --                   treat no subsequent arguments as options\n"
#if defined(SQLITE_HAVE_ZLIB) && !defined(SQLITE_OMIT_VIRTUALTABLE)
  "   -A ARGS...           run \".archive ARGS\" and exit\n"
#endif
  "   -append              append the database to the end of the file\n"
  "   -ascii               set output mode to 'ascii'\n"
  "   -bail                stop after hitting an error\n"
  "   -batch               force batch I/O\n"
  "   -box                 set output mode to 'box'\n"
  "   -column              set output mode to 'column'\n"
  "   -cmd COMMAND         run \"COMMAND\" before reading stdin\n"
  "   -csv                 set output mode to 'csv'\n"
#if !defined(SQLITE_OMIT_DESERIALIZE)
  "   -deserialize         open the database using sqlite3_deserialize()\n"
#endif
  "   -echo                print inputs before execution\n"
  "   -init FILENAME       read/process named file\n"
  "   -[no]header          turn headers on or off\n"
#if defined(SQLITE_ENABLE_MEMSYS3) || defined(SQLITE_ENABLE_MEMSYS5)
  "   -heap SIZE           Size of heap for memsys3 or memsys5\n"
#endif
  "   -help                show this message\n"
  "   -html                set output mode to HTML\n"
  "   -interactive         force interactive I/O\n"
  "   -json                set output mode to 'json'\n"
  "   -line                set output mode to 'line'\n"
  "   -list                set output mode to 'list'\n"
  "   -lookaside SIZE N    use N entries of SZ bytes for lookaside memory\n"
  "   -markdown            set output mode to 'markdown'\n"
#if !defined(SQLITE_OMIT_DESERIALIZE)
  "   -maxsize N           maximum size for a --deserialize database\n"
#endif
  "   -memtrace            trace all memory allocations and deallocations\n"
  "   -mmap N              default mmap size set to N\n"
#ifdef SQLITE_ENABLE_MULTIPLEX
  "   -multiplex           enable the multiplexor VFS\n"
#endif
  "   -newline SEP         set output row separator. Default: '\\n'\n"
  "   -nofollow            refuse to open symbolic links to database files\n"
  "   -nonce STRING        set the safe-mode escape nonce\n"
  "   -no-rowid-in-view    Disable rowid-in-view using sqlite3_config()\n"
  "   -nullvalue TEXT      set text string for NULL values. Default ''\n"
  "   -pagecache SIZE N    use N slots of SZ bytes each for page cache memory\n"
  "   -pcachetrace         trace all page cache operations\n"
  "   -quote               set output mode to 'quote'\n"
  "   -readonly            open the database read-only\n"
  "   -safe                enable safe-mode\n"
  "   -separator SEP       set output column separator. Default: '|'\n"
#ifdef SQLITE_ENABLE_SORTER_REFERENCES
  "   -sorterref SIZE      sorter references threshold size\n"
#endif
  "   -stats               print memory stats before each finalize\n"
  "   -table               set output mode to 'table'\n"
  "   -tabs                set output mode to 'tabs'\n"
  "   -unsafe-testing      allow unsafe commands and modes for testing\n"
  "   -version             show SQLite version\n"
  "   -vfs NAME            use NAME as the default VFS\n"
  "   -vfstrace            enable tracing of all VFS calls\n"
#ifdef SQLITE_HAVE_ZLIB
  "   -zip                 open the file as a ZIP Archive\n"faultsim_statezCOL_DB.archive ...             Manage SQL archives".archive ...             Manage SQL archives"   Each command must have exactly one of the following options:"   Each command must have exactly one of the following options:"     -c, --create               Create a new archive"     -c, --create               Create a new archive"     -u, --update               Add or update files with changed mtime"     -u, --update               Add or update files with changed mtime"char[71]     -i, --insert               Like -u but always add even if unchanged"     -i, --insert               Like -u but always add even if unchanged"char[73]     -r, --remove               Remove files from archive"     -r, --remove               Remove files from archive"     -t, --list                 List contents of archive"     -t, --list                 List contents of archive"     -x, --extract              Extract files from archive"     -x, --extract              Extract files from archive"   Optional arguments:"   Optional arguments:"     -v, --verbose              Print each filename as it is processed"     -v, --verbose              Print each filename as it is processed"     -f FILE, --file FILE       Use archive FILE (default is current db)"     -f FILE, --file FILE       Use archive FILE (default is current db)"     -a FILE, --append FILE     Open FILE using the apndvfs VFS"     -a FILE, --append FILE     Open FILE using the apndvfs VFS"     -C DIR, --directory DIR    Read/extract files from directory DIR"     -C DIR, --directory DIR    Read/extract files from directory DIR"     -g, --glob                 Use glob matching for names in archive"     -g, --glob                 Use glob matching for names in archive"     -n, --dryrun               Show the SQL that would have occurred"     -n, --dryrun               Show the SQL that would have occurred"   Examples:"   Examples:"     .ar -cf ARCHIVE foo bar  # Create ARCHIVE from files foo and bar"     .ar -cf ARCHIVE foo bar  # Create ARCHIVE from files foo and bar"     .ar -tf ARCHIVE          # List members of ARCHIVE"     .ar -tf ARCHIVE          # List members of ARCHIVE"     .ar -xvf ARCHIVE         # Verbosely extract files from ARCHIVE"     .ar -xvf ARCHIVE         # Verbosely extract files from ARCHIVE"   See also:"   See also:"      http://sqlite.org/cli.html#sqlite_archive_support"      http://sqlite.org/cli.html#sqlite_archive_support".auth ON|OFF             Show authorizer callbacks".auth ON|OFF             Show authorizer callbacks".backup ?DB? FILE        Backup DB (default "main") to FILE".backup ?DB? FILE        Backup DB (default \"main\") to FILE"   Options:"   Options:"       --append            Use the appendvfs"       --append            Use the appendvfs"       --async             Write to FILE without journal and fsync()"       --async             Write to FILE without journal and fsync()".bail on|off             Stop after hitting an error.  Default OFF".bail on|off             Stop after hitting an error.  Default OFF".cd DIRECTORY            Change the working directory to DIRECTORY".cd DIRECTORY            Change the working directory to DIRECTORY".changes on|off          Show number of rows changed by SQL".changes on|off          Show number of rows changed by SQL".check GLOB              Fail if output since .testcase does not match".check GLOB              Fail if output since .testcase does not match".clone NEWDB             Clone data into NEWDB from the existing database".clone NEWDB             Clone data into NEWDB from the existing database"char[74].connection [close] [#]  Open or close an auxiliary database connection".connection [close] [#]  Open or close an auxiliary database connection".crlf ?on|off?           Whether or not to use \r\n line endings".crlf ?on|off?           Whether or not to use \\r\\n line endings".databases               List names and files of attached databases".databases               List names and files of attached databases".dbconfig ?op? ?val?     List or change sqlite3_db_config() options".dbconfig ?op? ?val?     List or change sqlite3_db_config() options".dbinfo ?DB?             Show status information about the database".dbinfo ?DB?             Show status information about the database".dbtotxt                 Hex dump of the database file".dbtotxt                 Hex dump of the database file".dump ?OBJECTS?          Render database content as SQL".dump ?OBJECTS?          Render database content as SQL"     --data-only            Output only INSERT statements"     --data-only            Output only INSERT statements"     --newlines             Allow unescaped newline characters in output"     --newlines             Allow unescaped newline characters in output"     --nosys                Omit system tables (ex: "sqlite_stat1")"     --nosys                Omit system tables (ex: \"sqlite_stat1\")"     --preserve-rowids      Include ROWID values in the output"     --preserve-rowids      Include ROWID values in the output"   OBJECTS is a LIKE pattern for tables, indexes, triggers or views to dump"   OBJECTS is a LIKE pattern for tables, indexes, triggers or views to dump"   Additional LIKE patterns can be given in subsequent arguments"   Additional LIKE patterns can be given in subsequent arguments".echo on|off             Turn command echo on or off".echo on|off             Turn command echo on or off".eqp on|off|full|...     Enable or disable automatic EXPLAIN QUERY PLAN".eqp on|off|full|...     Enable or disable automatic EXPLAIN QUERY PLAN"   Other Modes:"   Other Modes:"      trigger               Like "full" but also show trigger bytecode"      trigger               Like \"full\" but also show trigger bytecode".excel                   Display the output of next command in spreadsheet".excel                   Display the output of next command in spreadsheet"   --bom                   Put a UTF8 byte-order mark on intermediate file"   --bom                   Put a UTF8 byte-order mark on intermediate file".exit ?CODE?             Exit this program with return-code CODE".exit ?CODE?             Exit this program with return-code CODE".expert                  EXPERIMENTAL. Suggest indexes for queries".expert                  EXPERIMENTAL. Suggest indexes for queries".explain ?on|off|auto?   Change the EXPLAIN formatting mode.  Default: auto".explain ?on|off|auto?   Change the EXPLAIN formatting mode.  Default: auto".filectrl CMD ...        Run various sqlite3_file_control() operations".filectrl CMD ...        Run various sqlite3_file_control() operations"   --schema SCHEMA         Use SCHEMA instead of "main""   --schema SCHEMA         Use SCHEMA instead of \"main\""   --help                  Show CMD details"   --help                  Show CMD details".fullschema ?--indent?   Show schema and the content of sqlite_stat tables".fullschema ?--indent?   Show schema and the content of sqlite_stat tables".headers on|off          Turn display of headers on or off".headers on|off          Turn display of headers on or off".help ?-all? ?PATTERN?   Show help text for PATTERN".help ?-all? ?PATTERN?   Show help text for PATTERN".import FILE TABLE       Import data from FILE into TABLE".import FILE TABLE       Import data from FILE into TABLE"     --ascii               Use \037 and \036 as column and row separators"     --ascii               Use \\037 and \\036 as column and row separators"     --csv                 Use , and \n as column and row separators"     --csv                 Use , and \\n as column and row separators"     --skip N              Skip the first N rows of input"     --skip N              Skip the first N rows of input"     --schema S            Target table to be S.TABLE"     --schema S            Target table to be S.TABLE"     -v                    "Verbose" - increase auxiliary output"     -v                    \"Verbose\" - increase auxiliary output"   Notes:"   Notes:"     *  If TABLE does not exist, it is created.  The first row of input"     *  If TABLE does not exist, it is created.  The first row of input"        determines the column names."        determines the column names."     *  If neither --csv or --ascii are used, the input mode is derived"     *  If neither --csv or --ascii are used, the input mode is derived"        from the ".mode" output mode"        from the \".mode\" output mode"     *  If FILE begins with "|" then it is a command that generates the"     *  If FILE begins with \"|\" then it is a command that generates the"        input text."        input text.",imposter INDEX TABLE    Create imposter table TABLE on index INDEX",imposter INDEX TABLE    Create imposter table TABLE on index INDEX".indexes ?TABLE?         Show names of indexes".indexes ?TABLE?         Show names of indexes"                           If TABLE is specified, only show indexes for"                           If TABLE is specified, only show indexes for"                           tables matching TABLE using the LIKE operator."                           tables matching TABLE using the LIKE operator.".intck ?STEPS_PER_UNLOCK?  Run an incremental integrity check on the db".intck ?STEPS_PER_UNLOCK?  Run an incremental integrity check on the db".limit ?LIMIT? ?VAL?     Display or change the value of an SQLITE_LIMIT".limit ?LIMIT? ?VAL?     Display or change the value of an SQLITE_LIMIT".lint OPTIONS            Report potential schema issues.".lint OPTIONS            Report potential schema issues."     Options:"     Options:"        fkey-indexes     Find missing foreign key indexes"        fkey-indexes     Find missing foreign key indexes".load FILE ?ENTRY?       Load an extension library".load FILE ?ENTRY?       Load an extension library".log FILE|on|off         Turn logging on or off.  FILE can be stderr/stdout".log FILE|on|off         Turn logging on or off.  FILE can be stderr/stdout".mode MODE ?OPTIONS?     Set output mode".mode MODE ?OPTIONS?     Set output mode"   MODE is one of:"   MODE is one of:"     ascii       Columns/rows delimited by 0x1F and 0x1E"     ascii       Columns/rows delimited by 0x1F and 0x1E"     box         Tables using unicode box-drawing characters"     box         Tables using unicode box-drawing characters"     csv         Comma-separated values"     csv         Comma-separated values"     column      Output in columns.  (See .width)"     column      Output in columns.  (See .width)"     html        HTML <table> code"     html        HTML <table> code"     insert      SQL insert statements for TABLE"     insert      SQL insert statements for TABLE"     json        Results in a JSON array"     json        Results in a JSON array"     line        One value per line"     line        One value per line"     list        Values delimited by "|""     list        Values delimited by \"|\""     markdown    Markdown table format"     markdown    Markdown table format"     qbox        Shorthand for "box --wrap 60 --quote""     qbox        Shorthand for \"box --wrap 60 --quote\""     quote       Escape answers as for SQL"     quote       Escape answers as for SQL"     table       ASCII-art table"     table       ASCII-art table"     tabs        Tab-separated values"     tabs        Tab-separated values"     tcl         TCL list elements"     tcl         TCL list elements"   OPTIONS: (for columnar modes or insert mode):"   OPTIONS: (for columnar modes or insert mode):"     --wrap N       Wrap output lines to no longer than N characters"     --wrap N       Wrap output lines to no longer than N characters"     --wordwrap B   Wrap or not at word boundaries per B (on/off)"     --wordwrap B   Wrap or not at word boundaries per B (on/off)"     --ww           Shorthand for "--wordwrap 1""     --ww           Shorthand for \"--wordwrap 1\""     --quote        Quote output text as SQL literals"     --quote        Quote output text as SQL literals"     --noquote      Do not quote output text"     --noquote      Do not quote output text"     TABLE          The name of SQL table used for "insert" mode"     TABLE          The name of SQL table used for \"insert\" mode".nonce STRING            Suspend safe mode for one command if nonce matches".nonce STRING            Suspend safe mode for one command if nonce matches".nullvalue STRING        Use STRING in place of NULL values".nullvalue STRING        Use STRING in place of NULL values".once ?OPTIONS? ?FILE?   Output for the next SQL command only to FILE".once ?OPTIONS? ?FILE?   Output for the next SQL command only to FILE"     If FILE begins with '|' then open as a pipe"     If FILE begins with '|' then open as a pipe"       --bom    Put a UTF8 byte-order mark at the beginning"       --bom    Put a UTF8 byte-order mark at the beginning"       -e       Send output to the system text editor"       -e       Send output to the system text editor"       --plain  Use text/plain output instead of HTML for -w option"       --plain  Use text/plain output instead of HTML for -w option"       -w       Send output as HTML to a web browser (same as ".www")"       -w       Send output as HTML to a web browser (same as \".www\")"       -x       Send output as CSV to a spreadsheet (same as ".excel")"       -x       Send output as CSV to a spreadsheet (same as \".excel\")".open ?OPTIONS? ?FILE?   Close existing database and reopen FILE".open ?OPTIONS? ?FILE?   Close existing database and reopen FILE"        --append        Use appendvfs to append database to the end of FILE"        --append        Use appendvfs to append database to the end of FILE"        --deserialize   Load into memory using sqlite3_deserialize()"        --deserialize   Load into memory using sqlite3_deserialize()"        --hexdb         Load the output of "dbtotxt" as an in-memory db"        --hexdb         Load the output of \"dbtotxt\" as an in-memory db"        --maxsize N     Maximum size for --hexdb or --deserialized database"        --maxsize N     Maximum size for --hexdb or --deserialized database"        --new           Initialize FILE to an empty database"        --new           Initialize FILE to an empty database"        --nofollow      Do not follow symbolic links"        --nofollow      Do not follow symbolic links"        --readonly      Open FILE readonly"        --readonly      Open FILE readonly"        --zip           FILE is a ZIP archive"        --zip           FILE is a ZIP archive"char[46].output ?FILE?           Send output to FILE or stdout if FILE is omitted".output ?FILE?           Send output to FILE or stdout if FILE is omitted"   If FILE begins with '|' then open it as a pipe."   If FILE begins with '|' then open it as a pipe."     --bom                 Prefix output with a UTF8 byte-order mark"     --bom                 Prefix output with a UTF8 byte-order mark"     -e                    Send output to the system text editor"     -e                    Send output to the system text editor"     --plain               Use text/plain for -w option"     --plain               Use text/plain for -w option"     -w                    Send output to a web browser"     -w                    Send output to a web browser"     -x                    Send output as CSV to a spreadsheet"     -x                    Send output as CSV to a spreadsheet".parameter CMD ...       Manage SQL parameter bindings".parameter CMD ...       Manage SQL parameter bindings"   clear                   Erase all bindings"   clear                   Erase all bindings"   init                    Initialize the TEMP table that holds bindings"   init                    Initialize the TEMP table that holds bindings"   list                    List the current parameter bindings"   list                    List the current parameter bindings"   set PARAMETER VALUE     Given SQL parameter PARAMETER a value of VALUE"   set PARAMETER VALUE     Given SQL parameter PARAMETER a value of VALUE"                           PARAMETER should start with one of: $ : @ ?"                           PARAMETER should start with one of: $ : @ ?"   unset PARAMETER         Remove PARAMETER from the binding table"   unset PARAMETER         Remove PARAMETER from the binding table".print STRING...         Print literal STRING".print STRING...         Print literal STRING".progress N              Invoke progress handler after every N opcodes".progress N              Invoke progress handler after every N opcodes"   --limit N                 Interrupt after N progress callbacks"   --limit N                 Interrupt after N progress callbacks"   --once                    Do no more than one progress interrupt"   --once                    Do no more than one progress interrupt"   --quiet|-q                No output except at interrupts"   --quiet|-q                No output except at interrupts"   --reset                   Reset the count for each input and interrupt"   --reset                   Reset the count for each input and interrupt".prompt MAIN CONTINUE    Replace the standard prompts".prompt MAIN CONTINUE    Replace the standard prompts".quit                    Stop interpreting input stream, exit if primary.".quit                    Stop interpreting input stream, exit if primary.".read FILE               Read input from FILE or command output".read FILE               Read input from FILE or command output"    If FILE begins with "|", it is a command that generates the input."    If FILE begins with \"|\", it is a command that generates the input.".recover                 Recover as much data as possible from corrupt db.".recover                 Recover as much data as possible from corrupt db."   --ignore-freelist        Ignore pages that appear to be on db freelist"   --ignore-freelist        Ignore pages that appear to be on db freelist"   --lost-and-found TABLE   Alternative name for the lost-and-found table"   --lost-and-found TABLE   Alternative name for the lost-and-found table"   --no-rowids              Do not attempt to recover rowid values"   --no-rowids              Do not attempt to recover rowid values"                            that are not also INTEGER PRIMARY KEYs"                            that are not also INTEGER PRIMARY KEYs".restore ?DB? FILE       Restore content of DB (default "main") from FILE".restore ?DB? FILE       Restore content of DB (default \"main\") from FILE".save ?OPTIONS? FILE     Write database to FILE (an alias for .backup ...)".save ?OPTIONS? FILE     Write database to FILE (an alias for .backup ...)".scanstats on|off|est    Turn sqlite3_stmt_scanstatus() metrics on or off".scanstats on|off|est    Turn sqlite3_stmt_scanstatus() metrics on or off".schema ?PATTERN?        Show the CREATE statements matching PATTERN".schema ?PATTERN?        Show the CREATE statements matching PATTERN"      --indent             Try to pretty-print the schema"      --indent             Try to pretty-print the schema"      --nosys              Omit objects whose names start with "sqlite_""      --nosys              Omit objects whose names start with \"sqlite_\"",selftest ?OPTIONS?      Run tests defined in the SELFTEST table",selftest ?OPTIONS?      Run tests defined in the SELFTEST table"    Options:"    Options:"       --init               Create a new SELFTEST table"       --init               Create a new SELFTEST table"       -v                   Verbose output"       -v                   Verbose output".separator COL ?ROW?     Change the column and row separators".separator COL ?ROW?     Change the column and row separators".sha3sum ...             Compute a SHA3 hash of database content".sha3sum ...             Compute a SHA3 hash of database content"      --schema              Also hash the sqlite_schema table"      --schema              Also hash the sqlite_schema table"      --sha3-224            Use the sha3-224 algorithm"      --sha3-224            Use the sha3-224 algorithm"      --sha3-256            Use the sha3-256 algorithm (default)"      --sha3-256            Use the sha3-256 algorithm (default)"      --sha3-384            Use the sha3-384 algorithm"      --sha3-384            Use the sha3-384 algorithm"      --sha3-512            Use the sha3-512 algorithm"      --sha3-512            Use the sha3-512 algorithm"    Any other argument is a LIKE pattern for tables to hash"    Any other argument is a LIKE pattern for tables to hash".shell CMD ARGS...       Run CMD ARGS... in a system shell".shell CMD ARGS...       Run CMD ARGS... in a system shell".show                    Show the current values for various settings".show                    Show the current values for various settings".stats ?ARG?             Show stats or turn stats on or off".stats ?ARG?             Show stats or turn stats on or off"   off                      Turn off automatic stat display"   off                      Turn off automatic stat display"   on                       Turn on automatic stat display"   on                       Turn on automatic stat display"   stmt                     Show statement stats"   stmt                     Show statement stats"   vmstep                   Show the virtual machine step count only"   vmstep                   Show the virtual machine step count only".system CMD ARGS...      Run CMD ARGS... in a system shell".system CMD ARGS...      Run CMD ARGS... in a system shell".tables ?TABLE?          List names of tables matching LIKE pattern TABLE".tables ?TABLE?          List names of tables matching LIKE pattern TABLE",testcase NAME           Begin redirecting output to 'testcase-out.txt'",testcase NAME           Begin redirecting output to 'testcase-out.txt'",testctrl CMD ...        Run various sqlite3_test_control() operations",testctrl CMD ...        Run various sqlite3_test_control() operations"                           Run ".testctrl" with no arguments for details"                           Run \".testctrl\" with no arguments for details".timeout MS              Try opening locked tables for MS milliseconds".timeout MS              Try opening locked tables for MS milliseconds".timer on|off            Turn SQL timer on or off".timer on|off            Turn SQL timer on or off".trace ?OPTIONS?         Output each SQL statement as it is run".trace ?OPTIONS?         Output each SQL statement as it is run"    FILE                    Send output to FILE"    FILE                    Send output to FILE"    stdout                  Send output to stdout"    stdout                  Send output to stdout"    stderr                  Send output to stderr"    stderr                  Send output to stderr"    off                     Disable tracing"    off                     Disable tracing"    --expanded              Expand query parameters"    --expanded              Expand query parameters"    --plain                 Show SQL as it is input"    --plain                 Show SQL as it is input"    --stmt                  Trace statement execution (SQLITE_TRACE_STMT)"    --stmt                  Trace statement execution (SQLITE_TRACE_STMT)"    --profile               Profile statements (SQLITE_TRACE_PROFILE)"    --profile               Profile statements (SQLITE_TRACE_PROFILE)"    --row                   Trace each row (SQLITE_TRACE_ROW)"    --row                   Trace each row (SQLITE_TRACE_ROW)"    --close                 Trace connection close (SQLITE_TRACE_CLOSE)"    --close                 Trace connection close (SQLITE_TRACE_CLOSE)".version                 Show source, library and compiler versions".version                 Show source, library and compiler versions".vfsinfo ?AUX?           Information about the top-level VFS".vfsinfo ?AUX?           Information about the top-level VFS".vfslist                 List all available VFSes".vfslist                 List all available VFSes".vfsname ?AUX?           Print the name of the VFS stack".vfsname ?AUX?           Print the name of the VFS stack".width NUM1 NUM2 ...     Set minimum column widths for columnar output".width NUM1 NUM2 ...     Set minimum column widths for columnar output"     Negative values right-justify"     Negative values right-justify".www                     Display output of the next command in web browser".www                     Display output of the next command in web browser"    --plain                 Show results as text/plain, not as HTML"    --plain                 Show results as text/plain, not as HTML"savedWhereTracesavedSelectTraceneedCsvQuotemodeDescrline"line"semi"semi"prettyprint"prettyprint"scanexp"scanexp"recover_methodsrecover_gZIPFILE_SCHEMACREATE TABLE y(name PRIMARY KEY,mode,mtime,sz,rawdata,data,method,z HIDDEN) WITHOUT ROWID;"CREATE TABLE y("
    "name PRIMARY KEY,"  /* 0: Name of file in zip archive */
    "mode,"              /* 1: POSIX mode for file */
    "mtime,"             /* 2: Last modification time (secs since 1970)*/
    "sz,"                /* 3: Size of object */
    "rawdata,"           /* 4: Raw data */
    "data,"              /* 5: Uncompressed data */
    "method,"            /* 6: Compression method (integer) */
    "z HIDDEN"           /* 7: Name of zip file */
  ") WITHOUT ROWID;"apvfsSqliteHdrapnd_io_methodsapnd_vfscompletionModuleseriesModuleu8[]unsigned char[]b85_cOffset'*'-4b64NumeralsABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"b64DigitValuesconst PercentileFunc[]PercentileFunc[]aPercentFuncmedian"median"percentile"percentile"percentile_cont"percentile_cont"percentile_disc"percentile_disc"ersaztPcacheMethodspcachetraceOutpcacheBaseersaztMethodsmemtraceOutmemtraceBaseaUWidthdynPromptArgv0seenInterruptglobalDbstdout_is_consolestdin_is_interactivebail_on_erroriBeginsBeginenableTimerSQLITE_SHELL_IS_UTF8QSS_SEMITERM(qss)(((qss)&~QSS_HasDark)==QSS_EndingSemi)QSS_PLAINDARK(qss)(((qss)&~QSS_EndingSemi)==QSS_HasDark)QSS_PLAINWHITE(qss)(((qss)&~QSS_EndingSemi)==QSS_Start)QSS_INPLAIN(qss)(((qss)&QSS_CharMask)==QSS_Start)QSS_SETV(qss,newst)((newst) | ((qss) & QSS_ScanMask))CTIMEOPT_VAL(opt)CTIMEOPT_VAL_(opt)#optSHELL_COLFIX_DBAUTOCOLUMN_SEP"_"0x002session_close_all(X,Y)"\342\224\274""\342\224\264""\342\224\254""\342\224\244""\342\224\234""\342\224\230""\342\224\224""\342\224\220""\342\224\214"BOX_13"\342\224\202"BOX_24"\342\224\200""\x1E""\x1F""\t"ShellClearFlag(P,X)((P)->shellFlgs&=(~(X)))ShellSetFlag(P,X)((P)->shellFlgs|=(X))ShellHasFlag(P,X)(((P)->shellFlgs & (X))!=0)SHELL_TRACE_NORMALIZEDAUTOEQP_offColModeOpts_default_qbox{ 60, 1, 0 }ColModeOpts_default{ 60, 0, 0 }RECOVER_VFS_WRAPPER(code)int rc = SQLITE_OK; if( pFd->pMethods==&recover_methods ){ pFd->pMethods = recover_g.pMethods; rc = code; pFd->pMethods = &recover_methods; }else{ rc = code; } return rc;recoverAssertMutexHeld()RECOVER_MUTEX_IDRECOVER_EHIDDEN_HIDDENRECOVER_EHIDDEN_NONEDBDATA_MX_CELL(pgsz)((pgsz-8)/6)"CREATE TABLE x(" "  pgno INTEGER," "  child INTEGER," "  schema TEXT HIDDEN" ")""CREATE TABLE x(" "  pgno INTEGER," "  cell INTEGER," "  field INTEGER," "  value ANY," "  schema TEXT HIDDEN" ")"_SQLITE_RECOVER_HSQLITE_SHELL_HAVE_RECOVER(-4418371)_SQLITE_INTCK_H"t592690916721053953805701627921227776"STRLEN(int)strlenNEVER(X)(X)ALWAYS(X)SQLITEEXPERT_HzipfileWrite16(aBuf,val){ zipfilePutU16(aBuf,val); aBuf+=2; }zipfileWrite32(aBuf,val){ zipfilePutU32(aBuf,val); aBuf+=4; }zipfileRead16(aBuf)( aBuf+=2, zipfileGetU16(aBuf-2) )zipfileRead32(aBuf)( aBuf+=4, zipfileGetU32(aBuf-4) )0x800((3<<8) + 30)MIN(a,b)((a)<(b) ? (a) : (b))UINT16_TYPEunsigned short intUINT32_TYPEunsigned intORIGFILE(p)((sqlite3_file*)(((ApndFile*)(p))+1))ORIGVFS(p)((sqlite3_vfs*)((p)->pAppData))APND_START_ROUNDUP(fsz)(((fsz)+APND_ALIGN_MASK) & ~APND_ALIGN_MASK)APND_ALIGN_MASK((sqlite3_int64)(APND_ROUNDUP-1))APND_ROUNDUP(0x40000000)(APND_MARK_PREFIX_SZ+APND_MARK_FOS_SZ)COMPLETION_MODULESCOMPLETION_TRIGGERSCOMPLETION_INDEXESCOMPLETION_COLLATIONSCOMPLETION_FUNCTIONSCOMPLETION_PRAGMASFSDIR_SCHEMA"(name,mode,mtime,data,path HIDDEN,dir HIDDEN)"0xfffffffre_freere_compilere_match(((sqlite3_int64)-1) - LARGEST_INT64)(0xffffffff|(((sqlite3_uint64)0xffffffff)<<32))(0xffffffff|(((sqlite3_int64)0x7fffffff)<<32))BASE85_EXPOSE(db,pzErr)BASE85_INIT(db)sqlite3_base85_init(db, 0, 0)base85Numeral(dn)((char)(((dn) < 4)? (char)((dn) + '#') : (char)((dn) - 4 + '*')))IS_B85(c)(B85_CLASS(c) & 1)B85_DNOS(c)b85_cOffset[B85_CLASS(c)]B85_CLASS(c)(((c)>='#')+((c)>'&')+((c)>='*')+((c)>'z'))OMIT_BASE85_CHECKERsqlite3_base_initBASE64_EXPOSE(db,pzErr)BASE64_INIT(db)sqlite3_base64_init(db, 0, 0)BX_NUMERAL(dv)(b64Numerals[(u8)(dv)])IS_BX_PAD(bdp)((bdp)==PC)IS_BX_WS(bdp)((bdp)==WS)IS_BX_DIGIT(bdp)(((u8)(bdp))<0x80)U8_TYPEDEF'='0x820x81SWAP_DOUBLE(X,Y){double ttt=(X);(X)=(Y);(Y)=ttt;}R4(v,w,x,y,z,i)z+=(w^x^y)+blk(i)+0xCA62C1D6+rol(v,5);w=ror(w,2);R3(v,w,x,y,z,i)z+=(((w|x)&y)|(w&x))+blk(i)+0x8F1BBCDC+rol(v,5);w=ror(w,2);R2(v,w,x,y,z,i)z+=(w^x^y)+blk(i)+0x6ED9EBA1+rol(v,5);w=ror(w,2);R1(v,w,x,y,z,i)z+=((w&(x^y))^y)+blk(i)+0x5A827999+rol(v,5);w=ror(w,2);Rb0(v,w,x,y,z,i)z+=((w&(x^y))^y)+blk0be(i)+0x5A827999+rol(v,5);w=ror(w,2);Rl0(v,w,x,y,z,i)z+=((w&(x^y))^y)+blk0le(i)+0x5A827999+rol(v,5);w=ror(w,2);blk(i)(block[i&15] = rol(block[(i+13)&15]^block[(i+8)&15] ^block[(i+2)&15]^block[i&15],1))blk0be(i)block[i]blk0le(i)(block[i] = (ror(block[i],8)&0xFF00FF00) |(rol(block[i],8)&0x00FF00FF))ror(x,k)SHA_ROT(x,32-(k),k)rol(x,k)SHA_ROT(x,k,32-(k))SHA_ROT(x,l,r)((x) << (l) | (x) >> (r))ROL64(a,x)((a<<x)|(a>>(64-x)))a44(p->u.s[24])a43(p->u.s[23])a42(p->u.s[22])a41(p->u.s[21])a40(p->u.s[20])a34(p->u.s[19])a33(p->u.s[18])a32(p->u.s[17])a31(p->u.s[16])a30(p->u.s[15])a24(p->u.s[14])a23(p->u.s[13])a22(p->u.s[12])a21(p->u.s[11])a20(p->u.s[10])a14(p->u.s[9])a13(p->u.s[8])a12(p->u.s[7])a11(p->u.s[6])a10(p->u.s[5])a04(p->u.s[4])a03(p->u.s[3])a02(p->u.s[2])a01(p->u.s[1])a00(p->u.s[0])SHA3_BYTEORDER1234SQLITE_EXTENSION_INIT2(X)(void)(X)SQLITE_EXTENSION_INIT1STAT_CHR_SRCSTAT_CHR_SRC(mode)(S_ISREG(mode)||S_ISFIFO(mode)||S_ISCHR(mode))SCAN_TRACKER_REFTYPECONTINUE_PROMPT_PSTATE(&dynPrompt)CONTINUE_PAREN_INCR(p,n)if(p && stdin_is_interactive) (trackParenLevel(p,n))CONTINUE_PROMPT_AWAITC(p,c)if(p && stdin_is_interactive) setLexemeOpen(p, 0, c)CONTINUE_PROMPT_AWAITS(p,s)if(p && stdin_is_interactive) setLexemeOpen(p, s, 0)CONTINUE_PROMPT_RESETdo {setLexemeOpen(&dynPrompt,0,0); trackParenLevel(&dynPrompt,0);} while(0)CONTINUATION_PROMPTdynamicContinuePrompt()ArraySize(X)(int)(sizeof(X)/sizeof(X[0]))UNUSED_PARAMETER(x)(void)(x)END_TIMER(X)endTimer(X)BEGIN_TIMERbeginTimer()sputz(fp,z)sqlite3_fputs(z,fp)eputz(z)sqlite3_fputs(z,stderr)SQLITE_INTERNAL_LINKAGEsqlite3_fsetmode(F,X)sqlite3_fprintfsqlite3_fputssqlite3_fgetssqlite3_popensqlite3_fopen_SQLITE3_STDIO_H_ToLower(X)(char)tolower((unsigned char)X)IsDigit(X)isdigit((unsigned char)X)IsSpace(X)isspace((unsigned char)X)deliberate_fall_throughSHELL_USE_LOCAL_GETLINEshell_stifle_history(X)shell_write_history(X)shell_read_history(X)GETPID_FILE_OFFSET_BITS_LARGE_FILESQLITE_OS_WINRTSHELL_STRINGIFY(f)SHELL_STRINGIFY_(f)#f(defined(_WIN32) || defined(WIN32)) && !defined(_CRT_SECURE_NO_WARNINGS)SQLITE_CUSTOM_INCLUDE!defined(SQLITE_OS_WINRT)defined(_MSC_VER)(defined(__RTP__) || defined(_WRS_KERNEL)) && !SQLITE_OMIT_LOAD_EXTENSIONSQLITE_DISABLE_LFSdefined(SQLITE_SHELL_FIDDLE) && !defined(_POSIX_SOURCE)!defined(_WIN32) && !defined(WIN32)!defined(__RTP__) && !defined(_WRS_KERNEL) && !defined(SQLITE_WASI)(!defined(_WIN32) && !defined(WIN32)) || defined(__MINGW32__)defined(__MINGW32__)S_ISLNKHAVE_READLINEHAVE_EDITLINEHAVE_EDITLINE || HAVE_READLINEHAVE_LINENOISEdefined(GCC_VERSION) && GCC_VERSION>=7000000defined(_WIN32) || defined(WIN32)defined(_WIN32_WCE)defined(SQLITE_U8TEXT_ONLY)defined(SQLITE_U8TEXT_STDIO)SQLITE_USE_W32_FOR_CONSOLE_IOSQLITE_SHELL_FIDDLE!defined(_WIN32) && !defined(WIN32) && !defined(__minux)defined(_WRS_KERNEL) || defined(__RTP__)(defined(_WIN32) || defined(WIN32))!SQLITE_OS_WINRTSQLITE_OMIT_DYNAPROMPTSQLITE_ENABLE_IOTRACEdefined(_WIN32) && defined(_MSC_VER)defined(_WIN32) && defined(_MSC_VER) && !defined(SQLITE_WINDIRENT_H)S_ISREGS_ISDIRMODE_T_DEFINEDINO_T_DEFINEDNULL_INTPTR_TBAD_INTPTR_TDIRENT_DEFINEDDIR_DEFINEDis_filteredSQLITE_AMALGAMATIONdefined(i386)     || defined(__i386__)   || defined(_M_IX86) ||    \defined(sparc)    || defined(__ppc__)SHA3_BYTEORDER==1234SHA3_BYTEORDER==4321UNUSED_PARAMETERdefined(SQLITE3_H)defined(SQLITE_STATIC_PERCENTILE)defined(_WIN32) && !defined(SQLITE3_H) && !defined(SQLITE_STATIC_PERCENTILE)SQLITE3EXT_HGCC_VERSION>=7000000SQLITE_SHELL_EXTFUNCSBASE85_STANDALONESQLITE_OMIT_VIRTUALTABLEZERO_ARGUMENT_GENERATE_SERIESdefined(SQLITE_DEBUG)defined(_WIN32)defined(FILEIO_WIN32_DLL) && (defined(_WIN32) || defined(WIN32))defined(AT_FDCWD) && 0APPENDVFS_TESTSQLITE_HAVE_ZLIBSQLITE_NO_STDINTHAVE_UINT32_THAVE_UINT16_Tdefined(SQLITE_COVERAGE_TEST) || defined(SQLITE_MUTATION_TEST)defined(SQLITE_OMIT_AUXILIARY_SAFETY_CHECKS)!defined(NDEBUG)!defined(SQLITEEXPERT_H)!defined(SQLITE_AMALGAMATION)!defined(SQLITE_OMIT_SCHEMA_PRAGMAS) \!defined(SQLITE_OMIT_VIRTUALTABLE) && defined(SQLITE_ENABLE_DBPAGE_VTAB)SQLITE_HAVE_SQLITE3R!defined(SQLITEINT_H)SQLITE_OMIT_UTF16defined(SQLITE_THREADSAFE) && SQLITE_THREADSAFE==0SQLITE_THREADSAFE+0>=1 && defined(SQLITE_DEBUG)SQLITE_SHELL_EXTSRCdefined(SQLITE_ENABLE_SESSION)SQLITE_NOHAVE_SYSTEM(defined(_WIN32) || defined(WIN32)) && !defined(_WIN32_WCE)SQLITE_OMIT_AUTHORIZATIONSQLITE_OMIT_PROGRESS_CALLBACK__linux__SQLITE_OMIT_DECLTYPESQLITE_ENABLE_COLUMN_METADATAYYTRACKMAXSTACKDEPTHSQLITE_ENABLE_STMT_SCANSTATUSdefined(SQLITE_HAVE_ZLIB) && !defined(SQLITE_OMIT_VIRTUALTABLE) \SQLITE_DEBUGSQLITE_OMIT_TEST_CONTROL!defined(SQLITE_OMIT_LOAD_EXTENSION) && !defined(SQLITE_SHELL_FIDDLE)!defined(SQLITE_SHELL_FIDDLE)SQLITE_OMIT_DESERIALIZE!defined(SQLITE_NOHAVE_SYSTEM) && !defined(SQLITE_SHELL_FIDDLE)SQLITE_OMIT_TRACE(HAVE_READLINE || HAVE_EDITLINE) \HAVE_LINENOISE==2SQLITE_OMIT_POPENdefined(__APPLE__)!defined SQLITE_OMIT_VIRTUALTABLE!defined(SQLITE_OMIT_VIRTUALTABLE) && defined(SQLITE_HAVE_ZLIB)SHELL_DEBUGSHELL_AUTOCOLUMN_SEPSHELL_COLUMN_RENAME_CLEANSQLITE_ENABLE_MATH_FUNCTIONS!defined(SQLITE_OMIT_VIRTUALTABLE) && defined(SQLITE_HAVE_ZLIB) \SQLITE_UNTESTABLE!defined(SQLITE_ENABLE_STMT_SCANSTATUS)!defined(SQLITE_ENABLE_BYTECODE_VTAB)SQLITE_OMIT_INTROSPECTION_PRAGMAS!defined(SQLITE_OMIT_SCHEMA_PRAGMAS) && !defined(SQLITE_OMIT_VIRTUALTABLE)YYCOVERAGEdefined(SQLITE_DEBUG) && !defined(SQLITE_OMIT_VIRTUALTABLE)defined(__clang__) && defined(__clang_major__)defined(__GNUC__) && defined(__VERSION__)SQLITE_OMIT_COMPLETE!defined(_WIN32) && !defined(WIN32) && !defined(_WIN32_WCE) \defined(_WIN32) || defined(WIN32) || defined(_WIN32_WCE) \defined(SQLITE_HAVE_ZLIB) && !defined(SQLITE_OMIT_VIRTUALTABLE)!defined(SQLITE_OMIT_DESERIALIZE)defined(SQLITE_ENABLE_MEMSYS3) || defined(SQLITE_ENABLE_MEMSYS5)SQLITE_ENABLE_MULTIPLEXSQLITE_ENABLE_SORTER_REFERENCES(defined(_WIN32) || defined(WIN32)) \!SQLITE_SHELL_IS_UTF8!defined(_WIN32_WCE)defined(SIGTRAP)USE_SYSTEM_SQLITE+0!=1SQLITE_SHELL_DBNAME_PROCdefined(SQLITE_ENABLE_SORTER_REFERENCES)SQLITE_SHELL_INIT_PROCSQLITE_OMIT_MEMORYDB(HAVE_READLINE || HAVE_EDITLINE) && !defined(SQLITE_OMIT_READLINE_COMPLETION)HAVE_LINENOISE==1__VERSION__"EDG gcc 13.3 mode"SQLITE_ENABLE_DBPAGE_VTAB0x7fffffffffffffffLL0x7fffffffffffffffL__x86_64/* SQLITE_SHELL_FIDDLE *//*
** Trivial exportable function for emscripten. It processes zSql as if
** it were input to the sqlite3 shell and redirects all output to the
** wasm binding. fiddle_main() must have been called before this
** is called, or results are undefined.
*//*assume EOF*//* DB size is not an even multiple of the buffer size. Reduce
    ** buffer size so that we do not unduly inflate the db size when
    ** exporting. *//*
** Uses the current database's VFS xRead to stream the db file's
** contents out to the given callback. The callback gets a single
** chunk of size n (its 2nd argument) on each call and must return 0
** on success, non-0 on error. This function returns 0 on success,
** SQLITE_NOTFOUND if no db is open, or propagates any other non-0
** code from the callback. Note that this is not thread-friendly: it
** expects that it will be the only thread reading the db file and
** takes no measures to ensure that is the case.
*//*
      ** Resolve problem reported in
      ** https://sqlite.org/forum/forumpost/0b41a25d65
      *//*
** Completely wipes out the contents of the currently-opened database
** but leaves its storage intact for reuse. If any transactions are
** active, they are forcibly rolled back.
*//*
** Returns the filename of the given db name, assuming "main" if
** zDbName is NULL. Returns NULL if globalDb is not opened.
*//*
** Intended to be called via a SharedWorker() while a separate
** SharedWorker() (which manages the wasm module) is performing work
** which should be interrupted. Unfortunately, SharedWorker is not
** portable enough to make real use of.
*//* Only for emcc experimentation purposes. *//*
** Returns a pointer to the given DB name's VFS. If zDbName is 0 then
** "main" is assumed. Returns 0 if no db with the given name is
** open.
*//*
** Returns a pointer to the current DB handle.
*//* SQLITE_SHELL_FIDDLE... *//* Clear the global data structure so that valgrind will detect memory
  ** leaks *//* In WASM mode we have to leave the db state in place so that
  ** client code can "push" SQL into it after this call returns. *//*extra-version-info*//* Run commands received from standard input
    *//* Run all arguments that do not begin with '-' as if they were separate
    ** command-line inputs, except for the argToSkip argument which contains
    ** the database filename.
    *//* Acted upon in first pass. *//* Run commands that follow -cmd first and separately from commands
      ** that simply appear on the command-line.  This seems goofy.  It would
      ** be better if all commands ran in the order that they appear.  But
      ** we retain the goofy behavior for historical compatibility. *//* already handled *//* Need to check for interactive override here to so that it can
      ** affect console setup (for Windows only) and testing thereof.
      *//* No-op.  The bail_on_error flag should already be set. *//* Undocumented command-line option: -backslash
      ** Causes C-style backslash escapes to be evaluated in SQL statements
      ** prior to sending the SQL into SQLite.  Useful for injecting
      ** crazy bytes in the middle of SQL statements for testing and debugging.
      *//* Make a second pass through the command-line argument and set
  ** options.  This second pass is delayed until after the initialization
  ** file is processed so that the command-line arguments will override
  ** settings in the initialization file.
  *//* Process the initialization file if there is one.  If no -init option
  ** is given on the command line, look for a file named ~/.sqliterc and
  ** try to process it.
  *//* Go ahead and open the database file if it already exists.  If the
  ** file does not exist, delay opening it.  This prevents empty database
  ** files from being created if a user mistypes the database name argument
  ** to the sqlite command-line tool.
  *//* All the sqlite3_config() calls have now been made. So it is safe
  ** to call sqlite3_initialize() and process any command line -vfs option. *//* If the SQLITE_SHELL_INIT_PROC macro is defined, then it is the name
    ** of a C-function that will perform initialization actions on SQLite that
    ** occur just before or after sqlite3_initialize(). Use this compile-time
    ** option to embed this shell program in larger applications. *//* no-op - catch this on the second pass *//* All remaining command-line arguments are passed to the ".archive"
      ** command, so ignore them *//* Need to check for batch mode here to so we can avoid printing
      ** informational messages (like from process_sqliterc) before
      ** we do the actual processing of arguments later in a second pass.
      *//* Excess arguments are interpreted as SQL (or dot-commands) and
        ** mean that nothing is read from stdin *//* Do an initial pass through the command-line argument to locate
  ** the name of the database file, the name of the initialization file,
  ** the size of the alternative malloc heap, options affecting commands
  ** or SQL run from the command line, and the first command to execute.
  *//* If the SQLITE_SHELL_DBNAME_PROC macro is defined, then it is the name
    ** of a C-function that will provide the name of the database file.  Use
    ** this compile-time option to embed this shell program in larger
    ** applications. *//* On Windows, we must translate command-line arguments into UTF-8.
  ** The SQLite memory allocator subsystem has to be enabled in order to
  ** do this.  But we want to run an sqlite3_shutdown() afterwards so that
  ** subsequent sqlite3_config() calls will work.  So copy all results into
  ** memory that does not come from the SQLite memory allocator.
  *//* Register a valid signal handler early, before much else is done. *//* Make sure stderr is unbuffered *//* Value of -vfs command-line option *//* Routine to output from vfstrace
*//*
** Get the argument to an --option.  Throw an error and die if no argument
** is available.
*//*
** Output text to the console in a font that attracts extra attention.
*//*
** Initialize the state information in data
*//*
** Internal check:  Verify that the SQLite is uninitialized.  Print a
** error message if it is initialized.
*//*
** Show available command line options
*//* Name of config file. NULL to use default *//* Configuration data *//*
** Read input from the file given by sqliterc_override.  Or if that
** parameter is NULL, take input from the first of find_xdg_config()
** or ~/.sqliterc which is found.
**
** Returns the number of errors.
*//*
** On non-Windows platforms, look for $XDG_CONFIG_HOME.
** If ${XDG_CONFIG_HOME}/sqlite3/sqliterc is found, return
** the path to it.  If there is no $(XDG_CONFIG_HOME) then
** look for $(HOME)/.config/sqlite3/sqliterc and if found
** return that.  If none of these are found, return 0.
**
** The string returned is obtained from sqlite3_malloc() and
** should be freed by the caller.
*//* !_WIN32_WCE *//* Windows CE (arm-wince-mingw32ce-gcc) does not provide getenv()
   *//*
** Return a pathname which is the user's home directory.  A
** 0 return indicates an error of some kind.
*//* This may be incomplete. Let the SQL parser deal with that. *//* Grow buffer by half-again increments when big. *//* No single-line dispositions remain; accumulate line(s). *//* exit requested *//* Just swallow single-line whitespace *//* End of input *//* This will be more informative in a later version. *//* Accumulated line status (so far) *//* Line number for start of current input *//* Number of errors seen *//* Error code *//* Allocated zSql[] space *//* Bytes of zSql[] used *//* Length of current line *//* Accumulated SQL text *//* A single input line *//*
** Read input from *in and process it.  If *in==0 then input
** is interactive - the user is typing it it.  Otherwise, input
** is coming from a file or device.  A prompt is issued and history
** is saved only if input is interactive.  An interrupt signal will
** cause this routine to exit immediately, unless input is interactive.
**
** Return the number of errors.
*//* Parse the next line from shellState.wasm.zInput. *//*
** Alternate one_input_line() impl for wasm mode. This is not in the primary
** impl because we need the global shellState and cannot access it from that
** function without moving lots of code around (creating a larger/messier diff).
*//*
** Run a single line of SQL.  Return the number of errors.
*//* Now check if the database is empty. *//*
** This function is called after processing each line of SQL in the
** runOneSqlLine() function. Its purpose is to detect scenarios where
** defensive mode should be automatically turned off. Specifically, when
**
**   1. The first line of input is "PRAGMA foreign_keys=OFF;",
**   2. The second line of input is "BEGIN TRANSACTION;",
**   3. The database is empty, and
**   4. The shell is not running in --safe mode.
** 
** The implementation uses the ShellState.eRestoreState to maintain state:
**
**    0: Have not seen any SQL.
**    1: Have seen "PRAGMA foreign_keys=OFF;".
**    2-6: Currently running .dump transaction. If the "2" bit is set,
**         disable DEFENSIVE when done. If "4" is set, disable DQS_DDL.
**    7: Nothing left to do. This function becomes a no-op.
*//*
** Return true if zSql is a complete SQL statement.  Return false if it
** ends in the middle of a string literal or C-style comment.
*//*
** The CLI needs a working sqlite3_complete() to work properly.  So error
** out of the build if compiling with SQLITE_OMIT_COMPLETE.
*//* SQL Server *//* Oracle *//*
** Return TRUE if the line typed in is an SQL command terminator other
** than a semi-colon.  The SQL Server style "go" command is understood
** as is the Oracle "/".
*//* FALLTHRU *//* Swallow doubled end-delimiter.*//* intentional narrowing loss *//*
** Scan line for classification to guide shell's handling.
** The scan is resumable for subsequent lines when prior
** return values are passed as the 2nd argument.
*//* Line scan result and intermediate states (supporting scan resumption)
*//* !defined(SQLITE_OMIT_TRACE) *//* !defined(SQLITE_UNTESTABLE) *//* sqlite3_test_control(sqlite3*) *//* sqlite3_test_control(int, int) *//* Make sure the schema has been loaded *//* sqlite3_test_control(int, int, sqlite3*) *//* sqlite3_test_control(int, uint) *//* sqlite3_test_control(int) *//* sqlite3_test_control(int, db, int) *//* Name of optimization *//* Display this on output *//* Mask for this optimization *//* Special processing for .testctrl opt MASK ...
        ** Each MASK argument can be one of:
        **
        **      +LABEL       Enable the named optimization 
        **
        **      -LABEL       Disable the named optimization
        **
        **      INTEGER      Mask of optimizations to disable
        *//* convert testctrl text option to value. allow any unique prefix
    ** of the option name, or a numerical value. *//* --help lists all test-controls *//* The argument can optionally begin with "-" or "--" *//* 0: usage.  1: %d  2: %x  3: no-output *//*{"bitvec_test",        SQLITE_TESTCTRL_BITVEC_TEST, 1,  ""              },*//*{"benign_malloc_hooks",SQLITE_TESTCTRL_BENIGN_MALLOC_HOOKS,1, ""        },*//* Usage notes *//* Not valid unless --unsafe-testing *//* Integer code for that option *//* Name of a test-control option *//* !defined(SQLITE_SHELL_FIDDLE) *//* Begin redirecting output to the file "testcase-out.txt" *//* Pretty-print the contents of array azResult[] to the output *//* Run the SQL statement prepared by the above block. Store the results
    ** as an array of nul-terminated strings in azResult[].  *//* It is an historical accident that the .indexes command shows an error
      ** when called with the wrong number of arguments whereas the .tables
      ** command does not. *//* !defined(SQLITE_NOHAVE_SYSTEM) && !defined(SQLITE_SHELL_FIDDLE) *//*consoleRenewSetup();*//*consoleRestore();*//* !defined(*_OMIT_SCHEMA_PRAGMAS) && !defined(*_OMIT_VIRTUALTABLE) *//* assert(lrc==SQLITE_NOMEM); // might also be SQLITE_ERROR if the
        ** user does cruel and unnatural things like ".limit expr_depth 0". *//* lower-case query is first run, producing upper-case query. *//* Query for reversible to-blob-to-text check *//* Set of queries used to read all content *//* Complete SQL for the query to run the hash *//* Separator *//* SQL to be run *//* For querying tables names *//* Only show the query that would have run *//* Hash algorithm to use *//* Hash each table separately *//* Also hash the schema *//* Loop counter *//* Which table to checksum. 0 means everything *//* End loop over k *//* End loop over rows of content from SELFTEST *//* Query against the SELFTEST table *//* Answer for a query *//* Number of tests runs *//* Loop counters *//* True if SELFTEST already exists *//* Verbose output *//* True to initialize the SELFTEST table *//* Undocumented commands for internal testing.  Subject to change
  ** without notice. *//* If no command name matches, show a syntax error *//* .session open DB NAME
    ** Open a new session called NAME on the attached database DB.
    ** DB is normally "main".
    *//* .session list
    ** List all currently open sessions
    *//* .session isempty
    ** Determine if the session is empty
    *//* .session indirect ?BOOLEAN?
    ** Query or set the indirect flag
    *//* .session filter GLOB ....
    ** Set a list of GLOB patterns of table names to be excluded.
    *//* .session enable ?BOOLEAN?
    ** Query or set the enable flag
    *//* .session close
    ** Close the identified session
    *//* .session changeset FILE
    ** .session patchset FILE
    ** Write a changeset or patchset into a file.  The file is overwritten.
    *//* .session attach TABLE
    ** Invoke the sqlite3session_attach() interface to attach a particular
    ** table so that it is never filtered.
    *//* SQLITE_OMIT_PROGRESS_CALLBACK *//* .parameter unset NAME
    ** Remove the NAME binding from the parameter binding table, if it
    ** exists.
    *//* .parameter set NAME VALUE
    ** Set or reset a bind parameter.  NAME should be the full parameter
    ** name exactly as it appears in the query.  (ex: $abc, @def).  The
    ** VALUE can be in either SQL literal notation, or if not it will be
    ** understood to be a text string.
    *//* .parameter init
    ** Make sure the TEMP table used to hold bind parameters exists.
    ** Create it if necessary.
    *//* .parameter list
    ** List all bind parameters.
    *//* .parameter clear
    ** Clear all bind parameters by dropping the TEMP table that holds them.
    *//* SQLITE_NOHAVE_SYSTEM *//* text editor mode *//* web-browser mode. *//* Always include the BOM on Windows, as Excel does
                          ** not work without it. *//* spreadsheet mode.  Output as CSV. *//* Web browser *//* text editor *//* spreadsheet *//* --plain option *//* 0: .output, 1: .once, 2: .excel/.www *//* As a fall-back open a TEMP database *//* WASM mode has its own sandboxed pseudo-filesystem. *//* If a filename is specified, try to open it first *//* Close the existing database *//* !SQLITE_SHELL_FIDDLE *//* SQLITE_OMIT_DESERIALIZE *//* Check for command-line arguments *//* True to delete file before opening *//* Index in azArg[] of the filename *//* Name of the database file to open *//* Pointer to constant filename *//* Return immediately to bypass the safe mode reset
                 ** at the end of this procedure *//* Apply defaults for qbox pseudo-mode.  If that
         * overwrites already-set values, user was informed of this.
         *//* Must have a non-empty FILE. (Will not load self.) *//* Integer code for that limit *//* Name of a limit *//* !defined(SQLITE_OMIT_TEST_CONTROL) *//* Also allowed, but not documented:
      **
      **    .imposter TABLE IMPOSTER
      **
      ** where TABLE is a WITHOUT ROWID table.  In that case, the
      ** imposter is another WITHOUT ROWID table with the columns in
      ** storage order. *//* Length of the PRIMARY KEY string for isWO tables *//* True if making an imposter of a WITHOUT ROWID table *//*
        ** For CSV mode, per RFC 4180, accept EOF in lieu of final
        ** record terminator but only for last field of multi-field row.
        ** (If there are too few fields, it's not valid CSV anyway.)
        *//*
        ** Did we reach end-of-file OR end-of-line before finding any
        ** columns in ASCII mode?  If so, stop instead of NULL filling
        ** the remaining columns.
        *//*
        ** Did we reach end-of-file before finding any columns?
        ** If so, stop instead of NULL filling the remaining columns.
        *//* Space for ",?" for each column *//* Quoted table name *//* Quoted schema name *//* space for "INSERT INTO", "VALUES(", ")\0" *//* no columns, no error *//* Table does not exist.  Create it. *//* To ensure sCtx.z is allocated *//* Below, resources must be freed before exit. *//* When importing CSV (only), if the row separator is set to the
        ** default output row separator, change it to the default input
        ** row separator.  This avoids having to maintain different input
        ** and output row separators. *//* If neither the --csv or --ascii options are specified, then set
      ** the column and row separator characters from the output mode. *//* CREATE TABLE statement text *//* Use output mode to determine separators *//* Initial lines to skip *//* Larger for more console output *//* Func to read one value *//* Reader context *//* An SQL statement *//* Number of bytes in p->colSeparator[] *//* True to COMMIT or ROLLBACK at end *//* Number of bytes in an SQL string *//* Number of columns in the table *//* A statement *//* Name of file to extra content from *//* Schema of zTable *//* Insert data into this table *//* convert filectrl text option to value. allow any unique prefix
    ** of the option name, or a numerical value. *//* --help lists all file-controls *//* 0: usage  1: %lld  2: no-result *//* Integer result to display if rc2==1 *//* { "win32_av_retry", SQLITE_FCNTL_WIN32_AV_RETRY,  "COUNT DELAY"    },*//* { "pragma",         SQLITE_FCNTL_PRAGMA,          "NAME ARG"       },*//* The ".explain" command is automatic now.  It is largely pointless.  It
  ** retained purely for backwards compatibility *//* Set writable_schema=ON since doing so forces SQLite to initialize
    ** as much of the schema as it can even if the sqlite_schema table is
    ** corrupt. *//* When playing back a "dump", the content might appear in an order
      ** which causes immediate foreign key constraints to be violated.
      ** So disable foreign-key constraint enforcement to prevent problems. *//* azArg[i] contains a LIKE pattern. This ".dump" request should
        ** only dump data for tables for which either the table name matches
        ** the LIKE pattern, or the table appears to be a shadow table of
        ** a virtual table for which the name matches the LIKE pattern.
        *//* SQLITE_SHELL_HAVE_RECOVER *//* No-op *//* List available connections *//* Cancel output redirection, if it is currently set (by .testcase)
  ** Then read the content of the testcase-out.txt file and compare against
  ** azArg[1].  If there are differences, report an error and exit.
  *//* The undocumented ".breakpoint" command causes a call to the no-op
  ** routine named test_breakpoint().
  *//* Undocumented.  Legacy only.  See "crlf" below *//* no tokens, no error *//* Process the input line.
  *//* Parse the input line into tokens.
  *//*
** If an input line begins with "." then invoke this routine to
** process that line.
**
** Return 1 on error, 2 to exit, and 0 otherwise.
*//*
** This is the fault-sim callback
*//* Skip this many before first fault *//* Turn off after this many hits.  0 for never *//* Number of hits seen so far *//* When to print output *//* Reset iCnt to this value after each fault *//* Trigger the fault only if iCnt is already zero *//* The error code to return on a fault *//* ID that triggers a simulated fault.  -1 means "any" *//*
** Fault-Simulator state and logic.
*//*
** Check if the sqlite_schema table contains one or more virtual tables. If
** parameter zLike is not NULL, then it is an SQL expression that the
** sqlite_schema row must also match. If one or more such rows are found,
** print the following warning to the output:
**
** WARNING: Script requires that SQLITE_DBCONFIG_DEFENSIVE be disabled
*//* Consider: remove this *//* Formulate the columns spec, close the DB, zero *pDb. *//* Add initial or additional column. Init db if necessary. *//* No chopping, never touch incoming names. *//* Find minimum extraneous leading 0's for uniqueness *//* ...RENAME_MINIMAL_ONE_PASS *//* Counting on SQLITE_MAX_COLUMN < 100,000 here. (32767 is the hard limit.) *//* Queries and D{D,M}L used here *//* Define character (as C string) to separate generated column ordinal
 * from protected part of incoming column names. This defaults to "_"
 * so that incoming column identifiers that did not need not be quoted
 * remain usable without being quoted. It must be one character.
 *//* Otherwise, memory is faster/better for the transient DB. *//* If this is set, the DB can be in a file. *//*
 * zAutoColumn(zCol, &db, ?) => Maybe init db, add column zCol to it.
 * zAutoColumn(0, &db, ?) => (db!=0) Form columns spec for CREATE TABLE,
 *   close db and set it to 0, and return the columns spec, to later
 *   be sqlite3_free()'ed by the caller.
 * The return is 0 when either:
 *   (a) The db was not initialized and zCol==0 (There are no columns.)
 *   (b) zCol!=0  (Column was added, db initialized as needed.)
 * The 3rd argument, pRenamed, references an out parameter. If the
 * pointer is non-zero, its referent will be set to a summary of renames
 * done if renaming was necessary, or set to 0 if none was done. The out
 * string (if any) must be sqlite3_free()'ed by the caller.
 *//*
** Implementation of ".intck STEPS_PER_UNLOCK" command.
*//* Debug use only *//* This option determines the name of the ATTACH-ed database used
      ** internally by the recovery extension.  The default is "" which
      ** means to use a temporary database that is automatically deleted
      ** when closed.  This option is undocumented and might disappear at
      ** any moment. *//* 0 if --no-rowids *//* 0 if --ignore-freelist is specified *//* Name of "recovery" database.  Debug only *//*
** This function is called to recover data from the database. A script
** to construct a new database containing all recovered data is output
** on stream pState->out.
*//*
** This function is used as a callback by the recover extension. Simply
** print the supplied SQL statement to stdout.
*//* !defined(SQLITE_OMIT_VIRTUALTABLE) && defined(SQLITE_HAVE_ZLIB) *//* End of the ".archive" or ".ar" command logic
*******************************************************************************//* Number of entries in azArg[] *//* Array of arguments passed to dot command *//* True if -A command-line option, not .ar cmd *//* Current shell tool state *//*
** Implementation of ".ar" dot command.
*//* Initialize the table for an SQLAR *//* Initialize the zipfile virtual table, if necessary *//* SQL table into which to insert *//* Return code *//* For iterating through azFile[] *//* Only update if file has changed *//* true for a --create. *//* Command arguments and options *//*
** Implementation of .ar "create", "insert", and "update" commands.
**
**     create    ->     Create a new SQL archive
**     insert    ->     Insert or reinsert all files listed
**     update    ->     Insert files that have changed or that were not
**                      previously in the archive
**
** Create the "sqlar" table in the database if it does not already exist.
** Then add each file in the azFile[] array to the archive. Directories
** are added recursively. If argument bVerbose is non-zero, a message is
** printed on stdout for each file archived.
**
** The create command is the same as update, except that it drops
** any existing "sqlar" table before beginning.  The "insert" command
** always overwrites every file named on the command-line, where as
** "update" only overwrites if the size or mtime or mode has changed.
*//*
** Run the SQL statement in zSql.  Or if doing a --dryrun, merely print it out.
*//* Run the SELECT statement twice. The first time, writefile() is called
    ** for all archive members that should be extracted. The second time,
    ** only for the directories. This is because the timestamps for
    ** extracted directories must be reset after they are populated (as
    ** populating them changes the timestamp).  *//* If arguments are specified, check that they actually exist within
  ** the archive before proceeding. And formulate a WHERE clause to
  ** match them.  *//*
** Implementation of .ar "eXtract" command.
*//* stdout? *//* Verify that args actually exist within the archive before proceeding.
    ** And formulate a WHERE clause to match them.  *//*
** Implementation of .ar "Remove" command.
*//*
** Implementation of .ar "lisT" command.
*//* OUT: New WHERE clause *//*
** Format a WHERE clause that can be used against the "sqlar" table to
** identify all archive members that match the command arguments held
** in (*pAr). Leave this WHERE clause in (*pzWhere) before returning.
** The caller is responsible for eventually calling sqlite3_free() on
** any non-NULL (*pzWhere) value. Here, "match" means strict equality
** when pAr->bGlob is false and GLOB match when pAr->bGlob is true.
*//*
** This function assumes that all arguments within the ArCommand.azArg[]
** array refer to archive members, as for the --extract, --list or --remove
** commands. It checks that each of them are "present". If any specified
** file is not present in the archive, an error is printed to stderr and an
** error code returned. Otherwise, if all specified arguments are present
** in the archive, SQLITE_OK is returned. Here, "present" means either an
** exact equality when pAr->bGlob is false or a "name GLOB pattern" match
** when pAr->bGlob is true.
**
** This function strips any trailing '/' characters from each argument.
** This is consistent with the way the [tar] command seems to work on
** Linux.
*//* Iterator *//* Matching option *//* Argument for option, if any *//* A long option *//* A -- option, indicating that all remaining command line words
          ** are command arguments.  *//* One or more short options *//* All remaining command line words are command arguments. *//* Non-traditional invocation *//* Traditional style [tar] invocation *//* Populate this object *//*
** Parse the command line for an ".ar" command. The results are written into
** structure (*pAr). SQLITE_OK is returned if the command line is parsed
** successfully, otherwise an error message is written to stderr and
** SQLITE_ERROR returned.
*//*
** Other (non-command) switches.
*//*
** Values for ArCommand.eCmd.
*//*
** Print an error message for the .ar command to stderr and return
** SQLITE_ERROR.
*//*
** Print a usage message for the .ar command to stderr and return SQLITE_ERROR.
*//* Database containing the archive *//* Output to this stream *//* Shell state *//* Array of command arguments *//* --directory argument, or NULL *//* --file argument, or NULL *//* "sqlar", "zipfile($file)" or "zip" *//* Number of command arguments *//* Run from -A instead of .archive *//* True if --glob *//* True if --append *//* True if --dry-run *//* True if the archive is a ZIP *//* True if --verbose *//* An AR_CMD_* value *//*
** Structure representing a single ".ar" command.
*//******************************************************************************
** The ".archive" or ".ar" command.
*//* !defined SQLITE_OMIT_VIRTUALTABLE *//* Reset the prepared statement created using shellPreparePrintf().
**
** This routine is could be marked "static".  But it is not always used,
** depending on compile-time options.  By omitting the "static", we avoid
** nuisance compiler warnings about "defined but not used".
*//* 
** Finalize the prepared statement created using shellPreparePrintf().
*//*
** Create a prepared statement using printf-style arguments for the SQL.
*//*
** Implementation of ".lint" dot command.
*//* Register the fkey_collate_clause() SQL function *//*
  ** This SELECT statement returns one row for each foreign key constraint
  ** in the schema of the main database. The column values are:
  **
  ** 0. The text of an SQL statement similar to:
  **
  **      "EXPLAIN QUERY PLAN SELECT 1 FROM child_table WHERE child_key=?"
  **
  **    This SELECT is similar to the one that the foreign keys implementation
  **    needs to run internally on child tables. If there is an index that can
  **    be used to optimize this query, then it can also be used by the FK
  **    implementation to optimize DELETE or UPDATE statements on the parent
  **    table.
  **
  ** 1. A GLOB pattern suitable for sqlite3_strglob(). If the plan output by
  **    the EXPLAIN QUERY PLAN command matches this pattern, then the schema
  **    contains an index that can be used to optimize the query.
  **
  ** 2. Human readable text that describes the child table and columns. e.g.
  **
  **       "child_table(child_key1, child_key2)"
  **
  ** 3. Human readable text that describes the parent table and columns. e.g.
  **
  **       "parent_table(parent_key1, parent_key2)"
  **
  ** 4. A full CREATE INDEX statement for an index that could be used to
  **    optimize DELETE or UPDATE statements on the parent table. e.g.
  **
  **       "CREATE INDEX child_table_child_key ON child_table(child_key)"
  **
  ** 5. The name of the parent table.
  **
  ** These six values are used by the C logic below to generate the report.
  *//* Send output here *//* Compiled version of SQL statement below *//* How much to indent CREATE INDEX by *//* To iterate through azArg[] *//* If -groupbyparent is present *//* If -verbose is present *//* Database handle to query "main" db of *//*
** The implementation of dot-command ".lint fkey-indexes".
*//* Initialize to avoid false-positive warning *//*
** The implementation of SQL scalar function fkey_collate_clause(), used
** by the ".lint fkey-indexes" command. This scalar function is always
** called with four arguments - the parent table name, the parent column name,
** the child table name and the child column name.
**
**   fkey_collate_clause('parent-tab', 'parent-col', 'child-tab', 'child-col')
**
** If either of the named tables or columns do not exist, this function
** returns an empty string. An empty string is also returned if both tables
** and columns exist but have the same default collation sequence. Or,
** if both exist but the default collation sequences are different, this
** function returns the string " COLLATE <parent-collation>", where
** <parent-collation> is the default collation sequence of the parent column.
*//* If p->db is an in-memory database then the TEMPFILENAME file-control
    ** will not work and we will need to fallback to guessing *//*
** Create a new temp file name with the given suffix.
*//*
** Try to delete the temporary file (if there is one) and free the
** memory used to hold the name of the temp file.
*//*
** Delete a file.
*//*
** Compare the string as a command-line option with either one or two
** initial "-" characters.
*//*
** Compare the pattern in zGlob[] against the text in z[].  Return TRUE
** if they match and FALSE (0) if they do not match.
**
** Globbing rules:
**
**      '*'       Matches any sequence of zero or more characters.
**
**      '?'       Matches exactly one character.
**
**     [...]      Matches one character from the enclosed list of
**                characters.
**
**     [^...]     Matches one character not in the enclosed list.
**
**      '#'       Matches any sequence of one or more digits with an
**                optional + or - sign in front
**
**      ' '       Any span of whitespace matches any other span of
**                whitespace.
**
** Extra whitespace at the end of z[] is ignored.
*//*
** Print the current sqlite3_errmsg() value to stderr and return 1.
*//*
** Print the given string as an error message.
*//* Characters ok to display *//*
** Implementation of the ".dbtotxt" command.
**
** Return 1 on error, 2 to exit, and 0 otherwise.
*//*
** Implementation of the ".dbinfo" command.
**
** Return 1 on error, 2 to exit, and 0 otherwise.
*//*
** Convert a 2-byte or 4-byte big-endian integer into a native integer
*//*
** Run an SQL command and return the single integer result.
*//* !defined(SQLITE_NOHAVE_SYSTEM) *//* Give the start/open/xdg-open command some time to get
        ** going before we continue, and potential delete the
        ** p->zTempFile data file out from under it *//*
** Change the output file back to stdout.
**
** If the p->doXdgOpen flag is set, that means the output was being
** redirected to a temporary file named by p->zTempFile.  In that case,
** launch start/open/xdg-open on that temporary file.
*//*
** Change the output stream (file or pipe or console) to something else.
*//*
** Open a new database file named "zNewDb".  Try to recover as much information
** as possible out of the main database (which might be corrupt) and write it
** into zNewDb.
*//*
** Try to transfer all rows of the schema that match zWhere.  For
** each row, invoke xForEach() on the object defined by that row.
** If an error is encountered while moving forward through the
** sqlite_schema table, try again moving backwards.
*//* End for(k=0...) *//* End while *//* End for *//*
** Try to transfer data for table zTable.  If an error is seen while
** moving forward, try to go backwards.  The backwards movement won't
** work for WITHOUT ROWID tables.
*//* Read a single field of ASCII delimited text.
**
**   +  Input comes from p->in.
**   +  Store results in p->z of length p->n.  Space to hold p->z comes
**      from sqlite3_malloc64().
**   +  Use p->cSep as the column separator.  The default is "\x1F".
**   +  Use p->rSep as the row separator.  The default is "\x1E".
**   +  Keep track of the row number in p->nLine.
**   +  Store the character that terminates the field in p->cTerm.  Store
**      EOF on end-of-file.
**   +  Report syntax errors on stderr
*//* If this is the first field being parsed and it begins with the
    ** UTF-8 BOM  (0xEF BB BF) then skip the BOM *//* Read a single field of CSV text.  Compatible with rfc4180 and extended
** with the option of having a separator other than ",".
**
**   +  Input comes from p->in.
**   +  Store results in p->z of length p->n.  Space to hold p->z comes
**      from sqlite3_malloc64().
**   +  Use p->cSep as the column separator.  The default is ",".
**   +  Use p->rSep as the row separator.  The default is "\n".
**   +  Keep track of the line number in p->nLine.
**   +  Store the character that terminates the field in p->cTerm.  Store
**      EOF on end-of-file.
**   +  Report syntax errors on stderr
*//* Append a single byte to z[] *//* Clean up resourced used by an ImportCtx *//* The row separator character.  (Usually "\n") *//* The column separator character.  (Usually ",") *//* Character that terminated the most recent field *//* True if one or more bytes already read *//* Number of errors encountered *//* Number of rows imported *//* Current line number *//* Space allocated for z[] *//* Number of bytes in z *//* Accumulated text for a field *//* Func to close in *//* Read the CSV text from this input stream *//* Name of the input file *//*
** An object used to read a CSV and other files for import.
*//*
** A no-op routine that runs with the ".breakpoint" doc-command.  This is
** a useful spot to set a debugger breakpoint.
**
** This routine does not do anything practical.  The code are there simply
** to prevent the compiler from optimizing this routine out.
*//* Auxiliary output *//* Usually a pointer to sqlite_stmt *//* The ShellState pointer *//* The trace type *//*
** A routine for handling output from sqlite3_trace().
*//*
** Try to open an output file.   The names "stdout" and "stderr" are
** recognized and do the right thing.  NULL is returned if the output
** filename is "off".
*//*
** Close an output file, assuming it is not stderr or stdout
*//*
** Set or clear a shell flag according to a boolean value.
*//*
** Interpret zArg as either an integer or a boolean value.  Return 1 or 0
** for TRUE and FALSE.  Return the integer value if appropriate.
*//*
** Do C-language style dequoting.
**
**    \a    -> alarm
**    \b    -> backspace
**    \t    -> tab
**    \n    -> newline
**    \v    -> vertical tab
**    \f    -> form feed
**    \r    -> carriage return
**    \s    -> space
**    \"    -> "
**    \'    -> '
**    \\    -> backslash
**    \NNN  -> ascii character NNN in octal
**    \xHH  -> ascii character HH in hexadecimal
*//* Load the schema *//*
** Linenoise completion callback. Note that the 3rd argument is from
** the "msteveb" version of linenoise, not the "antirez" version.
*//*
** Readline completion callbacks
*//*
** Attempt to close the database connection.  Report errors.
*//* Let custom-included extensions expose their functionality.
     * The WHATEVER_EXPOSE( db, pzErrorMsg ) macro should cause
     * the SQL functions, virtual tables, collating sequences or
     * VFS's implemented by the extension to be registered.
     *//* Let custom-included extensions get their ..._init() called.
     * The WHATEVER_INIT( db, pzErrorMsg, pApi ) macro should cause
     * the extension's sqlite3_*_init( db, pzErrorMsg, pApi )
     * initialization routine to be called.
     *//* Create a preprocessing mechanism for extensions to make
     * their own provisions for being built into the shell.
     * This is a short-span macro. See further below for usage.
     *//* Reflect the use or absence of --unsafe-testing invocation. *//*
** Make sure the database is open.  If it is not, then open it.  If
** the database fails to open, print an error message and exit.
*//* Open as ZIP if name matches *.zip *//* Return after error if true *//* Flags for open_db().
**
** The default behavior of open_db() is to exit(1) if the database fails to
** open.  The OPEN_DB_KEEPALIVE flag changes that so that it prints an error
** but still returns without calling exit.
**
** The OPEN_DB_ZIPFILE flag causes open_db() to prefer to open files as a
** ZIP archive if the file does not exist or is empty and its name matches
** the *.zip pattern.
*//*
** Scalar function "usleep(X)" invokes sqlite3_sleep(X) and returns X.
*//* Round n up to the next multiple of pgsz *//*
** Reconstruct an in-memory database using the output from the "dbtotxt"
** program.  Read content from the file in p->aAuxDb[].zDbFilename.
** If p->aAuxDb[].zDbFilename is 0, then read from standard input.
*//*
** Try to deduce the type of file for zName based on its content.  Return
** one of the SHELL_OPEN_* constants.
**
** If the file does not exist or is empty but its name looks like a ZIP
** archive and the dfltZip flag is true, then assume it is a ZIP archive.
** Otherwise, assume an ordinary database regardless of the filename if
** the type cannot be determined from content.
*//*
** Implementation of the xFilter function for an open session.  Omit
** any tables named by ".session filter" but let all other table through.
*//*
** Close all OpenSession objects and release all associated resources.
*//*
** Close a single OpenSession object and release all of its associated
** resources.
*//*
** Read the content of file zName into memory obtained from sqlite3_malloc64()
** and return a pointer to the buffer. The caller is responsible for freeing
** the memory.
**
** If parameter pnByte is not NULL, (*pnByte) is set to the number of bytes
** read.
**
** For convenience, a nul-terminator byte is always appended to the data read
** from the file before the buffer is returned. This byte is not included in
** the final value of (*pnByte), if applicable.
**
** NULL is returned if any error is encountered. The final value of *pnByte
** is undefined in this case.
*//* Forward reference *//* Look for documented commands that contain zPattern anywhere.
    ** Show complete text of all documented commands that match. *//* when zPattern is a prefix of exactly one command, then include
        ** the details of that command, which should begin at offset j *//* Seek documented commands for which zPattern is an exact prefix *//* Show all or most commands
    ** *zPattern==0   => summary of documented commands only
    ** *zPattern=='0' => whole help for undocumented commands
    ** Otherwise      => whole help for documented commands
    *//*
** Output help text.
**
** zPattern describes the set of commands for which help text is provided.
** If zPattern is NULL, then show all commands, but only give a one-line
** description of each.
**
** Return the number of matches.
*//* SQLITE_OMIT_TRACE *//* Note that .open is (partially) available in WASM builds but is
  ** currently only intended to be used by the fiddle tool, not
  ** end users, so is "undocumented." *//*
** Text of help messages.
**
** The help text for each individual command begins with a line that starts
** with ".".  Subsequent lines are supplemental information.
**
** There must be two or more spaces between the end of the command and the
** start of the description of what that command does.
*//*
** Run zQuery.  Use dump_callback() as the callback routine so that
** the contents of the query are output as SQL statements.
**
** If we get a SQLITE_CORRUPT error, rerun the query after appending
** "ORDER BY rowid DESC" to the end.
*//* Build an appropriate SELECT statement *//* If preserving the rowid, add a column list after the table name.
    ** In other words:  "INSERT INTO tab(rowid,a,b,c,...) VALUES(...)"
    ** instead of the usual "INSERT INTO tab VALUES(...)".
    *//* Always quote the table name, even if it appears to be pure ascii,
    ** in case it is a keyword. Ex:  INSERT INTO "table" ... *//*
** This is a different callback routine used for dumping the database.
** Each row received by this callback consists of a table name,
** the table type ("index" or "table") and SQL to create the table.
** This routine should print text sufficient to recreate the table.
*//*
** Toggle the reverse_unordered_selects setting.
*//* At this point, we know that azRowid[j] is not the name of any
        ** ordinary column in the table.  Verify that azRowid[j] is a valid
        ** name for the rowid before adding it to azCol[0].  WITHOUT ROWID
        ** tables will fail this last check *//* Only preserve the rowid if we can find a name to use for the
    ** rowid *//* If a single PRIMARY KEY column with type INTEGER was seen, then it
    ** might be an alias for the ROWID.  But it might also be a WITHOUT ROWID
    ** table or a INTEGER PRIMARY KEY DESC column, neither of which are
    ** ROWID aliases.  To distinguish these cases, check to see if
    ** there is a "pk" entry in "PRAGMA index_list".  There will be
    ** no "pk" index if the PRIMARY KEY really is an alias for the ROWID.
    *//* The decision of whether or not a rowid really needs to be preserved
  ** is tricky.  We never need to preserve a rowid for a WITHOUT ROWID table
  ** or a table with an INTEGER PRIMARY KEY.  We are unable to preserve
  ** rowids on tables where the rowid is inaccessible because there are other
  ** columns in the table named "rowid", "_rowid_", and "oid".
  *//* True if one PRIMARY KEY column of type INTEGER *//* Number of PRIMARY KEY columns seen *//*
** Return a list of pointers to strings which are the names of all
** columns in table zTab.   The memory to hold the names is dynamically
** allocated and must be released by the caller using a subsequent call
** to freeColumnList().
**
** The azCol[0] entry is usually NULL.  However, if zTab contains a rowid
** value that needs to be preserved, then azCol[0] is filled in with the
** name of the rowid column.
**
** The first regular column in the table is azCol[1].  The list is terminated
** by an entry with azCol[i]==0.
*//* azCol[0] is a static string *//*
** Release memory previously allocated by tableColumnList().
*//* end while *//* clear saved stmt handle *//* Finalize the statement just executed. If this fails, save a
      ** copy of the error message. Otherwise, set zSql to point to the
      ** next statement to execute. *//* print loop-counters if required *//* print usage stats if stats on *//* If the shell is currently in ".explain" mode, gather the extra
        ** data required to add indents to the output.*//* Also do an EXPLAIN for ".eqp full" mode *//* Show the EXPLAIN QUERY PLAN if .eqp is on *//* save off the prepared statement handle and reset row count *//* this happens for a comment or white-space *//* Tail of unprocessed SQL *//* Return Code *//* Statement to execute. *//* Pointer to ShellState *//*
** Execute a statement or set of statements.  Print
** any result rows/columns depending on the current mode
** set via the supplied callback.
**
** This is very similar to SQLite's built-in sqlite3_exec()
** function except it takes a slightly different callback
** and callback data argument.
*//* ifndef SQLITE_OMIT_VIRTUALTABLE *//*
** Implementation of ".expert" dot command.
*//*
** This function is called either to silently clean up the object
** created by the ".expert" command (if bCancel==1), or to generate a
** report from it and then clean it up (if bCancel==0).
**
** If successful, SQLITE_OK is returned. Otherwise, an SQLite error
** code. In this case, (*pzErr) may be set to point to a buffer containing
** an English language error message. It is the responsibility of the
** caller to eventually free this buffer using sqlite3_free().
*//*
** This function is called to process SQL if the previous shell command
** was ".expert". It passes the SQL in the second argument directly to
** the sqlite3expert object.
**
** If successful, SQLITE_OK is returned. Otherwise, an SQLite error
** code. In this case, (*pzErr) may be set to point to a buffer containing
** an English language error message. It is the responsibility of the
** caller to eventually free this buffer using sqlite3_free().
*//* call the supplied callback with the result row data *//* if data and types extracted successfully... *//* end for *//* from for *//* extract the data and data types *//* save off ptrs to column names *//* Result types *//* Results *//* Names of result columns *//* allocate space for col name ptr, value ptr, and type *//* if we have a result set... *//* perform the first step.  this will tell us if we
  ** have a result set or not and how wide it is.
  *//* Statement to run *//*
** Run a prepared statement
*//*
** Run a prepared statement and output the result in one of the
** table-oriented formats: MODE_Column, MODE_Markdown, MODE_Table,
** or MODE_Box.
**
** This is different from ordinary exec_prepared_stmt() in that
** it has to run the entire query and gather the results into memory
** first, in order to determine column widths, before providing
** any output.
*//* Not reached *//* Extract the value of the i-th current column for pStmt as an SQL literal
** value.  Memory is obtained from sqlite3_malloc64() and must be freed by
** the caller.
*//* Perhaps try to back up to a better place to break the line *//* Output text *//* Output column number *//* Input bytes to be displayed *//* Output bytes generated *//* Input bytes consumed *//* If true, avoid breaking mid-word *//* Max width.  0 means no limit *//* OUT: Tail of the input for next line *//* Input text to be transformed *//*
** z[] is a line of text that is to be displayed the .mode box or table or
** similar tabular formats.  z[] might contain control characters such
** as \n, \t, \f, or \r.
**
** Compute characters to display on the first line of z[].  Stop at the
** first \r, \n, or \f.  Expand \t into spaces.  Return a copy (obtained
** from malloc()) of that first line, which caller should free sometime.
** Write anything to display on the next line into *pzTail.  If this is
** the last line, write a NULL into *pzTail. (*pzTail is not allocated.)
*//*
** Draw a horizontal separator for a MODE_Box table.
*//* Draw horizontal line N characters long using unicode box
** characters
*//* U+253c -|- *//* U+2534 -'- *//* U+252c -,- *//* U+2524 -|  *//* U+251c  |- *//* U+2518 -'  *//* U+2514  '- *//* U+2510 -,  *//* U+250c  ,- *//* U+2502  |  *//* U+2500 --- *//*
** UTF8 box-drawing characters.  Imagine box lines like this:
**
**           1
**           |
**       4 --+-- 2
**           |
**           3
**
** Each box characters has between 2 and 4 of the lines leading from
** the center.  The characters are here identified by the numbers of
** their corresponding lines.
*//* Nothing to do *//*
** Bind parameters on a prepared statement.
**
** Parameter bindings are taken from a TEMP table of the form:
**
**    CREATE TEMP TABLE sqlite_parameters(key TEXT PRIMARY KEY, value)
**    WITHOUT ROWID;
**
** No bindings occur if this table does not exist.  The name of the table
** begins with "sqlite_" so that it will not collide with ordinary application
** tables.  The table must be in the TEMP schema.
*//* Create the TEMP table used to store parameter bindings *//*
** Disable and restore .wheretrace and .treetrace/.selecttrace settings.
*//* Database to query *//*
** Display scan stats.
*//*
** Free the array allocated by explain_data_prepare().
*//* Grow the p->aiIndent array as required *//* Assuming that p2 is an instruction address, set variable p2op to the
    ** index of that instruction in the aiIndent[] array. p2 and p2op may be
    ** different if the current instruction is part of a sub-program generated
    ** by an SQL trigger or foreign key.  *//* The caller guarantees that the leftmost 4 columns of the statement
  ** passed to this function are equivalent to the leftmost 4 columns
  ** of EXPLAIN statement output. In practice the statement may be
  ** an EXPLAIN, or it may be a query on the bytecode() virtual table.  *//* Index of operation in p->aiIndent[] *//* Allocated size of p->aiIndent[], abYield *//* True if op is an OP_Yield *//*
** If compiled statement pSql appears to be an EXPLAIN statement, allocate
** and populate the ShellState.aiIndent[] array with the number of
** spaces each opcode should be indented before it is output.
**
** The indenting rules are:
**
**     * For each "Next", "Prev", "VNext" or "VPrev" instruction, indent
**       all opcodes that occur between the p2 jump destination and the opcode
**       itself by 2 spaces.
**
**     * Do the previous for "Return" instructions for when P2 is positive.
**       See tag-20220407a in wherecode.c and vdbe.c.
**
**     * For each "Goto", if the jump destination is earlier in the program
**       and ends on one of:
**          Yield  SeekGt  SeekLt  RowSetRead  Rewind
**       or if the P1 parameter is one instead of zero,
**       then indent all opcodes between the earlier instruction
**       and "Goto" by 2 spaces.
*//*
** Parameter azArray points to a zero-terminated array of strings. zStr
** points to a single nul-terminated string. Return non-zero if zStr
** is equal, according to strcmp(), to any of the strings in the array.
** Otherwise, return zero.
*//* Do not remove this machine readable comment: extra-stats-output-here *//* True to reset the stats *//*
** Display memory stats.
*//* Which status to display *//* Format for the result *//* Label for this one line *//* Write to this channel *//*
** Display a single line of status using 64-bit values.
*//*
** Attempt to display I/O stats on Linux using /proc/PID/io
*//* SQL string, or NULL *//* Error code returned from API *//* When the error occurs *//*
** Allocate space and save off string indicating current error.
*//* SELECT statement to extract content *//* Query context *//*
** Execute a query statement that will generate SQL output.  Print
** the result columns, comma-separated, on a line and then add a
** semicolon terminator to the end of that line.
**
** If the number of columns is 1 and that column contains text "--"
** then write the semicolon on a separate line.  That way, if a
** "--" comment occurs at the end of the statement, the comment
** won't consume the semicolon terminator.
*//*
** Maybe construct two lines of text that point out the position of a
** syntax error.  Return a pointer to the text, in memory obtained from
** sqlite3_malloc().  Or, if the most recent error does not involve a
** specific token that we can point to, return an empty string.
**
** In all cases, the memory returned is obtained from sqlite3_malloc64()
** and should be released by the caller invoking sqlite3_free().
*//*
** Set the destination table field of the ShellState structure to
** the name of the table given.  Escape any quote characters in the
** table name.
*//* Desired answer *//* Command text *//* Operator:  memo run *//* Test number *//*
** Generate an appropriate SELFTEST table in the main database.
*//*
** This is the callback routine from sqlite3_exec() that appends all
** output onto the end of a ShellText object.
*//* since we don't have type info, call the shell_callback with a NULL value *//*
** This is the callback routine that the SQLite library
** invokes for each row of a query result.
*//* Copy from z[i] back to z[j] *//* .schema and .fullschema with --indent *//* .schema and .fullschema output *//* If there is no data, exit early. *//* If this is the first row seen, print out the headers *//* Column types.  Might be NULL *//* Column names *//* Text of each result column *//* Number of result columns *//*
** This is the callback routine that the shell
** invokes for each row of a query result.
*//*
** Print a markdown or table-style row separator using ascii-art
*//*
** Print N dashes
*//*
** Progress handler callback.
*//*
** Display and reset the EXPLAIN QUERY PLAN data
*//* Render a single level of the graph that has iEqpId as its parent.  Called
** recursively to render sublevels.
*//* Return the next EXPLAIN QUERY PLAN line with iEqpId that occurs after
** pOld, or return the first such line if pOld is NULL
*//*
** Free and reset the EXPLAIN QUERY PLAN data that has been collected
** in p->sGraph.
*//*
** Add a new entry to the EXPLAIN QUERY PLAN data
*//*
** Return true if string z[] has nothing but whitespace and comments to the
** end of the first line.
*//*
** Print a schema statement.  Part of MODE_Semi and MODE_Pretty output.
**
** This routine converts some CREATE TABLE statements for shadow tables
** in FTS3/4/5 into CREATE TABLE IF NOT EXISTS statements.
**
** If the schema statement in z[] contains a start-of-comment and if
** sqlite3_complete() returns false, try to terminate the comment before
** printing the result.  https://sqlite.org/forum/forumpost/d7be961c5c
*//*
** When the ".auth ON" is set, the following authorizer callback is
** invoked.  It always returns SQLITE_OK.
*//* In WASM builds the filesystem is a virtual sandbox, so
      ** there's no harm in using ATTACH. *//*
** This authorizer runs in safe mode.
*//* One of the CTRL_*_EVENT constants *//*
** This routine runs for console events (e.g. Ctrl-C) on Win32
*//*
** This routine runs when the user presses Ctrl-C
*//*
** Output a single term of CSV.  Actually, p->colSeparator is used for
** the separator, which may or may not be a comma.  p->nullValue is
** the null value.  Strings are quoted if necessary.  The separator
** is only issued if bSep is true.
*//*
** If a field contains any character identified by a 1 in the following
** array, then the string must be quoted for CSV.
*//*
** Output the given string with characters that are special to
** HTML escaped.
*//*
** Output the given string as quoted according to JSON quoting rules.
*//* double-quote, backslash, rubout *//*
** Output the given string as a quoted according to C or TCL quoting rules.
*//* Eat lead byte's count. *//* Trailing bytes are too few, too many, or invalid. *//* Got lead byte, look at trail bytes.*//* not a lead byte *//* ASCII *//* Skip over as much z[] input char sequence as is valid UTF-8,
** limited per nAccept char's or whole characters and containing
** no char cn such that ((1<<cn) & ccm)!=0. On return, the
** sequence z:return (inclusive:exclusive) is validated UTF-8.
** Limit: nAccept>=0 => char count, nAccept<0 => character
 *//*
** Find earliest of chars within s specified in zAny.
** With ns == ~0, is like strpbrk(s,zAny) and s must be 0-terminated.
*//*
** Output the given string as a quoted string using SQL quoting conventions.
** Additionallly , escape the "\n" and "\r" characters so that they do not
** get corrupted by end-of-line translation facilities in some operating
** systems.
**
** This is like output_quoted_string() but with the addition of the \r\n
** escape mechanism.
*//*
** Output the given string as a quoted string using SQL quoting conventions.
**
** See also: output_quoted_escaped_string()
*//* Space to store a generated string *//* Try these first *//* Result must not appear anywhere in z *//*
** Find a string that is not found anywhere in z[].  Return a pointer
** to that string.
**
** Try to use zA and zB first.  If both of those are already found in z[]
** then make up some string and store it in the buffer zBuf.
*//*
** Output the given string as a hex-encoded blob (eg. X'1234' )
*//*
** Set output mode to text or binary for Windows.
*//*
** Save or restore the current output mode
*//* If the file did not originally contain \r\n then convert any new
      ** \r\n back into \n *//* If the original contains \r\n then do no conversions back to \n *//* Remember whether or not the value originally contained \r\n *//* When writing the file to be edited, do \n to \r\n conversions on systems
  ** that want \r\n line endings *//*
** SQL function:   edit(VALUE)
**                 edit(VALUE,EDITOR)
**
** These steps:
**
**     (1) Write VALUE into a temporary file.
**     (2) Run program EDITOR on that temporary file.
**     (3) Read the temporary file back and return its content as the result.
**     (4) Delete the temporary file
**
** If the EDITOR argument is omitted, use the value in the VISUAL
** environment variable.  If still there is no EDITOR, through an error.
**
** Also throw an error if the EDITOR program returns a non-zero exit code.
*//*
** If in safe mode, print an error message described by the arguments
** and exit immediately.
*//*
** SQL function:  shell_putsnl(X)
**
** Write the text X to the screen (or whatever output is being directed)
** adding a newline at the end, and then return X.
*//*
** A callback for the sqlite3_log() interface.
*//*
** Limit input nesting via .read or any other input redirect.
** It's not too expensive, so a generous allowance can be made.
*//*
** These are the column/row/line separators used by the various
** import/export modes.
*//* Full web-page output *//* Like MODE_Explain, but for ".scanstats vm" *//* No query output shown *//* Output only a count of the rows of output *//* Unicode box-drawing characters *//* MySQL-style table formatting *//* Markdown formatting *//* Output JSON *//* Converts EXPLAIN QUERY PLAN output into a graph *//* Pretty-print schemas *//* Use ASCII unit and record separators (0x1F/0x1E) *//* Like MODE_Column, but do not truncate data *//* Quote strings, numbers are plain *//* Generate ANSI-C or TCL quoted elements *//* Quote values as for SQL *//* Generate SQL "insert" statements *//* Generate an XHTML table *//* Same as MODE_List but append ";" to each line *//* One record per line with a separator *//* One record per line in neat columns *//* One column per line.  Blank line between records *//*
** These are the allowed modes.
*//*
** Macros for testing and setting shellFlgs
*//* allow unsafe testing features *//* .dump omits system tables *//* .dump show data only *//* showHeader has been specified *//* .echo on/off, or --echo setting *//* .changes setting *//* .dump --newline flag *//* .dump preserves rowid values *//* The --backslash option is used *//* Lookaside memory is used *//* The --pagecache option is used *//*
** These are the allowed shellFlgs values
*//* Cancel the --limit after firing once *//* Reset the count when the progress
                                   ** callback limit is reached, and for each
                                   ** top-level SQL statement *//* Omit announcing every progress callback *//* Bits in the ShellState.flgProgress variable *//* Show normalized SQL text *//* Show expanded SQL text *//* Show input SQL text *//* Allowed values for ShellState.eTraceType
*//* Use "dbtotxt" output as data source *//* Open using sqlite3_deserialize() *//* Open a normal database read-only *//* Use the zipfile virtual table *//* Use appendvfs *//* Normal database file *//* No open-mode specified *//* Allowed values for ShellState.openMode
*//* Show full EXPLAIN *//* On and also show plans for triggers *//* Automatic EQP is on *//* Automatic EXPLAIN QUERY PLAN is off *//* Allowed values for ShellState.autoEQP
*//* Default name for db file *//* Cursor pos into zInput *//* Input string from wasm/JS proxy *//* Valid if previous command was ".expert OPT..." *//* Information for the graphical EXPLAIN QUERY PLAN *//* Nonce for temporary safe-mode escapes *//* Index of current op in aiIndent[] *//* Size of array aiIndent[] *//* Array of indents used in MODE_Explain *//* Currently active database connection *//* Array of all database connections *//* Array of sessions.  [0] is in focus. *//* Number of active sessions *//* Free this memory allocation on close *//* Filename used to open the connection *//* Connection pointer *//* Storage space for auxiliary database connections *//* Write log output here *//* Current statement if any. *//* Filename for *out *//* The text to print when a NULL comes back from
                         ** the database *//* Number of slots in colWidth[] and actualWidth[] *//* Actual width of each column *//* Requested width of each column in columnar modes *//* Saved row separator *//* Saved column separator *//* Row separator character for MODE_Ascii *//* Column separator character for several modes *//* Name of current test case *//* Temporary file that might need deleting *//* Name of destination table when MODE_Insert *//* --maxsize argument to .open *//* Saved copy of flags *//* Various flags *//* Flags for the progress callback *//* Maximum progress callbacks before failing *//* Number of progress callbacks encountered *//* Number of ".check" commands run *//* True to show column names in List or Column mode *//* True if PRAGMA writable_schema=ON *//* Output mode before ".explain on" *//* temporary output mode for the current query *//* Saved mode *//* An output mode setting *//* Output for sqlite3_trace() *//* Write results here *//* Read commands from this stream *//* Additional flags to open.  (SQLITE_OPEN_NOFOLLOW) *//* Line number of last line read from in *//* Number of records displayed so far *//* Revert to stdout when reaching zero *//* Track nesting level of .read and other redirects *//* Mask of vertical lines in the EQP output graph *//* True to display memory stats before each finalize *//* Option values affecting columnar mode output *//* Do NL-to-CRLF translations when enabled (maybe) *//* See comments above doAutoDetectRestore() *//* The long-term value of bSafeMode *//* True to prohibit unsafe operations *//* SHELL_TRACE_* value for type of trace *//* Depth of the EQP output graph *//* Invoke start/open/xdg-open in output_reset() *//* SHELL_OPEN_NORMAL, _APPENDVFS, or _ZIPFILE *//* True to display scan stats before each finalize *//* autoEQP is in trace mode *//* autoEQP is in test mode *//* Run EXPLAIN QUERY PLAN prior to each SQL stmt *//* Automatically turn on .explain mode *//* The database *//*
** State information about the database connection is contained in an
** instance of the following structure.
*//* In columnar modes, wrap at word boundaries  *//* Quote results for .mode box and table *//* In columnar modes, wrap lines reaching this limit *//* Parameters affecting columnar mode result display (defaulting together) *//* Graph prefix *//* Last element of the pRow list *//* Linked list of all rows of the EQP output *//* All EQP output is collected into an instance of the following *//* Text to display for this row *//* Next row in sequence *//* ID of the parent row *//* ID for this row *//* A single line in the EQP output *//* The open session *//* Array of xFilter rejection GLOB patterns *//* Number of xFilter rejection GLOB patterns *//* Symbolic name for this session *//*
** State information for a single open session
*//* SQLITE_HAVE_SQLITE3R *//************************* End ../ext/recover/sqlite3recover.c ********************//*
** Free all resources associated with the recover handle passed as the only
** argument. The results of using a handle with any sqlite3_recover_**
** API function after it has been passed to this function are undefined.
**
** A copy of the value returned by the first call made to sqlite3_recover_run()
** on this handle is returned, or SQLITE_OK if sqlite3_recover_run() has
** not been called on this handle.
*//*
** Do the configured recovery operation. Return SQLITE_OK if successful, or
** else an SQLite error code.
*//*
** Do a unit of work towards the recovery job. Return SQLITE_OK if
** no error has occurred but database recovery is not finished, SQLITE_DONE
** if database recovery has been successfully completed, or an SQLite
** error code if an error has occurred.
*//* This undocumented magic configuration option is used to set the
        ** name of the auxiliary database that is ATTACH-ed to the database
        ** connection and used to hold state information during the
        ** recovery process.  This option is for debugging use only and
        ** is subject to change or removal at any time. *//*
** Configure the handle.
*//*
** Return the handle error code.
*//*
** Return the handle error message, if any.
*//*
** Initialize a recovery handle that returns recovered data in the
** form of SQL statements via a callback.
*//*
** Initialize a recovery handle that creates a new database containing
** the recovered data.
*//* Context arg for _recover_init_sql() *//* SQL callback for _recover_init_sql() *//* Output URI for _recover_init() *//*
** This is a worker function that does the heavy lifting for both init
** functions:
**
**     sqlite3_recover_init()
**     sqlite3_recover_init_sql()
**
** All this function does is allocate space for the recover handle and
** take copies of the input parameters. All the real work is done within
** sqlite3_recover_run().
*//* If no error has occurred, commit the write transaction on the output
      ** database. Regardless of whether or not an error has occurred, make
      ** an attempt to end the read transaction on the input database.  *//* Open transactions on both the input and output databases. *//* Open the output database. And register required virtual tables and 
      ** user functions with the new handle. *//* This is the very first call to sqlite3_recover_step() on this object.
      *//*
** This function does the work of a single sqlite3_recover_step() call. It
** is guaranteed that the handle is not in an error state when this
** function is called.
*//*
** Uninstall the VFS wrapper that was installed around the file-descriptor open
** on the input database for recover handle p. Mutex RECOVER_MUTEX_ID must be
** held when this function is called.
*//*
** Install the VFS wrapper around the file-descriptor open on the input
** database for recover handle p. Mutex RECOVER_MUTEX_ID must be held
** when this function is called.
*//*
** Methods of the wrapper VFS. All methods except for xRead() and xClose()
** simply uninstall the sqlite3_io_methods wrapper, invoke the equivalent
** method on the lower level VFS, then reinstall the wrapper before returning.
** Those that return an integer value use the RECOVER_VFS_WRAPPER macro.
*//*
** Used to make sqlite3_io_methods wrapper methods less verbose.
*//* Ensure that the database has a valid header file. The only fields
      ** that really matter to recovery are:
      **
      **   + Database page size (16-bits at offset 16)
      **   + Size of db in pages (32-bits at offset 28)
      **   + Database encoding (32-bits at offset 56)
      **
      ** Also preserved are:
      **
      **   + first freelist page (32-bits at offset 32)
      **   + size of freelist (32-bits at offset 36)
      **   + the wal-mode flags (16-bits at offset 18)
      **
      ** We also try to preserve the auto-vacuum, incr-value, user-version
      ** and application-id fields - all 32 bit quantities at offsets 
      ** 52, 60, 64 and 68. All other fields are set to known good values.
      **
      ** Byte offset 105 should also contain the page-size as a 16-bit 
      ** integer.
      *//*
** The xRead() method of the wrapper VFS. This is used to intercept calls
** to read page 1 of the input database.
*//* Size of database file in bytes *//* Possible nReserve value *//* File-handle open on input database *//* Recover handle *//*
** Detect the page-size of the database opened by file-handle pFd by 
** searching the first part of the file for a well-formed SQLite b-tree 
** page. If parameter nReserve is non-zero, then as well as searching for
** a b-tree page with zero reserved bytes, this function searches for one
** with nReserve reserved bytes at the end of it.
**
** If successful, set variable p->detected_pgsz to the detected page-size
** in bytes and return SQLITE_OK. Or, if no error occurs but no valid page
** can be found, return SQLITE_OK but leave p->detected_pgsz set to 0. Or,
** if an error occurs (e.g. an IO or OOM error), then an SQLite error code
** is returned. The final value of p->detected_pgsz is undefined in this
** case.
*//*
** Write value v to buffer a[] as a 32-bit big-endian unsigned integer.
*//*
** Write value v to buffer a[] as a 16-bit big-endian unsigned integer.
*//* iVersion *//* Run through the cells *//* Follow the free-list. This is the same format for all b-tree pages. *//* Offset of cell array in page *//* Number of cells on page *//*
** The second argument points to a buffer n bytes in size. If this buffer
** or a prefix thereof appears to contain a well-formed SQLite b-tree page, 
** return the page-size in bytes. Otherwise, if the buffer does not 
** appear to contain a well-formed b-tree page, return 0.
*//*
** Decode an SQLite varint from buffer a[]. Write the decoded value to (*pVal)
** and return the number of bytes consumed.
*//*
** Decode and return an unsigned 32-bit big-endian integer value from 
** buffer a[].
*//*
** Decode and return an unsigned 16-bit big-endian integer value from 
** buffer a[].
*//*
** Free all resources allocated as part of sqlite3_recover_step() calls.
*//*
** Free all resources allocated as part of sqlite3_recover_step() calls
** in one of the RECOVER_STATE_LOSTANDFOUND[123] states.
*//*
** Perform one step (sqlite3_recover_step()) of work for the connection 
** passed as the only argument, which is guaranteed to be in
** RECOVER_STATE_LOSTANDFOUND2 state - during which the pages identified 
** in RECOVER_STATE_LOSTANDFOUND1 are sorted into sets that likely belonged 
** to the same database tree.
*//*
** Initialize resources required by RECOVER_STATE_LOSTANDFOUND2 
** state - during which the pages identified in RECOVER_STATE_LOSTANDFOUND1
** are sorted into sets that likely belonged to the same database tree.
*//*
** Perform one step (sqlite3_recover_step()) of work for the connection 
** passed as the only argument, which is guaranteed to be in
** RECOVER_STATE_LOSTANDFOUND1 state - during which the set of pages not
** already allocated to a recovered schema element is determined.
*//* Prepare a statement to iterate through all pages that are part of any tree
  ** in the recoverable part of the input database schema to the bitmap. And,
  ** if !p->bFreelistCorrupt, add all pages that appear to be part of the
  ** freelist.  *//*
** Initialize resources required by sqlite3_recover_step() in
** RECOVER_STATE_LOSTANDFOUND1 state - during which the set of pages not
** already allocated to a recovered schema element is determined.
*//* Bind the root page of this table within the original database to 
      ** SELECT statement p1->pSel. The SELECT statement will then iterate
      ** through cells that look like they belong to table pTab.  *//* If this is the sqlite_sequence table, delete any rows added by
      ** earlier INSERT statements on tables with AUTOINCREMENT primary
      ** keys before recovering its contents. The p1->pTbls SELECT statement
      ** is rigged to deliver "sqlite_sequence" last of all, so we don't
      ** worry about it being modified after it is recovered. *//* If this table is unknown, return early. The caller will invoke this
      ** function again and it will move on to the next table.  *//*
** Perform one step (sqlite3_recover_step()) of work for the connection 
** passed as the only argument, which is guaranteed to be in
** RECOVER_STATE_WRITING state - during which tables recovered from the
** schema of the input database are populated with recovered data.
*//*
** Clean up resources allocated by recoverWriteDataInit() (stuff in 
** sqlite3_recover.w1).
*//* Prepare the SELECT to loop through schema tables (pTbls) and the SELECT
  ** to loop through cells that appear to belong to a single table (pSel). *//* Allocate an array of (sqlite3_value*) in which to accumulate the values
  ** that will be written to the output database in a single row. *//* Figure out the maximum number of columns for any table in the schema *//*
** Initialize resources required in RECOVER_STATE_WRITING state - during which
** tables recovered from the schema of the input database are populated with
** recovered data.
*//* Name of lost_and_found table *//*
** Initialize resources required in RECOVER_STATE_LOSTANDFOUND3 
** state - during which the lost-and-found table of the output database 
** is populated with recovered data that can not be assigned to any 
** recovered schema object.
*//*
** Perform one step (sqlite3_recover_step()) of work for the connection 
** passed as the only argument, which is guaranteed to be in
** RECOVER_STATE_LOSTANDFOUND3 state - during which the lost-and-found 
** table of the output database is populated with recovered data that can 
** not be assigned to any recovered schema object.
*//* Discard the accumulated row data *//* id *//* nfield *//* pgno *//* rootpgno *//* Insert the new row *//*
** Recover data from page iPage of the input database and write it to
** the lost-and-found table in the output database.
*//*
** Input database page iPg contains data that will be written to the
** lost-and-found table of the output database. This function attempts
** to identify the root page of the tree that page iPg belonged to.
** If successful, it sets output variable (*piRoot) to the page number
** of the root page and returns SQLITE_OK. Otherwise, if an error occurs,
** an SQLite error code is returned and the final value of *piRoot 
** undefined.
*//*
** Synthesize and prepare an INSERT statement to write to the lost_and_found
** table in the output database. The name of the table is zTab, and it has
** nField c* fields.
*//* Number of column fields in new table *//* Recover object *//*
** This function attempts to create a lost and found table within the 
** output db. If successful, it returns a pointer to a buffer containing
** the name of the new table. It is the responsibility of the caller to
** eventually free this buffer using sqlite3_free().
**
** If an error occurs, NULL is returned and an error code and error 
** message left in the recover handle.
*//*
** Search the list of RecoverTable objects at p->pTblList for one that
** has root page iRoot in the input database. If such an object is found,
** return a pointer to it. Otherwise, return NULL.
*//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). In this case it returns NULL.
**
** Otherwise, if the recover handle is configured to create an output
** database (was created by sqlite3_recover_init()), then this function
** prepares and returns an SQL statement to INSERT a new record into table
** pTab, assuming the first nField fields of a record extracted from disk
** are valid.
**
** For example, if table pTab is:
**
**     CREATE TABLE name(a, b GENERATED ALWAYS AS (a+1) STORED, c, d, e);
**
** And nField is 4, then the SQL statement prepared and returned is:
**
**     INSERT INTO (a, c, d) VALUES (?1, ?2, ?3);
**
** In this case even though 4 values were extracted from the input db,
** only 3 are written to the output, as the generated STORED column 
** cannot be written.
**
** If the recover handle is in SQL callback mode, then the SQL statement
** prepared is such that evaluating it returns a single row containing
** a single text value - itself an SQL statement similar to the above,
** except with SQL literals in place of the variables. For example:
**
**     SELECT 'INSERT INTO (a, c, d) VALUES (' 
**          || quote(?1) || ', '
**          || quote(?2) || ', '
**          || quote(?3) || ')';
**
** In either case, it is the responsibility of the caller to eventually
** free the statement handle using sqlite3_finalize().
*//*
** This function is called after the output database has been populated. It
** adds all recovered schema elements that were not created in the output
** database by recoverWriteSchema1() - everything except for tables and
** UNIQUE indexes. Specifically:
**
**     * views,
**     * triggers,
**     * non-UNIQUE indexes.
**
** If the recover handle is in SQL callback mode, then equivalent callbacks
** are issued to create the schema elements.
*//*
** This function is called after recoverCacheSchema() has cached those parts
** of the input database schema that could be recovered in temporary table
** "recovery.schema". This function creates in the output database copies
** of all parts of that schema that must be created before the tables can
** be populated. Specifically, this means:
**
**     * all tables that are not VIRTUAL, and
**     * UNIQUE indexes.
**
** If the recovery handle uses SQL callbacks, then callbacks containing
** the associated "CREATE TABLE" and "CREATE INDEX" statements are made.
**
** Additionally, records are added to the sqlite_schema table of the
** output database for any VIRTUAL tables. The CREATE VIRTUAL TABLE
** records are written directly to sqlite_schema, not actually executed.
** If the handle is in SQL callback mode, then callbacks are invoked 
** with equivalent SQL statements.
*//* Root page of same table in INPUT db *//* Name of table created in output db *//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK).
**
** Otherwise, argument zName must be the name of a table that has just been
** created in the output database. This function queries the output db
** for the schema of said table, and creates a RecoverTable object to
** store the schema in memory. The new RecoverTable object is linked into
** the list at sqlite3_recover.pTblList.
**
** Parameter iRoot must be the root page of table zName in the INPUT 
** database.
*//*
** Attach the auxiliary database 'recovery' to the output database handle.
** This temporary database is used during the recovery process and then 
** discarded.
*//* Register the custom user-functions with the output handle. *//* Register the sqlite_dbdata and sqlite_dbptr virtual table modules.
  ** These two are registered with the output database handle - this
  ** module depends on the input handle supporting the sqlite_dbpage
  ** virtual table only.  *//* For iterating through aFunc[] *//* New database handle *//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). A copy of the error code is returned in
** this case. 
**
** Otherwise, an attempt is made to open the output database, attach
** and create the schema of the temporary database used to store
** intermediate data, and to register all required user functions and
** virtual table modules with the output handle.
**
** If no error occurs, SQLITE_OK is returned. Otherwise, an error code
** and error message are left in the recover handle and a copy of the
** error code returned.
*//* Truncate the output database to 0 pages in size. This is done by 
  ** opening a new, empty, temp db, then using the backup API to clobber 
  ** any existing output db with a copy of it. *//*
** Transfer the following settings from the input database to the output
** database:
**
**   + page-size,
**   + auto-vacuum settings,
**   + database encoding,
**   + user-version (PRAGMA user_version), and
**   + application-id (PRAGMA application_id), and
*//*
** If this recover handle is not in SQL callback mode (i.e. was not created 
** using sqlite3_recover_init_sql()) of if an error has already occurred, 
** this function is a no-op. Otherwise, issue a callback with SQL statement
** zSql as the parameter. 
**
** If the callback returns non-zero, set the recover handle error code to
** the value returned (so that the caller will abandon processing).
*//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). A copy of the error code is returned in
** this case. 
**
** Otherwise, attempt to populate temporary table "recovery.schema" with the
** parts of the database schema that can be extracted from the input database.
**
** If no error occurs, SQLITE_OK is returned. Otherwise, an error code
** and error message are left in the recover handle and a copy of the
** error code returned. It is not considered an error if part of all of
** the database schema cannot be recovered due to corruption.
*//*
** Implementation of scalar SQL function "escape_crlf".  The argument passed to
** this function is the output of built-in function quote(). If the first
** character of the input is "'", indicating that the value passed to quote()
** was a text value, then this function searches the input for "\n" and "\r"
** characters and adds a wrapper similar to the following:
**
**   replace(replace(<input>, '\n', char(10), '\r', char(13));
**
** Or, if the first character of the input is not "'", then a copy of the input
** is returned.
*//*
** The implementation of a user-defined SQL function invoked by the 
** sqlite_dbdata and sqlite_dbptr virtual table modules to access pages
** of the database being recovered.
**
** This function always takes a single integer argument. If the argument
** is zero, then the value returned is the number of pages in the db being
** recovered. If the argument is greater than zero, it is a page number. 
** The value returned in this case is an SQL blob containing the data for 
** the identified page of the db being recovered. e.g.
**
**     SELECT getpage(0);       -- return number of pages in db
**     SELECT getpage(4);       -- return page 4 of db as a blob of data 
*//*
** Implementation of SQL scalar function "page_is_used". This function
** is used as part of the procedure for locating orphan rows for the
** lost-and-found table, and it depends on those routines having populated
** the sqlite3_recover.laf.pUsed variable.
**
** The only argument to this function is a page-number. It returns true 
** if the page has already been used somehow during data recovery, or false
** otherwise.
**
**     SELECT page_is_used(<pgno>);
*//*
** Implementation of SQL scalar function "read_i32". The first argument to 
** this function must be a blob. The second a non-negative integer. This 
** function reads and returns a 32-bit big-endian integer from byte
** offset (4*<arg2>) of the blob.
**
**     SELECT read_i32(<blob>, <idx>)
*//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). Zero is returned in this case.
**
** Otherwise, execute "PRAGMA page_count" against the input database. If
** successful, return the integer result. Or, if an error occurs, leave an
** error code and error message in the sqlite3_recover handle and return
** zero.
*//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). NULL is returned in this case.
**
** Otherwise, an attempt is made to interpret zFmt as a printf() style
** formatting string and the result of using the trailing arguments for
** parameter substitution with it written into a buffer obtained from
** sqlite3_malloc(). If successful, a pointer to the buffer is returned.
** It is the responsibility of the caller to eventually free the buffer
** using sqlite3_free().
**
** Or, if an error occurs, an error code and message is left in the recover
** handle and NULL returned.
*//*
** Bind the value pVal to parameter iBind of statement pStmt. Leave an
** error in the recover handle passed as the first argument if an error
** (e.g. an OOM) occurs.
*//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). A copy of p->errCode is returned in this 
** case.
**
** Otherwise, execute SQL script zSql. If successful, return SQLITE_OK.
** Or, if an error occurs, leave an error code and message in the recover
** handle and return a copy of the error code.
*//*
** Finalize SQLite statement handle pStmt. If the call to sqlite3_reset() 
** indicates that an error occurred, and there is not already an error
** in the recover handle passed as the first argument, set the error
** code and error message appropriately.
*//*
** Reset SQLite statement handle pStmt. If the call to sqlite3_reset() 
** indicates that an error occurred, and there is not already an error
** in the recover handle passed as the first argument, set the error
** code and error message appropriately.
**
** This function returns a copy of the statement handle pointer passed
** as the second argument.
*//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). 
**
** Otherwise, argument zFmt is used as a printf() style format string,
** along with any trailing arguments, to create an SQL statement. This
** SQL statement is prepared against database handle db and, if successful,
** the statment handle returned. Or, if an error occurs - either during
** the printf() formatting or when preparing the resulting SQL - an
** error code and message are left in the recover handle.
*//*
** This function is a no-op if recover handle p already contains an error
** (if p->errCode!=SQLITE_OK). 
**
** Otherwise, it attempts to prepare the SQL statement in zSql against
** database handle db. If successful, the statement handle is returned.
** Or, if an error occurs, NULL is returned and an error left in the
** recover handle.
*//*
** Set the recover handle error to the error code and message returned by
** calling sqlite3_errcode() and sqlite3_errmsg(), respectively, on database
** handle db.
*//*
** Query bitmap object pMap for the state of the bit associated with page
** iPg. Return 1 if it is set, or 0 otherwise.
*//*
** Set the bit associated with page iPg in bitvec pMap.
*//*
** Free a bitmap object allocated by recoverBitmapAlloc().
*//*
** This function is a no-op if p->errCode is initially other than SQLITE_OK.
** In this case it returns NULL.
**
** Otherwise, an attempt is made to allocate and return a bitmap object
** large enough to store a bit for all page numbers between 1 and nPg,
** inclusive. The bitmap is initially zeroed.
*//*
** Set the error code and error message for the recover handle passed as
** the first argument. The error code is set to the value of parameter
** errCode.
**
** Parameter zFmt must be a printf() style formatting string. The handle 
** error message is set to the result of using any trailing arguments for 
** parameter substitutions in the formatting string.
**
** For example:
**
**   recoverError(p, SQLITE_ERROR, "no such table: %s", zTablename);
*//*
** This function is a no-op if the recover handle passed as the first 
** argument already contains an error (if p->errCode!=SQLITE_OK). 
**
** Otherwise, an attempt is made to allocate, zero and return a buffer nByte
** bytes in size. If successful, a pointer to the new buffer is returned. Or,
** if an OOM error occurs, NULL is returned and the handle error code
** (p->errCode) set to SQLITE_NOMEM.
*//*
** Like strlen(). But handles NULL pointer arguments.
*//*
** Mutex handling:
**
**    recoverEnterMutex()       -   Enter the recovery mutex
**    recoverLeaveMutex()       -   Leave the recovery mutex
**    recoverAssertMutexHeld()  -   Assert that the recovery mutex is held
*//* 
** Default value for SQLITE_RECOVER_ROWIDS (sqlite3_recover.bRecoverRowid).
*//*
** Use this static SQLite mutex to protect the globals during the
** first call to sqlite3_recover_step().
*//*
** Global variables used by this extension.
*//*
** The various states in which an sqlite3_recover object may exist:
**
**   RECOVER_STATE_INIT:
**    The object is initially created in this state. sqlite3_recover_step()
**    has yet to be called. This is the only state in which it is permitted
**    to call sqlite3_recover_config().
**
**   RECOVER_STATE_WRITING:
**
**   RECOVER_STATE_LOSTANDFOUND1:
**    State to populate the bitmap of pages used by other tables or the
**    database freelist.
**
**   RECOVER_STATE_LOSTANDFOUND2:
**    Populate the recovery.map table - used to figure out a "root" page
**    for each lost page from in the database from which records are
**    extracted.
**
**   RECOVER_STATE_LOSTANDFOUND3:
**    Populate the lost-and-found table itself.
*//* List of tables recovered from schema *//* SELECT against input db sqlite_dbdata *//* Output database *//* Fields used within sqlite3_recover_run() *//* Variables used with states RECOVER_STATE_LOSTANDFOUND[123] *//* Variables used with eState==RECOVER_STATE_WRITING *//* For sqlite3_recover_errmsg() *//* For sqlite3_recover_errcode() *//* Error code and error message *//* SQLITE_RECOVER_SLOWINDEXES setting *//* SQLITE_RECOVER_ROWIDS setting *//* SQLITE_RECOVER_FREELIST_CORRUPT setting *//* Name of lost-and-found table (or NULL) *//* State database to use (or NULL) *//* Values configured by sqlite3_recover_config() *//* Pointer to SQL callback function *//* SQL callback context *//* URI for output database *//* Name of input db ("main" etc.) *//* Input database *//* Copies of sqlite3_recover_init[_sql]() parameters *//*
** Main recover handle structure.
*//* INSERT INTO lost_and_found ... *//* Size of db in pages *//*
** State variables (part of the sqlite3_recover structure) used while
** recovering data destined for the lost and found table (states
** RECOVER_STATE_LOSTANDFOUND[123]).
*//* Number of valid entries in apVal[] *//* Array of nMax values *//* Max column count in any schema table *//* Table currently being written *//*
** State variables (part of the sqlite3_recover structure) used while
** recovering data for tables identified in the recovered schema (state
** RECOVER_STATE_WRITING).
*//* Array of 32-bit bitmasks *//* Size of bitmap *//*
** Bitmap object used to track pages in the input database. Allocated
** and manipulated only by the following functions:
**
**     recoverBitmapAlloc()
**     recoverBitmapFree()
**     recoverBitmapSet()
**     recoverBitmapQuery()
**
** nPg:
**   Largest page number that may be stored in the bitmap. The range
**   of valid keys is 1 to nPg, inclusive.
**
** aElem[]:
**   Array large enough to contain a bit for each key. For key value
**   iKey, the associated bit is the bit (iKey%32) of aElem[iKey/32].
**   In other words, the following is true if bit iKey is set, or 
**   false if it is clear:
**
**       (aElem[iKey/32] & (1 << (iKey%32))) ? 1 : 0
*//* Stored generated column *//* Virtual generated column *//* Column is __HIDDEN__ *//* Normal database column *//* True for IPK column *//* Binding to use in INSERT *//* Field in record on disk *//*
** Each database column is represented by an instance of the following object
** stored in the RecoverTable.aCol[] array of the associated table.
**
** iField:
**   The index of the associated field within database records. Or -1 if
**   there is no associated field (e.g. for virtual generated columns).
**
** iBind:
**   The bind index of the INSERT statement to bind this columns values
**   to. Or 0 if there is no such index (iff (iField<0)).
**
** bIPK:
**   True if this is the INTEGER PRIMARY KEY column.
**
** zCol:
**   Name of column.
**
** eHidden:
**   A RECOVER_EHIDDEN_* constant value (see below for interpretation of each).
*//* If >0, bind rowid to INSERT here *//* True for intkey, false for without rowid *//* Array of columns *//* Number of columns in table *//* Name of table *//* Root page in original database *//*
** When recovering rows of data that can be associated with table
** definitions recovered from the sqlite_schema table, each table is
** represented by an instance of the following object.
**
** iRoot:
**   The root page in the original database. Not necessarily (and usually
**   not) the same in the recovered database.
**
** zTab:
**   Name of the table.
**
** nCol/aCol[]:
**   aCol[] is an array of nCol columns. In the order in which they appear 
**   in the table.
**
** bIntkey:
**   Set to true for intkey tables, false for WITHOUT ROWID.
**
** iRowidBind:
**   Each column in the aCol[] array has associated with it the index of
**   the bind parameter its values will be bound to in the INSERT statement
**   used to construct the output database. If the table does has a rowid
**   but not an INTEGER PRIMARY KEY column, then iRowidBind contains the
**   index of the bind paramater to which the rowid value should be bound.
**   Otherwise, it contains -1. If the table does contain an INTEGER PRIMARY 
**   KEY column, then the rowid value should be bound to the index associated
**   with the column.
**
** pNext:
**   All RecoverTable objects used by the recovery operation are allocated
**   and populated as part of creating the recovered database schema in
**   the output database, before any non-schema data are recovered. They
**   are then stored in a singly-linked list linked by this variable beginning
**   at sqlite3_recover.pTblList.
*//* typedef sqlite3_int64 i64; *//* typedef unsigned char u8; *//* typedef unsigned int u32; *//*
** Declaration for public API function in file dbdata.c. This may be called
** with NULL as the final two arguments to register the sqlite_dbptr and
** sqlite_dbdata virtual tables with a database handle.
*//* #include "sqlite3recover.h" *//*
** 2022-08-27
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
*//************************* Begin ../ext/recover/sqlite3recover.c ******************//************************* End ../ext/recover/dbdata.c ********************//* xIntegrity *//* xShadowName *//* xRollbackTo *//* xRelease *//* xSavepoint *//* xRename *//* xFindMethod *//* xRollback *//* xCommit *//* xSync *//* xBegin *//* xUpdate *//* xRowid - read data *//* xColumn - read data *//* xEof - check for end of scan *//* xNext - advance a cursor *//* xFilter - configure scan constraints *//* xClose - close a cursor *//* xOpen - open a cursor *//* xDestroy *//* xDisconnect *//* xBestIndex *//* xConnect *//* xCreate *//*
** Invoke this routine to register the "sqlite_dbdata" virtual table module
*//* 
** Return the rowid for an sqlite_dbdata or sqlite_dptr table.
*//*
** Return a column for the sqlite_dbdata or sqlite_dbptr table.
*//* Try to determine the encoding of the db by inspecting the header
  ** field on page 1. *//* 
** xFilter method for sqlite_dbdata and sqlite_dbptr.
*//*
** Attempt to figure out the encoding of the database by retrieving page 1
** and inspecting the header field. If successful, set the pCsr->enc variable
** and return SQLITE_OK. Otherwise, return an SQLite error code.
*//* 
** Determine the size in pages of database zSchema (where zSchema is
** "main", "temp" or the name of an attached database) and set 
** pCsr->szDb accordingly. If successful, return SQLITE_OK. Otherwise,
** an SQLite error code.
*//*
** Return true if nul-terminated string zSchema ends in "()". Or false
** otherwise.
*//* 
** Return true if the cursor is at EOF.
*//* Advance to the next cell. The next iteration of the loop will load
        ** the record and so on. *//* Load content from overflow pages *//* Load the nLocal bytes of payload *//* Allocate space for payload. And a bit more to catch small buffer
            ** overruns caused by attempting to read a varint or similar from 
            ** near the end of a corrupt record.  *//* Figure out how much data to read from the local page *//* If this is a leaf intkey cell, load the rowid *//* Load the "byte of payload including overflow" field *//* For an interior node cell, skip past the child-page number *//* This is not a b-tree page with records on it. Continue. *//* If there is no record loaded, load it now. *//*
** Move an sqlite_dbdata or sqlite_dbptr cursor to the next entry.
*//* Maximum number of fields that may appear in a single record. This is
** the "hard-limit", according to comments in sqliteLimit.h. *//* This macro is a copy of the MX_CELL() macro in the SQLite core. Given
** a page-size, it returns the maximum number of cells that may be present
** on the page.  *//*
** Load a value of type eType from buffer pData and use it to set the
** result of context object pCtx.
*//*
** Return the number of bytes of space used by an SQLite value of type
** eType.
*//*
** Like dbdataGetVarint(), but set the output to 0 if it is less than 0
** or greater than 0xFFFFFFFF. This can be used for all varints in an
** SQLite database except for key values in intkey tables.
*//*
** Read a varint.  Put the value in *pVal and return the number of bytes.
*//* OUT: Size of (*ppPage) in bytes *//* OUT: pointer to page buffer *//* Page number of page to load *//* Cursor object *//*
** Load page pgno from the database via the sqlite_dbpage virtual table.
** If successful, set (*ppPage) to point to a buffer containing the page
** data, (*pnPage) to the size of that buffer in bytes and return
** SQLITE_OK. In this case it is the responsibility of the caller to
** eventually free the buffer using sqlite3_free().
**
** Or, if an error occurs, set both (*ppPage) and (*pnPage) to 0 and
** return an SQLite error code.
*//* 
** Utility methods to decode 16 and 32-bit big-endian unsigned integers. 
*//*
** Close an sqlite_dbdata or sqlite_dbptr cursor.
*//*
** Restore a cursor object to the state it was in when first allocated 
** by dbdataOpen().
*//*
** Open a new sqlite_dbdata or sqlite_dbptr cursor.
*//*
** This function interprets two types of constraints:
**
**       schema=?
**       pgno=?
**
** If neither are present, idxNum is set to 0. If schema=? is present,
** the 0x01 bit in idxNum is set. If pgno=? is present, the 0x02 bit
** in idxNum is set.
**
** If both parameters are present, schema is in position 0 and pgno in
** position 1.
*//*
** Disconnect from or destroy a sqlite_dbdata or sqlite_dbptr virtual table.
*//*
** Connect to an sqlite_dbdata (pAux==0) or sqlite_dbptr (pAux!=0) virtual 
** table.
*//*
** Release the allocation managed by buffer pBuf.
*//*
** Ensure the buffer passed as the first argument is at least nMin bytes
** in size. If an error occurs while attempting to resize the buffer,
** SQLITE_NOMEM is returned. Otherwise, SQLITE_OK.
*//* Column and schema definitions for sqlite_dbptr *//* Column and schema definitions for sqlite_dbdata *//* True for sqlite3_dbptr table *//* For fetching database pages *//* Base class.  Must be first *//* Table object *//* Integer key value *//* Text encoding *//* Current field number *//* Size of header in bytes *//* Size of pRec[] in bytes *//* Only for the sqlite_dbdata table *//* True to stop after one page *//* Current cell number *//* Number of cells on aPage[] *//* Size of aPage[] in bytes *//* Buffer containing page *//* Current page number *//*
** Buffer type.
*//* #include "sqlite3.h" *//*
** 2019-04-17
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file contains an implementation of two eponymous virtual tables,
** "sqlite_dbdata" and "sqlite_dbptr". Both modules require that the
** "sqlite_dbpage" eponymous virtual table be available.
**
** SQLITE_DBDATA:
**   sqlite_dbdata is used to extract data directly from a database b-tree
**   page and its associated overflow pages, bypassing the b-tree layer.
**   The table schema is equivalent to:
**
**     CREATE TABLE sqlite_dbdata(
**       pgno INTEGER,
**       cell INTEGER,
**       field INTEGER,
**       value ANY,
**       schema TEXT HIDDEN
**     );
**
**   IMPORTANT: THE VIRTUAL TABLE SCHEMA ABOVE IS SUBJECT TO CHANGE. IN THE
**   FUTURE NEW NON-HIDDEN COLUMNS MAY BE ADDED BETWEEN "value" AND
**   "schema".
**
**   Each page of the database is inspected. If it cannot be interpreted as
**   a b-tree page, or if it is a b-tree page containing 0 entries, the
**   sqlite_dbdata table contains no rows for that page.  Otherwise, the
**   table contains one row for each field in the record associated with
**   each cell on the page. For intkey b-trees, the key value is stored in
**   field -1.
**
**   For example, for the database:
**
**     CREATE TABLE t1(a, b);     -- root page is page 2
**     INSERT INTO t1(rowid, a, b) VALUES(5, 'v', 'five');
**     INSERT INTO t1(rowid, a, b) VALUES(10, 'x', 'ten');
**
**   the sqlite_dbdata table contains, as well as from entries related to 
**   page 1, content equivalent to:
**
**     INSERT INTO sqlite_dbdata(pgno, cell, field, value) VALUES
**         (2, 0, -1, 5     ),
**         (2, 0,  0, 'v'   ),
**         (2, 0,  1, 'five'),
**         (2, 1, -1, 10    ),
**         (2, 1,  0, 'x'   ),
**         (2, 1,  1, 'ten' );
**
**   If database corruption is encountered, this module does not report an
**   error. Instead, it attempts to extract as much data as possible and
**   ignores the corruption.
**
** SQLITE_DBPTR:
**   The sqlite_dbptr table has the following schema:
**
**     CREATE TABLE sqlite_dbptr(
**       pgno INTEGER,
**       child INTEGER,
**       schema TEXT HIDDEN
**     );
**
**   It contains one entry for each b-tree pointer between a parent and
**   child page in the database.
*//************************* Begin ../ext/recover/dbdata.c ******************//************************* End ../ext/recover/sqlite3recover.h ********************//* ifndef _SQLITE_RECOVER_H *//* 
** Clean up a recovery object created by a call to sqlite3_recover_init().
** The results of using a recovery object with any API after it has been
** passed to this function are undefined.
**
** This function returns the same value as sqlite3_recover_errcode().
*//*
** If this function is called on an sqlite3_recover handle after
** an error occurs, an SQLite error code is returned. Otherwise, SQLITE_OK.
*//*
** If an error has been encountered during a prior call to
** sqlite3_recover_step(), then this function attempts to return a 
** pointer to a buffer containing an English language explanation of 
** the error. If no error message is available, or if an out-of memory 
** error occurs while attempting to allocate a buffer in which to format
** the error message, NULL is returned.
**
** The returned buffer remains valid until the sqlite3_recover handle is
** destroyed using sqlite3_recover_finish().
*//* 
** Run the recovery operation to completion. Return SQLITE_OK if successful,
** or an SQLite error code otherwise. Calling this function is the same
** as executing:
**
**     while( SQLITE_OK==sqlite3_recover_step(p) );
**     return sqlite3_recover_errcode(p);
*//*
** Perform a unit of work towards the recovery operation. This function 
** must normally be called multiple times to complete database recovery.
**
** If no error occurs but the recovery operation is not completed, this
** function returns SQLITE_OK. If recovery has been completed successfully
** then SQLITE_DONE is returned. If an error has occurred, then an SQLite
** error code (e.g. SQLITE_IOERR or SQLITE_NOMEM) is returned. It is not
** considered an error if some or all of the data cannot be recovered
** due to database corruption.
**
** Once sqlite3_recover_step() has returned a value other than SQLITE_OK,
** all further such calls on the same recover handle are no-ops that return
** the same non-SQLITE_OK value.
*//*
** SQLITE_RECOVER_LOST_AND_FOUND:
**   The pArg argument points to a string buffer containing the name
**   of a "lost-and-found" table in the output database, or NULL. If
**   the argument is non-NULL and the database contains seemingly
**   valid pages that cannot be associated with any table in the
**   recovered part of the schema, data is extracted from these
**   pages to add to the lost-and-found table.
**
** SQLITE_RECOVER_FREELIST_CORRUPT:
**   The pArg value must actually be a pointer to a value of type
**   int containing value 0 or 1 cast as a (void*). If this option is set
**   (argument is 1) and a lost-and-found table has been configured using
**   SQLITE_RECOVER_LOST_AND_FOUND, then is assumed that the freelist is 
**   corrupt and an attempt is made to recover records from pages that
**   appear to be linked into the freelist. Otherwise, pages on the freelist
**   are ignored. Setting this option can recover more data from the
**   database, but often ends up "recovering" deleted records. The default 
**   value is 0 (clear).
**
** SQLITE_RECOVER_ROWIDS:
**   The pArg value must actually be a pointer to a value of type
**   int containing value 0 or 1 cast as a (void*). If this option is set
**   (argument is 1), then an attempt is made to recover rowid values
**   that are not also INTEGER PRIMARY KEY values. If this option is
**   clear, then new rowids are assigned to all recovered rows. The
**   default value is 1 (set).
**
** SQLITE_RECOVER_SLOWINDEXES:
**   The pArg value must actually be a pointer to a value of type
**   int containing value 0 or 1 cast as a (void*). If this option is clear
**   (argument is 0), then when creating an output database, the recover 
**   module creates and populates non-UNIQUE indexes right at the end of the
**   recovery operation - after all recoverable data has been inserted
**   into the new database. This is faster overall, but means that the
**   final call to sqlite3_recover_step() for a recovery operation may
**   be need to create a large number of indexes, which may be very slow.
**
**   Or, if this option is set (argument is 1), then non-UNIQUE indexes
**   are created in the output database before it is populated with 
**   recovered data. This is slower overall, but avoids the slow call
**   to sqlite3_recover_step() at the end of the recovery operation.
**
**   The default option value is 0.
*//*
** Configure an sqlite3_recover object that has just been created using
** sqlite3_recover_init() or sqlite3_recover_init_sql(). This function
** may only be called before the first call to sqlite3_recover_step()
** or sqlite3_recover_run() on the object.
**
** The second argument passed to this function must be one of the
** SQLITE_RECOVER_* symbols defined below. Valid values for the third argument
** depend on the specific SQLITE_RECOVER_* symbol in use.
**
** SQLITE_OK is returned if the configuration operation was successful,
** or an SQLite error code otherwise.
*//* 
** These two APIs attempt to create and return a new sqlite3_recover object.
** In both cases the first two arguments identify the (possibly
** corrupt) database to recover data from. The first argument is an open
** database handle and the second the name of a database attached to that
** handle (i.e. "main", "temp" or the name of an attached database).
**
** If sqlite3_recover_init() is used to create the new sqlite3_recover
** handle, then data is recovered into a new database, identified by
** string parameter zUri. zUri may be an absolute or relative file path,
** or may be an SQLite URI. If the identified database file already exists,
** it is overwritten.
**
** If sqlite3_recover_init_sql() is invoked, then any recovered data will
** be returned to the user as a series of SQL statements. Executing these
** SQL statements results in the same database as would have been created
** had sqlite3_recover_init() been used. For each SQL statement in the
** output, the callback function passed as the third argument (xSql) is 
** invoked once. The first parameter is a passed a copy of the fourth argument
** to this function (pCtx) as its first parameter, and a pointer to a
** nul-terminated buffer containing the SQL statement formated as UTF-8 as 
** the second. If the xSql callback returns any value other than SQLITE_OK,
** then processing is immediately abandoned and the value returned used as
** the recover handle error code (see below).
**
** If an out-of-memory error occurs, NULL may be returned instead of
** a valid handle. In all other cases, it is the responsibility of the
** application to avoid resource leaks by ensuring that
** sqlite3_recover_finish() is called on all allocated handles.
*//*
** An instance of the sqlite3_recover object represents a recovery
** operation in progress.
**
** Constructors:
**
**    sqlite3_recover_init()
**    sqlite3_recover_init_sql()
**
** Destructor:
**
**    sqlite3_recover_finish()
**
** Methods:
**
**    sqlite3_recover_config()
**    sqlite3_recover_errcode()
**    sqlite3_recover_errmsg()
**    sqlite3_recover_run()
**    sqlite3_recover_step()
*//*
** OVERVIEW:
**
** To use the API to recover data from a corrupted database, an
** application:
**
**   1) Creates an sqlite3_recover handle by calling either
**      sqlite3_recover_init() or sqlite3_recover_init_sql().
**
**   2) Configures the new handle using one or more calls to
**      sqlite3_recover_config().
**
**   3) Executes the recovery by repeatedly calling sqlite3_recover_step() on
**      the handle until it returns something other than SQLITE_OK. If it
**      returns SQLITE_DONE, then the recovery operation completed without 
**      error. If it returns some other non-SQLITE_OK value, then an error 
**      has occurred.
**
**   4) Retrieves any error code and English language error message using the
**      sqlite3_recover_errcode() and sqlite3_recover_errmsg() APIs,
**      respectively.
**
**   5) Destroys the sqlite3_recover handle and frees all resources
**      using sqlite3_recover_finish().
**
** The application may abandon the recovery operation at any point 
** before it is finished by passing the sqlite3_recover handle to
** sqlite3_recover_finish(). This is not an error, but the final state
** of the output database, or the results of running the partial script
** delivered to the SQL callback, are undefined.
*//*
** 2022-08-27
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file contains the public interface to the "recover" extension -
** an SQLite extension designed to recover data from corrupted database
** files.
*//************************* Begin ../ext/recover/sqlite3recover.h ******************//************************* End ../ext/misc/vfstrace.c ********************//*
** Look for the named VFS.  If it is a TRACEVFS, then unregister it
** and delete it.
*//* True to make the new VFS the default *//* 2nd argument to xOut.  ex: stderr *//* Output routine.  ex: fputs *//* Name of the underlying VFS *//* Name of the newly constructed VFS *//*
** Clients invoke this routine to construct a new trace-vfs shim.
**
** Return SQLITE_OK on success.  
**
** SQLITE_NOMEM is returned in the case of a memory allocation error.
** SQLITE_NOTFOUND is returned if zOldVfsName does not exist.
*//*
** Override system calls.
*//*
** Return the most recent error code and message
*//*
** Return the current time as a Julian Day number in *pTimeOut.
*//*
** Sleep for nMicro microseconds. Return the number of microseconds 
** actually slept.
*//*
** Populate the buffer pointed to by zBufOut with nByte bytes of 
** random data.
*//*
** Close the dynamic library handle pHandle.
*//*
** Return a pointer to the symbol zSymbol in the dynamic library pHandle.
*//*
** Populate the buffer zErrMsg (size nByte bytes) with a human readable
** utf-8 string describing the most recent error encountered associated 
** with dynamic libraries.
*//*
** Open the dynamic library located at zPath and return a handle.
*//*
** Populate buffer zOut with the full canonical pathname corresponding
** to the pathname in zPath. zOut is guaranteed to point to a buffer
** of at least (DEVSYM_MAX_PATHNAME+1) bytes.
*//*
** Test for access permissions. Return true if the requested permission
** is available, or false otherwise.
*//*
** Delete the file located at zPath. If the dirSync argument is true,
** ensure the file-system modifications are synced to disk before
** returning.
*//*
** Open an vfstrace file handle.
*//*
** Shared-memory operations.
*//*
** Return the device characteristic flags supported by an vfstrace-file.
*//*
** Return the sector-size in bytes for an vfstrace-file.
*//*
** File control method. For custom operations on an vfstrace-file.
*//*
** Check if another file-handle holds a RESERVED lock on an vfstrace-file.
*//*
** Unlock an vfstrace-file.
*//*
** Lock an vfstrace-file.
*//*
** Return the name of a lock.
*//*
** Return the current file-size of an vfstrace-file.
*//*
** Sync an vfstrace-file.
*//*
** Truncate an vfstrace-file.
*//*
** Write data to an vfstrace-file.
*//*
** Read data from an vfstrace-file.
*//*
** Close an vfstrace-file.
*//*
** Turn tracing output on or off according to mMask.
*//*
** Append to a buffer.
*//*
** Convert value rc into a string and print it using zFormat.  zFormat
** should have exactly one %s
*//*
** Try to convert an error code into a symbolic name for that error code.
*//*
** Send trace output defined by zFormat and subsequent arguments.
*//*
** Return a pointer to the tail of the pathname.  Examples:
**
**     /home/drh/xyzzy.txt -> xyzzy.txt
**     xyzzy.txt           -> xyzzy.txt
*//*
** Method declarations for vfstrace_vfs.
*//*
** Method declarations for vfstrace_file.
*//* Also coverse xUnfetch *//*
** Bit values for vfstrace_info.mTrace.
*//* The real underlying file *//* Base name of the file *//* The trace-VFS to which this file belongs *//*
** The sqlite3_file object for the trace VFS
*//* Pointer back to the trace VFS *//* Name of this trace-VFS *//* First argument to xOut *//* Tracing on/off *//* Mask of interfaces to trace *//* The underlying real VFS *//*
** An instance of this structure is attached to the each trace VFS to
** provide auxiliary information.
*//*
** 2011 March 16
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file contains code implements a VFS shim that writes diagnostic
** output for each VFS call, similar to "strace".
**
** USAGE:
**
** This source file exports a single symbol which is the name of a
** function:
**
**   int vfstrace_register(
**     const char *zTraceName,         // Name of the newly constructed VFS
**     const char *zOldVfsName,        // Name of the underlying VFS
**     int (*xOut)(const char*,void*), // Output routine.  ex: fputs
**     void *pOutArg,                  // 2nd argument to xOut.  ex: stderr
**     int makeDefault                 // Make the new VFS the default
**   );
**
** Applications that want to trace their VFS usage must provide a callback
** function with this prototype:
**
**   int traceOutput(const char *zMessage, void *pAppData);
**
** This function will "output" the trace messages, where "output" can
** mean different things to different applications.  The traceOutput function
** for the command-line shell (see shell.c) is "fputs" from the standard
** library, which means that all trace output is written on the stream
** specified by the second argument.  In the case of the command-line shell
** the second argument is stderr.  Other applications might choose to output
** trace information to a file, over a socket, or write it into a buffer.
**
** The vfstrace_register() function creates a new "shim" VFS named by
** the zTraceName parameter.  A "shim" VFS is an SQLite backend that does
** not really perform the duties of a true backend, but simply filters or
** interprets VFS calls before passing them off to another VFS which does
** the actual work.  In this case the other VFS - the one that does the
** real work - is identified by the second parameter, zOldVfsName.  If
** the 2nd parameter is NULL then the default VFS is used.  The common
** case is for the 2nd parameter to be NULL.
**
** The third and fourth parameters are the pointer to the output function
** and the second argument to the output function.  For the SQLite
** command-line shell, when the -vfstrace option is used, these parameters
** are fputs and stderr, respectively.
**
** The fifth argument is true (non-zero) to cause the newly created VFS
** to become the default VFS.  The common case is for the fifth parameter
** to be true.
**
** The call to vfstrace_register() simply creates the shim VFS that does
** tracing.  The application must also arrange to use the new VFS for
** all database connections that are created and for which tracing is 
** desired.  This can be done by specifying the trace VFS using URI filename
** notation, or by specifying the trace VFS as the 4th parameter to
** sqlite3_open_v2() or by making the trace VFS be the default (by setting
** the 5th parameter of vfstrace_register() to 1).
**
**
** ENABLING VFSTRACE IN A COMMAND-LINE SHELL
**
** The SQLite command line shell implemented by the shell.c source file
** can be used with this module.  To compile in -vfstrace support, first
** gather this file (test_vfstrace.c), the shell source file (shell.c),
** and the SQLite amalgamation source files (sqlite3.c, sqlite3.h) into
** the working directory.  Then compile using a command like the following:
**
**    gcc -o sqlite3 -Os -I. -DSQLITE_ENABLE_VFSTRACE \
**        -DSQLITE_THREADSAFE=0 -DSQLITE_ENABLE_FTS3 -DSQLITE_ENABLE_RTREE \
**        -DHAVE_READLINE -DHAVE_USLEEP=1 \
**        shell.c test_vfstrace.c sqlite3.c -ldl -lreadline -lncurses
**
** The gcc command above works on Linux and provides (in addition to the
** -vfstrace option) support for FTS3 and FTS4, RTREE, and command-line
** editing using the readline library.  The command-line shell does not
** use threads so we added -DSQLITE_THREADSAFE=0 just to make the code
** run a little faster.   For compiling on a Mac, you'll probably need
** to omit the -DHAVE_READLINE, the -lreadline, and the -lncurses options.
** The compilation could be simplified to just this:
**
**    gcc -DSQLITE_ENABLE_VFSTRACE \
**         shell.c test_vfstrace.c sqlite3.c -ldl -lpthread
**
** In this second example, all unnecessary options have been removed
** Note that since the code is now threadsafe, we had to add the -lpthread
** option to pull in the pthreads library.
**
** To cross-compile for windows using MinGW, a command like this might
** work:
**
**    /opt/mingw/bin/i386-mingw32msvc-gcc -o sqlite3.exe -Os -I \
**         -DSQLITE_THREADSAFE=0 -DSQLITE_ENABLE_VFSTRACE \
**         shell.c test_vfstrace.c sqlite3.c
**
** Similar compiler commands will work on different systems.  The key
** invariants are (1) you must have -DSQLITE_ENABLE_VFSTRACE so that
** the shell.c source file will know to include the -vfstrace command-line
** option and (2) you must compile and link the three source files
** shell,c, test_vfstrace.c, and sqlite3.c.
**
** RUNTIME CONTROL OF VFSTRACE OUTPUT
**
** The application can use the "vfstrace" pragma to control which VFS
** APIs are traced.  To disable all output:
**
**    PRAGMA vfstrace('-all');
**
** To enable all output (which is the default setting):
**
**    PRAGMA vfstrace('+all');
**
** Individual APIs can be enabled or disabled by name, with or without
** the initial "x" character.  For example, to set up for tracing lock
** primatives only:
**
**    PRAGMA vfstrace('-all, +Lock,Unlock,ShmLock');
**
** The argument to the vfstrace pragma ignores capitalization and any
** characters other than alphabetics, '+', and '-'.
*//************************* Begin ../ext/misc/vfstrace.c ******************//************************* End ../ext/misc/stmtrand.c ********************//* Unused parameter *//*
** Function:     stmtrand(SEED)
**
** Return a pseudo-random number.
*//* auxdata key *//* State of the pseudo-random number generator *//* #include "sqlite3ext.h" *//*
** 2024-05-24
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** An SQL function that return pseudo-random non-negative integers.
**
**      SELECT stmtrand(123);
**
** A special feature of this function is that the same sequence of random
** integers is returned for each invocation of the statement.  This makes
** the results repeatable, and hence useful for testing.  The argument is
** an integer which is the seed for the random number sequence.  The seed
** is used by the first invocation of this function only and is ignored
** for all subsequent calls within the same statement.
**
** Resetting a statement (sqlite3_reset()) also resets the random number
** sequence.
*//************************* Begin ../ext/misc/stmtrand.c ******************//************************* End ../ext/intck/sqlite3intck.c ********************//*
** Return the SQL statement used to check object zObj. Or, if zObj is 
** NULL, the current SQL statement.
*//*
** Close any read transaction the integrity-check object is holding open
** on the database.
*//*
** Return the error code and message.
*//*
** Return a message describing the corruption encountered by the most recent
** call to sqlite3_intck_step(), or NULL if no corruption was encountered.
*//* Normal case, do nothing. *//*
** Step the integrity-check object.
*//*
** Free the integrity-check object.
*//* OUT: New integrity-check handle *//* "main", "temp" etc. *//* Database handle to operate on *//*
** Open a new integrity-check object.
*//* This table contains a single row consisting of a single value -
      ** the text of an SQL expression that may be used by the main SQL
      ** statement to output an SQL literal that can be used to resume
      ** the scan if it is suspended. e.g. for a rowid table, an expression
      ** like:
      **
      **     format('(%d,%d)', _rowid_, n.ii)
      *//* expr(e) contains one row for each index on table zObj. Value e
      ** is set to an expression that evaluates to NULL if the required
      ** entry is present in the index, or an error message otherwise.  *//* zCommon *//* Table tabname contains a single row. The first column, "db", contains
      ** the name of the db containing the table (e.g. "main") and the second,
      ** "tab", the name of the table itself.  *//* Table idxname contains a single row. The first column, "db", contains
      ** the name of the db containing the table (e.g. "main") and the second,
      ** "tab", the name of the table itself.  *//* If the object being checked is a table, append "NOT INDEXED".
           ** Otherwise, append "INDEXED BY <index>", and then, if the index 
           ** is a partial index " WHERE <condition>".  *//*
      ** For a PK declared as "PRIMARY KEY(a, b) ... WITHOUT ROWID", where
      ** the intck_wrapper aliases of "a" and "b" are "c1" and "c2":
      **
      **   o_pk:   "o.c1, o.c2"
      **   i_pk:   "i.'a', i.'b'"
      **   ...
      **   n_pk:   2
      *//* Table idx_cols contains 1 row for each column in each index on the
      ** table being checked. Columns are:
      **
      **   idx_name: Name of the index.
      **   idx_ispk: True if this index is the PK of a WITHOUT ROWID table.
      **   col_name: Name of indexed column, or NULL for index on expression.
      **   col_expr: Indexed expression, including COLLATE clause.
      **   col_alias: Alias used for column in 'intck_wrapper' table.
      *//* Relation without_rowid also contains just one row. Column "b" is
      ** set to true if the table being examined is a WITHOUT ROWID table,
      ** or false otherwise.  *//* OUT: Number of key-values for this scan *//* Restart key vector, if any *//* Object (table or index) to scan *//* Integrity check object *//*
** Return a pointer to a nul-terminated buffer containing the SQL statement
** used to check database object zObj (a table or index) for corruption.
** If parameter zPrev is not NULL, then it must be a string containing the
** vector key required to restart the check where it left off last time.
** If pnKeyVal is not NULL, then (*pnKeyVal) is set to the number of
** columns in the vector key value for the specified object.
**
** This function uses the sqlite3_intck error code convention.
*//*
** Return true if zObj is an index, or false otherwise.
*//*
** Return true if sqlite3_intck.db has automatic indexes enabled, false
** otherwise.
*//*
** User-defined SQL function wrapper for intckParseCreateIndex():
**
**     SELECT parse_create_index(<sql>, <icol>);
*//* Trim any whitespace from the start and end of the returned string. *//* iStart is now the byte offset of 1 byte passed the final ')' in the
  ** CREATE INDEX statement. Try to find a WHERE clause to return.  *//* Check if this is the end of the current column - either a "," or ")"
    ** when nOpen==1.  *//* Skip forward until the first "(" token *//*
** Argument z points to the text of a CREATE INDEX statement. This function
** identifies the part of the text that contains either the index WHERE 
** clause (if iCol<0) or the iCol'th column of the index.
**
** If (iCol<0), the identified fragment does not include the "WHERE" keyword,
** only the expression that follows it. If (iCol>=0) then the identified
** fragment does not include any trailing sort-order keywords - "ASC" or 
** "DESC".
**
** If the CREATE INDEX statement does not contain the requested field or
** clause, NULL is returned and (*pnByte) is set to 0. Otherwise, a pointer to
** the identified fragment is returned and output parameter (*pnByte) set
** to its size in bytes.
*//*
** Return true if argument c is an ascii whitespace character.
*//*
** Return the size in bytes of the first token in nul-terminated buffer z.
** For the purposes of this call, a token is either:
**
**   *  a quoted SQL string,
*    *  a contiguous series of ascii alphabet characters, or
*    *  any other single byte.
*//* If this is a new object, ensure the previous key value is cleared. *//*
** Find the next database object (table or index) to check. If successful,
** set sqlite3_intck.zObj to point to a nul-terminated buffer containing
** the object's name before returning.
*//* Object is an index. *//* Object is a table, not an index. This is the easy case,as there are 
    ** no DESC columns or NULL values in a primary key.  *//*
** This is used by sqlite3_intck_unlock() to save the vector key value 
** required to restart the current pCheck query as a nul-terminated string 
** in p->zKey.
*//*
** A wrapper around sqlite3_mprintf() that uses the sqlite3_intck error
** code convention.
*//*
** Execute SQL statement zSql. There is no way to obtain any results 
** returned by the statement. This function uses the sqlite3_intck error
** code convention.
*//*
** If there is already an error in handle p, return it. Otherwise, call
** sqlite3_step() on the statement handle and return that value.
*//*
** Finalize SQL statement pStmt. If an error occurs and the handle passed
** as the first argument does not already contain an error, store the
** error in the handle.
*//*
** If the handle passed as the first argument is already in the error state,
** then this function is a no-op (returns NULL immediately). Otherwise, if an
** error occurs within this function, it leaves an error in said handle.
**
** Otherwise, this function treats argument zFmt as a printf() style format
** string. It formats it according to the trailing arguments and then 
** attempts to prepare the results and return the resulting prepared
** statement.
*//*
** If the handle passed as the first argument is already in the error state,
** then this function is a no-op (returns NULL immediately). Otherwise, if an
** error occurs within this function, it leaves an error in said handle.
**
** Otherwise, this function attempts to prepare SQL statement zSql and
** return the resulting statement handle to the user.
*//*
** Some error has occurred while using database p->db. Save the error message
** and error code currently held by the database handle in p->rc and p->zErr.
*//* Returned by sqlite3_intck_test_sql() *//* Error message *//* Current check statement *//* Current object. Or NULL. *//* Copy of zDb parameter to _open() *//*
** nKeyVal:
**   The number of values that make up the 'key' for the current pCheck
**   statement.
**
** rc:
**   Error code returned by most recent sqlite3_intck_step() or 
**   sqlite3_intck_unlock() call. This is set to SQLITE_DONE when
**   the integrity-check operation is finished.
**
** zErr:
**   If the object has entered the error state, this is the error message.
**   Is freed using sqlite3_free() when the object is deleted.
**
** zTestSql:
**   The value returned by the most recent call to sqlite3_intck_testsql().
**   Each call to testsql() frees the previous zTestSql value (using
**   sqlite3_free()) and replaces it with the new value it will return.
*//* #include "sqlite3intck.h" *//*
** 2024-02-08
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
*//************************* Begin ../ext/intck/sqlite3intck.c ******************//************************* End ../ext/intck/sqlite3intck.h ********************//* ifndef _SQLITE_INTCK_H *//*
** This API is used for testing only. It returns the full-text of an SQL
** statement used to test object zObj, which may be a table or index.
** The returned buffer is valid until the next call to either this function
** or sqlite3_intck_close() on the same sqlite3_intck handle.
*//*
** If an error has occurred in an earlier call to sqlite3_intck_step()
** or sqlite3_intck_unlock(), then this method returns the associated 
** SQLite error code. Additionally, if pzErr is not NULL, then (*pzErr)
** may be set to point to a nul-terminated string containing an English
** language error message. Or, if no error message is available, to
** NULL.
**
** If no error has occurred within sqlite3_intck_step() or
** sqlite_intck_unlock() calls on the handle passed as the first argument, 
** then SQLITE_OK is returned and (*pzErr) set to NULL.
*//*
** Close any read-transaction opened by an earlier call to 
** sqlite3_intck_step(). Any subsequent call to sqlite3_intck_step() will
** open a new transaction. Return SQLITE_OK if successful, or an SQLite error
** code otherwise.
**
** If an error occurs, then the integrity-check handle is placed in an error
** state. In this state all subsequent calls to sqlite3_intck_step() or 
** sqlite3_intck_unlock() will immediately return the same error. The 
** sqlite3_intck_error() method may be used to obtain an English language 
** error message in this case.
*//*
** If the previous call to sqlite3_intck_step() encountered corruption 
** within the database, then this function returns a pointer to a buffer
** containing a nul-terminated string describing the corruption in 
** English. If the previous call to sqlite3_intck_step() did not encounter
** corruption, or if there was no previous call, this function returns 
** NULL.
*//*
** Do the next step of the integrity-check operation specified by the handle
** passed as the only argument. This function returns SQLITE_DONE if the 
** integrity-check operation is finished, or an SQLite error code if
** an error occurs, or SQLITE_OK if no error occurs but the integrity-check
** is not finished. It is not considered an error if database corruption
** is encountered.
**
** Following a successful call to sqlite3_intck_step() (one that returns
** SQLITE_OK), sqlite3_intck_message() returns a non-NULL value if 
** corruption was detected in the db.
**
** If an error occurs and a value other than SQLITE_OK or SQLITE_DONE is
** returned, then the integrity-check handle is placed in an error state.
** In this state all subsequent calls to sqlite3_intck_step() or 
** sqlite3_intck_unlock() will immediately return the same error. The 
** sqlite3_intck_error() method may be used to obtain an English language 
** error message in this case.
*//*
** Close and release all resources associated with a handle opened by an
** earlier call to sqlite3_intck_open(). The results of using an
** integrity-check handle after it has been passed to this function are
** undefined.
*//* OUT: New sqlite3_intck handle *//* Database name ("main", "temp" etc.) *//*
** Open a new incremental integrity-check object. If successful, populate
** output variable (*ppOut) with the new object handle and return SQLITE_OK.
** Or, if an error occurs, set (*ppOut) to NULL and return an SQLite error
** code (e.g. SQLITE_NOMEM).
**
** The integrity-check will be conducted on database zDb (which must be "main",
** "temp", or the name of an attached database) of database handle db. Once
** this function has been called successfully, the caller should not use 
** database handle db until the integrity-check object has been destroyed
** using sqlite3_intck_close().
*//*
** An ongoing incremental integrity-check operation is represented by an
** opaque pointer of the following type.
*//*
** Incremental Integrity-Check Extension
** -------------------------------------
**
** This module contains code to check whether or not an SQLite database
** is well-formed or corrupt. This is the same task as performed by SQLite's
** built-in "PRAGMA integrity_check" command. This module differs from
** "PRAGMA integrity_check" in that:
**
**   +  It is less thorough - this module does not detect certain types
**      of corruption that are detected by the PRAGMA command. However,
**      it does detect all kinds of corruption that are likely to cause
**      errors in SQLite applications.
**
**   +  It is slower. Sometimes up to three times slower.
**
**   +  It allows integrity-check operations to be split into multiple
**      transactions, so that the database does not need to be read-locked
**      for the duration of the integrity-check.
**
** One way to use the API to run integrity-check on the "main" database
** of handle db is:
**
**   int rc = SQLITE_OK;
**   sqlite3_intck *p = 0;
**
**   sqlite3_intck_open(db, "main", &p);
**   while( SQLITE_OK==sqlite3_intck_step(p) ){
**     const char *zMsg = sqlite3_intck_message(p);
**     if( zMsg ) printf("corruption: %s\n", zMsg);
**   }
**   rc = sqlite3_intck_error(p, &zErr);
**   if( rc!=SQLITE_OK ){
**     printf("error occured (rc=%d), (errmsg=%s)\n", rc, zErr);
**   }
**   sqlite3_intck_close(p);
**
** Usually, the sqlite3_intck object opens a read transaction within the
** first call to sqlite3_intck_step() and holds it open until the 
** integrity-check is complete. However, if sqlite3_intck_unlock() is
** called, the read transaction is ended and a new read transaction opened
** by the subsequent call to sqlite3_intck_step().
*//************************* Begin ../ext/intck/sqlite3intck.h ******************//************************* End ../ext/expert/sqlite3expert.c ********************//*
** Free an sqlite3expert object.
*//*
** Return a component of the report.
*//*
** Return the total number of statements that have been added to this
** sqlite3expert using sqlite3_expert_sql().
*//* Figure out which of the candidate indexes are preferred by the query
  ** planner and report the results to the user.  *//* Formulate the EXPERT_REPORT_CANDIDATES text *//* Generate the stat1 data *//* Create candidate indexes within the in-memory database file *//* Do trigger processing to collect any extra IdxScan structures *//* Ensure that the provided statement compiles against user's DB. *//* OUT: Error message (if any) *//* SQL statement to add *//* From sqlite3_expert_new() *//*
** Add an SQL statement to the analysis.
*//*
** Configure an sqlite3expert object.
*//* If an error has occurred, free the new object and reutrn NULL. Otherwise,
  ** return the new sqlite3expert handle.  *//* Register the auth callback with dbv *//* Create the vtab schema *//* Copy the entire schema of database [db] into [dbm]. *//* Register UDFs from database [db] with [dbm] and [dbv]. *//* Allow custom collations to be dealt with through prepare. *//* Open two in-memory databases to work with. The "vtab database" (dbv)
  ** will contain a virtual table corresponding to each real table in
  ** the user database schema, and a copy of each view. It is used to
  ** collect information regarding the WHERE, ORDER BY and other clauses
  ** of the user's query.
  *//*
** Allocate a new sqlite3expert object.
*//* no-op.  Only happens on OOM *//*
** Register UDFs from user database with another.
*//* VDBE should never be run. *//*
** dummy functions for no-op implementation of UDFs during expert's work
*//* And a callback to register above upon actual need *//*
** Define and possibly pretend to use a useless collation sequence.
** This pretense allows expert to accept SQL using custom collations.
*//* If iSample==0, no sqlite_stat1 data is required. *//*
** This function is called as part of sqlite3_expert_analyze(). Candidate
** indexes have already been created in database sqlite3expert.dbm, this
** function populates sqlite_stat1 table in the same database.
**
** The stat1 data is generated by querying the 
*//*no-op*//* Formulate the query text *//* This index contains an expression. Ignore it. *//*
** Implementation of scalar function sqlite_expert_rem().
*//* SQLITE_TEXT/BLOB value *//* Size of buffer z *//* Bytes of space allocated at z *//* SQLITE_FLOAT value *//* SQLITE_INTEGER value *//* SQLITE_NULL, INTEGER, REAL, TEXT, BLOB *//* Number of rows returned *//* Number of rows seen *//* Target nRet/nRow value *//* The CVT statement to create the vtab *//* The statement the vtab will pass to sqlite3_declare_vtab() *//* A view. Or a trigger on a view. *//* For each table in the main db schema:
  **
  **   1) Add an entry to the p->pTable list, and
  **   2) Create the equivalent virtual table in dbv.
  *//*
** Execute SQL command zSql using database handle db. If no error occurs,
** set (*pzErr) to NULL and return SQLITE_OK. 
**
** If an error does occur, return an SQLite error code and set (*pzErr) to
** point to a buffer containing an English language error message. Except,
** if the error message begins with "no such module:", then ignore the
** error and return as if the SQL statement had succeeded.
**
** This is used to copy as much of the database schema as possible while 
** ignoring any errors related to missing virtual table modules.
*//* OUT: True if object exists *//*
** This function tests if the schema of the main database of database handle
** db contains an object named zTab. Assuming no error occurs, output parameter
** (*pbContains) is set to true if zTab exists, or false if it does not.
**
** Or, if an error occurs, an SQLite error code is returned. The final value
** of (*pbContains) is undefined in this case.
*//* Rename the table in the temp schema to zInt *//* Create the table and its triggers in the temp schema *//* int iNotUsed = sqlite3_column_int(pExplain, 2); *//* int iParent = sqlite3_column_int(pExplain, 1); *//* int iId = sqlite3_column_int(pExplain, 0); *//* OUT: Error message (sqlite3_malloc) *//*
** This function is called after candidate indexes have been created. It
** runs all the queries to see which indexes they prefer, and populates
** IdxStatement.zIdx and IdxStatement.zEQP with the results.
*//*
** Free the linked list of IdxWrite objects starting at pTab.
*//*
** Free the linked list of IdxTable objects starting at pTab.
*//*
** Free all elements of the linked list starting from pStatement up 
** until pLast (pLast is not freed).
*//*
** Free all elements of the linked list starting from pScan up until pLast
** (pLast is not freed).
*//*
** Free all elements of the linked list starting at pConstraint.
*//*
** Create candidate indexes in database [dbm] based on the data in 
** linked-list pScan.
*//* If no range/ORDER BY passed by the caller, create a version of the
  ** index for each range constraint.  *//* Create an index using the == constraints collected above. And the
  ** range constraint/ORDER BY terms passed in by the caller, if any. *//* Gather up all the == constraints. *//* range/ORDER BY constraints for inclusion *//* Create indexes for this scan *//*
** Return true if list pList (linked by IdxConstraint.pLink) contains
** a constraint compatible with *p. Otherwise return false.
*//* This return means "Gave up trying to find a unique index name." *//* Is is unique among table, view and index names? *//* Index name *//* Hash the list of columns to come up with a name for the index *//* Suppress unused parameter warning *//* Callback for sqlite3_exec() with query with leading count(*) column.
 * The first argument is expected to be an int*, referent to be incremented
 * if that leading column is not exactly '0'.
 *//* Zero the IdxConstraint.bFlag values in the pEq list *//* Count the elements in list pEq *//* Number of elements in pEq *//* List of range constraints *//* List of == constraints *//* Scan for table to search for index on *//* Database to search *//* OUT: Error code *//*
** Search database dbm for an index compatible with the one idxCreateFromCons()
** would create from arguments pScan, pEq and pTail. If no error occurs and 
** such an index is found, return non-zero. Or, if no such index is found,
** return zero.
**
** If an error occurs, set *pRc to an SQLite error code and return zero.
*//* Table index will be created on *//* Column defn accumulated so far *//* IN/OUT: Error code *//*
** This function appends an index column definition suitable for constraint
** pCons to the string passed as zIn and returns the result.
*//*
** Return true if zId must be quoted in order to use it as an SQL
** identifier, or false otherwise.
*//*
** This function is a no-op if *pRc is set to anything other than 
** SQLITE_OK when it is called.
**
** If *pRc is initially set to SQLITE_OK, then the text specified by
** the printf() style arguments is appended to zIn and the result returned
** in a buffer allocated by sqlite3_malloc(). sqlite3_free() is called on
** zIn before returning.
*//* OUT: Error message (if not) *//* OUT: New object (if successful) *//* Database connection to read details from *//*
** Attempt to allocate an IdxTable structure corresponding to table zTab
** in the main database of connection db. If successful, set (*ppOut) to
** point to the new object and return SQLITE_OK. Otherwise, return an
** SQLite error code and set (*ppOut) to NULL. In this case *pzErrmsg may be
** set to point to an error string.
**
** It is the responsibility of the caller to eventually free either the
** IdxTable object or error message using sqlite3_free().
*//*
** Finalize SQL statement pStmt. If (*pRc) is SQLITE_OK when this function
** is called, set it to the return value of sqlite3_finalize() before
** returning. Otherwise, discard the sqlite3_finalize() return value.
*//*
** End of virtual table implementation.
*************************************************************************//* xRename - rename the table *//* xFindFunction - function overloading *//* xRollback - rollback transaction *//* xCommit - commit transaction *//* xSync - sync transaction *//* xBegin - begin transaction *//* xUpdate - write data *//* xEof *//* xDestroy - Drop a table *//* xDisconnect - Disconnect from a table *//* xBestIndex - Determine search strategy *//* xConnect - connect to an existing table *//* xCreate - create a table *//* 
** Virtual table module xFilter method.
*//* 
** Virtual table module xColumn method.
*//* 
** Virtual table module xRowid method.
*//* 
** Virtual table module xNext method.
*//*
** Virtual table module xEof method.
**
** Return non-zero if the cursor does not currently point to a valid 
** record (i.e if the scan has finished), or zero otherwise.
*//* 
** Virtual table module xClose method.
*//* 
** Virtual table module xOpen method.
*//* Add the ORDER BY to the IdxScan object *//* Add the constraints to the IdxScan object *//* Link the new scan object into the list *//* 
** This function is the implementation of both the xConnect and xCreate
** methods of the r-tree virtual table.
**
**   argv[0]   -> module name
**   argv[1]   -> database name
**   argv[2]   -> table name
**   argv[...] -> column names...
*//*************************************************************************
** Beginning of virtual table implementation.
*//* Trailing printf() arguments *//* printf() format of SQL statement *//* OUT: sqlite3_malloc()ed error message *//* OUT: Compiled SQL statement *//* Database handle to compile against *//*
** Prepare an SQL statement using the results of a printf() formatting.
*//* SQL statement to compile *//*
** Prepare an SQL statement.
*//* Write error here *//*
** An error associated with database handle db has just occurred. Pass
** the error message to callback function xOut.
*//*
** Allocate and return a new IdxConstraint object. Set the IdxConstraint.zColl
** variable to point to a copy of nul-terminated string zColl.
*//*
** If the hash table contains an entry with a key equal to the string
** passed as the final two arguments to this function, return a pointer
** to the payload string. Otherwise, if zKey/nKey is not present in the
** hash table, return NULL.
*//*
** If zKey/nKey is present in the hash table, return a pointer to the 
** hash-entry object.
*//*
** If zKey is already present in the hash table, return non-zero and do
** nothing. Otherwise, add an entry with key zKey and payload string zVal to
** the hash table passed as the second argument. 
*//*
** Return the index of the hash bucket that the string specified by the
** arguments to this function belongs.
*//*
** Reset an IdxHash hash table.
*//*
** Initialize an IdxHash hash table.
*//*
** Allocate and return nByte bytes of zeroed memory using sqlite3_malloc(). 
** If the allocation fails, set *pRc to SQLITE_NOMEM and return NULL.
*//* For EXPERT_REPORT_CANDIDATES *//* Hash containing all candidate indexes *//* Error code from whereinfo hook *//* True once analysis has run *//* List of IdxStatement objects *//* List of write objects *//* List of scan objects *//* List of all IdxTable objects *//* Vtab schema for this analysis *//* In-memory db for this analysis *//* User database *//* Percentage of tables to sample for stat1 *//*
** sqlite3expert object.
*//* Next entry in hash *//* Next entry in same hash bucket *//* nul-terminated value string 2 *//* nul-terminated value string *//* nul-terminated key *//*
** A hash table for storing strings. With space for a payload string
** with each entry. Methods are:
**
**   idxHashInit()
**   idxHashClear()
**   idxHashAdd()
**   idxHashSearch()
*//* Plan *//* Indexes *//* SQL statement *//* Statement number *//*
** Each statement being analyzed is represented by an instance of this
** structure.
*//*
** An object of the following type is created for each unique table/write-op
** seen. The objects are stored in a singly-linked list beginning at
** sqlite3expert.pWrite.
*//* Next table in linked list of all tables *//*
** Information regarding a single database table. Extracted from 
** "PRAGMA table_info" by function idxGetTableInfo().
*//* Next IdxScan object for same analysis *//* List of < constraints *//* ORDER BY columns *//* Mask of columns required for cov. index *//* Database containing table zTable *//* Associated table object *//*
** A single scan of a single table.
*//* See above *//* Next constraint in pEq or pRange list *//* True if ORDER BY <expr> DESC *//* Used by idxFindCompatible() *//* Constrained table column *//* True for range, false for eq *//* Collation sequence *//*
** A single constraint. Equivalent to either "col = ?" or "col < ?" (or
** any other type of single-ended range constraint on a column).
**
** pLink:
**   Used to temporarily link IdxConstraint objects into lists while
**   creating candidate indexes.
*//*
** A temp table name that we assume no user database will actually use.
** If this assumption proves incorrect triggers on the table with the
** conflicting name will be ignored.
*//* typedef sqlite3_uint64 u64; *//* !defined(SQLITE_AMALGAMATION) *//* #include "sqlite3expert.h" *//*
** 2017 April 09
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
*//************************* Begin ../ext/expert/sqlite3expert.c ******************//************************* End ../ext/expert/sqlite3expert.h ********************//* !defined(SQLITEEXPERT_H) *//*
** Free an (sqlite3expert*) handle and all associated resources. There 
** should be one call to this function for each successful call to 
** sqlite3-expert_new().
*//*
** Values for the third argument passed to sqlite3_expert_report().
*//*
** Return a component of the report.
**
** This function is called after sqlite3_expert_analyze() to extract the
** results of the analysis. Each call to this function returns either a
** NULL pointer or a pointer to a buffer containing a nul-terminated string.
** The value passed as the third argument must be one of the EXPERT_REPORT_*
** #define constants defined below.
**
** For some EXPERT_REPORT_* parameters, the buffer returned contains 
** information relating to a specific SQL statement. In these cases that
** SQL statement is identified by the value passed as the second argument.
** SQL statements are numbered from 0 in the order in which they are parsed.
** If an out-of-range value (less than zero or equal to or greater than the
** value returned by sqlite3_expert_count()) is passed as the second argument
** along with such an EXPERT_REPORT_* parameter, NULL is always returned.
**
** EXPERT_REPORT_SQL:
**   Return the text of SQL statement iStmt.
**
** EXPERT_REPORT_INDEXES:
**   Return a buffer containing the CREATE INDEX statements for all recommended
**   indexes for statement iStmt. If there are no new recommeded indexes, NULL 
**   is returned.
**
** EXPERT_REPORT_PLAN:
**   Return a buffer containing the EXPLAIN QUERY PLAN output for SQL query
**   iStmt after the proposed indexes have been added to the database schema.
**
** EXPERT_REPORT_CANDIDATES:
**   Return a pointer to a buffer containing the CREATE INDEX statements 
**   for all indexes that were tested (for all SQL statements). The iStmt
**   parameter is ignored for EXPERT_REPORT_CANDIDATES calls.
*//*
** Return the total number of statements loaded using sqlite3_expert_sql().
** The total number of SQL statements may be different from the total number
** to calls to sqlite3_expert_sql().
*//*
** This function is called after the sqlite3expert object has been configured
** with all SQL statements using sqlite3_expert_sql() to actually perform
** the analysis. Once this function has been called, it is not possible to
** add further SQL statements to the analysis.
**
** If successful, SQLITE_OK is returned and (*pzErr) is set to NULL. Or, if
** an error occurs, an SQLite error code is returned and (*pzErr) set to 
** point to a buffer containing an English language error message. In this
** case it is the responsibility of the caller to eventually free the buffer
** using sqlite3_free().
**
** If an error does occur within this function, the sqlite3expert object
** is no longer useful for any purpose. At that point it is no longer
** possible to add further SQL statements to the object or to re-attempt
** the analysis. The sqlite3expert object must still be freed using a call
** sqlite3_expert_destroy().
*//* SQL statement(s) to add *//* From a successful sqlite3_expert_new() *//*
** Specify zero or more SQL statements to be included in the analysis.
**
** Buffer zSql must contain zero or more complete SQL statements. This
** function parses all statements contained in the buffer and adds them
** to the internal list of statements to analyze. If successful, SQLITE_OK
** is returned and (*pzErr) set to NULL. Or, if an error occurs - for example
** due to a error in the SQL - an SQLite error code is returned and (*pzErr)
** may be set to point to an English language error message. In this case
** the caller is responsible for eventually freeing the error message buffer
** using sqlite3_free().
**
** If an error does occur while processing one of the statements in the
** buffer passed as the second argument, none of the statements in the
** buffer are added to the analysis.
**
** This function must be called before sqlite3_expert_analyze(). If a call
** to this function is made on an sqlite3expert object that has already
** been passed to sqlite3_expert_analyze() SQLITE_MISUSE is returned
** immediately and no statements are added to the analysis.
*//*
** Configure an sqlite3expert object.
**
** EXPERT_CONFIG_SAMPLE:
**   By default, sqlite3_expert_analyze() generates sqlite_stat1 data for
**   each candidate index. This involves scanning and sorting the entire
**   contents of each user database table once for each candidate index
**   associated with the table. For large databases, this can be 
**   prohibitively slow. This option allows the sqlite3expert object to
**   be configured so that sqlite_stat1 data is instead generated based on a
**   subset of each table, or so that no sqlite_stat1 data is used at all.
**
**   A single integer argument is passed to this option. If the value is less
**   than or equal to zero, then no sqlite_stat1 data is generated or used by
**   the analysis - indexes are recommended based on the database schema only.
**   Or, if the value is 100 or greater, complete sqlite_stat1 data is
**   generated for each candidate index (this is the default). Finally, if the
**   value falls between 0 and 100, then it represents the percentage of user
**   table rows that should be considered when generating sqlite_stat1 data.
**
**   Examples:
**
**     // Do not generate any sqlite_stat1 data
**     sqlite3_expert_config(pExpert, EXPERT_CONFIG_SAMPLE, 0);
**
**     // Generate sqlite_stat1 data based on 10% of the rows in each table.
**     sqlite3_expert_config(pExpert, EXPERT_CONFIG_SAMPLE, 10);
*//*
** Create a new sqlite3expert object.
**
** If successful, a pointer to the new object is returned and (*pzErr) set
** to NULL. Or, if an error occurs, NULL is returned and (*pzErr) set to
** an English-language error message. In this case it is the responsibility
** of the caller to eventually free the error message buffer using
** sqlite3_free().
*//*
** 2017 April 07
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
*//************************* Begin ../ext/expert/sqlite3expert.h ******************//************************* End ../ext/misc/sqlar.c ********************//*
** Implementation of the "sqlar_uncompress(X,SZ)" SQL function
**
** Parameter SZ is interpreted as an integer. If it is less than or
** equal to zero, then this function returns a copy of X. Or, if
** SZ is equal to the size of X when interpreted as a blob, also
** return a copy of X. Otherwise, decompress blob X using zlib
** utility function uncompress() and return the results (another
** blob).
*//*
** Implementation of the "sqlar_compress(X)" SQL function.
**
** If the type of X is SQLITE_BLOB, and compressing that blob using
** zlib utility function compress() yields a smaller blob, return the
** compressed blob. Otherwise, return a copy of X.
**
** SQLar uses the "zlib format" for compressed content.  The zlib format
** contains a two-byte identification header and a four-byte checksum at
** the end.  This is different from ZIP which uses the raw deflate format.
**
** Future enhancements to SQLar might add support for new compression formats.
** If so, those new formats will be identified by alternative headers in the
** compressed data.
*//*
** 2017-12-17
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** Utility functions sqlar_compress() and sqlar_uncompress(). Useful
** for working with sqlar archives and used by the shell tool's built-in
** sqlar support.
*//************************* Begin ../ext/misc/sqlar.c ******************//************************* End ../ext/misc/zipfile.c ********************//* SQLITE_OMIT_VIRTUALTABLE *//*
** Register the "zipfile" virtual table.
*//*
** xFinalize() callback for zipfile aggregate function.
*//* Increment the count of entries in the archive *//* Append the CDS record to the directory of the new archive *//* Append the data to the body of the new archive *//* Append the LFH to the body of the new archive *//* Assemble the ZipfileEntry object for the new zip archive entry *//* If this is a directory entry, ensure that there is exactly one '/'
  ** at the end of the path. Or, if this is not a directory and the path
  ** ends in '/' it is an error. *//* Decode the "mtime" argument. *//* Decode the "mode" argument. *//* Now inspect the data. If this is NULL, then the new entry must be a
  ** directory.  Otherwise, figure out whether or not the data should
  ** be deflated or simply stored in the zip archive. *//* Inspect the 'method' parameter. This must be either 0 (store), 8 (use
  ** deflate compression) or NULL (choose automatically).  *//* Check that the 'name' parameter looks ok. *//* Martial the arguments into stack variables *//* Free this before returning *//* Size of zName in bytes *//* Path (name) of new entry *//* crc32 of uncompressed data *//* Size of data before compression *//* Size of aData[] in bytes *//* Possibly compressed data for new entry *//* Compression method to use (0 or 8) *//* New entry to add to zip archive *//* Aggregate function context *//*
** xStep() callback for the zipfile() aggregate. This can be called in
** any of the following ways:
**
**   SELECT zipfile(name,data) ...
**   SELECT zipfile(name,mode,mtime,data) ...
**   SELECT zipfile(name,mode,mtime,data,method) ...
*//* Byte allocated at a[] *//* Size of buffer in bytes *//* Pointer to buffer *//* OUT: User data for *pxFunc *//* OUT: Result *//* Name of SQL function *//* Number of SQL function arguments *//* Virtual table handle *//*
** xFindFunction method.
*//* Write out the EOCD record *//* Write out all entries *//*
** Serialize the CDS structure into buffer aBuf[]. Return the number
** of bytes written.
*//* Size of trailing comment in bytes*//* Create the new CDS record. *//* Check that we're not inserting a duplicate entry -OR- updating an
    ** entry with a path, thereby making it into a duplicate. *//* For a directory, check that the last character in the path is a
      ** '/'. This appears to be required for compatibility with info-zip
      ** (the unzip command on unix). It does not create directories
      ** otherwise.  *//* Value specified for "data", and possibly "method". This must be
        ** a regular file or a symlink. *//* data=NULL. A directory *//* Check that "sz" and "rawdata" are both NULL: *//* If this is a DELETE or UPDATE, find the archive entry to delete. *//* True for an update that modifies "name" *//* Also free this *//* Free this *//* Compression method for new entry *//* Size of pData buffer in bytes *//* Pointer to buffer containing content *//* strlen(zPath) *//* Path for new entry *//* Uncompressed size *//* Modification time for new entry *//* Mode for new entry *//* New in-memory CDS entry *//*
** xUpdate method.
*//*
** Unless it is NULL, entry pOld is currently part of the pTab->pFirstEntry
** linked list.  Remove it from the list and free the object.
*//*
** Return a 32-bit timestamp in UNIX epoch format.
**
** If the value passed as the only argument is either NULL or an SQL NULL,
** return the current time. Otherwise, return the value stored in (*pVal)
** cast to a 32-bit unsigned integer.
*//*
** Return the current time as a 32-bit timestamp in UNIX epoch format (like
** time(2)).
*//* Open a write fd on the file. Also load the entire central directory
  ** structure into memory. During the transaction any new file data is 
  ** appended to the archive file, but the central directory is accumulated
  ** in main-memory until the transaction is committed.  *//*
** Both (const char*) arguments point to nul-terminated strings. Argument
** nB is the value of strlen(zB). This function returns 0 if the strings are
** identical, ignoring any trailing '/' character in either path.  *//* The "mode" attribute is a directory, but data has been specified.
    ** Or vice-versa - no data but "mode" is a file or symlink.  *//* OUT: Error message *//* OUT: Mode value *//* If true, default to directory *//* The "extra" data *//* Add the file name *//* Write the LFH itself *//*
** xBestIndex callback.
*//* True for an in-memory zipfile *//* Zip file to scan *//*
** xFilter callback.
*//*
** Add object pNew to the linked list that begins at ZipfileTab.pFirstEntry 
** and ends with pLastEntry. If argument pBefore is NULL, then pNew is added
** to the end of the list. Otherwise, it is added to the list immediately
** before pBefore (which is guaranteed to be a part of said list).
*//* Scan backwards looking for the signature bytes *//* Total size of file in bytes *//* Offset to read from *//* Bytes to read from file *//* Temporary buffer *//* Object to populate *//* Read from this file if aBlob==0 *//* Size of aBlob[] in bytes *//* Pointer to in-memory file image *//* Return errors here *//*
** If aBlob is not NULL, then it points to a buffer nBlob bytes in size
** containing an entire zip archive image. Or, if aBlob is NULL, then pFile
** is guaranteed to be a file-handle open on a zip file.
**
** This function attempts to locate the EOCD record within the zip archive
** and populate *pEOCD with the results of decoding it. SQLITE_OK is
** returned if successful. Otherwise, an SQLite error code is returned and
** an English language error message may be left in virtual-table pTab.
*//*
** Return TRUE if the cursor is at EOF.
*//* z *//* method *//* Figure out if this is a directory or a zero-sized file. Consider
          ** it to be a directory either if the mode suggests so, or if
          ** the final character in the name is '/'.  *//* data *//* rawdata *//* sz *//* mtime *//* TODO: Whether or not the following is correct surely depends on
      ** the platform on which the archive was created.  *//* mode *//* name *//* Which column to return *//* First argument to sqlite3_result_...() *//* The cursor *//*
** Return values of columns for the row at which the series_cursor
** is currently pointing.
*//* Output *//* Input *//*
** Buffer aIn (size nIn bytes) contains uncompressed data. This function
** compresses it and sets (*ppOut) to point to a buffer containing the
** compressed data. The caller is responsible for eventually calling
** sqlite3_free() to release buffer (*ppOut). Before returning, (*pnOut) 
** is set to the size of buffer (*ppOut) in bytes.
**
** If no error occurs, SQLITE_OK is returned. Otherwise, an SQLite error
** code is returned and an error message left in virtual-table handle
** pTab. The values of (*ppOut) and (*pnOut) are left unchanged in this
** case.
*//* Expected output size *//* Size of buffer aIn[] in bytes *//* Compressed data *//* Store result here *//*
** Buffer aIn (size nIn bytes) contains compressed data. Uncompressed, the
** size is nOut bytes. This function uncompresses the data and sets the
** return value in context pCtx to the result (a blob).
**
** If an error occurs, an error code is left in pCtx instead.
*//*
** Advance an ZipfileCsr to its next row of output.
*//* OUT: Pointer to new object *//* Offset of CDS record *//* If aBlob==0, read from this file *//* Store any error message here *//*
** If aBlob is not NULL, then it is a pointer to a buffer (nBlob bytes in
** size) containing an entire zip archive image. Or, if aBlob is NULL,
** then pFile is a file-handle open on a zip file. In either case, this
** function creates a ZipfileEntry object based on the zip archive entry
** for which the CDS record is at offset iOff.
**
** If successful, SQLITE_OK is returned and (*ppEntry) set to point to
** the new object. Otherwise, an SQLite error code is returned and the
** final value of (*ppEntry) undefined.
*//* || (mUnixTime % 2) *//* Convert unix timestamp to JD (2440588 is noon on 1/1/1970) *//*
** The opposite of zipfileMtime(). This function populates the mTime and
** mDate fields of the CDS structure passed as the first argument according
** to the UNIX timestamp value passed as the second.
*//*
** Convert the standard MS-DOS timestamp stored in the mTime and mDate
** fields of the CDS structure passed as the only argument to a 32-bit
** UNIX seconds-since-the-epoch timestamp. Return the result.
**
** "Standard" MS-DOS time format:
**
**   File modification time:
**     Bits 00-04: seconds divided by 2
**     Bits 05-10: minute
**     Bits 11-15: hour
**   File modification date:
**     Bits 00-04: day
**     Bits 05-08: month (1-12)
**     Bits 09-15: years from 1980 
**
** https://msdn.microsoft.com/en-us/library/9kkf9tah.aspx
*//* 0x01 -> modtime is present *//*
** Buffer aExtra (size nExtra bytes) contains zip archive "extra" fields.
** Scan through this buffer to find an "extra-timestamp" field. If one
** exists, extract the 32-bit modification-timestamp from it and store
** the value in output parameter *pmTime.
**
** Zero is returned if no extra-timestamp record could be found (and so
** *pmTime is left unchanged), or non-zero otherwise.
**
** The general format of an extra field is:
**
**   Header ID    2 bytes
**   Data Size    2 bytes
**   Data         N bytes
*//*
** Decode the LFH record in buffer aBuf into (*pLFH). Return SQLITE_ERROR
** if the record is not well-formed, or SQLITE_OK otherwise.
*//*
** Decode the CDS record in buffer aBuf into (*pCDS). Return SQLITE_ERROR
** if the record is not well-formed, or SQLITE_OK otherwise.
*//*
** Magic numbers used to read CDS records.
*//*
** Write a 32-bit little endiate integer into buffer aBuf.
*//*
** Write a 16-bit little endiate integer into buffer aBuf.
*//*
** Read and return a 32-bit little-endian unsigned integer from buffer aBuf.
*//*
** Read and return a 16-bit little-endian unsigned integer from buffer aBuf.
*//* OUT: Error message (from sqlite3_malloc) *//* Number of bytes to read *//* Read into this buffer *//* Read from this file *//*
** Read nRead bytes of data from offset iOff of file pFile into buffer
** aRead[]. Return SQLITE_OK if successful, or an SQLite error code
** otherwise. 
**
** If an error does occur, output variable (*pzErrmsg) may be set to point
** to an English language error message. It is the responsibility of the
** caller to eventually free this buffer using
** sqlite3_free().
*//*
** Set the error message for the virtual table associated with cursor
** pCsr to the results of vprintf(zFmt, ...).
*//* Remove this cursor from the ZipfileTab.pCsrList list. *//*
** Destructor for an ZipfileCsr.
*//*
** Reset a cursor back to the state it was in when first returned
** by zipfileOpen().
*//*
** Constructor for a new ZipfileCsr object.
*//*
** This method is the destructor for zipfile vtab objects.
*//*
** Release resources that should be freed at the end of a write 
** transaction.
*//*
** Free the ZipfileEntry structure indicated by the only argument.
*//* If the table name is not "zipfile", require that the argument be
  ** specified. This stops zipfile tables from being created as:
  **
  **   CREATE VIRTUAL TABLE zzz USING zipfile();
  **
  ** It does not prevent:
  **
  **   CREATE VIRTUAL TABLE zipfile USING zipfile();
  *//*
** Construct a new ZipfileTab virtual table object.
** 
**   argv[0]   -> module name  ("zipfile")
**   argv[1]   -> database name
**   argv[2]   -> table name
**   argv[...] -> "column name" and other module argument fields.
*//*
** If string zIn is quoted, dequote it in place. Otherwise, if the string
** is not quoted, do nothing.
*//*
** Set the error message contained in context ctx to the results of
** vprintf(zFmt, ...).
*//* Size of archive at start of transaction *//* Current size of zip archive *//* File handle open on zip archive *//* Last element in pFirstEntry list *//* Linked list of all files (if pWriteFd!=0) *//* The following are used by write transactions only *//* List of cursors *//* Temporary buffer used for various tasks *//* Host database connection *//* Zip file this table accesses (may be NULL) *//* Base class - must be first *//* Next cursor on same virtual table *//* Current entry *//* Free this list when cursor is closed or reset *//* Parse of central directory record *//* Offset of next record in central directory *//* Zip file *//* Used outside of write transactions *//* If next xNext() call is no-op *//* True when at EOF *//* Cursor ID *//* 
** Cursor type for zipfile tables.
*//* Next element in in-memory CDS *//* cds.szCompressed bytes of compressed data *//* Offset to data in file (if aData==0) *//* cds.nExtra+cds.nComment bytes of extra data *//* Modification time, in UNIX format *//* Parsed CDS record *//*
*** 4.3.7  Local file header:
***
***   local file header signature     4 bytes  (0x04034b50)
***   version needed to extract       2 bytes
***   general purpose bit flag        2 bytes
***   compression method              2 bytes
***   last mod file time              2 bytes
***   last mod file date              2 bytes
***   crc-32                          4 bytes
***   compressed size                 4 bytes
***   uncompressed size               4 bytes
***   file name length                2 bytes
***   extra field length              2 bytes
***   
*//* Filename (sqlite3_malloc()) *//*
*** 4.3.12  Central directory structure:
***
*** ...
***
***   central file header signature   4 bytes  (0x02014b50)
***   version made by                 2 bytes
***   version needed to extract       2 bytes
***   general purpose bit flag        2 bytes
***   compression method              2 bytes
***   last mod file time              2 bytes
***   last mod file date              2 bytes
***   crc-32                          4 bytes
***   compressed size                 4 bytes
***   uncompressed size               4 bytes
***   file name length                2 bytes
***   extra field length              2 bytes
***   file comment length             2 bytes
***   disk number start               2 bytes
***   internal file attributes        2 bytes
***   external file attributes        4 bytes
***   relative offset of local header 4 bytes
*//*
*** 4.3.16  End of central directory record:
***
***   end of central dir signature    4 bytes  (0x06054b50)
***   number of this disk             2 bytes
***   number of the disk with the
***   start of the central directory  2 bytes
***   total number of entries in the
***   central directory on this disk  2 bytes
***   total number of entries in
***   the central directory           2 bytes
***   size of the central directory   4 bytes
***   offset of start of central
***   directory with respect to
***   the starting disk number        4 bytes
***   .ZIP file comment length        2 bytes
***   .ZIP file comment       (variable size)
*//*
** The sizes of the fixed-size part of each of the three main data 
** structures in a zip archive.
*//*
** Magic numbers used to read and write zip files.
**
** ZIPFILE_NEWENTRY_MADEBY:
**   Use this value for the "version-made-by" field in new zip file
**   entries. The upper byte indicates "unix", and the lower byte 
**   indicates that the zip file matches pkzip specification 3.0. 
**   This is what info-zip seems to do.
**
** ZIPFILE_NEWENTRY_REQUIRED:
**   Value for "version-required-to-extract" field of new entries.
**   Version 2.0 is required to support folders and deflate compression.
**
** ZIPFILE_NEWENTRY_FLAGS:
**   Value for "general-purpose-bit-flags" field of new entries. Bit
**   11 means "utf-8 filename and comment".
**
** ZIPFILE_SIGNATURE_CDS:
**   First 4 bytes of a valid CDS record.
**
** ZIPFILE_SIGNATURE_LFH:
**   First 4 bytes of a valid LFH record.
**
** ZIPFILE_SIGNATURE_EOCD
**   First 4 bytes of a valid EOCD record.
*//* Index of column "file" in the above *//* 7: Name of zip file *//* 6: Compression method (integer) *//* 5: Uncompressed data *//* 4: Raw data *//* 3: Size of object *//* 2: Last modification time (secs since 1970)*//* 1: POSIX mode for file *//* 0: Name of file in zip archive *//*
** Definitions for mode bitmasks S_IFDIR, S_IFREG and S_IFLNK.
**
** In some ways it would be better to obtain these values from system 
** header files. But, the dependency is undesirable and (a) these
** have been stable for decades, (b) the values are part of POSIX and
** are also made explicit in [man stat], and (c) are part of the 
** file format for zip archives.
*//* SQLITE_AMALGAMATION *//* typedef UINT16_TYPE u16;           // 2-byte unsigned integer // *//* typedef UINT32_TYPE u32;           // 4-byte unsigned integer // *//* When used as part of the CLI, the sqlite3_stdio.h module will have
** been included before this one. In that case use the sqlite3_stdio.h
** #defines.  If not, create our own for fopen().
*//*
** 2017-12-26
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file implements a virtual table for reading and writing ZIP archive
** files.
**
** Usage example:
**
**     SELECT name, sz, datetime(mtime,'unixepoch') FROM zipfile($filename);
**
** Current limitations:
**
**    *  No support for encryption
**    *  No support for ZIP archives spanning multiple files
**    *  No support for zip64 extensions
**    *  Only the "inflate/deflate" (zlib) compression method is supported
*//************************* Begin ../ext/misc/zipfile.c ******************//************************* End ../ext/misc/appendvfs.c ********************//* 
** This routine is called when the extension is loaded.
** Register the new VFS.
*//*
** All other VFS methods are pass-thrus.
*//*
** Delete an apnd file.
** For an appendvfs, this could mean delete the appendvfs portion,
** leaving the appendee as it was before it gained an appendvfs.
** For now, this code deletes the underlying file too.
*//* Round newly added appendvfs location to #define'd page boundary. 
    ** Note that nothing has yet been written to the underlying file.
    ** The append mark will be written along with first content write.
    ** Until then, paf->iMark value indicates it is not yet written.
    *//* Append mark found *//* The file being opened appears to be just an ordinary DB. Copy
    ** the base dispatch-table so this instance mimics the base VFS. 
    *//* Append mark not yet written *//* The appendvfs is not to be used for transient or temporary databases.
    ** Just use the base VFS open to initialize the given file object and
    ** open the underlying file. (Appendvfs is then unused for this file.)
    *//*
** Open an apnd file handle.
*//* rule 2 *//*
** Check to see if the file is an ordinary SQLite database file.
** Return true iff so. Parameter sz is the file's size.
*//* It's an appendvfs database *//* If file has the correct end-marker, the expected odd size, and the
    ** SQLite DB type marker where the end-marker puts it, then it
    ** is an appendvfs database.
    *//*
** Check to see if the file is an appendvfs SQLite database file.
** Return true iff it is such. Parameter sz is the file's size.
*//*
** Try to read the append-mark off the end of a file.  Return the
** start of the appended database if the append-mark is present.
** If there is no valid append-mark, return -1;
**
** An append-mark is only valid if the NNNNNNNN start-of-database offset
** indicates that the appended database contains at least one page.  The
** start-of-database value must be a multiple of 512.
*//* Release a memory-mapped page *//* Cannot read what is not yet there. *//* Fetch a page of a memory-mapped file *//* Unmap a shared memory segment *//* Memory barrier operation on shared memory *//* Perform locking on a shared-memory segment *//* Create a shared memory file mapping *//*
** Return the device characteristic flags supported by an apnd-file.
*//*
** Return the sector-size in bytes for an apnd-file.
*//*
** File control method. For custom operations on an apnd-file.
*//*
** Check if another file-handle holds a RESERVED lock on an apnd-file.
*//*
** Unlock an apnd-file.
*//*
** Lock an apnd-file.
*//*
** Return the current file-size of an apnd-file.
** If the append mark is not yet there, the file-size is 0.
*//*
** Sync an apnd-file.
*//* Truncate underlying file just past append mark *//* The append mark goes out first so truncate failure does not lose it. *//*
** Truncate an apnd-file.
*//* If append-mark is absent or will be overwritten, write it. *//*
** Write data to an apnd-file.
*//*
** Add the append-mark onto what should become the end of the file.
*  If and only if this succeeds, internal ApndFile.iMark is updated.
*  Parameter iWriteEnd is the appendvfs-relative offset of the new mark.
*//*
** Read data from an apnd-file.
*//*
** Close an apnd-file.
*//* xUnfetch *//* xFetch *//* xShmUnmap *//* xShmBarrier *//* xShmLock *//* xShmMap *//* xDeviceCharacteristics *//* xSectorSize *//* xFileControl *//* xCheckReservedLock *//* xUnlock *//* xLock *//* xFileSize *//* xTruncate *//* xWrite *//* xRead *//* xClose *//* xNextSystemCall *//* xGetSystemCall *//* xSetSystemCall *//* xCurrentTimeInt64 *//* xGetLastError *//* xCurrentTime *//* xSleep *//* xRandomness *//* xDlClose *//* xDlSym *//* xDlError *//* xDlOpen *//* xFullPathname *//* xAccess *//* xDelete *//* xOpen *//* pAppData (set when registered) *//* zName *//* pNext *//* mxPathname *//* szOsFile (set when registered) *//* iVersion (set when registered) *//*
** Methods for ApndVfs
*//*
** Methods for ApndFile
*//* Always followed by another sqlite3_file that describes the whole file *//* Offset of the append mark.  -1 if unwritten *//* Offset to the start of the database *//* Subclass.  MUST BE FIRST! *//* An open appendvfs file
**
** An instance of this structure describes the appended database file.
** A separate sqlite3_file object is always appended. The appended
** sqlite3_file object (which can be accessed using ORIGFILE()) describes
** the entire file, including the prefix, the database, and the
** append-mark.
**
** The structure of an AppendVFS database is like this:
**
**   +-------------+---------+----------+-------------+
**   | prefix-file | padding | database | append-mark |
**   +-------------+---------+----------+-------------+
**                           ^          ^
**                           |          |
**                         iPgOne      iMark
**
**
** "prefix file" -  file onto which the database has been appended.
** "padding"     -  zero or more bytes inserted so that "database"
**                  starts on an APND_ROUNDUP boundary
** "database"    -  The SQLite database file
** "append-mark" -  The 25-byte "Start-Of-SQLite3-NNNNNNNN" that indicates
**                  the offset from the start of prefix-file to the start
**                  of "database".
**
** The size of the database is iMark - iPgOne.
**
** The NNNNNNNN in the "Start-Of-SQLite3-NNNNNNNN" suffix is the value
** of iPgOne stored as a big-ending 64-bit integer.
**
** iMark will be the size of the underlying file minus 25 (APND_MARKSIZE).
** Or, iMark is -1 to indicate that it has not yet been written.
*//* Access to a lower-level VFS that (might) implement dynamic loading,
** access to randomness, etc.
*//*
** Forward declaration of objects used by this utility
*//*
** Try to align the database to an even multiple of APND_ROUNDUP bytes.
*//*
** Maximum size of the combined prefix + database + append-mark.  This
** must be less than 0x40000000 to avoid locking issues on Windows.
*//* The append mark at the end of the database is:
**
**     Start-Of-SQLite3-NNNNNNNN
**     123456789 123456789 12345
**
** The NNNNNNNN represents a 64-bit big-endian unsigned integer which is
** the offset to page 1, and also the length of the prefix content.
*//*
** 2017-10-20
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file implements a VFS shim that allows an SQLite database to be
** appended onto the end of some other file, such as an executable.
**
** A special record must appear at the end of the file that identifies the
** file as an appended database and provides the offset to the first page
** of the exposed content. (Or, it is the length of the content prefix.)
** For best performance page 1 should be located at a disk page boundary,
** though that is not required.
**
** When opening a database using this VFS, the connection might treat
** the file as an ordinary SQLite database, or it might treat it as a
** database appended onto some other file.  The decision is made by
** applying the following rules in order:
**
**  (1)  An empty file is an ordinary database.
**
**  (2)  If the file ends with the appendvfs trailer string
**       "Start-Of-SQLite3-NNNNNNNN" that file is an appended database.
**
**  (3)  If the file begins with the standard SQLite prefix string
**       "SQLite format 3", that file is an ordinary database.
**
**  (4)  If none of the above apply and the SQLITE_OPEN_CREATE flag is
**       set, then a new database is appended to the already existing file.
**
**  (5)  Otherwise, SQLITE_CANTOPEN is returned.
**
** To avoid unnecessary complications with the PENDING_BYTE, the size of
** the file containing the database is limited to 1GiB. (1073741824 bytes)
** This VFS will not read or write past the 1GiB mark.  This restriction
** might be lifted in future versions.  For now, if you need a larger
** database, then keep it in a separate file.
**
** If the file being opened is a plain database (not an appended one), then
** this shim is a pass-through into the default underlying VFS. (rule 3)
**//************************* Begin ../ext/misc/appendvfs.c ******************//************************* End ../ext/misc/completion.c ********************//*
** This following structure defines all the methods for the 
** completion virtual table.
*//* Number of arguments that completeFilter() expects *//* Index of the stop= constraint, or -1 if none *//* Index of the start= constraint, or -1 if none *//* The query plan bitmask *//* Loop over constraints *//*
** SQLite will invoke this method one or more times while planning a query
** that uses the completion virtual table.  This routine needs to create
** a query plan for each invocation and compute an estimated cost for that
** plan.
**
** There are two hidden parameters that act as arguments to the table-valued
** function:  "prefix" and "wholeline".  Bit 0 of idxNum is set if "prefix"
** is available and bit 1 is set if "wholeline" is available.
*//*
** This method is called to "rewind" the completion_cursor object back
** to the first row of output.  This method is always called at least
** once prior to any call to completionColumn() or completionRowid() or 
** completionEof().
*//*
** Return TRUE if the cursor has been moved off of the last
** row of output.
*//*
** Return the rowid for the current row.  In this implementation, the
** rowid is the same as the output value.
*//*
** Return values of columns for the row at which the completion_cursor
** is currently pointing.
*//* When all rows are finished, advance to the next phase *//* Extract the next row of content *//* This case is when the phase presets zCurrentRow *//* If >=0, step pCur->pStmt and use the i-th column *//* Next phase to try if current phase reaches end *//*
** Advance a completion_cursor to its next row of output.
**
** The ->ePhase, ->j, and ->pStmt fields of the completion_cursor object
** record the current state of the scan.  This routine sets ->zCurrentRow
** to the current row of output and then returns.  If no more rows remain,
** then ->ePhase is set to COMPLETION_EOF which will signal the virtual
** table that has reached the end of its scan.
**
** The current implementation just lists potential identifiers and
** keywords and filters them by zPrefix.  Future enhancements should
** take zLine into account to try to restrict the set of identifiers and
** keywords based on what would be legal at the current point of input.
*//*
** Destructor for a completion_cursor.
*//*
** Reset the completion_cursor.
*//*
** Constructor for a new completion_cursor object.
*//*
** This method is the destructor for completion_cursor objects.
*//* Used for debugging only *//* ePhase - used for debugging only *//* Entire line seen so far *//* Prefix of the word to be completed *//* Suggested completion of the input *//* Column numbers *//*
** The completionConnect() method is invoked to create a new
** completion_vtab that describes the completion virtual table.
**
** Think of this routine as the constructor for completion_vtab objects.
**
** All this routine needs to do is:
**
**    (1) Allocate the completion_vtab object and initialize all fields.
**
**    (2) Tell SQLite (via the sqlite3_declare_vtab() interface) what the
**        result set of queries against completion will look like.
*//* Also VIEWs and TRIGGERs *//* Values for ePhase:
*//* inter-phase counter *//* Current phase *//* The rowid *//* Current statement *//* Length of the zCurrentRow string *//* Current output row *//* The whole that we want to complete *//* The prefix for the word we want to complete *//* Number of bytes in zPrefix and zLine *//* Database connection for this cursor *//* completion_cursor is a subclass of sqlite3_vtab_cursor which will
** serve as the underlying representation of a cursor that scans
** over rows of the result
*//* Database connection for this completion vtab *//* completion_vtab is a subclass of sqlite3_vtab which will
** serve as the underlying representation of a completion virtual table
*//*
** 2017-07-10
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file implements an eponymous virtual table that returns suggested
** completions for a partial SQL input.
**
** Suggested usage:
**
**     SELECT DISTINCT candidate COLLATE nocase
**       FROM completion($prefix,$wholeline)
**      ORDER BY 1;
**
** The two query parameters are optional.  $prefix is the text of the
** current word being typed and that is to be completed.  $wholeline is
** the complete input line, used for context.
**
** The raw completion() table might return the same candidate multiple
** times, for example if the same column name is used to two or more
** tables.  And the candidates are returned in an arbitrary order.  Hence,
** the DISTINCT and ORDER BY are recommended.
**
** This virtual table operates at the speed of human typing, and so there
** is no attempt to make it fast.  Even a slow implementation will be much
** faster than any human can type.
**
*//************************* Begin ../ext/misc/completion.c ******************//************************* End ../ext/misc/fileio.c ********************//* To allow a standalone DLL, make test_windirent.c use the same
 * redefined SQLite API calls as the above extension code does.
 * Just pull in this .c to accomplish this. As a beneficial side
 * effect, this extension becomes a single translation unit. *//*
** Register the "fsdir" virtual table.
*//* The pIdxInfo->estimatedCost should have been initialized to a huge
    ** number.  Leave it unchanged. *//* If input parameters are unusable, disallow this plan *//* True if an unusable DIR= constraint is seen *//* True if an unusable PATH= constraint is seen *//* Index in pIdxInfo->aConstraint of DIR= *//* Index in pIdxInfo->aConstraint of PATH= *//*
** SQLite will invoke this method one or more times while planning a query
** that uses the generate_series virtual table.  This routine needs to create
** a query plan for each invocation and compute an estimated cost for that
** plan.
**
** In this implementation idxNum is used to represent the
** query plan.  idxStr is unused.
**
** The query plan is represented by values of idxNum:
**
**  (1)  The path value is supplied by argv[0]
**  (2)  Path is in argv[0] and dir is in argv[1]
*//*
** xFilter callback.
**
** idxNum==1   PATH parameter only
** idxNum==2   Both PATH and DIR supplied
*//*
** Return the rowid for the current row. In this implementation, the
** first row returned is assigned rowid value 1, and each subsequent
** row a value 1 more than that of the previous.
*//* The FSDIR_COLUMN_PATH and FSDIR_COLUMN_DIR are input parameters.
      ** always return their values as NULL *//* EOF *//* Descend into this directory *//*
** Advance an fsdir_cursor to its next row of output.
*//*
** Set the error message for the virtual table associated with cursor
** pCur to the results of vprintf(zFmt, ...).
*//*
** Destructor for an fsdir_cursor.
*//*
** Reset a cursor back to the state it was in when first returned
** by fsdirOpen().
*//*
** Constructor for a new fsdir_cursor object.
*//*
** This method is the destructor for fsdir vtab objects.
*//*
** Construct a new fsdir virtual table object.
*//* Current rowid *//* Path to current entry *//* Current lstat() results *//* Hierarchy of directories being traversed *//* Index of current entry *//* Number of entries in aLvl[] array *//* Name of directory (nul-terminated) *//* From opendir() *//* 
** Cursor type for recursively iterating through a directory structure.
*//*
** SQL function:   lsmode(MODE)
**
** Given a numberic st_mode from stat(), convert it into a human-readable
** text string in the style of "ls -l".
*//*
** Implementation of the "writefile(W,X[,Y[,Z]]])" SQL function.  
** Refer to header comments at the top of this file for details.
*//* Legacy unix. 
    **
    ** Do not use utimes() on a symbolic link - it sees through the link and
    ** modifies the timestamps on the target. Or fails if the target does 
    ** not exist.  *//* Recent unix *//* utimensat() is not universally available *//* Windows *//* The mkdir() call to create the directory failed. This might not
        ** be an error though - if there is already a directory at the same
        ** path and either the permissions already match or can be changed
        ** to do so using chmod(), it is not an error.  *//* MTIME parameter (or -1 to not set time) *//* MODE parameter passed to writefile() *//* Data to write *//* File to write *//* Context to return bytes written in *//*
** This function does the work for the writefile() UDF. Refer to 
** header comments at the top of this file for details.
*//*
** Argument zFile is the name of a file that will be created and/or written
** by SQL function writefile(). This function ensures that the directory
** zFile will be written to exists, creating it if required. The permissions
** for any path components created by this function are set in accordance
** with the current umask.
**
** If an OOM condition is encountered, SQLITE_NOMEM is returned. Otherwise,
** SQLITE_OK is returned if the directory is successfully created, or
** SQLITE_ERROR otherwise.
*//*
** This function is used in place of lstat().  On Windows, special handling
** is required in order for the included time to be returned as UTC.  On all
** other systems, this function simply calls lstat().
*//*
** This function is used in place of stat().  On Windows, special handling
** is required in order for the included time to be returned as UTC.  On all
** other systems, this function simply calls stat().
*//*
** This function attempts to normalize the time values found in the stat()
** buffer to UTC.  This is necessary on Win32, where the runtime library
** appears to return these values as local times.
*//* To allow a standalone DLL, use this next replacement function: *//*
** This function is designed to convert a Win32 FILETIME structure into the
** number of seconds since the Unix Epoch (1970-01-01 00:00:00 UTC).
*//*
** Implementation of the "readfile(X)" SQL function.  The entire content
** of the file named X is read and returned as a BLOB.  NULL is returned
** if the file does not exist or is unreadable.
*//* File does not exist or is unreadable. Leave the result set to NULL. *//*
** Set the result stored by context ctx to a blob containing the 
** contents of file zName.  Or, leave the result unchanged (NULL)
** if the file does not exist or is unreadable.
**
** If the file exceeds the SQLite blob size limit, through an
** SQLITE_TOOBIG error.
**
** Throw an SQLITE_IOERR if there are difficulties pulling the file
** off of disk.
*//* Path is relative to this directory *//* Path to top of search *//* File content *//* Last modification time *//* Access mode *//* Name of the file *//*    0    1    2     3    4           5             *//*
** Structure of the fsdir() table-valued function
*//* #  include "test_windirent.h" *//*
** 2014-06-13
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This SQLite extension implements SQL functions readfile() and
** writefile(), and eponymous virtual type "fsdir".
**
** WRITEFILE(FILE, DATA [, MODE [, MTIME]]):
**
**   If neither of the optional arguments is present, then this UDF
**   function writes blob DATA to file FILE. If successful, the number
**   of bytes written is returned. If an error occurs, NULL is returned.
**
**   If the first option argument - MODE - is present, then it must
**   be passed an integer value that corresponds to a POSIX mode
**   value (file type + permissions, as returned in the stat.st_mode
**   field by the stat() system call). Three types of files may
**   be written/created:
**
**     regular files:  (mode & 0170000)==0100000
**     symbolic links: (mode & 0170000)==0120000
**     directories:    (mode & 0170000)==0040000
**
**   For a directory, the DATA is ignored. For a symbolic link, it is
**   interpreted as text and used as the target of the link. For a
**   regular file, it is interpreted as a blob and written into the
**   named file. Regardless of the type of file, its permissions are
**   set to (mode & 0777) before returning.
**
**   If the optional MTIME argument is present, then it is interpreted
**   as an integer - the number of seconds since the unix epoch. The
**   modification-time of the target file is set to this value before
**   returning.
**
**   If five or more arguments are passed to this function and an
**   error is encountered, an exception is raised.
**
** READFILE(FILE):
**
**   Read and return the contents of file FILE (type blob) from disk.
**
** FSDIR:
**
**   Used as follows:
**
**     SELECT * FROM fsdir($path [, $dir]);
**
**   Parameter $path is an absolute or relative pathname. If the file that it
**   refers to does not exist, it is an error. If the path refers to a regular
**   file or symbolic link, it returns a single row. Or, if the path refers
**   to a directory, it returns one row for the directory, and one row for each
**   file within the hierarchy rooted at $path.
**
**   Each row has the following columns:
**
**     name:  Path to file or directory (text value).
**     mode:  Value of stat.st_mode for directory entry (an integer).
**     mtime: Value of stat.st_mtime for directory entry (an integer).
**     data:  For a regular file, a blob containing the file data. For a
**            symlink, a text value containing the text of the link. For a
**            directory, NULL.
**
**   If a non-NULL value is specified for the optional $dir parameter and
**   $path is a relative path, then $path is interpreted relative to $dir. 
**   And the paths returned in the "name" column of the table are also 
**   relative to directory $dir.
**
** Notes on building this extension for Windows:
**   Unless linked statically with the SQLite library, a preprocessor
**   symbol, FILEIO_WIN32_DLL, must be #define'd to create a stand-alone
**   DLL form of this extension for WIN32. See its use below for details.
*//************************* Begin ../ext/misc/fileio.c ******************//************************* End ../ext/misc/regexp.c ********************//* SQLITE_DEBUG *//* The regexpi(PATTERN,STRING) function is a case-insensitive version
    ** of regexp(PATTERN,STRING). *//*
** Invoke this routine to register the regexp() function with the
** SQLite database connection.
*//*
** This function is used for testing and debugging only.  It is only available
** if the SQLITE_DEBUG compile-time option is used.
**
** Compile a regular expression and then convert the compiled expression into
** text and return that text.
*//* True to invoke sqlite3_set_auxdata() *//* Compile error message *//* String being searched *//* The regular expression *//* Compiled regular expression *//*
** Implementation of the regexp() SQL function.  This function implements
** the build-in REGEXP operator.  The first argument to the function is the
** pattern and the second argument is the string.  So, the SQL statements:
**
**       A REGEXP B
**
** is implemented as regexp(B,A).
*//* The following is a performance optimization.  If the regex begins with
  ** ".*" (if the input regex lacks an initial "^") and afterwards there are
  ** one or more matching characters, enter those matching characters into
  ** zInit[].  The re_match() routine can then search ahead in the input 
  ** string looking for the initial match without having to run the whole
  ** regex engine over the string.  Do not worry about trying to match
  ** unicode characters beyond plane 0 - those are very rare and this is
  ** just an optimization. *//*
** Compile a textual regular expression in zIn[] into a compiled regular
** expression suitable for us by re_match() and return a pointer to the
** compiled regular expression in *ppRe.  Return NULL on success or an
** error message if something goes wrong.
*//* Free and reclaim all the memory used by a previously compiled
** regular expression.  Applications should invoke this routine once
** for every call to re_compile() to avoid memory leaks.
*//* Compile an element of regular expression text (anything that can be
** an operand to the "|" operator).  Return NULL on success or a pointer
** to the error message if there is a problem.
*//* Compile RE text into a sequence of opcodes.  Continue up to the
** first unmatched ")" character, then return.  If an error is found,
** return a pointer to the error message string.
*//* Peek at the next byte of input *//* Forward declaration *//* A backslash character has been seen, read the next character and
** return its interpretation.
*//* Return true if c is a hexadecimal digit character:  [0-9a-fA-F]
** If c is a hex digit, also set *pV = (*pV)*16 + valueof(c).  If
** c is not a hex digit *pV is unchanged.
*//* Make a copy of N opcodes starting at iStart onto the end of the RE
** under construction.
*//* Append a new opcode and argument to the end of the RE under construction.
*//* Insert a new opcode and argument into an RE under construction.  The
** insertion point is just prior to existing opcode iBefore.
*//* Resize the opcode and argument arrays for an RE under construction.
*//* fall-through *//* Look for the initial prefix match, if there is one. *//* Run a compiled regular expression on the zero-terminated input
** string zIn[].  Return true on a match and false if there is no match.
*//* Return true if c is a perl "space" character:  [ \t\r\n\v\f] *//* Return true if c is a "digit" character:  [0-9] *//* Return true if c is a perl "word" character:  [A-Za-z0-9_] *//* Extract the next unicode character from *pzIn and return it.  Advance
** *pzIn to the first byte past the end of the character returned.  To
** be clear:  this routine converts utf8 to unicode.  This routine is 
** optimized for the common case where the next character is a single byte.
*//* Add a state to the given state set if it is not already there *//* Slots allocated for aOp[] and aArg[] *//* Number of entries in aOp[] and aArg[] *//* Number of bytes in zInit *//* Initial text to match *//* Next character function *//* Arguments to each operator *//* Operators for the virtual machine *//* Error message to return *//* Regular expression text *//* A compiled NFA (or an NFA that is in the process of being compiled) is
** an instance of the following object.
*//* EOF when i>=mx *//* Next byte to read *//* All text *//* An input string read one character at a time.
*//* Current states *//* Number of current states *//* Because this is an NFA and not a DFA, multiple states can be active at
** once.  An instance of the following object records all active states in
** the NFA.  The implementation is optimized for the common case where the
** number of actives states is small.
*//* Each opcode is a "state" in the NFA *//* Opcode names used for symbolic debugging *//* Currently at the start of the string *//* Boundary between word and non-word *//* Not a digit *//* space:  [ \t\n\r\v\f] *//* digit:  [0-9] *//* Not a perl word character *//* Perl word character [A-Za-z0-9_] *//* Range of values in a character class *//* Single value in a character class *//* Beginning of a [^...] character class *//* Beginning of a [...] character class *//* Halt and indicate a successful match *//* Jump to opcode at iArg *//* Continue to both next and opcode at iArg *//* Special optimized version of .* *//* Match any one character.  (Implements ".") *//* Match the one character in the argument *//* The NFA is implemented as sequence of opcodes taken from the following
** set.  Each opcode has a single integer argument.
*//* Start of input - larger than an UTF-8 *//* The end-of-input character *//*
** The following #defines change the names of some functions implemented in
** this file to prevent name collisions with C-library functions of the
** same name.
*//*
** 2012-11-13
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** The code in this file implements a compact but reasonably
** efficient regular-expression matcher for posix extended regular
** expressions against UTF8 text.
**
** This file is an SQLite extension.  It registers a single function
** named "regexp(A,B)" where A is the regular expression and B is the
** string to be matched.  By registering this function, SQLite will also
** then implement the "B regexp A" operator.  Note that with the function
** the regular expression comes first, but with the operator it comes
** second.
**
**  The following regular expression syntax is supported:
**
**     X*      zero or more occurrences of X
**     X+      one or more occurrences of X
**     X?      zero or one occurrences of X
**     X{p,q}  between p and q occurrences of X
**     (X)     match X
**     X|Y     X or Y
**     ^X      X occurring at the beginning of the string
**     X$      X occurring at the end of the string
**     .       Match any single character
**     \c      Character c where c is one of \{}()[]|*+?.
**     \c      C-language escapes for c in afnrtv.  ex: \t or \n
**     \uXXXX  Where XXXX is exactly 4 hex digits, unicode value XXXX
**     \xXX    Where XX is exactly 2 hex digits, unicode value XX
**     [abc]   Any single character from the set abc
**     [^abc]  Any single character not in the set abc
**     [a-z]   Any single character in the range a-z
**     [^a-z]  Any single character not in the range a-z
**     \b      Word boundary
**     \w      Word character.  [A-Za-z0-9_]
**     \W      Non-word character
**     \d      Digit
**     \D      Non-digit
**     \s      Whitespace character
**     \S      Non-whitespace character
**
** A nondeterministic finite automaton (NFA) is used for matching, so the
** performance is bounded by O(N*M) where N is the size of the regular
** expression and M is the size of the input string.  The matcher never
** exhibits exponential behavior.  Note that the X{p,q} operator expands
** to p copies of X following by q-p copies of X? and that the size of the
** regular expression in the O(N*M) performance bound is computed after
** this expansion.
*//************************* Begin ../ext/misc/regexp.c ******************//************************* End ../ext/misc/series.c ********************//*
** This following structure defines all the methods for the 
** generate_series virtual table.
*//* If either boundary is missing, we have to generate a huge span
    ** of numbers.  Make this case very expensive so that the query
    ** planner will work hard to avoid it. *//* We have start= and LIMIT *//* Both start= and stop= boundaries are available.  This is the 
    ** the preferred case *//* The start, stop, and step columns are inputs.  Therefore if there
    ** are unusable constraints on any of start, stop, or step then
    ** this plan is unusable *//* The current generate_column() implementation requires at least one
  ** argument (the START value).  Legacy versions assumed START=0 if the
  ** first argument was omitted.  Compile with -DZERO_ARGUMENT_GENERATE_SERIES
  ** to obtain the legacy behavior *//* Ignore OFFSET if LIMIT is omitted *//* do nothing *//* bitmask for those column *//* 0 for start, 1 for stop, 2 for step *//* This implementation assumes that the start, stop, and step columns
  ** are the last three columns in the virtual table. *//* Constraints on start, stop, step, LIMIT, OFFSET,
                         ** and value.  aIdx[5] covers value=, value>=, and
                         ** value>,  aIdx[6] covers value<= and value< *//* Number of arguments that seriesFilter() expects *//* Mask of unusable constraints *//* EQ constraint seen on the START column *//*
** SQLite will invoke this method one or more times while planning a query
** that uses the generate_series virtual table.  This routine needs to create
** a query plan for each invocation and compute an estimated cost for that
** plan.
**
** In this implementation idxNum is used to represent the
** query plan.  idxStr is unused.
**
** The query plan is represented by bits in idxNum:
**
**   0x0001  start = $num
**   0x0002  stop = $num
**   0x0004  step = $num
**   0x0008  output is in descending order
**   0x0010  output is in ascending order
**   0x0020  LIMIT $num
**   0x0040  OFFSET $num
**   0x0080  value = $num
**   0x0100  value >= $num
**   0x0200  value > $num
**   0x1000  value <= $num
**   0x2000  value < $num
**
** Only one of 0x0100 or 0x0200 will be returned.  Similarly, only
** one of 0x1000 or 0x2000 will be returned.  If the 0x0080 is set, then
** none of the 0xff00 bits will be set.
**
** The order of parameters passed to xFilter is as follows:
**
**    * The argument to start= if bit 0x0001 is in the idxNum mask
**    * The argument to stop= if bit 0x0002 is in the idxNum mask
**    * The argument to step= if bit 0x0004 is in the idxNum mask
**    * The argument to LIMIT if bit 0x0020 is in the idxNum mask
**    * The argument to OFFSET if bit 0x0040 is in the idxNum mask
**    * The argument to value=, or value>= or value> if any of
**      bits 0x0380 are in the idxNum mask
**    * The argument to value<= or value< if either of bits 0x3000
**      are in the mask
**
*//* If any of the constraints have a NULL value, then return no rows.
      ** See ticket https://www.sqlite.org/src/info/fac496b61722daf2 *//* Apply LIMIT and OFFSET constraints, if any *//* Try to reduce the range of values to be generated based on
    ** constraints on the "value" column.
    *//* Extract the maximum range of output values determined by
    ** constraints on the "value" column.
    *//* Extract the LIMIT and OFFSET values, but do not apply them yet.
  ** The range must first be constrained by the limits on value.
  *//* If there are constraints on the value column but there are
  ** no constraints on  the start, stop, and step columns, then
  ** initialize the default range to be the entire range of 64-bit signed
  ** integers.  This range will contracted by the value column constraints
  ** further below.
  *//*
** This method is called to "rewind" the series_cursor object back
** to the first row of output.  This method is always called at least
** once prior to any call to seriesColumn() or seriesRowid() or
** seriesEof().
**
** The query plan selected by seriesBestIndex is passed in the idxNum
** parameter.  (idxStr is not used in this implementation.)  idxNum
** is a bitmask showing which constraints are available:
**
**   0x0001:    start=VALUE
**   0x0002:    stop=VALUE
**   0x0004:    step=VALUE
**   0x0008:    descending order
**   0x0010:    ascending order
**   0x0020:    LIMIT  VALUE
**   0x0040:    OFFSET  VALUE
**   0x0080:    value=VALUE
**   0x0100:    value>=VALUE
**   0x0200:    value>VALUE
**   0x1000:    value<=VALUE
**   0x2000:    value<VALUE
**
** This routine should initialize the cursor and position it so that it
** is pointing at the first row, or pointing off the end of the table
** (so that seriesEof() will return true) if the table is empty.
*//* True to cause run-time checking of the start=, stop=, and/or step=
** parameters.  The only reason to do this is for testing the
** constraint checking logic for virtual tables in the SQLite core.
*//*
** Return the rowid for the current row, logically equivalent to n+1 where
** "n" is the ascending integer in the aforesaid production definition.
*//*
** Advance a series_cursor to its next row of output.
*//*
** Destructor for a series_cursor.
*//*
** Constructor for a new series_cursor object.
*//*
** This method is the destructor for series_cursor objects.
*//*
** The seriesConnect() method is invoked to create a new
** series_vtab that describes the generate_series virtual table.
**
** Think of this routine as the constructor for series_vtab objects.
**
** All this routine needs to do is:
**
**    (1) Allocate the series_vtab object and initialize all fields.
**
**    (2) Tell SQLite (via the sqlite3_declare_vtab() interface) what the
**        result set of queries against generate_series will look like.
*//* (this) Derived class data *//* series_cursor is a subclass of sqlite3_vtab_cursor which will
** serve as the underlying representation of a cursor that scans
** over rows of the result
*//*
** Progress sequence generator to yield next value, if any.
** Leave its state to either yield next value or be at EOF.
** Return whether there is a next value, or 0 at EOF.
*//* Under UBSAN (or on 1's complement machines), must do this in steps.
       * In this clause, iTerm>=0 and iBase<0 . *//* Under UBSAN (or on 1's complement machines), must do this in steps.
       * In this clause, iBase>=0 and iTerm<0 . *//*
** Prepare a SequenceSpec for use in generating an integer series
** given initialized iBase, iTerm and iStep values. Sequence is
** initialized per given isReversing. Other members are computed.
*//* Sequence is being reverse generated *//* Sequence generation not exhausted *//* Current value during generation *//* Current index during generation *//* maximum sequence index (aka "n") *//* Increment ("step") *//* Terminal value to actually use *//* Starting value to actually use *//* Original terminal value ("stop") *//* Original starting value ("start") *//* Under UBSAN (or on 1's complement machines), must do this last term
   * in steps to avoid the dreaded (and harmless) signed multiply overlow. *//* With 2's complement ALU, this next can be 1 step, but is split into
     * 2 for UBSAN's satisfaction (and hypothetical 1's complement ALUs.) *//* Get ix into signed i64 range. *//*
** Return that member of a generate_series(...) sequence whose 0-based
** index is ix. The 0th member is given by smBase. The sequence members
** progress per ix increment by smStep.
*//*
** 2015-08-18, 2023-04-28
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file demonstrates how to create a table-valued-function using
** a virtual table.  This demo implements the generate_series() function
** which gives the same results as the eponymous function in PostgreSQL,
** within the limitation that its arguments are signed 64-bit integers.
**
** Considering its equivalents to generate_series(start,stop,step): A
** value V[n] sequence is produced for integer n ascending from 0 where
**  ( V[n] == start + n * step  &&  sgn(V[n] - stop) * sgn(step) >= 0 )
** for each produced value (independent of production time ordering.)
**
** All parameters must be either integer or convertable to integer.
** The start parameter is required.
** The stop parameter defaults to (1<<32)-1 (aka 4294967295 or 0xffffffff)
** The step parameter defaults to 1 and 0 is treated as 1.
**
** Examples:
**
**      SELECT * FROM generate_series(0,100,5);
**
** The query above returns integers from 0 through 100 counting by steps
** of 5.
**
**      SELECT * FROM generate_series(0,100);
**
** Integers from 0 through 100 with a step size of 1.
**
**      SELECT * FROM generate_series(20) LIMIT 10;
**
** Integers 20 through 29.
**
**      SELECT * FROM generate_series(0,-100,-5);
**
** Integers 0 -5 -10 ... -100.
**
**      SELECT * FROM generate_series(0,-1);
**
** Empty sequence.
**
** HOW IT WORKS
**
** The generate_series "function" is really a virtual table with the
** following schema:
**
**     CREATE TABLE generate_series(
**       value,
**       start HIDDEN,
**       stop HIDDEN,
**       step HIDDEN
**     );
**
** The virtual table also has a rowid, logically equivalent to n+1 where
** "n" is the ascending integer in the aforesaid production definition.
**
** Function arguments in queries against this virtual table are translated
** into equality constraints against successive hidden columns.  In other
** words, the following pairs of queries are equivalent to each other:
**
**    SELECT * FROM generate_series(0,100,5);
**    SELECT * FROM generate_series WHERE start=0 AND stop=100 AND step=5;
**
**    SELECT * FROM generate_series(0,100);
**    SELECT * FROM generate_series WHERE start=0 AND stop=100;
**
**    SELECT * FROM generate_series(20) LIMIT 10;
**    SELECT * FROM generate_series WHERE start=20 LIMIT 10;
**
** The generate_series virtual table implementation leaves the xCreate method
** set to NULL.  This means that it is not possible to do a CREATE VIRTUAL
** TABLE command with "generate_series" as the USING argument.  Instead, there
** is a single generate_series virtual table that is always available without
** having to be created first.
**
** The xBestIndex method looks for equality constraints against the hidden
** start, stop, and step columns, and if present, it uses those constraints
** to bound the sequence of generated values.  If the equality constraints
** are missing, it uses 0 for start, 4294967295 for stop, and 1 for step.
** xBestIndex returns a small cost when both start and stop are available,
** and a very large cost if either start or stop are unavailable.  This
** encourages the query planner to order joins such that the bounds of the
** series are well-defined.
**
** Update on 2024-08-22:
** xBestIndex now also looks for equality and inequality constraints against
** the value column and uses those constraints as additional bounds against
** the sequence range.  Thus, a query like this:
**
**     SELECT value FROM generate_series($SA,$EA)
**      WHERE value BETWEEN $SB AND $EB;
**
** Is logically the same as:
**
**     SELECT value FROM generate_series(max($SA,$SB),min($EA,$EB));
**
** Constraints on the value column can server as substitutes for constraints
** on the hidden start and stop columns.  So, the following two queries
** are equivalent:
**
**     SELECT value FROM generate_series($S,$E);
**     SELECT value FROM generate_series WHERE value BETWEEN $S and $E;
**
*//************************* Begin ../ext/misc/series.c ******************//************************* End ../ext/misc/ieee754.c ********************//*
** SQL Function:   ieee754_inc(r,N)
**
** Move the floating point value r by N quantums and return the new
** values.
**
** Behind the scenes: this routine merely casts r into a 64-bit unsigned
** integer, adds N, then casts the value back into float.
**
** Example:  To find the smallest positive number:
**
**     SELECT ieee754_inc(0.0,+1);
*//*
** Functions to convert between blobs and floats.
*//* Subnormal *//* Limit the range of e.  Ticket 22dea1cfdb9151e4 2021-03-02 *//*
** Implementation of the ieee754() function
*//* Mark a function parameter as unused, to suppress nuisance compiler
** warnings. *//*
** 2013-04-17
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This SQLite extension implements functions for the exact display
** and input of IEEE754 Binary64 floating-point numbers.
**
**   ieee754(X)
**   ieee754(Y,Z)
**
** In the first form, the value X should be a floating-point number.
** The function will return a string of the form 'ieee754(Y,Z)' where
** Y and Z are integers such that X==Y*pow(2,Z).
**
** In the second form, Y and Z are integers which are the mantissa and
** base-2 exponent of a new floating point number.  The function returns
** a floating-point value equal to Y*pow(2,Z).
**
** Examples:
**
**     ieee754(2.0)             ->     'ieee754(2,0)'
**     ieee754(45.25)           ->     'ieee754(181,-2)'
**     ieee754(2, 0)            ->     2.0
**     ieee754(181, -2)         ->     45.25
**
** Two additional functions break apart the one-argument ieee754()
** result into separate integer values:
**
**     ieee754_mantissa(45.25)  ->     181
**     ieee754_exponent(45.25)  ->     -2
**
** These functions convert binary64 numbers into blobs and back again.
**
**     ieee754_from_blob(x'3ff0000000000000')  ->  1.0
**     ieee754_to_blob(1.0)                    ->  x'3ff0000000000000'
**
** In all single-argument functions, if the argument is an 8-byte blob
** then that blob is interpreted as a big-endian binary64 value.
**
**
** EXACT DECIMAL REPRESENTATION OF BINARY64 VALUES
** -----------------------------------------------
**
** This extension in combination with the separate 'decimal' extension
** can be used to compute the exact decimal representation of binary64
** values.  To begin, first compute a table of exponent values:
**
**    CREATE TABLE pow2(x INTEGER PRIMARY KEY, v TEXT);
**    WITH RECURSIVE c(x,v) AS (
**      VALUES(0,'1')
**      UNION ALL
**      SELECT x+1, decimal_mul(v,'2') FROM c WHERE x+1<=971
**    ) INSERT INTO pow2(x,v) SELECT x, v FROM c;
**    WITH RECURSIVE c(x,v) AS (
**      VALUES(-1,'0.5')
**      UNION ALL
**      SELECT x-1, decimal_mul(v,'0.5') FROM c WHERE x-1>=-1075
**    ) INSERT INTO pow2(x,v) SELECT x, v FROM c;
**
** Then, to compute the exact decimal representation of a floating
** point value (the value 47.49 is used in the example) do:
**
**    WITH c(n) AS (VALUES(47.49))
**          ---------------^^^^^---- Replace with whatever you want
**    SELECT decimal_mul(ieee754_mantissa(c.n),pow2.v)
**      FROM pow2, c WHERE pow2.x=ieee754_exponent(c.n);
**
** Here is a query to show various boundry values for the binary64
** number format:
**
**    WITH c(name,bin) AS (VALUES
**       ('minimum positive value',        x'0000000000000001'),
**       ('maximum subnormal value',       x'000fffffffffffff'),
**       ('mininum positive nornal value', x'0010000000000000'),
**       ('maximum value',                 x'7fefffffffffffff'))
**    SELECT c.name, decimal_mul(ieee754_mantissa(c.bin),pow2.v)
**      FROM pow2, c WHERE pow2.x=ieee754_exponent(c.bin);
**
*//************************* Begin ../ext/misc/ieee754.c ******************//************************* End ../ext/misc/base85.c ********************//* standalone program *//* Not needed, ..._init() does this. *//*
** Define some macros to allow this extension to be built into the shell
** conveniently, in conjunction with use of SQLITE_SHELL_EXTFUNCS. This
** allows shell.c, as distributed, to have this extension built in.
*//*
** Establish linkage to running SQLite library.
*//* may overestimate *//*    ulongs    tail   newlines  tailenc+nul*//* This function does the work for the SQLite base85(x) UDF. *//* This function does the work for the SQLite is_base85(t) UDF. *//* Say whether input char sequence is all (base85 and/or whitespace).*//* Adjust for early (non-digit) end of group. *//* Decode base85 text into a byte buffer. *//* Encode a byte buffer into base85 text. If pSep!=0, it's a C string
** to be appended to encoded groups to limit their length to B85_DARK_MAX
** or to terminate the last group (to aid concatenation.)
*//* Convert small integer, known to be in 0..84 inclusive, to base85 numeral.
 * Do not use the macro form with argument expression having a side-effect.*//* Width of base64 lines. Should be an integer multiple of 5. *//* Not used, *//* Say whether c is a base85 numeral. *//* Provide digitValue to b85Numeral offset as a function of above class. *//* Classify c according to interval within USASCII set w.r.t. base85
 * Values of 1 and 3 are base85 numerals. Values of 0, 2, or 4 are not.
 *//* # include "sqlite3ext.h" *//*
** 2022-11-16
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This is a utility for converting binary to base85 or vice-versa.
** It can be built as a standalone program or an SQLite3 extension.
**
** Much like base64 representations, base85 can be sent through a
** sane USASCII channel unmolested. It also plays nicely in CSV or
** written as TCL brace-enclosed literals or SQL string literals.
** It is not suited for unmodified use in XML-like documents.
**
** The encoding used resembles Ascii85, but was devised by the author
** (Larry Brasfield) before Mozilla, Adobe, ZMODEM or other Ascii85
** variant sources existed, in the 1984 timeframe on a VAX mainframe.
** Further, this is an independent implementation of a base85 system.
** Hence, the author has rightfully put this into the public domain.
**
** Base85 numerals are taken from the set of 7-bit USASCII codes,
** excluding control characters and Space ! " ' ( ) { | } ~ Del
** in code order representing digit values 0 to 84 (base 10.)
**
** Groups of 4 bytes, interpreted as big-endian 32-bit values,
** are represented as 5-digit base85 numbers with MS to LS digit
** order. Groups of 1-3 bytes are represented with 2-4 digits,
** still big-endian but 8-24 bit values. (Using big-endian yields
** the simplest transition to byte groups smaller than 4 bytes.
** These byte groups can also be considered base-256 numbers.)
** Groups of 0 bytes are represented with 0 digits and vice-versa.
** No pad characters are used; Encoded base85 numeral sequence
** (aka "group") length maps 1-to-1 to the decoded binary length.
**
** Any character not in the base85 numeral set delimits groups.
** When base85 is streamed or stored in containers of indefinite
** size, newline is used to separate it into sub-sequences of no
** more than 80 digits so that fgets() can be used to read it.
**
** Length limitations are not imposed except that the runtime
** SQLite string or blob length limits are respected. Otherwise,
** any length binary sequence can be represented and recovered.
** Base85 sequences can be concatenated by separating them with
** a non-base85 character; the conversion to binary will then
** be the concatenation of the represented binary sequences.

** The standalone program either converts base85 on stdin to create
** a binary file or converts a binary file to base85 on stdout.
** Read or make it blurt its help for invocation details.
**
** The SQLite3 extension creates a function, base85(x), which will
** either convert text base85 to a blob or a blob to text base85
** and return the result (or throw an error for other types.)
** Unless built with OMIT_BASE85_CHECKER defined, it also creates a
** function, is_base85(t), which returns 1 iff the text t contains
** nothing other than base85 numerals and whitespace, or 0 otherwise.
**
** To build the extension:
** Set shell variable SQDIR=<your favorite SQLite checkout directory>
** and variable OPTS to -DOMIT_BASE85_CHECKER if is_base85() unwanted.
** *Nix: gcc -O2 -shared -I$SQDIR $OPTS -fPIC -o base85.so base85.c
** OSX: gcc -O2 -dynamiclib -fPIC -I$SQDIR $OPTS -o base85.dylib base85.c
** Win32: gcc -O2 -shared -I%SQDIR% %OPTS% -o base85.dll base85.c
** Win32: cl /Os -I%SQDIR% %OPTS% base85.c -link -dll -out:base85.dll
**
** To build the standalone program, define PP symbol BASE85_STANDALONE. Eg.
** *Nix or OSX: gcc -O2 -DBASE85_STANDALONE base85.c -o base85
** Win32: gcc -O2 -DBASE85_STANDALONE -o base85.exe base85.c
** Win32: cl /Os /MD -DBASE85_STANDALONE base85.c
*//************************* Begin ../ext/misc/base85.c ******************//************************* End ../ext/misc/base64.c ********************//* may overestimate due to LF and padding *//* LFs and a 0-terminator *//* quads needed *//* This function does the work for the SQLite base64(x) UDF. *//* bdp is the digit value. *//* Treat whitespace as pad and terminate this group.*//*  Treat dark non-digits as pad, but they terminate decode too. *//* Decode base64 text into a byte buffer. *//* Skip over text which is not base64 numeral(s). *//* Do the bit-shuffle, exploiting unsigned input to avoid masking. *//* Encode a byte buffer into base64 text with linefeeds appended to limit
** encoded group lengths to B64_DARK_MAX or to terminate the last group.
*//* Width of base64 lines. Should be an integer multiple of 4. *//* p                               z                 *//*    a                                            o *//* P                               Z                 *//*    A                                            O *//* 0  1            5            9            =       *//*sp                                  +            / *//*                                                US *//*                             HT LF VT  FF CR       *//* Decoding table, ASCII (7-bit) value to base 64 digit value or other *//* Not above or digit-value *//* whitespace *//* pad character *//* Quiet some compilers about some of our intentional code. *//*
** 2022-11-18
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This is a SQLite extension for converting in either direction
** between a (binary) blob and base64 text. Base64 can transit a
** sane USASCII channel unmolested. It also plays nicely in CSV or
** written as TCL brace-enclosed literals or SQL string literals,
** and can be used unmodified in XML-like documents.
**
** This is an independent implementation of conversions specified in
** RFC 4648, done on the above date by the author (Larry Brasfield)
** who thereby has the right to put this into the public domain.
**
** The conversions meet RFC 4648 requirements, provided that this
** C source specifies that line-feeds are included in the encoded
** data to limit visible line lengths to 72 characters and to
** terminate any encoded blob having non-zero length.
**
** Length limitations are not imposed except that the runtime
** SQLite string or blob length limits are respected. Otherwise,
** any length binary sequence can be represented and recovered.
** Generated base64 sequences, with their line-feeds included,
** can be concatenated; the result converted back to binary will
** be the concatenation of the represented binary sequences.
**
** This SQLite3 extension creates a function, base64(x), which
** either: converts text x containing base64 to a returned blob;
** or converts a blob x to returned text containing base64. An
** error will be thrown for other input argument types.
**
** This code relies on UTF-8 encoding only with respect to the
** meaning of the first 128 (7-bit) codes matching that of USASCII.
** It will fail miserably if somehow made to try to convert EBCDIC.
** Because it is table-driven, it could be enhanced to handle that,
** but the world and SQLite have moved on from that anachronism.
**
** To build the extension:
** Set shell variable SQDIR=<your favorite SQLite checkout directory>
** *Nix: gcc -O2 -shared -I$SQDIR -fPIC -o base64.so base64.c
** OSX: gcc -O2 -dynamiclib -fPIC -I$SQDIR -o base64.dylib base64.c
** Win32: gcc -O2 -shared -I%SQDIR% -o base64.dll base64.c
** Win32: cl /Os -I%SQDIR% base64.c -link -dll -out:base64.dll
*//************************* Begin ../ext/misc/base64.c ******************//************************* End ../ext/misc/percentile.c ********************//*
** Compute the final output of percentile().  Clean up all allocated
** memory if and only if bIsFinal is true.
*//* Find and remove the row *//* Ignore the Y value if it is infinity or NaN *//* If not NULL, then Y must be numeric.  Otherwise throw an error.
  ** Requirement 4 *//* Ignore rows for which Y is NULL *//* Allocate the session context. *//*
** The "inverse" function for percentile(Y,P) is called to remove a
** row that was previously inserted by "step".
*//* Uncomment for testing *//* The pivot value *//* Entries at or after a[iGt] are greater than rPivot *//* Entries before a[iLt] are less than rPivot *//*
** Sort an array of doubles.
**
** Algorithm: quicksort
**
** This is implemented separately rather than using the qsort() routine
** from the standard library because:
**
**    (1)  To avoid a dependency on qsort()
**    (2)  To avoid the function call to the comparison routine for each
**         comparison.
*//*
** Interchange two doubles.
*//* Allocate and store the Y *//* Throw an error if the Y value is infinity or NaN *//* Remember the P value.  Throw an error if the P value is different
  ** from any prior row, per Requirement (2). *//* Requirement 3:  P must be a number between 0 and 100 *//* Requirement 13:  median(Y) is the same as percentile(Y,50). *//*
** The "step" function for percentile(Y,P) is called once for each
** input row.
*//*
** Generate an error for a percentile function.
**
** The error format string must have exactly one occurrance of "%%s()"
** (with two '%' characters).  That substring will be replaced by the name
** of the function.
*//* Last element of search range *//* First element of search range *//*
** Search p (which must have p->bSorted) looking for an entry with
** value y.  Return the index of that entry.
**
** If bExact is true, return -1 if the entry is not found.
**
** If bExact is false, return the index at which a new entry with
** value y should be insert in order to keep the values in sorted
** order.  The smallest return value in this case will be 0, and
** the largest return value will be p->nUsed.
*//*
** Return TRUE if two doubles differ by 0.001 or less.
*//*
** Return TRUE if the input floating-point number is an infinity.
*//* True for percentile_disc() *//* Maximum value of the "fraction" input *//* Number of arguments *//* Function name *//* Details of each function in the percentile family *//* Array of Y values *//* Fraction.  0.0 to 1.0 *//* True if rPct is valid *//* True if advantageous to keep a[] sorted *//* True if a[] is already in sorted order *//* Number of slots actually used in a[] *//* Number of slots allocated for a[] *//* The following object is the group context for a single percentile()
** aggregate.  Remember all input Y values until the very end.
** Those values are accumulated in the Percentile.a[] array.
*//* #  include "sqlite3ext.h" *//* #  include "sqlite3.h" *//*
** 2013-05-28
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file contains code to implement the percentile(Y,P) SQL function
** and similar as described below:
**
**   (1)  The percentile(Y,P) function is an aggregate function taking
**        exactly two arguments.
**
**   (2)  If the P argument to percentile(Y,P) is not the same for every
**        row in the aggregate then an error is thrown.  The word "same"
**        in the previous sentence means that the value differ by less
**        than 0.001.
**
**   (3)  If the P argument to percentile(Y,P) evaluates to anything other
**        than a number in the range of 0.0 to 100.0 inclusive then an
**        error is thrown.
**
**   (4)  If any Y argument to percentile(Y,P) evaluates to a value that
**        is not NULL and is not numeric then an error is thrown.
**
**   (5)  If any Y argument to percentile(Y,P) evaluates to plus or minus
**        infinity then an error is thrown.  (SQLite always interprets NaN
**        values as NULL.)
**
**   (6)  Both Y and P in percentile(Y,P) can be arbitrary expressions,
**        including CASE WHEN expressions.
**
**   (7)  The percentile(Y,P) aggregate is able to handle inputs of at least
**        one million (1,000,000) rows.
**
**   (8)  If there are no non-NULL values for Y, then percentile(Y,P)
**        returns NULL.
**
**   (9)  If there is exactly one non-NULL value for Y, the percentile(Y,P)
**        returns the one Y value.
**
**  (10)  If there N non-NULL values of Y where N is two or more and
**        the Y values are ordered from least to greatest and a graph is
**        drawn from 0 to N-1 such that the height of the graph at J is
**        the J-th Y value and such that straight lines are drawn between
**        adjacent Y values, then the percentile(Y,P) function returns
**        the height of the graph at P*(N-1)/100.
**
**  (11)  The percentile(Y,P) function always returns either a floating
**        point number or NULL.
**
**  (12)  The percentile(Y,P) is implemented as a single C99 source-code
**        file that compiles into a shared-library or DLL that can be loaded
**        into SQLite using the sqlite3_load_extension() interface.
**
**  (13)  A separate median(Y) function is the equivalent percentile(Y,50).
**
**  (14)  A separate percentile_cont(Y,P) function is equivalent to
**        percentile(Y,P/100.0).  In other words, the fraction value in
**        the second argument is in the range of 0 to 1 instead of 0 to 100.
**
**  (15)  A separate percentile_disc(Y,P) function is like
**        percentile_cont(Y,P) except that instead of returning the weighted
**        average of the nearest two input values, it returns the next lower
**        value.  So the percentile_disc(Y,P) will always return a value
**        that was one of the inputs.
**
**  (16)  All of median(), percentile(Y,P), percentile_cont(Y,P) and
**        percentile_disc(Y,P) can be used as window functions.
**
** Differences from standard SQL:
**
**  *  The percentile_cont(X,P) function is equivalent to the following in
**     standard SQL:
**
**         (percentile_cont(P) WITHIN GROUP (ORDER BY X))
**
**     The SQLite syntax is much more compact.  The standard SQL syntax
**     is also supported if SQLite is compiled with the
**     -DSQLITE_ENABLE_ORDERED_SET_AGGREGATES option.
**
**  *  No median(X) function exists in the SQL standard.  App developers
**     are expected to write "percentile_cont(0.5)WITHIN GROUP(ORDER BY X)".
**
**  *  No percentile(Y,P) function exists in the SQL standard.  Instead of
**     percential(Y,P), developers must write this:
**     "percentile_cont(P/100.0) WITHIN GROUP (ORDER BY Y)".  Note that
**     the fraction parameter to percentile() goes from 0 to 100 whereas
**     the fraction parameter in SQL standard percentile_cont() goes from
**     0 to 1.
**
** Implementation notes as of 2024-08-31:
**
**  *  The regular aggregate-function versions of these routines work
**     by accumulating all values in an array of doubles, then sorting
**     that array using quicksort before computing the answer. Thus
**     the runtime is O(NlogN) where N is the number of rows of input.
**
**  *  For the window-function versions of these routines, the array of
**     inputs is sorted as soon as the first value is computed.  Thereafter,
**     the array is kept in sorted order using an insert-sort.  This
**     results in O(N*K) performance where K is the size of the window.
**     One can imagine alternative implementations that give O(N*logN*logK)
**     performance, but they require more complex logic and data structures.
**     The developers have elected to keep the asymptotically slower
**     algorithm for now, for simplicity, under the theory that window
**     functions are seldom used and when they are, the window size K is
**     often small.  The developers might revisit that decision later,
**     should the need arise.
*//************************* Begin ../ext/misc/percentile.c ******************//************************* End ../ext/misc/decimal.c ********************//*
** SQL Function:   decimal_pow2(N)
**
** Return the N-th power of 2.  N must be an integer.
*//*
** SQL Function:   decimal_mul(X, Y)
**
** Return the product of X and Y.
*//* Aggregate funcion:   decimal_sum(X)
**
** Works like sum() except that it uses decimal arithmetic for unlimited
** precision.
*//*
** SQL Function:   decimal_add(X, Y)
**                 decimal_sub(X, Y)
**
** Return the sum or difference of X and Y.
*//*
** Compare text in decimal order.
*//*
** SQL Function:   decimal(X)
** OR:             decimal_exp(X)
**
** Convert input X into decimal and then back into text.
**
** If X is originally a float, then a full decimal expansion of that floating
** point value is done.  Or if X is an 8-byte blob, it is interpreted
** as a float and similarly expanded.
**
** The decimal_exp(X) function returns the result in exponential notation.
** decimal(X) returns a complete decimal, without the e+NNN at the end.
*//* At this point m is the integer significand and e is the exponent *//* A NaN or an Infinity *//*
** Use an IEEE754 binary64 ("double") to generate a new Decimal object.
*//* Exit by break *//* Multiplier *//* The result to be returned *//*
** Create a new Decimal object that contains an integer power of 2.
*//*
** Multiply A by B.   A := A * B
**
** All significant digits after the decimal point are retained.
** Trailing zeros after the decimal point are omitted as long as
** the number of digits after the decimal point is no less than
** either the number of digits in either input.
*//*
** Add the value pB into pA.   A := A + B.
**
** Both pA and pB might become denormalized by this routine.
*//*
** Expand the Decimal so that it has a least nDigit digits and nFrac
** digits to the right of the decimal point.
*//*
** SQL Function:   decimal_cmp(X, Y)
**
** Return negative, zero, or positive if X is less then, equal to, or
** greater than Y.
*//*
** Compare to Decimal objects.  Return negative, 0, or positive if the
** first object is less than, equal to, or greater than the second.
**
** Preconditions for this routine:
**
**    pA!=0
**    pA->isNull==0
**    pB!=0
**    pB->isNull==0
*//* Array of digits *//* Zero value *//* Exponent value *//* Digits to the right of the decimal point *//* Number of digits not counting trailing zeros *//* Number of leading zeros *//* The output buffer *//*
** Make the given Decimal the result in an format similar to  '%+#e'.
** In other words, show exponential notation with leading and trailing
** zeros omitted.
*//*
** Make the given Decimal the result.
*//* Always interpret pIn as text if true *//* Construct the decimal object from this *//* Report error here, if not null *//*
** Allocate a new Decimal object from an sqlite3_value.  Return a pointer
** to the new object, or NULL if there is an error.  If the pCtx argument
** is not NULL, then errors are reported on it as well.
**
** If the pIn argument is SQLITE_TEXT or SQLITE_INTEGER, it is converted
** directly into a Decimal.  For SQLITE_FLOAT or for SQLITE_BLOB of length
** 8 bytes, the resulting double value is expanded into its decimal equivalent.
** If pIn is NULL or if it is a BLOB that is not exactly 8 bytes in length,
** then NULL is returned.
*//*
** Allocate a new Decimal object initialized to the text in zIn[].
** Return NULL if any kind of error occurs.
*//*
** Destroy a Decimal object
*//*
** Release memory held by a Decimal, but do not free the object itself.
*//* Array of digits.  Most significant first. *//* Number of digits to the right of the decimal point *//* Total number of digits *//* True upon initialization *//* True if holds a NULL rather than a number *//* True if an OOM is encountered *//* 0 for positive, 1 for negative *//* A decimal object *//*
** 2020-06-22
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** Routines to implement arbitrary-precision decimal math.
**
** The focus here is on simplicity and correctness, not performance.
*//************************* Begin ../ext/misc/decimal.c ******************//************************* End ../ext/misc/uint.c ********************//*
** Compare text in lexicographic order, except strings of digits
** compare in numeric order.
*//*
** 2020-04-14
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This SQLite extension implements the UINT collating sequence.
**
** UINT works like BINARY for text, except that embedded strings
** of digits compare in numeric order.
**
**     *   Leading zeros are handled properly, in the sense that
**         they do not mess of the maginitude comparison of embedded
**         strings of digits.  "x00123y" is equal to "x123y".
**
**     *   Only unsigned integers are recognized.  Plus and minus
**         signs are ignored.  Decimal points and exponential notation
**         are ignored.
**
**     *   Embedded integers can be of arbitrary length.  Comparison
**         is *not* limited integers that can be expressed as a
**         64-bit machine integer.
*//************************* Begin ../ext/misc/uint.c ******************//************************* End ../ext/misc/sha1.c ********************//* Compute a hash over the result of the query *//* Number of columns in the result set *//*
** Implementation of the sha1_query(SQL) function.
**
** This function compiles and runs the SQL statement(s) given in the
** argument. The results are hashed using SHA1 and that hash is returned.
**
** The original SQL text is included as part of the hash.
**
** The hash is not just a concatenation of the outputs.  Each query
** is delimited and each row and value within the query is delimited,
** with all values being marked with their datatypes.
*//*
** Implementation of the sha1(X) function.
**
** Return a lower-case hexadecimal rendering of the SHA1 hash of the
** argument X.  If X is a BLOB, it is hashed as is.  For all other
** types of input, X is converted into a UTF-8 string and the string
** is hash without the trailing 0x00 terminator.  The hash of a NULL
** value is NULL.
*//* End of the hashing logic
*****************************************************************************//* Should cause a SHA1Transform() *//* Endian independent *//* 1 for binary hash, 0 for hex hash *//* Store hex or binary hash here *//* The SHA1 context to finish and render *//* Add padding and compute the message digest.  Render the
** message digest as lower-case hexadecimal and put it into
** zOut[].  zOut[] must be at least 41 bytes long. *//* Add content to this context *//* Compute a string using sqlite3_vsnprintf() and hash it *//* Number of bytes in data *//* Data to be added *//* Add new content to the SHA1 hash *//* SHA1 initialization constants *//* Initialize a SHA1 context *//* Add the working vars back into context.state[] *//* 4 rounds of 20 operations each. Loop unrolled. *//*
  a = state[0];
  b = state[1];
  c = state[2];
  d = state[3];
  e = state[4];
  *//* Copy p->state[] to working vars *//* a, b, c, d, e; *//*
 * Hash a single 512-bit block. This is the core of the algorithm.
 *//*
 * (R0+R1), R2, R3, R4 are the different operations (rounds) used in SHA1
 *
 * Rl0() for little-endian and Rb0() for big-endian.  Endianness is
 * determined at run-time.
 *//* Context for the SHA1 hash *//******************************************************************************
** The Hash Engine
*//*
** 2017-01-27
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This SQLite extension implements functions that compute SHA1 hashes.
** Two SQL functions are implemented:
**
**     sha1(X)
**     sha1_query(Y)
**
** The sha1(X) function computes the SHA1 hash of the input X, or NULL if
** X is NULL.
**
** The sha1_query(Y) function evalutes all queries in the SQL statements of Y
** and returns a hash of their results.
*//************************* Begin ../ext/misc/sha1.c ******************//************************* End ../ext/misc/shathree.c ********************//*
** xFinal function for sha3_agg().
*//*
** xStep function for sha3_agg().
*//*
** Implementation of the sha3_query(SQL,SIZE) function.
**
** This function compiles and runs the SQL statement(s) given in the
** argument. The results are hashed using a SIZE-bit SHA3.  The default
** size is 256.
**
** The format of the byte stream that is hashed is summarized as follows:
**
**       S<n>:<sql>
**       R
**       N
**       I<int>
**       F<ieee-float>
**       B<size>:<bytes>
**       T<size>:<text>
**
** <sql> is the original SQL text for each statement run and <n> is
** the size of that text.  The SQL text is UTF-8.  A single R character
** occurs before the start of each row.  N means a NULL value.
** I mean an 8-byte little-endian integer <int>.  F is a floating point
** number with an 8-byte little-endian IEEE floating point value <ieee-float>.
** B means blobs of <size> bytes.  T means text rendered as <size>
** bytes of UTF-8.  The <n> and <size> values are expressed as an ASCII
** text integers.
**
** For each SQL statement in the X input, there is one S segment.  Each
** S segment is followed by zero or more R segments, one for each row in the
** result set.  After each R, there are one or more N, I, F, B, or T segments,
** one for each column in the result set.  Segments are concatentated directly
** with no delimiters of any kind.
*//*
** Update a SHA3Context using a single sqlite3_value.
*//* Compute a string using sqlite3_vsnprintf() with a maximum length
** of 50 bytes and add it to the hash.
*//*
** Implementation of the sha3(X,SIZE) function.
**
** Return a BLOB which is the SIZE-bit SHA3 hash of X.  The default
** size is 256.  If X is a BLOB, it is hashed as is.  
** For all other non-NULL types of input, X is converted into a UTF-8 string
** and the string is hashed without the trailing 0x00 terminator.  The hash
** of a NULL value is NULL.
*//*
** After all content has been added, invoke SHA3Final() to compute
** the final hash.  The function returns a pointer to the binary
** hash value.
*//*
** Make consecutive calls to the SHA3Update function to add new content
** to the hash
*//* Big endian.  Byte swap. *//* Little endian.  No byte swapping. *//* Big-endian *//* Known to be little-endian at compile-time. No-op *//*
** Initialize a new hash.  iSize determines the size of the hash
** in bits and should be one of 224, 256, 384, or 512.  Or iSize
** can be zero to use the default hash size of 256 bits.
*//*
** A single step of the Keccak mixing function for a 1600-bit state
*//* 224, 256, 358, or 512 *//* Insert next input into u.x[nLoaded^ixMask]. *//* Input bytes loaded into u.x[] so far this cycle *//* Bytes of input accepted per Keccak iteration *//* ... or 1600 bytes *//* Keccak state. 5x5 lines of 64 bits each *//*
** State structure for a SHA3 hash in progress
*//*
** Macros to determine whether the machine is big or little endian,
** and whether or not that determination is run-time or compile-time.
**
** For best performance, an attempt is made to guess at the byte-order
** using C-preprocessor macros.  If that is unsuccessful, or if
** -DSHA3_BYTEORDER=0 is set, then byte-order is determined
** at run-time.
*//*
** 2017-03-08
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This SQLite extension implements functions that compute SHA3 hashes
** in the way described by the (U.S.) NIST FIPS 202 SHA-3 Standard.
** Three SQL functions are implemented:
**
**     sha3(X,SIZE)
**     sha3_agg(Y,SIZE)
**     sha3_query(Z,SIZE)
**
** The sha3(X) function computes the SHA3 hash of the input X, or NULL if
** X is NULL.  If inputs X is text, the UTF-8 rendering of that text is
** used to compute the hash.  If X is a BLOB, then the binary data of the
** blob is used to compute the hash.  If X is an integer or real number,
** then that number if converted into UTF-8 text and the hash is computed
** over the text.
**
** The sha3_agg(Y) function computes the SHA3 hash of all Y inputs.  Since
** order is important for the hash, it is recommended that the Y expression
** by followed by an ORDER BY clause to guarantee that the inputs occur
** in the desired order.
**
** The sha3_query(Y) function evaluates all queries in the SQL statements of Y
** and returns a hash of their results.
**
** The SIZE argument is optional.  If omitted, the SHA3-256 hash algorithm
** is used.  If SIZE is included it must be one of the integers 224, 256,
** 384, or 512, to determine SHA3 hash variant that is computed.
**
** Because the sha3_agg() and sha3_query() functions compute a hash over
** multiple values, the values are encode to use include type information.
**
** In sha3_agg(), the sequence of bytes that gets hashed for each input
** Y depends on the datatype of Y:
**
**    typeof(Y)='null'         A single "N" is hashed.  (One byte)
**
**    typeof(Y)='integer'      The data hash is the character "I" followed
**                             by an 8-byte big-endian binary of the
**                             64-bit signed integer.  (Nine bytes total.)
**
**    typeof(Y)='real'         The character "F" followed by an 8-byte
**                             big-ending binary of the double.  (Nine
**                             bytes total.)
**
**    typeof(Y)='text'         The hash is over prefix "Tnnn:" followed
**                             by the UTF8 encoding of the text.  The "nnn"
**                             in the prefix is the minimum-length decimal
**                             representation of the octet_length of the text.
**                             Notice the ":" at the end of the prefix, which
**                             is needed to separate the prefix from the
**                             content in cases where the content starts
**                             with a digit.
**
**    typeof(Y)='blob'         The hash is taken over prefix "Bnnn:" followed
**                             by the binary content of the blob.  The "nnn"
**                             in the prefix is the mimimum-length decimal
**                             representation of the byte-length of the blob.
**
** According to the rules above, all of the following SELECT statements
** should return TRUE:
**
**    SELECT sha3(1) = sha3('1');
**
**    SELECT sha3('hello') = sha3(x'68656c6c6f');
**
**    WITH a(x) AS (VALUES('xyzzy'))
**      SELECT sha3_agg(x) = sha3('T5:xyzzy')            FROM a;
**
**    WITH a(x) AS (VALUES(x'010203'))
**      SELECT sha3_agg(x) = sha3(x'42333a010203')       FROM a;
**
**    WITH a(x) AS (VALUES(0x123456))
**      SELECT sha3_agg(x) = sha3(x'490000000000123456') FROM a;
**
**    WITH a(x) AS (VALUES(100.015625))
**      SELECT sha3_agg(x) = sha3(x'464059010000000000') FROM a;
**
**    WITH a(x) AS (VALUES(NULL))
**      SELECT sha3_agg(x) = sha3('N') FROM a;
**
**
** In sha3_query(), individual column values are encoded as with
** sha3_agg(), but with the addition that a single "R" character is
** inserted at the start of each row.
**
** Note that sha3_agg() hashes rows for which Y is NULL.  Add a FILTER
** clause if NULL rows should be excluded:
**
**    SELECT sha3_agg(x ORDER BY rowid) FILTER(WHERE x NOT NULL) FROM t1;
*//************************* Begin ../ext/misc/shathree.c ******************//************************* End ../ext/misc/pcachetrace.c ********************//* Deactivate memory tracing *//* Begin tracing memory allocations to out. *//* The substitute pcache methods *//* Methods that trace pcache activity *//* The original page cache routines *//*
** 2023-06-21
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file implements an extension that uses the SQLITE_CONFIG_PCACHE2
** mechanism to add a tracing layer on top of pluggable page cache of
** SQLite.  If this extension is registered prior to sqlite3_initialize(),
** it will cause all page cache activities to be logged on standard output,
** or to some other FILE specified by the initializer.
**
** This file needs to be compiled into the application that uses it.
**
** This extension is used to implement the --pcachetrace option of the
** command-line shell.
*//************************* Begin ../ext/misc/pcachetrace.c ******************//************************* End ../ext/misc/memtrace.c ********************//* The substitute memory allocator *//* Methods that trace memory allocations *//* The original memory allocation routines *//*
** 2019-01-21
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file implements an extension that uses the SQLITE_CONFIG_MALLOC
** mechanism to add a tracing layer on top of SQLite.  If this extension
** is registered prior to sqlite3_initialize(), it will cause all memory
** allocation activities to be logged on standard output, or to some other
** FILE specified by the initializer.
**
** This file needs to be compiled into the application that uses it.
**
** This extension is used to implement the --memtrace option of the
** command-line shell.
*//************************* Begin ../ext/misc/memtrace.c ******************//************************* End test_windirent.c ********************//* defined(WIN32) && defined(_MSC_VER) *//*
** Implementation of the POSIX closedir() function using the MSVCRT.
*//* not available *//* TODO: Remove this block to allow hidden and/or system files. *//*
** Implementation of the POSIX readdir_r() function using the MSVCRT.
*//*
** Implementation of the POSIX readdir() function using the MSVCRT.
*//* TODO: Remove this if Unix-style root paths are not used. *//*
** Implementation of the POSIX opendir() function using the MSVCRT.
*//*
    ** The function call to GetEnvironmentVariableA() succeeded
    ** -AND- the buffer contains the entire value.
    *//*
    ** The function call to GetEnvironmentVariableA() failed -OR-
    ** the buffer is not large enough.  Either way, return NULL.
    *//* Value returned by GetEnvironmentVariableA() *//* Size in chars *//* Maximum length, per MSDN *//*
** Implementation of the POSIX getenv() function using the Win32 API.
** This function is not thread-safe.
*//* #include "test_windirent.h" *//*
** 2015 November 30
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains code to implement most of the opendir() family of
** POSIX functions on Win32 using the MSVCRT.
*//************************* Begin test_windirent.c ******************//************************* End test_windirent.h ********************//*
** Finally, we can provide the function prototypes for the opendir(),
** readdir(), readdir_r(), and closedir() POSIX functions.
*//*
** Provide the function prototype for the POSIX compatible getenv()
** function.  This function is not thread-safe.
*//*
** Provide a macro, for use by the implementation, to determine if a
** particular directory entry should be skipped over when searching for
** the next directory entry that should be returned by the readdir() or
** readdir_r() functions.
*//* DIRENT constructed based on "_findnext". *//* DIRENT constructed based on "_findfirst". *//* Value returned by "_findfirst". *//* Name within the directory. *//* Win32 file attributes. *//* Sequence number, do not use. *//*
** We need to provide the necessary structures and related types.
*//*
** We need to define "NULL_INTPTR_T" and "BAD_INTPTR_T".
*//*
** We need to define "NAME_MAX" if it was not present in "limits.h".
*//*
** We may need to provide the "ino_t" type.
*//*
** We may need to provide the "mode_t" type.
*//*
** We may need several defines that should have been in "sys/stat.h".
*//*
** We need several things from the ANSI and MSVCRT headers.
*//*
** We need several support functions from the SQLite core.
*//*
** We need several data types from the Windows SDK header.
*//*
** 2015 November 30
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains declarations for most of the opendir() family of
** POSIX functions on Win32 using the MSVCRT.
*//************************* Begin test_windirent.h ******************//*
** The source code for several run-time loadable extensions is inserted
** below by the ../tool/mkshellc.tcl script.  Before processing that included
** code, we need to override some macros to make the included program code
** work here in the middle of this regular program.
*//*
** SQL function:  shell_add_schema(S,X)
**
** Add the schema name X to the CREATE statement in S and return the result.
** Examples:
**
**    CREATE TABLE t1(x)   ->   CREATE TABLE xyz.t1(x);
**
** Also works on
**
**    CREATE INDEX
**    CREATE UNIQUE INDEX
**    CREATE VIEW
**    CREATE TRIGGER
**    CREATE VIRTUAL TABLE
**
** This UDF is used by the .schema command to insert the schema name of
** attached databases into the middle of the sqlite_schema.sql field.
*//*
** SQL function:  shell_module_schema(X)
**
** Return a fake schema for the table-valued function or eponymous virtual
** table X.
*//*
** SQL function:  dtostr(X)
**
** Use the C-library printf() function to convert real value X into a string.
** Used for comparing the accuracy of SQLite's internal float-to-text conversion
** routines against the C-library.
*//*
** SQL function:  strtod(X)
**
** Use the C-library strtod() function to convert string X into a double.
** Used for comparing the accuracy of SQLite's internal text-to-float conversion
** routines against the C-library.
*//* The name of the virtual table *//* Schema of the database holding the vtab *//* The database connection containing the vtab *//*
** Construct a fake object name and column list to describe the structure
** of the view, virtual table, or table valued function zSchema.zName.
*//*
** Attempt to determine if identifier zName needs to be quoted, either
** because it contains non-alphanumeric characters, or because it is an
** SQLite keyword.  Be conservative in this estimate:  When in doubt assume
** that quoting is required.
**
** Return '"' if quoting is required.  Return 0 if no quoting is required.
*//* zIn is either a pointer to a NULL-terminated string in memory obtained
** from malloc(), or a NULL pointer. The string pointed to by zAppend is
** added to zIn, and the result returned in memory obtained from malloc().
** zIn, if it was not NULL, is freed.
**
** If the third argument, quote, is not '\0', then it is used as a
** quote character for zAppend.
*//*
** Initialize and destroy a ShellText object
*//*
** A variable length string to which one can append text.
*//*
** Interpret zArg as an integer value, possibly with suffixes.
*//*
** Return the value of a hexadecimal digit.  Return -1 if the input
** is not a hex digit.
*//* ^C trap creates a false EOF, so let "interrupt" thread catch up. *//*
** Retrieve a single line of input text.
**
** If in==0 then read from standard input and prompt before each line.
** If isContinuation is true, then a continuation prompt is appropriate.
** If isContinuation is zero, then the main prompt should be used.
**
** If zPrior is not NULL then it is a buffer from a prior call to this
** routine that can be reused.
**
** The result is stored in space obtained from malloc() and must either
** be freed by the caller or else passed back into this routine via the
** zPrior argument for reuse.
*//*
** This routine reads a line of text from FILE in, stores
** the text in memory obtained from malloc() and returns a pointer
** to the text.  NULL is returned at end of file, or if malloc()
** fails.
**
** If zLine is not NULL then it is a malloced buffer returned from
** a previous call to this routine that may be reused.
*//* On Windows, open first, then check the stream nature. This order
  ** is necessary because _stat() and sibs, when checking a named pipe,
  ** effectively break the pipe as its supplier sees it. *//*
** Return open FILE * if zFile exists, can be opened for read
** and is an ordinary file or a character stream source.
** Otherwise return 0.
*//*
** Return the length of a string in characters.  Multibyte UTF8 characters
** count as a single character.
*//*
** Compute a string length that is limited to what can be stored in
** lower 30 bits of a 32-bit signed integer.
*//*
** Determines if a string is a number of not.
*//*
** Output string zUtf to stdout as w characters.  If w is negative,
** then right-justify the text.  W is the width in UTF-8 characters, not
** in bytes.  This is different from the %*.*s specification in printf
** since with %*.*s the width is measured in bytes, not characters.
**
** Take into account zero-width and double-width Unicode characters.
** In other words, a zero-width character does not count toward the
** the w limit.  A double-width character counts as two.
*//*
** Return the width, in display columns, of a UTF-8 string.
**
** Each normal character counts as 1.  Zero-width characters count
** as zero, and double-width characters count as 2.
*//*
** Compute the value and length of a multi-byte UTF-8 character that
** begins at z[0].   Return the length.  Write the Unicode value into *pU.
**
** This routine only works for *multi-byte* UTF-8 characters.
*//* The general case *//* Fast path for common characters *//*
** Return an estimate of the width, in columns, for the single Unicode
** character c.  For normal characters, the answer is always 1.  But the
** estimate might be 0 or 2 for zero-width and double-width characters.
**
** Different display devices display unicode using different widths.  So
** it is impossible to know that true display width with 100% accuracy.
** Inaccuracies in the width estimates might cause columns to be misaligned.
** Unfortunately, there is nothing we can do about that.
*//* {1, 0x00000}, *//* First character in a span having this width *//* Width of the character in columns *//* Lookup table to estimate the number of columns consumed by a Unicode
** character.
*//*
** This routine works like printf in that its first argument is a
** format string and subsequent arguments are values to be substituted
** in place of % fields.  The result of formatting this string
** is written to iotrace.
*//*
** Write I/O traces to the following stream.
*//* Check a pointer to see if it is NULL.  If it is NULL, exit with an
** out-of-memory error.
*//* Indicate out-of-memory and exit. *//* !defined(SQLITE_OMIT_DYNAPROMPT) *//* Upon demand, derive the continuation prompt to display. *//* Record that a lexeme is opened, or closed with args==0. *//* Record parenthesis nesting level change, or force level to 0. *//*
** Optionally disable dynamic continuation prompt.
** Unless disabled, the continuation prompt shows open SQL lexemes if any,
** or open parentheses level if non-zero, or continuation prompt as set.
** This facility interacts with the scanner and process_input() where the
** below 5 macros are used.
*//*
** strcpy() workalike to squelch an unwarranted link-time warning
** from OpenBSD.
*//* This is variant of the standard-library strncpy() routine with the
** one change that the destination string is always zero-terminated, even
** if there is no zero-terminator in the first n-1 characters of the source
** string.
*//* Continuation prompt. default: "   ...> " *//* First line prompt.   default: "sqlite> " *//*
** Prompt strings. Initialized in main. Settable with
**   .prompt main continue
*//*
** This is the name of our program. It is set in main(), used
** in a number of other places, mostly for error messages.
*//*
** True if an interrupt (Control-C) has been received.
*//*
** The following is the open SQLite database.  We make a pointer
** to this database a static variable so that it can be accessed
** by the SIGINT handler to interrupt database processing.
*//*
** On Windows systems we need to know if standard output is a console
** in order to show that UTF-16 translation is done in the sign-on
** banner. The following variable is true if it is the console.
*//*
** Treat stdin as an interactive input if the following variable
** is true.  Otherwise, assume stdin is connected to a file or pipe.
*//*
** If the following flag is set, then command execution stops
** at an error if we are not interactive.
*//*
** Number of elements in an array
*//*
** Used to prevent warnings about unused parameters
*//*
** Print the timing results.
*//* Return the difference of two FILETIME structs in seconds *//*
** Begin timing an operation
*//* GetProcessTimes() isn't supported in WIN95 and some other Windows
    ** versions. See if the version we are running on has it, and if it
    ** does, save off a pointer to it and the current process handle.
    *//*
** Check to see if we have timer support.  Return 1 if necessary
** support found (or found previously).
*//* Saved resource information for the beginning of an operation *//* Return the difference of two time_structs in seconds *//* Wall-clock time at start *//* CPU time at start *//* system CPU time used *//* user CPU time used *//* VxWorks does not support getrusage() as far as we can determine *//* Never actually happens *//* Return the current wall-clock time *//* A version of strcmp() that works with NULL values *//* True if the timer is enabled *//* Deselect most features from the console I/O package for Fiddle. *//* Use console I/O package as a direct INCLUDE. *//************************* End ../ext/misc/sqlite3_stdio.c ********************//* defined(_WIN32) *//*
** Set the mode for an output stream.  mode argument is typically _O_BINARY or
** _O_TEXT.
*//* Writing to a file or other destination, just write bytes without
    ** any translation. *//* When writing to the command-prompt in Windows, it is necessary
    ** to use _O_WTEXT input mode and write UTF-16 characters.
    *//*
** Work-alike for fprintf() from the standard C library.
*//* As long as SQLITE_USE_W32_FOR_CONSOLE_IO is not defined, or for
      ** non-console I/O even if that macro is defined, write using the
      ** standard library. *//* If writing to the console, then the WriteConsoleW() is all we
      ** need to do. *//* One must use UTF16 in order to get unicode support when writing
    ** to the console on Windows. 
    *//*
** Work-alike for fputs() from the standard C library.
*//*
** Send ASCII text as O_BINARY.  But for Unicode characters U+0080 and
** greater, switch to O_U8TEXT.
*//* Reading from a file or other input source, just read bytes without
    ** any translation. *//* When reading from the command-prompt in Windows, it is necessary
    ** to use _O_WTEXT input mode to read UTF-16 characters, then translate
    ** that into UTF-8.  Otherwise, non-ASCII characters all get translated
    ** into '?'.
    *//*
** Work-alike for fgets() from the standard C library.
*//*
** Work-alike for the popen() routine from the standard C library.
*//*
** Work-alike for the fopen() routine from the standard C library.
*//*
** Determine if simulated binary mode should be used for output to fd
*//*
** Global variables determine if simulated O_BINARY mode is to be
** used for stdout or other, respectively.  Simulated O_BINARY mode
** means the mode is usually O_BINARY, but switches to O_U8TEXT for
** unicode characters U+0080 or greater (any character that has a
** multi-byte representation in UTF-8).  This is the only way we
** have found to render Unicode characters on a Windows console while
** at the same time avoiding undesirable \n to \r\n translation.
*//*
** If the SQLITE_U8TEXT_ONLY option is defined, then use O_U8TEXT
** when appropriate on all output.  (Sometimes use O_BINARY when
** rendering ASCII text in cases where NL-to-CRLF expansion would
** not be correct.)
**
** If the SQLITE_U8TEXT_STDIO option is defined, then use O_U8TEXT
** when appropriate when writing to stdout or stderr.  Use O_BINARY
** or O_TEXT (depending on things like the .mode and the .crlf setting
** in the CLI, or other context clues in other applications) for all
** other output channels.
**
** The default behavior, if neither of the above is defined is to
** use O_U8TEXT when writing to the Windows console (or anything
** else for which _isatty() returns true) and to use O_BINARY or O_TEXT
** for all other output channels.
**
** The SQLITE_USE_W32_FOR_CONSOLE_IO macro is also available.  If
** defined, it forces the use of Win32 APIs for all console I/O, both
** input and output.  This is necessary for some non-Microsoft run-times
** that implement stdio differently from Microsoft/Visual-Studio.
*//* #include "sqlite3_stdio.h" *//* This file is a no-op on all platforms except Windows *//*
** 2024-09-24
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** Implementation of standard I/O interfaces for UTF-8 that are missing
** on Windows.
*//************************* Begin ../ext/misc/sqlite3_stdio.c ******************//************************* End ../ext/misc/sqlite3_stdio.h ********************//* _SQLITE3_STDIO_H_ *//**** Definitions For All Other Platforms ****//**** Definitions For Windows ****//*
** 2024-09-24
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This header file contains definitions of interfaces that provide 
** cross-platform I/O for UTF-8 content.
**
** On most platforms, the interfaces definitions in this file are
** just #defines.  For example sqlite3_fopen() is a macro that resolves
** to the standard fopen() in the C-library.
**
** But Windows does not have a standard C-library, at least not one that
** can handle UTF-8.  So for windows build, the interfaces resolve to new
** C-language routines contained in the separate sqlite3_stdio.c source file.
**
** So on all non-Windows platforms, simply #include this header file and
** use the interfaces defined herein.  Then to run your application on Windows,
** also link in the accompanying sqlite3_stdio.c source file when compiling
** to get compatible interfaces.
*//************************* Begin ../ext/misc/sqlite3_stdio.h ******************//* string conversion routines only needed on Win32 *//* ctype macros that work with signed characters *//* Windows CE (arm-wince-mingw32ce-gcc) does not provide isatty()
 * thus we always assume that we have a console. That can be
 * overridden with the -batch command line option.
 *//* popen and pclose are not C89 functions and so are
  ** sometimes omitted from the <stdio.h> header *//* Make sure isatty() has a prototype. *//*
** emcc requires _POSIX_SOURCE (or one of several similar defines)
** to expose strdup().
*//*
** Enable large-file support for fopen() and friends on unix.
*//*
** No support for loadable extensions in VxWorks.
*//* defined(_MSC_VER) *//*
** Warning pragmas copied from msvc.h in the core.
*//*
** If SQLITE_SHELL_FIDDLE is defined then the shell is modified
** somewhat for use as a WASM module in a web browser. This flag
** should only be used when building the "fiddle" web application, as
** the browser-mode build has much different user input requirements
** and this build mode rewires the user input subsystem to account for
** that.
*//*
** Determine if we are dealing with WinRT, which provides only a subset of
** the full Win32 API.
*//*
** Optionally #include a user-defined header, whereby compilation options
** may be set prior to where they take effect, but after platform setup.
** If SQLITE_CUSTOM_INCLUDE=? is defined, its value names the #include
** file. Note that this macro has a like effect on sqlite3.c compilation.
*//* This needs to come before any includes for MSVC compiler *//*
** 2001 September 15
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains code to implement the "sqlite" command line
** utility for accessing SQLite databases.
*//* DO NOT EDIT!
** This file is automatically generated by the script in the canonical
** SQLite source tree at tool/mkshellc.tcl.  That script combines source
** code from various constituent source files of SQLite into this single
** "shell.c" file used to implement the SQLite command-line shell.
**
** Most of the code found below comes from the "src/shell.c.in" file in
** the canonical SQLite source tree.  That main file contains "INCLUDE"
** lines that specify other files in the canonical source tree that are
** inserted to getnerate this complete program source file.
**
** The code from multiple files is combined into this single "shell.c"
** source file to help make the command-line program easier to compile.
**
** To modify this program, get a copy of the canonical SQLite source tree,
** edit the src/shell.c.in" and/or some of the other files that are included
** by "src/shell.c.in", then rerun the tool/mkshellc.tcl script.
*/microsecondszSymbolsyncDirpCk/home/wjj/data/code/sqlite/sqlite_cfg.h/usr/include/inttypes.h/usr/include/x86_64-linux-gnu/bits/timex.h/usr/include/malloc.h/usr/include/pthread.h/usr/include/sched.h/usr/include/x86_64-linux-gnu/bits/sched.h/usr/include/x86_64-linux-gnu/bits/types/struct_sched_param.h/usr/include/x86_64-linux-gnu/bits/cpu-set.h/usr/include/x86_64-linux-gnu/bits/setjmp.h/usr/include/x86_64-linux-gnu/bits/types/struct___jmp_buf_tag.h/usr/include/x86_64-linux-gnu/bits/mathcalls-narrow.h/usr/include/x86_64-linux-gnu/bits/iscanonical.h/usr/include/x86_64-linux-gnu/bits/statx.h/usr/include/linux/stat.h/usr/include/linux/types.h/usr/include/x86_64-linux-gnu/asm/types.h/usr/include/asm-generic/types.h/usr/include/asm-generic/int-ll64.h/usr/include/x86_64-linux-gnu/asm/bitsperlong.h/usr/include/asm-generic/bitsperlong.h/usr/include/linux/posix_types.h/usr/include/linux/stddef.h/usr/include/x86_64-linux-gnu/asm/posix_types.h/usr/include/x86_64-linux-gnu/asm/posix_types_64.h/usr/include/asm-generic/posix_types.h/usr/include/x86_64-linux-gnu/bits/statx-generic.h/usr/include/x86_64-linux-gnu/bits/types/struct_statx_timestamp.h/usr/include/x86_64-linux-gnu/bits/types/struct_statx.h/usr/include/x86_64-linux-gnu/bits/types/struct_iovec.h/usr/include/linux/falloc.h/usr/include/x86_64-linux-gnu/sys/ioctl.h/usr/include/x86_64-linux-gnu/bits/ioctls.h/usr/include/x86_64-linux-gnu/asm/ioctls.h/usr/include/asm-generic/ioctls.h/usr/include/linux/ioctl.h/usr/include/x86_64-linux-gnu/asm/ioctl.h/usr/include/asm-generic/ioctl.h/usr/include/x86_64-linux-gnu/bits/ioctl-types.h/usr/include/x86_64-linux-gnu/sys/ttydefaults.h/usr/include/linux/close_range.h/usr/include/x86_64-linux-gnu/bits/types/error_t.h/usr/include/x86_64-linux-gnu/sys/mman.h/usr/include/x86_64-linux-gnu/bits/mman.h/usr/include/x86_64-linux-gnu/bits/mman-map-flags-generic.h/usr/include/x86_64-linux-gnu/bits/mman-linux.h/usr/include/x86_64-linux-gnu/bits/mman-shared.h/usr/include/x86_64-linux-gnu/bits/mman_ext.h/usr/include/dlfcn.h212/usr/include/x86_64-linux-gnu/bits/dlfcn.h213/usr/include/x86_64-linux-gnu/bits/dl_find_object.h214/home/wjj/data/code/sqlite/sqlite3.c<dlfcn.h><sys/mman.h><sys/ioctl.h><pthread.h><malloc.h><inttypes.h>"sqlite_cfg.h"TableEntryFts3KeywordFts4Optionvoid_functionOpenModeLOGFUNC_tEncNameSublistsqlite3StmtVtabInitsqlite_stmt"sqlite_stmt"stmtBestIndex500.0(double)500stmtFilterstmt_cursor *StmtRow *StmtRow **ppRowsizeof(StmtRow)int[11]STMT_NUM_INTEGER_COLUMNSTMT_COLUMN_NCOLSTMT_COLUMN_ROSTMT_COLUMN_BUSYSTMT_COLUMN_NSCANSTMT_COLUMN_NSORTSTMT_COLUMN_NAIDXSTMT_COLUMN_NSTEPSTMT_COLUMN_REPREPSTMT_COLUMN_RUNSTMT_COLUMN_MEMstmtEofstmtRowidstmtColumnSTMT_COLUMN_SQLstmtNextstmtClosestmtCsrResetstmtOpenstmt_vtab *stmtDisconnectstmtConnectCREATE TABLE x(sql,ncol,ro,busy,nscan,nsort,naidx,nstep,reprep,run,mem)"CREATE TABLE x(sql,ncol,ro,busy,nscan,nsort,naidx,nstep,"
                    "reprep,run,mem)"sqlite3DbpageRegisterdbpage_modulesqlite_dbpage"sqlite_dbpage"dbpageRollbackToDbpageTable *dbpageSyncBtree *pBtDb *Pager *pPagerdbpageBegindbpageUpdateDbPage *PgHdr *pDbPageisInsertSQLITE_Defensiveread-only"read-only"cannot delete"cannot delete"cannot insert"cannot insert"no such schema"no such schema"pBt==0bad page number"bad page number"notUsed1bad page value"bad page value"failed to open transaction"failed to open transaction"DbPage **PgHdr **update_faildbpageBeginTransdbpageRowidDbpageCursor *dbpageColumndbpageFilterargc>=1argc>(idxNum>>1)pCsr->pgno==1dbpageEofdbpageNextdbpageClosedbpageOpensizeof(DbpageCursor)dbpageBestIndexiPlanDBPAGE_COLUMN_SCHEMA1.0e6dbpageDisconnectdbpageConnectCREATE TABLE x(pgno INTEGER PRIMARY KEY, data BLOB, schema HIDDEN)"CREATE TABLE x(pgno INTEGER PRIMARY KEY, data BLOB, schema HIDDEN)"sizeof(DbpageTable)rc==SQLITE_OK || pTab==0sqlite3DbstatRegisterdbstat_moduledbstat"dbstat"statRowidStatCursor *statColumnstatFilterStatTable *zDbaseStrAccum *SELECT * FROM (SELECT 'sqlite_schema' AS name,1 AS rootpage,'table' AS type UNION ALL SELECT name,rootpage,type FROM "%w".sqlite_schema WHERE rootpage!=0)"SELECT * FROM ("
        "SELECT 'sqlite_schema' AS name,1 AS rootpage,'table' AS type"
        " UNION ALL "
        "SELECT name,rootpage,type"
        " FROM \"%w\".sqlite_schema WHERE rootpage!=0)"char[155]WHERE name=%Q"WHERE name=%Q" ORDER BY name" ORDER BY name"statEofstatNextstatNextRestartpCsr->aPagep==&pCsr->aPage[pCsr->iPage-1]StatPage *StatPage[32]"/"StatCell *pCellnUsableiOvfloverflow"overflow"%s%.3x+%.6x"%s%.3x+%.6x"ArraySize(pCsr->aPage)226056%s%.3x/"%s%.3x/"internal"internal""leaf"corrupted"corrupted"statGetPageDBSTAT_PAGE_PADDING_BYTESstatSizeAndOffsetsqlite3_int64[2]long long[2]230440sqlite3_int64(*)[2]long long(*)[2]statDecodePagenUnusedisLeaf&aHdr[3]&aHdr[5]&aHdr[1]&aData[iOff+2]&aData[iOff]&aData[nHdr+i*2]nPayload>=(u32)nLocalnLocal<=(nUsable-35)pPg==0sizeof(StatCell)statPageIsCorruptgetLocalPayloadnMinLocalnMaxLocalstatClosestatResetCountsstatResetCsrstatClearPagesizeof(StatPage)statClearCellsstatOpen2152sizeof(StatCursor)statBestIndexiAggstatDisconnectstatConnectnmToken *no such database: %s"no such database: %s"const char[258]sizeof(StatTable)RtreeGeomCallback *pGeomCtxsizeof(RtreeGeomCallback)RtreeDValue *geomCallbackRtreeMatchArg *memErrsizeof(RtreeMatchArg)sizeof(RtreeDValue)RtreeDValue[1]double[1]RtreeMatchArg"RtreeMatchArg"rtreeMatchArgFreertreeFreeCallbacksqlite3RtreeInitutf8rtreenode"rtreenode"rtreedepth"rtreedepth"rtreecheck"rtreecheck"RTREE_COORD_REAL32(void *)RTREE_COORD_REAL32rtree"rtree"RTREE_COORD_INT32(void *)RTREE_COORD_INT32rtree_i32"rtree_i32"wrong number of arguments to function rtreecheck()"wrong number of arguments to function rtreecheck()"zReportok"ok"rtreeIntegrityRtree *pRtreepzErr!=0 && *pzErr==0isQuickIn RTree %s.%s:
%z"In RTree %s.%s:\n%z"rtreeCheckTablenAuxRtreeCheck *sizeof(check)SELECT * FROM %Q.'%q_rowid'"SELECT * FROM %Q.'%q_rowid'"SELECT * FROM %Q.%Q"SELECT * FROM %Q.%Q"Schema corrupt or not an rtree"Schema corrupt or not an rtree"_rowid"_rowid"_parent"_parent"sqlite3_stmt *[2]rtreeCheckCountSELECT count(*) FROM %Q.'%q%s'"SELECT count(*) FROM %Q.'%q%s'"Wrong number of entries in %%%s table - expected %lld, actual %lld"Wrong number of entries in %%%s table"
              " - expected %lld, actual %lld"rtreeCheckNodeaNodenNodeiNode==1 || aParent!=0pCheck->nDim>0Node %lld is too small (%d bytes)"Node %lld is too small (%d bytes)"RTREE_MAX_DEPTHRtree depth out of range (%d)"Rtree depth out of range (%d)"Node %lld is too small for cell count of %d (%d bytes)"Node %lld is too small for cell count of %d (%d bytes)"rtreeCheckCellCoordRtreeCoord *4*2Dimension %d of cell %d on node %lld is corrupt"Dimension %d of cell %d on node %lld is corrupt"Dimension %d of cell %d on node %lld is corrupt relative to parent"Dimension %d of cell %d on node %lld is corrupt relative to parent"rtreeCheckMappingazSqlSELECT parentnode FROM %Q.'%q_parent' WHERE nodeno=?1"SELECT parentnode FROM %Q.'%q_parent' WHERE nodeno=?1"SELECT nodeno FROM %Q.'%q_rowid' WHERE rowid=?1"SELECT nodeno FROM %Q.'%q_rowid' WHERE rowid=?1"bLeaf==0 || bLeaf==1Mapping (%lld -> %lld) missing from %s table"Mapping (%lld -> %lld) missing from %s table"%_rowid"%_rowid"%_parent"%_parent"Found (%lld -> %lld) in %s table, expected (%lld -> %lld)"Found (%lld -> %lld) in %s table, expected (%lld -> %lld)"rtreeCheckGetNodeSELECT data FROM %Q.'%q_node' WHERE nodeno=?"SELECT data FROM %Q.'%q_node' WHERE nodeno=?"pNodepzReportnExpectiDepthaParentiNodepParentbLeafiKeypnNodeNode %lld missing from database"Node %lld missing from database"rtreeCheckAppendMsgRTREE_CHECK_MAX_ERROR%z%s%z"%z%s%z"rtreeCheckPreparertreeCheckResetInvalid argument to rtreedepth()"Invalid argument to rtreedepth()"zBlobnodetreeRtreeNode *sizeof(RtreeNode)968sizeof(Rtree)&nodecellRtreeCell *{%lld"{%lld" %g" %g"RtreeCoord[10]RTREE_MAX_DIMENSIONSrtreeIniteCoordTypeaErrMsgWrong number of columns for an rtree table"Wrong number of columns for an rtree table"Too few columns for an rtree table"Too few columns for an rtree table"Too many columns for an rtree table"Too many columns for an rtree table"Auxiliary rtree columns must be last"Auxiliary rtree columns must be last"RTREE_MAX_AUX_COLUMN<256RTREE_MAX_AUX_COLUMN_node"_node"CREATE TABLE x(%.*s INT"CREATE TABLE x(%.*s INT",%.*s",%.*s",%.*s REAL",%.*s REAL",%.*s INT",%.*s INT"azFormatrtreeInit_fail*ppVtab==0pRtree->nBusy==1rtreeTokenLengthgetNodeSizeiPageSizePRAGMA %Q.page_size"PRAGMA %Q.page_size"RTREE_MAXCELLSSELECT length(data) FROM '%q'.'%q_node' WHERE nodeno = 1"SELECT length(data) FROM '%q'.'%q_node' WHERE nodeno = 1"512-64(512-64)267undersize RTree blobs in "%q_node""undersize RTree blobs in \"%q_node\""getIntFromStmt SQLITE_NOMEMrtreeSqlInitN_STATEMENTsqlite3_stmt **[8]appStmtCREATE TABLE "%w"."%w_rowid"(rowid INTEGER PRIMARY KEY,nodeno"CREATE TABLE \"%w\".\"%w_rowid\"(rowid INTEGER PRIMARY KEY,nodeno",a%d",a%d");CREATE TABLE "%w"."%w_node"(nodeno INTEGER PRIMARY KEY,data);");CREATE TABLE \"%w\".\"%w_node\"(nodeno INTEGER PRIMARY KEY,data);"CREATE TABLE "%w"."%w_parent"(nodeno INTEGER PRIMARY KEY,parentnode);"CREATE TABLE \"%w\".\"%w_parent\"(nodeno INTEGER PRIMARY KEY,parentnode);"INSERT INTO "%w"."%w_node"VALUES(1,zeroblob(%d))"INSERT INTO \"%w\".\"%w_node\"VALUES(1,zeroblob(%d))"sqlite3_stmt ***isCreatepiValINSERT INTO"%w"."%w_rowid"(rowid,nodeno)VALUES(?1,?2)ON CONFLICT(rowid)DO UPDATE SET nodeno=excluded.nodeno"INSERT INTO\"%w\".\"%w_rowid\"(rowid,nodeno)VALUES(?1,?2)"
                  "ON CONFLICT(rowid)DO UPDATE SET nodeno=excluded.nodeno"char[108]SELECT * FROM "%w"."%w_rowid" WHERE rowid=?1"SELECT * FROM \"%w\".\"%w_rowid\" WHERE rowid=?1"UPDATE "%w"."%w_rowid"SET "UPDATE \"%w\".\"%w_rowid\"SET "a%d=?%d"a%d=?%d" WHERE rowid=?1" WHERE rowid=?1"INSERT OR REPLACE INTO '%q'.'%q_node' VALUES(?1, ?2)"INSERT OR REPLACE INTO '%q'.'%q_node' VALUES(?1, ?2)"DELETE FROM '%q'.'%q_node' WHERE nodeno = ?1"DELETE FROM '%q'.'%q_node' WHERE nodeno = ?1"SELECT nodeno FROM '%q'.'%q_rowid' WHERE rowid = ?1"SELECT nodeno FROM '%q'.'%q_rowid' WHERE rowid = ?1"INSERT OR REPLACE INTO '%q'.'%q_rowid' VALUES(?1, ?2)"INSERT OR REPLACE INTO '%q'.'%q_rowid' VALUES(?1, ?2)"DELETE FROM '%q'.'%q_rowid' WHERE rowid = ?1"DELETE FROM '%q'.'%q_rowid' WHERE rowid = ?1"SELECT parentnode FROM '%q'.'%q_parent' WHERE nodeno = ?1"SELECT parentnode FROM '%q'.'%q_parent' WHERE nodeno = ?1"INSERT OR REPLACE INTO '%q'.'%q_parent' VALUES(?1, ?2)"INSERT OR REPLACE INTO '%q'.'%q_parent' VALUES(?1, ?2)"DELETE FROM '%q'.'%q_parent' WHERE nodeno = ?1"DELETE FROM '%q'.'%q_parent' WHERE nodeno = ?1"rtreeShadowNamesizeof(azName)sizeof(azName[0])sizeof(azName)/sizeof(azName[0])"node"parent"parent"rtreeQueryStat1SELECT stat FROM %Q.sqlite_stat1 WHERE tbl = '%q_rowid'"SELECT stat FROM %Q.sqlite_stat1 WHERE tbl = '%q_rowid'"RTREE_MIN_ROWESTRTREE_DEFAULT_ROWESTrtreeSavepointiwtiSavepointrtreeRenameALTER TABLE %Q.'%q_node'   RENAME TO "%w_node";ALTER TABLE %Q.'%q_parent' RENAME TO "%w_parent";ALTER TABLE %Q.'%q_rowid'  RENAME TO "%w_rowid";"ALTER TABLE %Q.'%q_node'   RENAME TO \"%w_node\";"
    "ALTER TABLE %Q.'%q_parent' RENAME TO \"%w_parent\";"
    "ALTER TABLE %Q.'%q_rowid'  RENAME TO \"%w_rowid\";"char[145]rtreeRollbackrtreeEndTransactionrtreeBeginTransactionpRtree->inWrTrans==0rtreeUpdate518nData>=1sizeof(cell)steprcpLeafRtreeNode **pUpconstraintrtreeConstraintErroriCol==0 || iCol%2UNIQUE constraint failed: %s.%s"UNIQUE constraint failed: %s.%s"zCol1zCol2rtree constraint failed: %s.(%s<=%s)"rtree constraint failed: %s.(%s<=%s)"rtreeValueUp8388608.01.1920928955078125e-070.9999998807907104492RNDTOWARDS1.000000119209289551RNDAWAYrtreeValueDownrtreeDeleteRowidpLeaf!=0 || rc!=SQLITE_OK || CORRUPT_DBpChildrtreeNewRowidreinsertNodeContentzNewNameiDeletepiRowidrtreeInsertCellrc==0deleteCellpParent || pNode->iNode==1fixBoundingBoxremoveNodepNode->nRef==1rc!=SQLITE_OKfixLeafParentSplitNodenewCellIsRightaCellaiUsedpLeftpRightleftbboxrightbboxsizeof(RtreeCell)sizeof(RtreeCell)+sizeof(int)(sizeof(RtreeCell)+sizeof(int))rc!=0splitnode_outupdateMappingxSetMappingpNode==0splitNodeStartreeint **aaSortedaSpareiBestDimiBestSplitfBestMargin RTREE_ZEROsizeof(int*)marginfBestOverlapfBestAreaiBestLeftnLeftleftrightoverlapareaiHeightpBboxLeftpBboxRightpTargetpBboxSortByDimensionaCell[aLeft[iLeft]].aCoord[iDim*2]aCell[aLeft[iLeft]].aCoord[iDim*2+1]aCell[aRight[iRight]].aCoord[iDim*2]aCell[aRight[iRight]].aCoord[iDim*2+1]iLeftiRightnRightaLeftaRightxleft1xleft2xright1xright2parentWriterowidWriteAdjustTreecnt>100ChooseLeafiBestbFoundfMinGrowthfMinAreagrowthcellOverlapDCOORD(p->aCoord[jj])( (pRtree->eCoordType==0) ? ((double)p->aCoord[jj].f) : ((double)p->aCoord[jj].i) )DCOORD(aCell[ii].aCoord[jj])( (pRtree->eCoordType==0) ? ((double)aCell[ii].aCoord[jj].f) : ((double)aCell[ii].aCoord[jj].i) )p->aCoord[jj]aCell[ii].aCoord[jj]DCOORD(p->aCoord[jj+1])( (pRtree->eCoordType==0) ? ((double)p->aCoord[jj+1].f) : ((double)p->aCoord[jj+1].i) )DCOORD(aCell[ii].aCoord[jj+1])( (pRtree->eCoordType==0) ? ((double)aCell[ii].aCoord[jj+1].f) : ((double)aCell[ii].aCoord[jj+1].i) )p->aCoord[jj+1]aCell[ii].aCoord[jj+1]o(RtreeDValue)1x1x2(RtreeDValue)0cellContainsa1a2cellUnionp1->aCoord[ii].fp2->aCoord[ii].fp1->aCoord[ii+1].fp2->aCoord[ii+1].fp1->aCoord[ii].ip2->aCoord[ii].ip1->aCoord[ii+1].ip2->aCoord[ii+1].icellMarginp->aCoord[ii+1]p->aCoord[ii]cellAreapRtree->nDim>=1 && pRtree->nDim<=5iDimiParppLeafrtreeBestIndexzIdxStrsizeof(zIdxStr)pIdxInfo->idxStr==0sizeof(zIdxStr)-1(int)(sizeof(zIdxStr)-1)30.0doOmitRTREE_EQRTREE_GTRTREE_LERTREE_LTRTREE_GERTREE_MATCH6.0(double)6.0rtreeFilterRtreeCursor *"PUSH-F1:"(idxStr==0 && argc==0) || (idxStr && (int)strlen(idxStr)==argc*2)pCsr->bPoint==0pNew==0pCsr->bPoint==1"PUSH-Fm:"RtreeSearchPoint *RTREE_ZERORtreeNode *[5]RTREE_CACHE_SZRtreeConstraint *sizeof(RtreeConstraint)u32[41]unsigned int[41]281474976710656((sqlite3_int64)1)<<48(((sqlite3_int64)1)<<48)-281474976710656-(((sqlite3_int64)1)<<48)RTREE_FALSERTREE_TRUEdeserializeGeometryRTREE_QUERYfindLeafNodertreeColumnp==0pRtree->eCoordType==RTREE_COORD_INT32rtreeRowidrtreeNext"POP-Nx:"rtreeStepToLeafeIntnCell<200"POP-S:""PUSH-S:""POP-Se:"pCellData-1.0(sqlite3_rtree_dbl)-1rtreeSearchPointPopi==0 || i==1p->nPointpValuepiNodeconst RtreeSearchPointconst RtreeSearchPoint *rtreeSearchPointNewii==1ii<RTREE_CACHE_SZii<5pCur->aNode[ii]==0rtreeEnqueuesizeof(pCur->aPoint[0])iLevel<=RTREE_MAX_DEPTHrtreeNodeOfFirstSearchPointii==0 || ii==1pCur->bPoint || pCur->nPointpRC!=0rtreeSearchPointFirstrtreeSearchPointSwapi<jrtreeSearchPointComparenodeParentIndexnodeRowidIndexrtreeLeafConstraintxNp->op==RTREE_LE || p->op==RTREE_LT || p->op==RTREE_GE || p->op==RTREE_GT || p->op==RTREE_EQ || p->op==RTREE_TRUE || p->op==RTREE_FALSEFOUR_BYTE_ALIGNED(pCellData)__builtin_bswap32rtreeNonleafConstraint2540xfertreeCallbackConstraintsqlite3_rtree_dbl[10]double[10]pConstraint->op==RTREE_MATCH || pConstraint->op==RTREE_QUERYnCoord==2 || nCoord==4 || nCoord==6 || nCoord==8 || nCoord==10rtreeEofrtreeClosepRtree->nCursor>0resetCursor296sizeof(RtreeCursor)rtreeOpenrtreeDestroyDROP TABLE '%q'.'%q_node';DROP TABLE '%q'.'%q_rowid';DROP TABLE '%q'.'%q_parent';"DROP TABLE '%q'.'%q_node';"
    "DROP TABLE '%q'.'%q_rowid';"
    "DROP TABLE '%q'.'%q_parent';"rtreeDisconnectrtreeReleasepRtree->nCursor==0pRtree->nNodeRef==0 || pRtree->bCorruptrtreeReferencertreeConnectrtreeCreatenodeGetCellpCoordnodeGetCoordiCell<NCELL(pNode)nodeGetRowidpRCpiIndexpeWithinpSearchprScoreiCoordnodeReleasepNode->nRef>0pRtree->nNodeRef>0nodeWritenodeInsertCellnMaxCellnCell<=nMaxCellnodeDeleteCellpDstnodeOverwriteCellnodeAcquirepParent!=pNode->pParentnodeBlobResetnodeNewnodeHashDelete*ppRtreeNode *[97]HASHSIZEnodeHashInsertpNode->pNext==0nodeHashLookupnodeHashnodeZeronodeReferencep->nRef>0writeInt64__builtin_bswap64writeCoordFOUR_BYTE_ALIGNED(p)sizeof(RtreeCoord)==4writeInt16readInt64readCoordreadInt16sqlite3JsonTableFunctionsaModconst struct <unnamed>[2]struct <unnamed>[2]sizeof(aMod)sizeof(aMod[0])sizeof(aMod)/sizeof(aMod[0])json_each"json_each"json_tree"json_tree"sqlite3RegisterJsonFunctionsjsonRemoveFunc0|((0)*JSON_BLOB)0|((0)*0x08)jsonb0|((1)*JSON_BLOB)0|((1)*0x08)json_arrayjsonArrayFuncjsonb_arrayjson_array_lengthjsonArrayLengthFuncjson_error_positionjsonErrorFuncjson_extractjsonExtractFuncjsonb_extract->JSON_JSON0x01|((0)*JSON_BLOB)0x01|((0)*0x08)->>JSON_SQL0x02|((0)*JSON_BLOB)0x02|((0)*0x08)json_insertjsonSetFuncjsonb_insertjson_objectjsonObjectFuncjsonb_objectjson_patchjsonPatchFuncjsonb_patchjson_prettyjsonPrettyFuncjson_quotejsonQuoteFuncjson_removejsonb_removejson_replacejsonReplaceFuncjsonb_replacejson_setJSON_ISSET0x04|((0)*JSON_BLOB)0x04|((0)*0x08)jsonb_set0x04|((1)*JSON_BLOB)0x04|((1)*0x08)json_typejsonTypeFuncjson_validjsonValidFuncjson_group_arrayjsonArrayStepjsonArrayFinaljsonArrayValuejsonGroupInverseSQLITE_SUBTYPE|SQLITE_RESULT_SUBTYPE|SQLITE_UTF8| SQLITE_DETERMINISTIC0x000100000|0x001000000|1| 0x000000800jsonb_group_arrayJSON_BLOBSQLITE_SUBTYPE|SQLITE_RESULT_SUBTYPE|SQLITE_UTF8|SQLITE_DETERMINISTIC0x000100000|0x001000000|1|0x000000800json_group_objectjsonObjectStepjsonObjectFinaljsonObjectValuejsonb_group_objectFuncDef[]aJsonFuncFuncDef *FuncDef[34]2448ArraySize(aJsonFunc)83906568390657842342525200641943923326216449ppNode9472001262492178388609943718526214401jsonEachFilterJsonEachCursor *zRootJsonParse *sizeof(p->sParse)JSON_LOOKUP_NOTFOUNDJSONB_OBJECTJSONB_ARRAYJsonString *$"$"const JsonParseconst JsonParse *JsonParent *sizeof(JsonParent)json_each_malformed_inputmalformed JSON"malformed JSON"jsonEachBestIndexidxMaskJEACH_ROOT == JEACH_JSON+1iCol==0 || iCol==1iCol==0JEACH_JSONjsonEachRowidjsonEachColumnp->eType==JSONB_ARRAYJEACH_KEYJEACH_VALUEJSON_SUBTYPEJEACH_TYPEconst char *const[17]char *[17]JEACH_ATOMJEACH_IDJEACH_PARENTJEACH_FULLKEYJEACH_PATHjsonEachPathLengthp->sParse.eEdit==0cSavedjsonEachNextlevelChangejsonAppendPathNamep->nParent>0p->eType==JSONB_ARRAY || p->eType==JSONB_OBJECT[%lld]"[%lld]"needQuoteconst unsigned char[256]."%.*s"".\"%.*s\"".%.*s".%.*s"jsonSkipLabeljsonEachEofjsonEachClosejsonEachCursorResetjsonEachOpenTreejsonEachOpenEachJsonEachConnection *264jsonEachDisconnectjsonEachConnectCREATE TABLE x(key,value,type,atom,id,parent,fullkey,path,json HIDDEN,root HIDDEN)"CREATE TABLE x(key,value,type,atom,id,parent,fullkey,path,"
                    "json HIDDEN,root HIDDEN)"jsonObjectComputesqlite3_user_data(ctx){}"{}"sizeof(*pStr)inStrnNest!pStrjsonArrayCompute"[]"iErrPossizeof(s)s.zJson!=0s.zJson[k]FLAGS parameter to json_valid() must be between 1 and 15"FLAGS parameter to json_valid() must be"
                                " between 1 and 15"isFinalpxsizeof(px)0x3JSON_KEEPERRORJsonPretty *sizeof(x)JSON_LOOKUP_PATHERRORjson_type_donebIsSetJEDIT_SETJEDIT_INSreplace"replace"JEDIT_REPLJSON_EDITABLEJEDIT_DELjson_remove_patherrorjson_remove_donejxjson_object() requires an even number of arguments"json_object() requires an even number "
                                  "of arguments"json_object() labels must be TEXT"json_object() labels must be TEXT"pPatchJSON_MERGE_OKJSON_MERGE_OOMjsonMergePatchiTCursoriTStartiTEndBEiTEndeTLabeliTLabelnTLabelszTLabeliTValuenTValueszTValueiPCursoriPEndePLabeliPLabelnPLabelszPLabeliPValuenPValueszPValueiTarget>=0 && iTarget<pTarget->nBlobiPatch>=0 && iPatch<pPatch->nBlobszPatchszTargetn==0JSON_MERGE_BADPATCHJSON_MERGE_BADTARGETpTarget->oomJSONB_TEXTJSONB_TEXTRAWisEqualsavedDeltaszNew(flags & JSON_BLOB)==0JSON_ABPATH["["#"#"]"]"."".\""(JSON_SQL|JSON_BLOB)JSON_LOOKUP_ERRORfallthroughiPatchjson_extract_errorjsonAllAlphanumeErr@"@"jsonReturnParseflgsjsonParseFuncArgpFromCachectx!=0rebuild_from_cachep->zJson!=0isRCStrjson_pfa_malformedjson_pfa_oomjsonArgIsJsonbp->aBlob==0JSONB_FALSEjsonInsertIntoBlobax(argc&1)==1jsonInsertIntoBlob_patherrorjsonBadPathErrorbad JSON path: %Q"bad JSON path: %Q"jsonFunctionArgToBlobaNullsizeof(pParse[0])sqlite3IsNaN(r)u8[1]unsigned char[1]JSON cannot hold BLOB values"JSON cannot hold BLOB values"zJsonnJsonJSONB_NULLJSONB_FLOAT9e999"9e999"-9e999"-9e999"JSONB_INTjsonReturnFromBlobszEscape>=2szEscape>=3szEscape>=4iOut<=nOutsqlite3_user_data(pCtx)JSONB_TRUEJSONB_INT5bNegJSONB_FLOAT5to_doubleJSONB_TEXT5JSONB_TEXTJszEscape0x10000629145JSON_INVALID_CHARreturnfromblob_oomreturnfromblob_malformedjsonReturnTextJsonFromBlobaBlob==0jsonLookupStepnKey==0j>0pParse->eEdit==JEDIT_INSpParse->eEdit==JEDIT_SET!pParse->oompParse->aBlob!=0ix.aBlob!=0pParse->deltazPath[i]zPath[3]rawKeyeEditpParsetextOnlyiLabelrawLabelnInssizeof(ix)jsonCreateEditSubstructureconst u8[]emptyObjectsizeof(*pIns)const u8[2]unsigned char[2]jsonLabelComparejsonLabelCompareEscapednoinlinecLeftcRightrawLeft==0 || rawRight==0n<=nLeftn<=nRightjsonUnescapeOneCharn>0z[0]=='\\'vlo645120xfc00563200xdc000x3ff2260xe2jsonBytesToBypass0xa80xa9jsonBlobEditjsonAfterEditSizeAdjustpParse->delta!=0pParse->nBlobAlloc >= pParse->nBlobjsonbArrayCountjsonFuncArgMightBeBinaryjsonTranslateBlobToPrettyTextJSTRING_MALFORMED,
",\n": ": "pInszLeftrawLeftzRightrawRightpiOutiDelnDelaInspJsonpPrettyjsonPrettyIndentjsonTranslateBlobToTextzIn[k]zIn[k+1]zIn[0]=='\\'sz2>=1sz2>=2false"false"bOverflow9.0e999"9.0e999"%llu"%llu"sz2\""\\\""\u0009"\\u0009"\u00"\\u00"\u0000"\\u0000"malformed_jsonbjsonbPayloadSizei<=pParse->nBlobjsonReturnStringAsBlobpx.nBlobAlloc>0!px.bReadOnlyjsonConvertTextToBlobzJson[i]jsonTranslateTextToBlobiThisjson_parse_restartz[j]iBlob==pParse->nBlobi<=(u32)pParse->nJsonz[i+4]z[i+5]'-' < '0''+' < '0''.' < '0'z[i+2]t==0x00z[i+3]z[j-1]=='.'j-2>=iz[j-2]JSONB_INT+0x01==JSONB_INT5JSONB_FLOAT+0x01==JSONB_FLOAT5JSONB_INT+0x02==JSONB_FLOATz[i+nn]JSON_MAX_DEPTHiBlobparse_object_valueconst char[5]opcodecDelimparse_stringpSzseenEparse_number'X'inf"inf"inity"inity"parse_number_2parse_number_finish0x090x0b0x0c0xc22250xe12270xe3const NanInfNameconst NanInfName[5]NanInfName[5]sizeof(aNanInfName)const NanInfName *NanInfName *sizeof(aNanInfName[0])sizeof(aNanInfName)/sizeof(aNanInfName[0])jsonbValidityChecki+n+sz!=iEndz[j+1]z[j]!='\\'j==k"\/bfnrt"\"\\/bfnrt"szCsubjsonIs4HexBpOpjsonBlobChangePayloadSizeszTypenNeededdeltanewSize0xd0jsonBlobAppendNodejsonBlobExpandAndAppendNodejsonBlobAppendOneBytejsonBlobExpandAndAppendOneBytepParse->nBlob+1<=pParse->nBlobAllocjsonBlobMakeEditableaOld!pParse->bReadOnlypParse->nBlobAlloc >= pParse->nBlob + nExtrajsonBlobExpandN>pParse->nBlobAllocjsonWrongNumArgsjson_%s() needs an odd number of arguments"json_%s() needs an odd number of arguments"json5Whitespace0xa00x9a0x8a0xaf0x9fwhitespace_donejsonIs4HexjsonIs2HexjsonHexToInt4jsonHexToIntjsonParseFreejsonParseResetpParse->nJPRef<=1jsonReturnString(pParse!=0)==(ctx!=0)ctx==0 || ctx==p->pCtxsqlite3_user_data(p->pCtx)JSTRING_OOMjsonAppendSqlValue%!0.15g"%!0.15g"JSTRING_ERRjsonAppendStringp->nUsed<p->nAllocjsonAppendControlCharaSpecialsizeof(aSpecial)==32aSpecial['\b']=='b'aSpecial['\f']=='f'aSpecial['\n']=='n'aSpecial['\r']=='r'aSpecial['\t']=='t'c>=0 && c<sizeof(aSpecial)p->nUsed+7 <= p->nAllocconst char[32]jsonAppendSeparatorjsonStringTerminatejsonStringTrimOneCharp->nUsed>0jsonAppendCharjsonAppendCharExpandjsonPrintfjsonAppendRawNZN>0jsonAppendRawjsonStringExpandAndAppendjsonStringGrowjsonStringOomjsonStringResetjsonStringInitjsonStringZerosizeof(p->zSpace)jsonCacheSearchJsonCache *429938szPayloadaPayload-429938JSON_CACHE_IDJsonParse *[4]JSON_CACHE_SIZEJsonParse **p->a[i]->delta==0tmpsizeof(tmp)jsonCacheInsertpParse->zJson!=0pParse->bJsonIsRCStrpParse->delta==0(JSON_CACHE_SIZE-1)(JSON_CACHE_SIZE-1)*sizeof(p->a[0])pParse->nBlobAlloc>0jsonCacheDeleteGenericjsonCacheDeletesqlite3FtsUnicodeFoldconst TableEntryconst TableEntry[]TableEntry[]aEntryconst unsigned short[]unsigned short[]aiOffsizeof(unsigned short)==2 && sizeof(unsigned char)==1c>aEntry[0].iCodeiRes>=0 && c>=aEntry[iRes].iCoderet>0('a' - 'A')const TableEntry *TableEntry *iHiconst TableEntry[163]TableEntry[163]652sizeof(aEntry)sizeof(aEntry[0])sizeof(aEntry)/sizeof(aEntry[0])sizeof(aEntry)/sizeof(aEntry[0]) - 1iLoiTestcmpconst unsigned short[77]unsigned short[77]0x0000FFFF6656066600217218219775726410792107952322823256302045472154753547545475654787547935480957153572745792158019583636172265268653416537365406654086541065415654246543665439654506546265472654766547865480654826548865506655116551465521655276552865529sqlite3FtsUnicodeIsdiacriticmask01343897270x08029FDFmask12216880x000361F8817800768+32(unsigned int)1remove_diacriticaDiaunsigned short[126]aCharunsigned char[126]0x00000007252sizeof(aDia)sizeof(aDia[0])sizeof(aDia)/sizeof(aDia[0])sizeof(aDia)/sizeof(aDia[0]) - 1key>=aDia[iRes]sqlite3FtsUnicodeIsalnumconst unsigned intconst unsigned int[]const unsigned int[4]aAsciiaEntry[0]<keykey>=aEntry[iRes]const unsigned int *0x001F1<<22(1<<22)0x000003FFconst unsigned int[406]unsigned int[406]16244064050x3FF42279239670xFC00FFFF41607495690xF8000001sqlite3Fts3UnicodeTokenizerconst sqlite3_tokenizer_moduleconst sqlite3_tokenizer_module *sqlite3_tokenizer_module *const sqlite3_tokenizer_module **sqlite3_tokenizer_module **modulesqlite3_tokenizer *sqlite3_tokenizer **sqlite3_tokenizer_cursor *sqlite3_tokenizer_cursor **unicodeNextunicode_cursor *unicode_tokenizer *iCodezStartzEndzTerm429496524865534unicodeCloseunicodeOpensizeof(unicode_cursor)unicodeCreatesizeof(unicode_tokenizer)remove_diacritics=1"remove_diacritics=1"remove_diacritics=0"remove_diacritics=0"remove_diacritics=2"remove_diacritics=2"tokenchars="tokenchars="separators="separators="unicodeIsAlnum(sqlite3FtsUnicodeIsalnum(iCode) & 0xFFFFFFFE)==0unicodeIsExceptionunicodeAddExceptionsbAlnum==0 || bAlnum==1(sqlite3FtsUnicodeIsalnum((int)iCode) & 0xFFFFFFFE)==0unicodeDestroysqlite3Fts3MatchinfoFts3Cursor *Fts3Table *pcxFTS3_MATCHINFO_DEFAULTFts3Expr *sqlite3Fts3OffsetspModTermOffsetCtx *pCsr->isRequireSeek==0TermOffset *sizeof(TermOffset)iCurrent<=iMinPospCZDUMMYNDUMMYiCurrentzDocnDoceRemoveDiacriticbComplexppModulepaTokenpnTokenpiStartpiEndpiPosaInputnInputbAlnumpTokenizeriMinPos 0x7FFFFFFFpTerm0xFEsizeof(aBuffer)%d %d %d %d "%d %d %d %d "StrBuffer *offsets_outrc!=SQLITE_DONEfts3ExprRestartIfCbiPhraseFts3Phrase *fts3ExprTermOffsetInitnTermiPosiPos>=0sqlite3Fts3SnippetnSnippetSnippetFragment[4]aSnippetnFToken-64+64(mCovered&mSeen)==mCoverediSnipmCoveredmSeeniBestScoreiReadSnippetFragment *pFragmentsizeof(*pFragment)sFiSSizeofArray(aSnippet)nFToken>0snippet_outfts3GetMatchinfosInfobGlobalxDestroyOutMatchInfo *sizeof(MatchInfo)MatchinfoBuffer *nMatchinfou32 **unsigned int **fts3MatchinfoValueszArg[i]==FTS3_MATCHINFO_HITSFTS3_MATCHINFO_NPHRASEFTS3_MATCHINFO_NCOLFTS3_MATCHINFO_NDOCFTS3_MATCHINFO_AVGLENGTHFTS3_MATCHINFO_LENGTHpSelectDocsizeFTS3_MATCHINFO_LCSFTS3_MATCHINFO_LHITS_BMFTS3_MATCHINFO_LHITSpExprFts3DeferredToken *fts3MatchinfoLcsLcsIterator *aItersizeof(LcsIterator)nLcsnLivepItpAdvnThisLcsmatchinfo_lcs_outfts3LcsIteratorAdvancepReadpIter==0fts3MatchinfoLcsCbfts3MatchinfoSelectDoctotalsqlite3_data_count(pStmt)==1fts3MatchinfoSizecArg==FTS3_MATCHINFO_HITSfts3MatchinfoCheckFTS3_MATCHINFO_HITSunrecognized matchinfo request: %c"unrecognized matchinfo request: %c"fts3ExprLocalHitsCbfts3ExprGlobalHitsCbfts3ExprLHitGather(pExpr->pLeft==0)==(pExpr->pRight==0)fts3ExprLHitspPhrasep->flag==FTS3_MATCHINFO_LHITS_BM || p->flag==FTS3_MATCHINFO_LHITS*pIter==0x00 || *pIter==0x01&iColfts3ColumnlistCountfts3SnippetTextisShiftDonehlmaskDUMMY1iFinisHighlight(u64)1fts3SnippetShift(nSnippet-1-nRight)<=63 && (nSnippet-1-nRight)>=0nShift<=nDesirednDesirednShiftDUMMY2DUMMY3fts3StringAppendpStr->z!=0 && (pStr->nAlloc >= pStr->n+nAppend+1)zEllipsispnDocpaLenppEndcArgppCollistiFragmentisLastzOpenzCloseiLangidpHlmaskfts3BestSnippetnListsIterSnippetIter *sizeof(sIter)sizeof(SnippetPhrase)SnippetPhrase *iScore>=0iScoremCovermHighlitefts3SnippetFindPositionsrc==SQLITE_OK || pCsr==0rc!=SQLITE_OK || ( pPhrase->pList==0 && pPhrase->pHead==0 && pPhrase->pTail==0 )fts3SnippetDetailsmHighlightiCsr>=iStart && (iCsr - iStart)<=64i>=0iCsrmPhrasemPos0x0FEfts3SnippetNextCandidatepIter->nSnippet>=00x7FFFFFFFfts3SnippetAdvanceiIterfts3ExprPhraseCountnPhrasefts3ExprPhraseCountCbfts3ExprLoadDoclistsLoadDoclistCtx *fts3ExprLoadDoclistsCbsqlite3Fts3ExprIteratefts3ExprIterate2pExpr->pLeft && pExpr->pRightFTSQUERY_PHRASEFTSQUERY_NOTfts3GetDeltaPosition&iValsqlite3Fts3MIBufferFreep->aRef[0]==1u8[3]unsigned char[3]fts3MIBufferSetGlobalfts3MIBufferAllocxRetfts3MIBufferFree(u32*)p==&pBuf->aMatchinfo[1] || (u32*)p==&pBuf->aMatchinfo[pBuf->nElem+2]fts3MIBufferNewsizeof(MatchinfoBuffer)nStrsqlite3Fts3OptimizeSAVEPOINT fts3"SAVEPOINT fts3"RELEASE fts3"RELEASE fts3"ROLLBACK TO fts3"ROLLBACK TO fts3"sqlite3Fts3UpdateMethodaSzInsaSzDelnChngbInsertDonep->bHasStat==0 || p->bHasStat==1p->pSegments==0nArg==1 || nArg==(2 + p->nColumn + 3)sizeof(aSzDel[0])pNewRowidsqlite3_value_type(apVal[0])==SQLITE_INTEGERp->iPrevDocid==*pRowidupdate_outfts3DeleteByRowidisEmptySQL_DELETE_CONTENTSQL_DELETE_DOCSIZEsqlite3Fts3DeferTokenFts3PhraseToken *pDeferredsizeof(*pDeferred)pToken->pDeferred==0sqlite3Fts3DeferredTokenListPendingList *sqlite3Fts3CacheDeferredDoclistsiDocidpDefpTCiDum1iDum2pPTPendingList **sqlite3Fts3FreeDeferredTokenssqlite3Fts3FreeDeferredDoclistsfts3SpecialInsertoptimize"optimize"rebuild"rebuild"integrity-check"integrity-check"merge="merge="automerge="automerge=""flush"fts3DoIntegrityChecksqlite3Fts3IntegrityCheckcksum1cksum2pAllLangidSQL_SELECT_ALL_LANGIDSELECT %s"SELECT %s"iLangFts3Index *fts3ChecksumIndexfiltercksumFts3SegFilter *sizeof(filter)Fts3MultiSegReader *sizeof(csr)FTS3_SEGMENT_REQUIRE_POSFTS3_SEGMENT_IGNORE_EMPTYFTS3_SEGMENT_SCANFTS3_SEGCURSOR_ALLsqlite_uint64 *fts3ChecksumEntrypmSeenpiScorepiTokenpmCoverpmHighlightppIterpiIterpnPhrasepiPhrasepaOutzMatchinfopnChngpTokenppDatapbOkiIndexfts3DoAutoincrmergep->bFts4==0SQL_REPLACE_STATFTS_STAT_AUTOINCRMERGEfts3DoIncrmerge(MergeCount(p) / 2)nMergefts3Getint214748363sqlite3Fts3IncrmergepFilterIncrmergeWriter *pWriternSegiAbsLevelhintbDirtyHintsizeof(*pFilter)sizeof(*pCsr) + sizeof(*pFilter)696sizeof(*pWriter)808sizeof(*pCsr) + sizeof(*pFilter) + sizeof(*pWriter)Blob *nSeg>=2MAX(nMin,nSeg)((nMin)>(nSeg)?(nMin):(nSeg))nHintSegnMod<=0x7FFFFFFFbUseHint==1 || bUseHint==0const i64nModFTS3_SEGDIR_MAXLEVELpFindLevelbUseHintSQL_FIND_MERGE_LEVELnHintiHintAbsLevelbIgnorebEmptyfts3IncrmergeHintPop&pHint->a[i]pnInputi<=nHintfts3IncrmergeHintPushFTS3_VARINT_MAX2*FTS3_VARINT_MAXfts3IncrmergeHintLoadSQL_SELECT_STATpHint->a!=0FTS_STAT_INCRMERGEHINTaHintfts3IncrmergeHintStorepReplacefts3IncrmergeChompj<pCsr->nSegmentj<pCsr->nSegment && pSeg->iIdx==iFts3SegReader *pSegFts3SegReader **fts3TruncateSegmentrootiBlockiNewStartiOldStartpFetchSQL_SELECT_SEGDIRaRootnRootaBlocknBlockpDelSQL_DELETE_SEGMENTS_RANGEpChompSQL_CHOMP_SEGDIRfts3TruncateNodereaderprevNodeReader *pNew->n<=pNew->nAllocfts3StartNodepNode->nAlloc>=1+sqlite3Fts3VarintLen(iChild)pNode->nAlloc>=1fts3RepackSegdirLevelpUpdateSQL_SELECT_INDEXESSQL_SHIFT_SEGDIR_ENTRYp->bIgnoreSavepoint==0fts3RemoveSegdirEntrypDeleteSQL_DELETE_SEGDIR_ENTRYfts3IncrmergeWriternLeafEstpLeafEstpFirstBlockSQL_MAX_LEAF_NODE_ESTIMATESQL_NEXT_SEGMENTS_IDFTS_MAX_APPENDABLE_HEIGHTNodeWriter[16]NodeWriter *fts3IncrmergeOutputIdxpOutputIdxSQL_NEXT_SEGMENT_INDEXfts3IncrmergeLoadreader.aNodep->nNodeSizereader.term.n>0 || reader.aNode==0iLeafEndbAppendableaLeafnLeafnHeightFTS3_NODE_PADDINGsizeof(reader)fts3IsAppendablebResSQL_SEGMENT_IS_APPENDABLEfts3TermCmpnLhsnRhsfts3IncrmergeRelease*pRc || pNode->block.nAlloc==0*pRc || pNode->key.nAlloc==0pBlock1 + FTS3_VARINT_MAXpzpHintpiAbsLevelpnRempiBlockpiIdxpbResfts3IncrmergeAppendaDoclistnDoclistnSpacenSuffixfts3AppendToNodebFirstpNode->n>0(pNode->a[0]=='\0')==(aDoclist!=0)pPrev!=0pPrev->a!=0pNode->n<=pNode->nAllocfts3IncrmergePushiPtriLayernTerm>0iLayer<FTS_MAX_APPENDABLE_HEIGHTiLayer<16nPrefix+nSuffix<=nTermnPrefix>=0pNode->block.nAlloc>=p->nNodeSizeiNextPtrpBlknodeReaderInitsizeof(NodeReader)nodeReaderReleasenodeReaderNextp->aNode&p->aNode[p->iOff]&nPrefix&nSuffixp->term.a!=0&p->nDoclistp->iOff<=p->nNodeblobGrowBufferfts3IncrmergeCsrsizeof(Fts3SegReader *)SQL_SELECT_LEVELpCsr->nSegment==0fts3DoRebuildaSzsizeof(aSz[0])fts3DoOptimizebSeenDonefts3UpdateDocTotalsnStatsizeof(u32)+10(sizeof(u32)+10)FTS_STAT_DOCTOTALfts3InsertDocsizeSQL_REPLACE_DOCSIZEfts3DecodeIntArrayfts3EncodeIntArraysqlite3Fts3PendingTermsFlushFTS3_SEGCURSOR_PENDINGfts3SegmentMergeiNewLevelSegmentWriter *bIgnoreEmptyiMaxLeveliLevel==FTS3_SEGCURSOR_ALL || iLevel==FTS3_SEGCURSOR_PENDING || iLevel>=0iLevel<FTS3_SEGDIR_MAXLEVELiIndex>=0 && iIndex<p->nIndexcsr.apSegment[0]FTS3_SEGCURSOR_PENDING==-1Fts3HashElem *Fts3HashElem **csr.nSegment>0iNewLevel>=getAbsoluteLevel(p, iLangid, iIndex, 0)iNewLevel<getAbsoluteLevel(p, iLangid, iIndex,FTS3_SEGDIR_MAXLEVEL)iNewLevel<getAbsoluteLevel(p, iLangid, iIndex,1024)sizeof(Fts3SegFilter)SegmentWriter **pWriter || bIgnoreEmptyfinishedfts3PromoteSegmentsSQL_SELECT_LEVEL_RANGE2nLimitpUpdate1pUpdate2SQL_UPDATE_LEVEL_IDXSQL_UPDATE_LEVELfts3ReadEndBlockFieldiMulsqlite3Fts3SegReaderFinishsqlite3Fts3SegReaderStepisIgnoreEmptyisRequirePosisColFilterFTS3_SEGMENT_COLUMN_FILTERisPrefixFTS3_SEGMENT_PREFIXisScanisFirstFTS3_SEGMENT_FIRSTapSegmentnSegmentxCmpisIgnoreEmpty || (isRequirePos && !isColFilter)apSegment[0]pPrevbReturnDonepNBufpiEndBlockiDeltafts3GrowSegReaderBuffersqlite3Fts3MsrIncrRestartpCsr->zTerm==0pCsr->nTerm==0pCsr->aDoclist==0pCsr->nDoclist==0sqlite3Fts3MsrIncrStartpCsr->pFilter==0zTerm && nTerm>0iCol<0 || iCol<p->nColumnsqlite3Fts3SegReaderStartfts3SegReaderStartsqlite3Fts3MsrIncrNext(pMsr->aBuffer[nList] & 0xFE)==0x00fts3MsrBufferDatanList>0fts3ColumnFilteriCol>=0&iCurrentfts3DeleteSegdiriLevel>=0 || iLevel==FTS3_SEGCURSOR_ALLSQL_DELETE_SEGDIR_RANGESQL_DELETE_SEGDIR_LEVELfts3DeleteSegmentfts3SegmentIsMaxLevelSQL_SELECT_SEGDIR_MAX_LEVELfts3SegmentMaxLevelfts3IsEmptySQL_IS_EMPTYfts3SegWriterFreeSegmentNode *fts3SegWriterFlushiLastLeaffts3SegWriterAddsizeof(SegmentWriter)nPrefix<nTermSegmentNode **nData+nReq<=pWriter->nSizenSuffix>0nDoclist>0pWriter->zTerm==pWriter->zMallocfts3NodeFreepRight==0 || p->zMalloc==0fts3NodeWriteiNextLeaf==iFreenStartiNextFreeiNextLeaffts3TreeFinishNodeiHeight>=1 && iHeight<128fts3NodeAddTermpTreepTree->aData==(char *)&pTree[1]sizeof(SegmentNode)fts3PrefixCompressn<nNextfts3WriteSegdirSQL_INSERT_SEGDIR%lld %lld"%lld %lld"sqlite3Fts3MaxLevelSQL_SELECT_MXLEVELfts3WriteSegmentSQL_INSERT_SEGMENTSfts3SegReaderSortnSuspect<=nSegmentpTmpfts3SegReaderTermCmpfts3SegReaderDoclistCmpRevpLhs->aNode && pRhs->aNodefts3SegReaderDoclistCmpfts3SegReaderCmpsqlite3Fts3SegReaderPendingpReaderpEFts3Hash *aElem2sizeof(Fts3HashElem *)const Fts3Hashconst Fts3Hash *sizeof(Fts3SegReader)fts3CompareElemByTerm*(Fts3HashElem **)lhsz1*(Fts3HashElem **)rhsn1sqlite3Fts3SegReaderNewzRoot!=0 || nRoot==0zRoot!=0 || CORRUPT_DBsqlite3Fts3SegReaderFreesqlite3Fts3MsrOvflp->bFts4pgsz>0fts3SegReaderNextDocid*p==0pMsrpiDocidpaPoslistpnPoslistbZeroppListpnListnReaderpbMaxpisEmptyppWriterisCopyTermiLeafpiLastpaRootpnRootiLeftChildppTreenPrevzNextnNextiStartBlockiLeafEndBlockiEndBlocknLeafDatanSuspectpLhspRhsbPrefixppReaderlhsrhsiAgebLookupiStartLeafiEndLeafpnOvflppOffsetListpnOffsetListfts3SegReaderFirstDocidpReader->aDoclist!pReader->pOffsetListfts3SegReaderNextpElempReader->aNodepReader->iCurrentBlock<=pReader->iLeafEndBlock || CORRUPT_DBpReader->pBlob==0aCopy!fts3SegReaderIsPending(pReader)&pReader->nDoclistfts3SegReaderSetEoffts3SegReaderRequire!pReader->pBlob || (pFrom>=pReader->aNode && pFrom<&pReader->aNode[pReader->nNode])fts3SegReaderIncrReadpReader->nNode - pReader->nPopulateFTS3_NODE_CHUNKSIZE(4*1024)sqlite3Fts3SegmentsClosesqlite3Fts3ReadBlockpnBlob%s_segments"%s_segments""block"aByteFTS3_NODE_CHUNK_THRESHOLD(FTS3_NODE_CHUNK_THRESHOLD)fts3AllocateSegdirIdxpNextIdxiLangid>=0p->nIndex>=1getAbsoluteLevel(p, iLangid, iIndex, iLevel)fts3DeleteTerms*pbFound==0SQL_SELECT_CONTENT_BY_ROWIDlangidFromSelectfts3DeleteAllp->zContentTbl==0 || bContent==0SQL_DELETE_ALL_CONTENTSQL_DELETE_ALL_SEGMENTSSQL_DELETE_ALL_SEGDIRSQL_DELETE_ALL_DOCSIZESQL_DELETE_ALL_STATfts3InsertDatapContentInsertSQL_CONTENT_INSERTfts3InsertTermssqlite3Fts3PendingTermsClearfts3PendingTermsDocidbDelete==1 || bDelete==0fts3PendingTermsAddnWordpTokenizer && pModulepIndexfts3PendingTermsAddOnesizeof(Fts3HashElem)0==fts3HashFind(pHash, zToken, nToken)fts3PendingListDeletefts3PendingListAppend!p || p->iLastDocid<=iDocidp->nData<p->nSpacep->aData[p->nData]==0iPos>p->iLastPos || (iPos==0 && p->iLastPos==0)pendinglistappend_outfts3PendingListAppendVarintsizeof(*p) + 100sqlite3Fts3AllSegdirsiLevel==FTS3_SEGCURSOR_ALL || iLevel>=0SQL_SELECT_LEVEL_RANGEgetAbsoluteLevelp->nIndex>0fts3Writelockfts3SqlExecsqlite3Fts3SelectDocsizesqlite3Fts3SelectDoctotalfts3SelectDocsizeSQL_SELECT_DOCSIZEfts3SqlStmtconst char *[40]char *[40]DELETE FROM %Q.'%q_content' WHERE rowid = ?"DELETE FROM %Q.'%q_content' WHERE rowid = ?"SELECT NOT EXISTS(SELECT docid FROM %Q.'%q_content' WHERE rowid!=?)"SELECT NOT EXISTS(SELECT docid FROM %Q.'%q_content' WHERE rowid!=?)"DELETE FROM %Q.'%q_content'"DELETE FROM %Q.'%q_content'"DELETE FROM %Q.'%q_segments'"DELETE FROM %Q.'%q_segments'"DELETE FROM %Q.'%q_segdir'"DELETE FROM %Q.'%q_segdir'"DELETE FROM %Q.'%q_docsize'"DELETE FROM %Q.'%q_docsize'"DELETE FROM %Q.'%q_stat'"DELETE FROM %Q.'%q_stat'"SELECT %s WHERE rowid=?"SELECT %s WHERE rowid=?"SELECT (SELECT max(idx) FROM %Q.'%q_segdir' WHERE level = ?) + 1"SELECT (SELECT max(idx) FROM %Q.'%q_segdir' WHERE level = ?) + 1"REPLACE INTO %Q.'%q_segments'(blockid, block) VALUES(?, ?)"REPLACE INTO %Q.'%q_segments'(blockid, block) VALUES(?, ?)"SELECT coalesce((SELECT max(blockid) FROM %Q.'%q_segments') + 1, 1)"SELECT coalesce((SELECT max(blockid) FROM %Q.'%q_segments') + 1, 1)"REPLACE INTO %Q.'%q_segdir' VALUES(?,?,?,?,?,?)"REPLACE INTO %Q.'%q_segdir' VALUES(?,?,?,?,?,?)"SELECT idx, start_block, leaves_end_block, end_block, root FROM %Q.'%q_segdir' WHERE level = ? ORDER BY idx ASC"SELECT idx, start_block, leaves_end_block, end_block, root "
            "FROM %Q.'%q_segdir' WHERE level = ? ORDER BY idx ASC"char[112]SELECT idx, start_block, leaves_end_block, end_block, root FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ?ORDER BY level DESC, idx ASC"SELECT idx, start_block, leaves_end_block, end_block, root "
            "FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ?"
            "ORDER BY level DESC, idx ASC"char[135]SELECT count(*) FROM %Q.'%q_segdir' WHERE level = ?"SELECT count(*) FROM %Q.'%q_segdir' WHERE level = ?"SELECT max(level) FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ?"SELECT max(level) FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ?"DELETE FROM %Q.'%q_segdir' WHERE level = ?"DELETE FROM %Q.'%q_segdir' WHERE level = ?"DELETE FROM %Q.'%q_segments' WHERE blockid BETWEEN ? AND ?"DELETE FROM %Q.'%q_segments' WHERE blockid BETWEEN ? AND ?"INSERT INTO %Q.'%q_content' VALUES(%s)"INSERT INTO %Q.'%q_content' VALUES(%s)"DELETE FROM %Q.'%q_docsize' WHERE docid = ?"DELETE FROM %Q.'%q_docsize' WHERE docid = ?"REPLACE INTO %Q.'%q_docsize' VALUES(?,?)"REPLACE INTO %Q.'%q_docsize' VALUES(?,?)"SELECT size FROM %Q.'%q_docsize' WHERE docid=?"SELECT size FROM %Q.'%q_docsize' WHERE docid=?"SELECT value FROM %Q.'%q_stat' WHERE id=?"SELECT value FROM %Q.'%q_stat' WHERE id=?"REPLACE INTO %Q.'%q_stat' VALUES(?,?)"REPLACE INTO %Q.'%q_stat' VALUES(?,?)"DELETE FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ?"DELETE FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ?"SELECT ? UNION SELECT level / (1024 * ?) FROM %Q.'%q_segdir'"SELECT ? UNION SELECT level / (1024 * ?) FROM %Q.'%q_segdir'"SELECT level, count(*) AS cnt FROM %Q.'%q_segdir'   GROUP BY level HAVING cnt>=?  ORDER BY (level %% 1024) ASC, 2 DESC LIMIT 1"SELECT level, count(*) AS cnt FROM %Q.'%q_segdir' "
         "  GROUP BY level HAVING cnt>=?"
         "  ORDER BY (level %% 1024) ASC, 2 DESC LIMIT 1"char[127]SELECT 2 * total(1 + leaves_end_block - start_block)   FROM (SELECT * FROM %Q.'%q_segdir'         WHERE level = ? ORDER BY idx ASC LIMIT ?  )"SELECT 2 * total(1 + leaves_end_block - start_block) "
         "  FROM (SELECT * FROM %Q.'%q_segdir' "
         "        WHERE level = ? ORDER BY idx ASC LIMIT ?"
         "  )"DELETE FROM %Q.'%q_segdir' WHERE level = ? AND idx = ?"DELETE FROM %Q.'%q_segdir' WHERE level = ? AND idx = ?"UPDATE %Q.'%q_segdir' SET idx = ? WHERE level=? AND idx=?"UPDATE %Q.'%q_segdir' SET idx = ? WHERE level=? AND idx=?"SELECT idx, start_block, leaves_end_block, end_block, root FROM %Q.'%q_segdir' WHERE level = ? AND idx = ?"SELECT idx, start_block, leaves_end_block, end_block, root "
            "FROM %Q.'%q_segdir' WHERE level = ? AND idx = ?"char[107]UPDATE %Q.'%q_segdir' SET start_block = ?, root = ?WHERE level = ? AND idx = ?"UPDATE %Q.'%q_segdir' SET start_block = ?, root = ?"
            "WHERE level = ? AND idx = ?"char[79]SELECT 1 FROM %Q.'%q_segments' WHERE blockid=? AND block IS NULL"SELECT 1 FROM %Q.'%q_segments' WHERE blockid=? AND block IS NULL"SELECT idx FROM %Q.'%q_segdir' WHERE level=? ORDER BY 1 ASC"SELECT idx FROM %Q.'%q_segdir' WHERE level=? ORDER BY 1 ASC"SELECT max( level %% 1024 ) FROM %Q.'%q_segdir'"SELECT max( level %% 1024 ) FROM %Q.'%q_segdir'"SELECT level, idx, end_block FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ? ORDER BY level DESC, idx ASC"SELECT level, idx, end_block "
            "FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ? "
            "ORDER BY level DESC, idx ASC"char[106]UPDATE OR FAIL %Q.'%q_segdir' SET level=-1,idx=? WHERE level=? AND idx=?"UPDATE OR FAIL %Q.'%q_segdir' SET level=-1,idx=? "
            "WHERE level=? AND idx=?"UPDATE OR FAIL %Q.'%q_segdir' SET level=? WHERE level=-1"UPDATE OR FAIL %Q.'%q_segdir' SET level=? WHERE level=-1"SizeofArray(azSql)==SizeofArray(p->aStmt)eStmt<SizeofArray(azSql) && eStmt>=0sqlite3_stmt *[40]rc==SQLITE_OK || pStmt==0~SQLITE_PREPARE_NO_VTABsqlite3Fts3InitTokfts3tok_modulefts3tokenize"fts3tokenize"fts3tokRowidMethodFts3tokCursor *fts3tokColumnMethodiCol==4fts3tokEofMethodfts3tokFilterMethodFts3tokTable *zBytefts3tokNextMethodfts3tokCloseMethodfts3tokResetCursorfts3tokOpenMethodsizeof(Fts3tokCursor)fts3tokBestIndexMethodpInfo->estimatedCost>1000000.0fts3tokDisconnectMethodfts3tokConnectMethodpTokazDequotenDequoteCREATE TABLE x(input, token, start, end, position)FTS3_TOK_SCHEMAzModulesimple"simple"(rc==SQLITE_OK)==(pMod!=0)sizeof(Fts3tokTable)fts3tokDequoteArraysizeof(char *)pSpacefts3tokQueryTokenizerunknown tokenizer: %s"unknown tokenizer: %s"sqlite3Fts3SimpleTokenizerModulesimpleNextsimple_tokenizer_cursor *simple_tokenizer *iStartOffsetchsimpleClosesimpleOpensizeof(*c)bIncrpFromiBlockidpaBlobpnLoadpbFoundbContentbDeletepnWordeStmtpazDequoteppTokenpnBytespiStartOffsetpiEndOffsetpiPositionpInputsimpleDestroysimpleCreatesizeof(*t)char[128]fts3_isalnumsimpleDelimsqlite3Fts3InitHashTableanysqlite3Fts3InitTokenizerrc!=SQLITE_OK || *ppTokunknown tokenizer"unknown tokenizer"sqlite3Fts3NextTokensqlite3Fts3IsIdCharisFtsIdCharconst char[128]fts3TokenizerFuncargc==1 || argc==2sizeof(pPtr)argument type mismatch"argument type mismatch"fts3tokenize disabled"fts3tokenize disabled"fts3TokenizerEnabledisEnabledsqlite3Fts3PorterTokenizerModuleporterNextporter_tokenizer_cursor *z[c->iOffset]const char[80]char[80]porter_stemmerzReverse(int)sizeof(zReverse)(int)sizeof(zReverse)-7sizeof(zReverse)sizeof(zReverse)-6sizeof(zReverse)-5sess"sess""ss"sei"sei""i"dee"dee"ee"ee"gni"gni"de"de"ta"ta"ate"ate"lb"lb"ble"ble"zi"zi"ize"ize"'y'lanoita"lanoita"lanoit"lanoit"tion"tion"icne"icne"ence"ence"icna"icna"ance"ance"rezi"rezi"igol"igol"ilb"ilb"illa"illa"al"al"iltne"iltne"ent"ent"ile"ile""e"ilsuo"ilsuo"ous"ous"noitazi"noitazi"noita"noita"rota"rota"msila"msila"ssenevi"ssenevi"ive"ive"ssenluf"ssenluf"ful"ful"ssensuo"ssensuo"itila"itila"itivi"itivi"itilib"itilib"etaci"etaci"ic"ic"evita"evita"ezila"ezila"itici"itici"laci"laci"luf"luf"ssen"ssen"tneme"tneme"tnem"tnem"tne"tne"noi"noi"eta"eta"iti"iti"copy_stemmerhasDigitstemstar_ohdoubleConsonanthasVowelm_gt_1m_eq_1m_gt_0isVowelx>='a' && x<='z'const char[26]isConsonantporterCloseporterOpenporterDestroyporterCreateporter_tokenizer *sqlite3Fts3HashInserthrawelemnew_elemxHashpH!=0xHash!=0(pH->htsize & (pH->htsize-1))==0old_datapH->htsize>0_fts3ht *sqlite3Fts3HashFindsqlite3Fts3HashFindElemfts3RemoveElementByHashpH->first==0pH->count==0fts3FindElementByHashfts3Rehashnew_htnext_elem(new_size & (new_size-1))==0sizeof(struct _fts3ht)fts3HashInsertElementpHeadftsCompareFunctionkeyClass==FTS3_HASH_BINARYFTS3_HASH_STRINGftsHashFunctionfts3BinComparefts3BinHashfts3StrComparefts3StrHashsqlite3Fts3HashClearsqlite3Fts3HashInitkeyClass>=FTS3_HASH_STRING && keyClass<=FTS3_HASH_BINARYfts3HashFreefts3HashMallocsqlite3Fts3ExprFreepDel==0 || pDel->pParent==0p->pParent==0 || p==p->pParent->pRight || p==p->pParent->pLeftp==p->pParent->pRight || p==p->pParent->pLeftfts3FreeExprNodep->eType==FTSQUERY_PHRASE || p->pPhrase==0sqlite3Fts3ExprParseFts3Expr **SQLITE_FTS3_MAX_EXPR_DEPTHFTS expression tree is too large (maximum depth %d)"FTS expression tree is too large (maximum depth %d)"malformed MATCH expression: [%s]"malformed MATCH expression: [%s]"fts3ExprParseUnbalancednParsedsParseParseContext *sizeof(ParseContext)rc==SQLITE_OK || *ppExpr==0fts3ExprBalancep->pParent==0 || p->pParent->pLeft==pp->pLeft && p->pRightpParent==0 || pParent->pLeft==ppParent->pParent==0 || pParent->pParent->pLeft==pParentpParent==pRootpFree!=0pFree==0pLeft && pRightFTSQUERY_ANDFTSQUERY_ORapLeafsizeof(Fts3Expr *)fts3ExprCheckDepthfts3ExprParsepNotBranchisRequirePhrasenByte>0 || (rc!=SQLITE_OK && p==0)pRet && pPrevpPrev && pPrev->pLeft && pPrev->pRight==0rc!=SQLITE_OK || (nByte>0 && nByte<=nIn)isPhrasesqlite3_fts3_enable_parentheses!sqlite3_fts3_enable_parenthesespNotsizeof(Fts3Expr)pAndFTSQUERY_NEARppTokenizerppTokpnpzTokenxCondzInputpHpKeynew_sizekeyClasscopyKeybFts4iDefaultColppExprnMaxDepthpnConsumedexprparse_outinsertBinaryOperatorpSplitpSplit->pParent->pRight==pSplitopPrecedencep->eType!=FTSQUERY_PHRASEp->eType==FTSQUERY_ANDgetNextNodeconst Fts3Keywordconst Fts3Keyword[]Fts3Keyword[]aKeywordiColLennKey==4const Fts3Keyword[4]Fts3Keyword[4]sizeof(aKeyword)sizeof(struct Fts3Keyword)sizeof(aKeyword)/sizeof(struct Fts3Keyword)(int)(sizeof(aKeyword)/sizeof(struct Fts3Keyword))const Fts3Keyword *Fts3Keyword *~sqlite3_fts3_enable_parenthesesnNear SQLITE_FTS3_DEFAULT_NEAR_PARAMcNextnConsumedSQLITE_MAX_EXPR_DEPTHOR"OR"AND"AND"NOT"NOT"NEAR"NEAR"getNextStringnTempsizeof(Fts3Phrase)sizeof(Fts3Expr) + sizeof(Fts3Phrase)nToken==iisizeof(Fts3PhraseToken)Fts3PhraseToken[1]nTemp==0 || zTempgetnextstring_outfts3ReallocOrFreegetNextTokeniPositionsqlite3Fts3OpenTokenizersqlite3Fts3MallocZerofts3isspacesqlite3Fts3InitAuxfts3aux_modulefts4aux"fts4aux"fts3auxRowidMethodFts3auxCursor *fts3auxColumnMethodp->isEof==0*"*"Fts3auxColstats *fts3auxEofMethodfts3auxFilterMethodpFts3Fts3auxTable *iLangValiEqiGeiLeidxStr==0idxNum==FTS4AUX_EQ_CONSTRAINT || idxNum==0 || idxNum==FTS4AUX_LE_CONSTRAINT || idxNum==FTS4AUX_GE_CONSTRAINT || idxNum==(FTS4AUX_LE_CONSTRAINT|FTS4AUX_GE_CONSTRAINT)FTS4AUX_EQ_CONSTRAINTFTS4AUX_GE_CONSTRAINTFTS4AUX_LE_CONSTRAINT(iEq==0 && iGe==-1) || (iEq==-1 && iGe==0)pCsr->filter.zTermfts3auxNextMethodeState==3mcsizeof(struct Fts3auxColstats)fts3auxGrowStatArrayfts3auxCloseMethodfts3auxOpenMethodsizeof(Fts3auxCursor)fts3auxBestIndexMethod5.020000.0fts3auxDisconnectMethodpFts3->aStmt320SizeofArray(pFts3->aStmt)fts3auxConnectMethodzFts3nFts3CREATE TABLE x(term, col, documents, occurrences, languageid HIDDEN)FTS3_AUX_SCHEMAsizeof(Fts3auxTable)528sizeof(Fts3Table)560sizeof(Fts3auxTable) + sizeof(Fts3Table)bad_argsinvalid arguments to fts4aux constructor"invalid arguments to fts4aux constructor"sqlite3Fts3EvalPhraseCleanupFts3Doclist *sizeof(Fts3Doclist)sqlite3Fts3EvalPhrasePoslistiCol>=0 && iCol<pTab->nColumnpRun->pParentrc!=SQLITE_OK || pPhrase->bIncr==0pTest->eType==FTSQUERY_NEAR || pTest->eType==FTSQUERY_PHRASEpTest->eType==FTSQUERY_PHRASEpCsr->iPrevIdbDescDoclistbOrbTreeEofpNearpRunbEofSavepPh&iThissqlite3Fts3EvalPhraseStatspCsr->nDoc>0pExpr->aMIfts3EvalGatherStatspExpr->eType==FTSQUERY_PHRASEpRoot->bStartsqlite3_data_count(pCsr->pStmt)==0pRoot->bEof==0iPrevIdfts3AllocateMSIfts3EvalUpdateCountssqlite3Fts3MsrCancelfts3EvalRestartfts3EvalNextpCsr->isEof==0sqlite3Fts3EvalTestDeferredbMissfts3EvalTestExprbHitbHit1bHit2fts3EvalNearTestp->pRight->pPhrase->doclist.nList>0p->pParent && p->pParent->pLeft==pnTmpaPoslistfts3EvalNextRow!pLeft->bDeferred || !pRight->bDeferredpLeft->iDocidpRight->iDocidpRight->eType==FTSQUERY_PHRASEpLeft->bStart || pLeft->iDocid==pRight->iDocidpRight->bStart || pLeft->iDocid==pRight->iDocid*pRc!=SQLITE_OK || pRight->bStartiDiffpDliCmpppHeadaiOutfts3EvalNearTrimnParam1nParam2pPhrase->doclist.pListnNew<=pPhrase->doclist.nList && nNew>0pPhrase->doclist.pList[nNew]=='\0'fts3EvalInvalidatePoslistfts3EvalStartnOrFts3TokenAndCost *aTCsizeof(Fts3TokenAndCost)apOrppOrFts3TokenAndCost **Fts3Expr ***fts3EvalSelectDeferrednDocSizenMinEstnLoad4rc!=SQLITE_OK || nDocSize>0rc==SQLITE_OK || pList==0iTCnCountfts3EvalAverageDocsizea==0pCsr->nRowAvg>0fts3EvalTokenCostspExpr->eType==FTSQUERY_OR || pExpr->eType==FTSQUERY_AND || pExpr->eType==FTSQUERY_NEARfts3EvalStartReadersfts3EvalPhraseNextpDLfts3EvalIncrPhraseNextp->bIncr==1p->nToken<=MAX_INCR_PHRASE_TOKENSp->iDoclistToken<MAX_INCR_PHRASE_TOKENSa[i].iDocidrc!=SQLITE_OK || (p->nToken>=1 && a[p->nToken-1].bIgnore==0)rc!=SQLITE_OK || bMaxSetTokenDoclist[4]MAX_INCR_PHRASE_TOKENSTokenDoclist *bMaxSetFTS3_BUFFER_PADDINGpLpRnDistincrPhraseTokenNextp->bIgnore==0pPhrase->aToken[iToken].pSegcsr==0pToken->pSegcsr || pPhrase->iDoclistToken>=0fts3EvalDlPhraseNextpDL->aAll!=0 || pIter==0pIter>=&pDL->aAll[pDL->nAll] || *pItersqlite3Fts3DoclistNext*pbEof==0p || *piDocid==0!p || (p>=aDoclist && p<=&aDoclist[nDoclist])iVarsqlite3Fts3DoclistPrev!p || (p>aDoclist && p<&aDoclist[nDoclist])pDocidpSavefts3EvalPhraseStartbHaveIncrbIncrOkpSegcsrrc!=SQLITE_OK || p->nToken<1 || p->aToken[0].pSegcsr==0 || p->bIncrfts3EvalDeferredPhraseiTokennPoslistiPrev>=0p1 && p2nMaxUndeferrednDistancefts3EvalPhraseLoadpToken->pDeferred==0 || pToken->pSegcsr==0pToken->pSegcsr==0nThisfts3EvalPhraseMergeTokeniToken!=p->iDoclistTokennDifffts3EvalAllocateReaderspExpr->pPhrase->iDoclistToken==0Fts3MultiSegReader **sqlite3Fts3InitFts3HashWrapper *pSimplepPorterpUnicodesizeof(Fts3HashWrapper)porter"porter"unicode61"unicode61"snippet"snippet"offsets"offsets"matchinfo"matchinfo"fts3"fts3"fts4"fts4"hashDestroyfts3IntegrityMethodrc!=SQLITE_CORRUPT_VTABunable to validate the inverted index for FTS%d table %s.%s: %s"unable to validate the inverted index for"
                             " FTS%d table %s.%s: %s"malformed inverted index for FTS%d table %s.%s"malformed inverted index for FTS%d table %s.%s"fts3ShadowNamecontent"content"docsize"docsize"segdir"segdir"segments"segments""stat"fts3RollbackToMethodpTab->inTransactionpTab->mxSavepoint = iSavepointfts3ReleaseMethodpTab->mxSavepoint >= iSavepointpTab->mxSavepoint = iSavepoint-1fts3SavepointMethodpTab->mxSavepoint<=iSavepoint&pTab->aIndex[0].hPendingINSERT INTO %Q.%Q(%Q) VALUES('flush')"INSERT INTO %Q.%Q(%Q) VALUES('flush')"fts3RenameMethodp->nPendingData==0ALTER TABLE %Q.'%q_content'  RENAME TO '%q_content';"ALTER TABLE %Q.'%q_content'  RENAME TO '%q_content';"ALTER TABLE %Q.'%q_docsize'  RENAME TO '%q_docsize';"ALTER TABLE %Q.'%q_docsize'  RENAME TO '%q_docsize';"ALTER TABLE %Q.'%q_stat'  RENAME TO '%q_stat';"ALTER TABLE %Q.'%q_stat'  RENAME TO '%q_stat';"ALTER TABLE %Q.'%q_segments' RENAME TO '%q_segments';"ALTER TABLE %Q.'%q_segments' RENAME TO '%q_segments';"ALTER TABLE %Q.'%q_segdir'   RENAME TO '%q_segdir';"ALTER TABLE %Q.'%q_segdir'   RENAME TO '%q_segdir';"fts3FindFunctionMethodOverloadedOverloaded[]aOverloadOverloaded[4]Overloaded *SizeofArray(aOverload)fts3MatchinfoFuncnVal==1 || nVal==2Fts3Cursor **fts3OptimizeFuncnVal==1Index optimized"Index optimized"Index already optimal"Index already optimal"fts3OffsetsFuncfts3SnippetFunc<b>"<b>"</b>"</b>"<b>...</b>"<b>...</b>" 15nVal>=1wrong number of arguments to function snippet()"wrong number of arguments to function snippet()"fts3FunctionArgfts3cursor"fts3cursor"illegal first argument to %s"illegal first argument to %s"fts3ReversePoslistp==pStart || c==0fts3RollbackMethodp->inTransaction!=0p->inTransaction = 0p->mxSavepoint = -1;fts3CommitMethodFts3Table *p = (Fts3Table*)pVtabfts3BeginMethodp->inTransaction!=1fts3SetHasStat%s_stat"%s_stat"fts3SyncMethodconst u32nMinMergeiLastRowidrc==SQLITE_OK || mxLevel==0nMinMerge/16(nMinMerge/16)(int)nMinMergefts3UpdateMethodfts3ColumnMethodiCol>=0 && iCol<=p->nColumn+2((Fts3Table *)pCsr->base.pVtab)->pSegments==0fts3RowidMethodfts3EofMethodfts3FilterMethodeSearchpLangidpDocidGepDocidLeeSearch>=0 && eSearch<=(FTS3_FULLTEXT_SEARCH+p->nColumn)FTS3_FULLSCAN_SEARCHFTS3_HAVE_LANGIDFTS3_HAVE_DOCID_GEFTS3_HAVE_DOCID_LEiIdx==nValp->base.zErrMsg==0FTS3_DOCID_SEARCHFTS3_FULLTEXT_SEARCHSELECT %s WHERE rowid BETWEEN %lld AND %lld ORDER BY rowid %s"SELECT %s WHERE rowid BETWEEN %lld AND %lld ORDER BY rowid %s"SELECT %s ORDER BY rowid %s"SELECT %s ORDER BY rowid %s"fts3DocidRangefts3NextMethodfts3DoclistCountDocidsaEndfts3TermSelecttscTermSelect *sizeof(TermSelect)tsc.aaOutputchar *[16]int[16]SizeofArray(tsc.aaOutput)fts3SegReaderCursorFreefts3TermSegReaderCursorsizeof(Fts3MultiSegReader)nTCppTCpbEofbDescIdxbOptOkpnOrzFuncppPoslistiDefaultaListppSegcsrfts3SegReaderCursorAddZerosqlite3Fts3SegReaderCursorFTS3_SEGCURSOR_ALL<0 && FTS3_SEGCURSOR_PENDING<0isPrefix==0 || isScan==0fts3SegReaderCursoriLeavesEndBlockpifts3SegReaderCursorAppendapNewsizeof(Fts3SegReader*)fts3TermSelectMergepTS->aaOutputiOut>0aMergeSizeofArray(pTS->aaOutput)fts3TermSelectFinishMergesqlite3Fts3FirstFilterbWrittenfts3DoclistPhraseMergepEnd1pEnd2bFirstOutnDist>0iPrevSavebFirstOutSavefts3DoclistOrMerge(p-aOut)<=((p1?(p1-a1):n1)+(p2?(p2-a2):n2)+FTS3_VARINT_MAX-1)(p-aOut)<=n1+n2+FTS3_VARINT_MAX-1fts3PutDeltaVarint3iWrite*pbFirst==0 || iVal>=*piPrev*piPrev>=iVal*pbFirst || *piPrev==0*pbFirst==0 || iWrite>0fts3GetDeltaVarint3fts3PoslistNearMergepTmp1pTmp2aTmp2fts3PoslistPhraseMergeiCol1iCol2isSaveLeft==0 || isExact==0p!=0 && *p1!=0 && *p2!=0&iCol1POS_COLUMN&iCol2pp && p(*p1&0xFE)==0 && (*p2&0xFE)==0iPos1iPos2iSavefts3PoslistMerge&p1[1]&p2[1]POS_ENDfts3PutColNumberfts3ReadNextPos(*pp)fts3ColumnlistCopyc!=0 && ((*pEnd)&0xfe)==0fts3PoslistCopyc!=0 && (*pEnd)==0fts3PutDeltaVarintiVal-*piPrev > 0 || (*piPrev==0 && iVal==0)fts3SelectLeafpiLeaf || piLeaf2zNode&iHeight!piLeaf2 || !piLeaf || rc!=SQLITE_OK || (*piLeaf<=*piLeaf2)!piLeaf2 || !piLeaf || rc!=0 || (*piLeaf<=*piLeaf2)&iNewHeightiNewHeightfts3ScanInteriorNodezBufferisFirstTermnBuffernPrefix>=0 && nSuffix>=0finish_scanfts3CursorSeekfts3CursorSeekStmtSELECT %s WHERE rowid = ?"SELECT %s WHERE rowid = ?"fts3CloseMethodfts3ClearCursorsizeof(Fts3Cursor)sizeof(sqlite3_vtab_cursor)sizeof(Fts3Cursor)-sizeof(sqlite3_vtab_cursor)fts3CursorFinalizeStmtfts3OpenMethodfts3BestIndexMethodiLangidConsiDocidGeiDocidLe50000005000000.0bDocid1.000000000000000076e+501e501125899906842624((sqlite3_int64)1) << 50fts3SetUniqueFlagfts3SetEstimatedRows3008002fts3CreateMethodfts3ConnectMethodfts3InitVtabnStringisFts4nIndexaIndexbNoDocsizezCompresszUncompresszContentzLanguageidazNotindexednNotindexedstrlen(argv[0])==4(sqlite3_strnicmp(argv[0], "fts4", 4)==0 && isFts4) || (sqlite3_strnicmp(argv[0], "fts3", 4)==0 && !isFts4)sizeof(const char *)aFts4OptiOpt==6iOpt==SizeofArray(aFts4Opt)tokenize"tokenize"Fts4Option[]Fts4Option[8]prefix"prefix""compress""uncompress"order"order"languageid"languageid"notindexed"notindexed"iOptFts4Option *SizeofArray(aFts4Opt)unrecognized matchinfo: %s"unrecognized matchinfo: %s"asc"asc""desc"unrecognized order: %s"unrecognized order: %s"unrecognized parameter: %s"unrecognized parameter: %s"const char ***nString==0Fts3Index **error parsing prefix parameter: %s"error parsing prefix parameter: %s"sizeof(struct Fts3Index)sizeof(u8)FTS3_MAX_PENDING_DATAzCsr <= &((char *)p)[nByte]zNotno such column: %s"no such column: %s"zMissmissing %s parameter in fts4 constructor"missing %s parameter in fts4 constructor"fts3_init_outp->inTransaction = -1p->mxSavepoint = -1fts3ContentColumnspTSpaRightpnRightpiPrevpbFirstpp1pp2isSaveLeftisExactpiLeafpiLeaf2piFirstppVTabpazColpnColpnStrfts3PrefixParameterfts3GobbleIntMAX_NPREFIX10000000 10000000nIntsqlite3Fts3ReadIntfts3WriteExprListzFunction,%s(?)",%s(?)", ?", ?"fts3ReadExprListdocid"docid",%s(x.'c%d%q')",%s(x.'c%d%q')", x.%Q", x.%Q"langid"langid", x.'%q'", x.'%q'" FROM '%q'.'%q%s' AS x" FROM '%q'.'%q%s' AS x"_content"_content"fts3QuoteIdfts3Appendffts3IsSpecialColumnfts3DatabasePageSizep->nPgsz>0 || rc!=SQLITE_OKfts3CreateTableszContentColsdocid INTEGER PRIMARY KEY"docid INTEGER PRIMARY KEY"%z, 'c%d%q'"%z, 'c%d%q'"%z, langid"%z, langid"CREATE TABLE %Q.'%q_content'(%s)"CREATE TABLE %Q.'%q_content'(%s)"CREATE TABLE %Q.'%q_segments'(blockid INTEGER PRIMARY KEY, block BLOB);"CREATE TABLE %Q.'%q_segments'(blockid INTEGER PRIMARY KEY, block BLOB);"CREATE TABLE %Q.'%q_segdir'(level INTEGER,idx INTEGER,start_block INTEGER,leaves_end_block INTEGER,end_block INTEGER,root BLOB,PRIMARY KEY(level, idx));"CREATE TABLE %Q.'%q_segdir'("
        "level INTEGER,"
        "idx INTEGER,"
        "start_block INTEGER,"
        "leaves_end_block INTEGER,"
        "end_block INTEGER,"
        "root BLOB,"
        "PRIMARY KEY(level, idx)"
      ");"char[153]CREATE TABLE %Q.'%q_docsize'(docid INTEGER PRIMARY KEY, size BLOB);"CREATE TABLE %Q.'%q_docsize'(docid INTEGER PRIMARY KEY, size BLOB);"p->bHasStat==p->bFts4sqlite3Fts3CreateStatTableCREATE TABLE IF NOT EXISTS %Q.'%q_stat'(id INTEGER PRIMARY KEY, value BLOB);"CREATE TABLE IF NOT EXISTS %Q.'%q_stat'"
          "(id INTEGER PRIMARY KEY, value BLOB);"fts3DeclareVtab__langid"__langid"%Q, "%Q, "%z%Q, "%z%Q, "CREATE TABLE x(%s %Q HIDDEN, docid HIDDEN, %Q HIDDEN)"CREATE TABLE x(%s %Q HIDDEN, docid HIDDEN, %Q HIDDEN)"fts3DestroyMethodDROP TABLE IF EXISTS %Q.'%q_segments';DROP TABLE IF EXISTS %Q.'%q_segdir';DROP TABLE IF EXISTS %Q.'%q_docsize';DROP TABLE IF EXISTS %Q.'%q_stat';%s DROP TABLE IF EXISTS %Q.'%q_content';"DROP TABLE IF EXISTS %Q.'%q_segments';"
    "DROP TABLE IF EXISTS %Q.'%q_segdir';"
    "DROP TABLE IF EXISTS %Q.'%q_docsize';"
    "DROP TABLE IF EXISTS %Q.'%q_stat';"
    "%s DROP TABLE IF EXISTS %Q.'%q_content';"char[186]fts3DbExecsqlite3Fts3ErrMsgfts3DisconnectMethodp->aStmtSizeofArray(p->aStmt)fts3GetReverseVarintfts3GetDeltaVarintsqlite3Fts3Dequotesqlite3Fts3VarintLensqlite3Fts3GetVarint32a & 0x800x4000*pi0x3FFF0x2000000x1FFFFF20971510x0FFFFFFF0==(a & 0x80000000)*pi>=0sqlite3Fts3GetVarintBoundedshiftsqlite3Fts3GetVarintsqlite3Fts3GetVarintU*vsqlite3Fts3PutVarintvuq - (unsigned char *)p <= FTS3_VARINT_MAXfts3_term_cntfts3_global_term_cntnOptazCompileOptSQLITE_"SQLITE_"sqlite3DbNameToBtreepResult(sqlite3_int64)(p - pResult)==nBytedatabaseNamesqlite3*db==0 || db->aDb[0].pSchema!=00x00008int*sqlite3FaultFuncType(x = va_arg(ap,int))!=0sqlite3LocaltimeTypeconst char*sqlite3_context*sqlite3_uint64*db->aDb->pBtu32*u64*Schema *3435973836818446744039349813247~SQLITE_FkNoActionaProgxBenignBeginxBenignEndSQLITE_BYTEORDER123400SQLITE_LITTLEENDIAN123410SQLITE_BIGENDIANpNDBFLAG_InternalFuncsqlite3BtreeSeekCount(db->aDb->pBt)opTracerInrLogEstpI1pU64pI2pBtreepPager!=0fd!=0nSaveTable *Column *zDataTypezCollSeqnotnullprimarykeyautoincCOLFLAG_PRIMKEYTF_Autoincrementerror_outno such table column: %s.%s"no such table column: %s.%s"sqlite3CantopenErrorcannot open file"cannot open file"sqlite3GlobalConfig.xLog!=0sqlite3MisuseErrormisuse"misuse"sqlite3CorruptErrordatabase corruption"database corruption"sqlite3ReportError%s at line %d of [%.10s]"%s at line %d of [%.10s]"DbClientData *DbClientData **p->pData!=0sizeof(DbClientData)zName8!db->mallocFailedzFilename8  "\000\000"*ppDb || rc==SQLITE_NOMEM*ppDbDB_SchemaLoadedopenDatabaseisThreadsafe4294836223~SQLITE_OPEN_SHAREDCACHE280792181638647960161523253665304130840655128( SQLITE_OPEN_DELETEONCLOSE |
               SQLITE_OPEN_EXCLUSIVE |
               SQLITE_OPEN_MAIN_DB |
               SQLITE_OPEN_TEMP_DB |
               SQLITE_OPEN_TRANSIENT_DB |
               SQLITE_OPEN_MAIN_JOURNAL |
               SQLITE_OPEN_TEMP_JOURNAL |
               SQLITE_OPEN_SUBJOURNAL |
               SQLITE_OPEN_SUPER_JOURNAL |
               SQLITE_OPEN_NOMUTEX |
               SQLITE_OPEN_FULLMUTEX |
               SQLITE_OPEN_WAL
             )4294312167~( SQLITE_OPEN_DELETEONCLOSE |
               SQLITE_OPEN_EXCLUSIVE |
               SQLITE_OPEN_MAIN_DB |
               SQLITE_OPEN_TEMP_DB |
               SQLITE_OPEN_TRANSIENT_DB |
               SQLITE_OPEN_MAIN_JOURNAL |
               SQLITE_OPEN_TEMP_JOURNAL |
               SQLITE_OPEN_SUBJOURNAL |
               SQLITE_OPEN_SUPER_JOURNAL |
               SQLITE_OPEN_NOMUTEX |
               SQLITE_OPEN_FULLMUTEX |
               SQLITE_OPEN_WAL
             )784sizeof(sqlite3)db->mutexSQLITE_STATE_BUSYDb[2]sizeof(db->aLimit)==sizeof(aHardLimit)SQLITE_N_LIMITconst int[12]sizeof(db->aLimit)SQLITE_DEFAULT_WORKER_THREADS0x000200x00040SQLITE_ShortColNamesSQLITE_EnableTrigger2622082147483648SQLITE_EnableView2147745856SQLITE_CacheSpill21477458886871947673670867222624137438953472208306176096274877906944483184083040SQLITE_TrustedSchema483184083168SQLITE_AutoIndex483184115936Hash *NOCASE"NOCASE"RTRIM"RTRIM"SQLITE_OPEN_READONLY == 0x01SQLITE_OPEN_READWRITE == 0x02SQLITE_OPEN_CREATE == 0x040x46185023db->pVfs!=0Btree **SQLITE_DEFAULT_SYNCHRONOUSPAGER_SYNCHRONOUS_OFFSQLITE_STATE_OPENsqlite3BuiltinExtensions..(*const)(..)..(*const[8])(..)..(*[8])(..)..(*const *)(..)ArraySize(sqlite3BuiltinExtensions)SQLITE_DEFAULT_WAL_AUTOCHECKPOINTopendb_outdb->mutex!=0 || isThreadsafe==0 || sqlite3GlobalConfig.bFullMutex==0db!=0 || (rc&0xff)==SQLITE_NOMEMSQLITE_STATE_SICK(1<<(flags&7))==0x02(1<<(flags&7))==0x04(1<<(flags&7))==0x40uriParameterzFilename!=0sqlite3ParseUri*pzErrMsg==0&sqlite3GlobalConfig.bOpenUri&sqlite3Config.bOpenUrizUri[iIn]zUri[iIn+1]octet>=0 && octet<256__atomic_load_1const volatile voidconst volatile void *file:"file:"localhost"localhost"invalid uri authority: %.*s"invalid uri authority: %.*s"octetvfs"vfs"OpenMode *aModezModeTypecache"cache"OpenMode[3]shared"shared"private"private"OpenMode[]aCacheMode393216OpenMode[5]ro"ro"rw"rw"rwc"rwc"memory"memory"aOpenModeno such %s mode: %s"no such %s mode: %s"-129~SQLITE_OPEN_MEMORY%s mode not allowed: %s"%s mode not allowed: %s"~SQLITE_OPEN_URIno such vfs: %s"no such vfs: %s"parse_uri_outoldLimitaHardLimit[SQLITE_LIMIT_LENGTH]==SQLITE_MAX_LENGTHaHardLimit[SQLITE_LIMIT_SQL_LENGTH]==SQLITE_MAX_SQL_LENGTHaHardLimit[SQLITE_LIMIT_COLUMN]==SQLITE_MAX_COLUMNaHardLimit[SQLITE_LIMIT_EXPR_DEPTH]==SQLITE_MAX_EXPR_DEPTHaHardLimit[SQLITE_LIMIT_COMPOUND_SELECT]==SQLITE_MAX_COMPOUND_SELECTaHardLimit[SQLITE_LIMIT_VDBE_OP]==SQLITE_MAX_VDBE_OPaHardLimit[SQLITE_LIMIT_FUNCTION_ARG]==SQLITE_MAX_FUNCTION_ARGaHardLimit[SQLITE_LIMIT_ATTACHED]==SQLITE_MAX_ATTACHEDaHardLimit[SQLITE_LIMIT_LIKE_PATTERN_LENGTH]== SQLITE_MAX_LIKE_PATTERN_LENGTHaHardLimit[SQLITE_LIMIT_VARIABLE_NUMBER]==SQLITE_MAX_VARIABLE_NUMBERaHardLimit[SQLITE_LIMIT_TRIGGER_DEPTH]==SQLITE_MAX_TRIGGER_DEPTHaHardLimit[SQLITE_LIMIT_WORKER_THREADS]==SQLITE_MAX_WORKER_THREADSSQLITE_LIMIT_WORKER_THREADS==(SQLITE_N_LIMIT-1)SQLITE_MIN_LENGTHcreateCollationCollSeq *pCollenc2sqlite3_mutex_held(db->mutex)184348unable to delete/modify collation sequence due to active statements"unable to delete/modify collation sequence due to active statements"-9~SQLITE_UTF16_ALIGNEDaCollconst Hashconst Hash *enc2==SQLITE_UTF16enc2==SQLITE_UTF16_ALIGNED184300184291const u16const u16[]outOfMemconst u16[14]unsigned short[14]const u16 *const u16[34]unsigned short[34]pnIndexapIndexpnKeypzValuebDfltpCollNeededArgxCollNeeded16xCollNeededxDelzDefaultVfspFlagsppVfspzFilelimitIdnewLimit'P'184212db->pErr==0sqlite3TempInMemoryconst sqlite3const sqlite3 *sqlite3CheckpointbBusy!pnLog || *pnLog==-1!pnCkpt || *pnCkpt==-1SQLITE_MAX_DBiDb==SQLITE_MAX_ATTACHEDiDb==SQLITE_MAX_DBSQLITE_CHECKPOINT_PASSIVE==0SQLITE_CHECKPOINT_FULL==1SQLITE_CHECKPOINT_RESTART==2SQLITE_CHECKPOINT_TRUNCATE==3184076unknown database: %s"unknown database: %s"&db->u1.isInterrupted__atomic_store_4volatile int *nFramesqlite3WalDefaultHookSQLITE_TRACE_NONLEGACY_MASKSQLITE_TRACE_XPROFILESQLITE_TRACE_LEGACYsqlite3InvalidFunctionNotUsed2unable to use function %s in the requested context"unable to use function %s in the requested context"zFunc8FuncDestructor *createFunctionApisizeof(FuncDestructor)rc!=SQLITE_OK || (xStep==0 && xFinal==0)sqlite3CreateFuncextraFlagsxValue==0 || xSFunc==0SQLITE_MAX_FUNCTION_ARG183460SQLITE_FUNC_CONSTANT==SQLITE_DETERMINISTICSQLITE_FUNC_DIRECT==SQLITE_DIRECTONLY157491236720642044928054003712(SQLITE_DETERMINISTIC|SQLITE_DIRECTONLY|
                       SQLITE_SUBTYPE|SQLITE_INNOCUOUS|
                       SQLITE_RESULT_SUBTYPE|SQLITE_SELFORDER1)SQLITE_FUNC_ENCMASK(SQLITE_FUNC_ENCMASK|SQLITE_ANY)SQLITE_FUNC_UNSAFE==SQLITE_INNOCUOUSSQLITE_FUNC_UNSAFEunable to delete/modify user-function due to active statements"unable to delete/modify user-function due to active statements"p || db->mallocFailedp->funcFlags & SQLITE_DETERMINISTICp->funcFlags & SQLITE_DIRECTONLY__atomic_load_4sqlite3InvokeBusyHandlerBusyHandler *sqliteDefaultBusyCallbackdelaystotalstmoutdelaypriorcount>=0const u8[12](NDELAY-1)228sqlite3ErrStrconst char *const[]aMsgunknown error"unknown error"rc>=0516abort due to ROLLBACK"abort due to ROLLBACK"another row available"another row available"no more rows available"no more rows available"const char *const[29]char *[29]232ArraySize(aMsg)not an error"not an error"SQL logic error"SQL logic error"access permission denied"access permission denied"query aborted"query aborted"database is locked"database is locked"database table is locked"database table is locked"attempt to write a readonly database"attempt to write a readonly database"interrupted"interrupted"disk I/O error"disk I/O error"database disk image is malformed"database disk image is malformed"unknown operation"unknown operation"database or disk is full"database or disk is full"unable to open database file"unable to open database file"locking protocol"locking protocol"database schema has changed"database schema has changed"string or blob too big"string or blob too big"constraint failed"constraint failed"datatype mismatch"datatype mismatch"bad parameter or other API misuse"bad parameter or other API misuse"authorization denied"authorization denied"column index out of range"column index out of range"file is not a database"file is not a database"notification message"notification message"warning message"warning message"sqlite3RollbackAllinTransschemaChangeDBFLAG_SchemaChangeSQLITE_DeferFKs85899345928590458880(u64)(SQLITE_DeferFKs|SQLITE_CorruptRdOnly)18446744065119092735~(u64)(SQLITE_DeferFKs|SQLITE_CorruptRdOnly)sqlite3LeaveMutexAndCloseZombieHashElem *SQLITE_STATE_ZOMBIEdb->nDb<=2db->aDb==db->aDbStatic&db->aFunc&db->aCollSeq&db->aModuleModule *SQLITE_STATE_ERRORSQLITE_STATE_CLOSEDsqlite3LookasideUsed(db,0)==0iTxnsqlite3Close182809unable to close due to unfinalized statements or unfinished backups"unable to close due to unfinalized "
       "statements or unfinished backups"connectionIsBusyVdbe *disconnectAllVtab&pSchema->tblHashfunctionDestroypDestructor(p->funcFlags & SQLITE_FUNC_BUILTIN)==0sqlite3CloseSavepointsSavepoint *nocaseCollatingFuncsqlite3IsBinaryconst CollSeqconst CollSeq *p==0 || p->xCmp!=binCollFunc || strcmp(p->zName,"BINARY")==0rtrimCollFuncpK1pK2binCollFuncpKey1 && pKey2char*void*aFlagOpconst struct <unnamed>[21]struct <unnamed>[21]SQLITE_ForeignKeysSQLITE_Fts3TokenizerSQLITE_LoadExtensionSQLITE_NoCkptOnCloseSQLITE_EnableQPSGSQLITE_TriggerEQPSQLITE_ResetDatabaseSQLITE_WriteSchemaSQLITE_NoSchemaError134217729SQLITE_LegacyAlterSQLITE_DqsDDLSQLITE_DqsDMLSQLITE_LegacyFileFmtSQLITE_StmtScanStatusSQLITE_ReverseOrderArraySize(aFlagOp)oldFlagsbSeenBusysetupLookasideszAllocnBignSm-8LookasideSlot *(int)sizeof(LookasideSlot*)LOOKASIDE_SMALL3*LOOKASIDE_SMALLsz > (int)sizeof(LookasideSlot*)((uptr)p)<=szAlloc + (uptr)pStartop==SQLITE_CONFIG_LOGop==SQLITE_CONFIG_PCACHE_HDRSZMASKBIT64( SQLITE_CONFIG_LOG )0
       | MASKBIT64( SQLITE_CONFIG_LOG )MASKBIT64( SQLITE_CONFIG_PCACHE_HDRSZ )168427520
       | MASKBIT64( SQLITE_CONFIG_LOG )
       | MASKBIT64( SQLITE_CONFIG_PCACHE_HDRSZ )mAnytimeConfigOption182006sqlite3_mutex_methods*sqlite3_mem_methods*!sqlite3GlobalConfig.isInitsqlite3_pcache_methods2*&sqlite3GlobalConfig.xLog&sqlite3Config.xLogxLog&sqlite3GlobalConfig.pLogArg&sqlite3Config.pLogArgpLogArgbOpenUrisqlite3_mutex_methods *__atomic_store_8__atomic_store_1szMmapmxMmap2147418112SQLITE_MAX_MMAP_SIZESQLITE_DEFAULT_MMAP_SIZEsqlite3_mutex *pMainMtx;pMainMtxSQLITE_PTRSIZE==sizeof(char*)pMainMtx = sqlite3MutexAlloc(SQLITE_MUTEX_STATIC_MAIN);pMainMtx = sqlite3MutexAlloc(2);FuncDefHash *sizeof(sqlite3BuiltinFunctions)sqlite3GlobalConfig.nRefInitMutex==0sqlite3TestExtInitzSql8tokenconst u8[8]const u8[8][8]unsigned char[8][8]trans(u8)*zSqlzSql[nId]tkSEMItkWStkOTHERtkCREATE'T'tkTRIGGERtkTEMPtemporary"temporary"end"end"tkENDtkEXPLAINconst u8(*)[8]unsigned char(*)[8]sqlite3RunParserParse *pEnginetokenTypelastTokenParsedmxSqlLenpParentParsesEnginezSql!=0yyParser *pParse->pNewTable==0pParse->pNewTrigger==0pParse->nVar==0pParse->pVList==0tokenType==TK_SPACE || tokenType==TK_OVER || tokenType==TK_FILTER || tokenType==TK_ILLEGAL || tokenType==TK_WINDOW || tokenType==TK_QNUMBER || tokenType==TK_COMMENTn==6n==4db->mallocFailed==0 || pParse->rc!=SQLITE_OK || startedWithOomTK_WINDOWTK_SPACETK_SEMITK_OVERTK_FILTERTK_COMMENTTK_QNUMBERunrecognized token: "%T""unrecognized token: \"%T\""nErr==0%s in "%s""%s in \"%s\""Table **Trigger *VList *nErr==0 || pParse->rc!=SQLITE_OKu8 startedWithOom = db->mallocFailedsqlite3GetTokenz[0]==' 'z[0]=='\t'z[0]=='\n'z[0]=='\f'z[0]=='\r'delim=='`'delim=='\''delim=='"'z[0]=='0'z[0]=='1'z[0]=='2'z[0]=='3'z[0]=='4'z[0]=='5'z[0]=='6'z[0]=='7'z[0]=='8'z[0]=='9'z[0]=='.'z[2]z[0]=='$'z[0]=='@'z[0]==':'z[0]=='#'z[0]=='x'z[0]=='X'CC_SPACECC_MINUSTK_PTRTK_MINUSCC_LPTK_LPCC_RPTK_RPCC_SEMICC_PLUSTK_PLUSCC_STARTK_STARCC_SLASHTK_SLASHCC_PERCENTTK_REMCC_EQTK_EQCC_LTTK_LETK_NETK_LSHIFTTK_LTCC_GTTK_GETK_RSHIFTTK_GTCC_BANGTK_ILLEGALCC_PIPETK_BITORTK_CONCATCC_COMMATK_COMMACC_ANDTK_BITANDCC_TILDATK_BITNOTCC_QUOTETK_STRINGTK_IDCC_DOTTK_DOTCC_DIGITTK_INTEGERSQLITE_DIGIT_SEPARATORTK_FLOATCC_QUOTE2CC_VARNUMTK_VARIABLECC_DOLLARCC_VARALPHACC_KYWD0CC_KYWDCC_XTK_BLOBCC_IDCC_BOMCC_NULanalyzeFilterKeywordanalyzeOverKeywordanalyzeWindowKeywordTK_ASgetTokenTK_JOIN_KWsqlite3IsIdCharSQLITE_N_KEYWORDconst char[666]char[666]666const unsigned short[148]unsigned short[148]const unsigned char[148]unsigned char[148]sqlite3KeywordCode TK_IDkeywordCodezKWz[n-1]const unsigned char[274]unsigned char[274]i==1i==2i==3i==4i==5i==6i==8i==9i==10i==11i==12i==13i==14i==15i==16i==17i==18i==19i==20i==21i==22i==23i==24i==25i==26i==27i==28i==29i==30i==31i==32i==33i==34i==35i==36i==37i==38i==39i==40i==41i==42i==43i==44i==45i==46i==47i==48i==49i==50i==51i==52i==53i==54i==55i==56i==57i==58i==59i==60i==61i==62i==63i==64i==65i==66i==67i==68i==69i==70i==71i==72i==73i==74i==75i==76i==77i==78i==79i==80i==81i==82i==83i==84i==85i==86i==87i==88i==89i==90i==91i==92i==93i==94i==95i==96i==97i==98i==99i==100i==101i==102i==103i==104i==105i==106i==107i==108i==109i==110i==111i==112i==113i==114i==115i==116i==117i==118i==119i==120i==121i==122i==123i==124i==125i==126i==127i==128i==129i==130i==131i==132i==133i==134i==135i==136i==137i==138i==139i==140i==141i==142i==143i==144i==145i==146i==147-33~0x20xSFuncnOpsxProgressxBusytripCodeforceZombielastTokenpzNamepnNamepTypeconst unsigned char[127]unsigned char[127]sqlite3ParserFallbackiToken<(int)(sizeof(yyFallback)/sizeof(yyFallback[0]))const unsigned short[187]unsigned short[187]sqlite3ParseryyminorunionyyactyypParseryypParser->yytos!=0yyStackEntry *yypParser->yytos>=yypParser->yystackyyact==yypParser->yytos->statenoyyact == YY_ERROR_ACTION1257YY_MIN_REDUCEyyrulenoconst signed charconst signed char[409]signed char[409]const signed char *1253YY_MAX_SHIFTREDUCE1255YY_ACCEPT_ACTIONYYMINORTYPE *union <unnamed> *yy_acceptyypParser->yytos==yypParser->yystackyy_syntax_erroryymajorincomplete input"incomplete input"yy_reduceyygotoyymspyysizeyyruleno==6yyruleno==7yyruleno==324yyruleno==9yyruleno==18yyruleno==47yyruleno==62yyruleno==72yyruleno==81yyruleno==100yyruleno==246yyruleno==65yyruleno==106yyLookahead!=YYNOCODEyyruleno==67pParse->isCreatep->op==TK_TRUEFALSE && sqlite3ExprTruthValue(p)yyruleno==76yyruleno==173yyruleno==80yyruleno==219yyruleno==222yyruleno==247yyruleno==75yyruleno==174yyruleno==91yyruleno==97yyruleno==134yyruleno==144yyruleno==234yyruleno==237yyruleno==242yyruleno==117yyruleno==258yyruleno==259yyruleno==110yymsp[-1].minor.yy563 && yymsp[-1].minor.yy563->nSrc>0yymsp[-3].minor.yy563!=0pOld->fg.fixedSchema==0pNew->u4.pSubq!=0 && pNew->u4.pSubq->pSelect!=0yyruleno==131yyruleno==145yyruleno==143yyruleno==148yyruleno==153yyruleno==155yyruleno==232yyruleno==233yyruleno==252yyruleno==154yyruleno==156yyruleno==231yyruleno==251yyruleno==184yymsp[0].minor.yy0.z[1]t.n>=2pList->nExpryyruleno==199yyruleno==200yyruleno==201yyruleno==202yyruleno==203yyruleno==204yyruleno==215TK_UPLUS>TK_PLUSTK_UMINUS == TK_MINUS + (TK_UPLUS - TK_PLUS)yyruleno==221yyruleno==243yyruleno==282yyruleno==266yyruleno==287yyruleno==288yymsp[-2].minor.yy319!=0yymsp[-1].minor.yy319!=0yyruleno==303yyruleno==304yyruleno==306yymsp[0].minor.yy483!=0yymsp[-1].minor.yy483yyruleno==327yyruleno==328yyruleno==330yyruleno==334yymsp[-3].minor.yy483!=0yyruleno==344yyruleno==345yyruleno!=346yyruleno==347yyruleno==348yyruleno!=349yyruleno==350yyruleno==351yyruleno==352yyruleno==353yyruleno==354yyruleno==355yyruleno!=356yyruleno==357yyruleno==358yyruleno==359yyruleno==360yyruleno==361yyruleno==362yyruleno!=363yyruleno!=364yyruleno==365yyruleno==366yyruleno==367yyruleno==368yyruleno==369yyruleno==370yyruleno==371yyruleno!=372yyruleno==373yyruleno!=374yyruleno!=375yyruleno!=376yyruleno==377yyruleno==378yyruleno==379yyruleno!=380yyruleno==381yyruleno!=382yyruleno==383yyruleno==384yyruleno==385yyruleno!=386yyruleno!=387yyruleno==388yyruleno==389yyruleno==390yyruleno==391yyruleno==392yyruleno==393yyruleno==394yyruleno==395yyruleno==396yyruleno==397yyruleno==398yyruleno==399yyruleno==400yyruleno==401yyruleno==402yyruleno==403yyruleno==404yyruleno==405yyruleno==406yyruleno!=407yyruleno!=408yylhsminorTK_DEFERRED324SAVEPOINT_BEGINSAVEPOINT_RELEASESAVEPOINT_ROLLBACK246Select *TF_WithoutRowidTF_NoVisibleRowid640unknown table option: %.*s"unknown table option: %.*s"strict"strict"TF_StrictExpr *TK_UMINUSExprList *SrcList *SQLITE_IDXTYPE_UNIQUEOE_None2570x01010x0000000x0000ff652800x00ff00OE_SetNullOE_SetDfltOE_CascadeOE_Restrict222247OE_DefaultOE_IgnoreOE_ReplaceSRT_OutputDBFLAG_EncodingFixedSelectDest *With *OnOrUsing *SF_MultiValue4294966271~SF_MultiValueTK_ALLWindow *SF_ValuesSF_DistinctSF_All234237242const Tokenconst Token *TK_ASTERISKpDot258259SrcItem[1]SrcItem *IdList *Subquery *SF_NestedFrompSubqueryJT_INNERSQLITE_SO_ASCSQLITE_SO_DESCSQLITE_SO_UNDEFINED233231251TK_LIMITset list"set list"pFromClauseasUpsert *-11temp1temp2temp3temp4TK_REGISTERconst Parseconst Parse *TK_CASTTK_VECTORExprList_item[1]ExprList_item *41948164194824EP_PropagatebNotTK_NOTEP_InfixFuncTK_NOTNULLTK_ISTK_ISNULLTK_ISNOT215TK_UPLUS(TK_UPLUS-TK_PLUS)221220TK_BETWEEN223pRHSTK_SELECTTK_INnExprpSelectRHSTK_EXISTSTK_CASE229230235236238243-10SQLITE_IDXTYPE_APPDEFIndex *282OE_Abort241244245249253260TriggerStep *263TK_INSTEADTK_BEFORE265TK_UPDATE268287269288271272qualified table names are not allowed on INSERT, UPDATE, and DELETE statements within triggers"qualified table names are not allowed on INSERT, UPDATE, and DELETE "
        "statements within triggers"273the INDEXED BY clause is not allowed on UPDATE or DELETE statements within triggers"the INDEXED BY clause is not allowed on UPDATE or DELETE statements "
        "within triggers"274the NOT INDEXED clause is not allowed on UPDATE or DELETE statements within triggers"the NOT INDEXED clause is not allowed on UPDATE or DELETE statements "
        "within triggers"275276277278279TK_RAISE281OE_Rollback283OE_Fail284285286289290291292293294295297298299300301302303306307M10d_Any308M10d_Yes309M10d_No310Cte *311312313314315316317318319321TK_UNBOUNDEDTK_CURRENT322323325327326330329331332333334335337338339sizeof(Window)340341342343yyruleno<sizeof(yyRuleInfoLhs)/sizeof(yyRuleInfoLhs[0])const unsigned short[409]unsigned short[409]!(yyact>YY_MAX_SHIFT && yyact<=YY_MAX_SHIFTREDUCE)yyact!=YY_ERROR_ACTION"... then shift"yy_shiftyytosyytos <= yypParser->yystackEnd582YY_MAX_SHIFT845YY_MIN_SHIFTREDUCE412yyNewState"Shift"yyStackOverflowyy_find_reduce_actionstateno<=YY_REDUCE_COUNTconst shortconst short[413]short[413]const short *short *iLookAhead!=YYNOCODEi>=0 && i<YY_ACTTAB_COUNTyy_lookahead[i]==iLookAheadconst unsigned short[2207]unsigned short[2207]yy_find_shift_actionstateno <= YY_SHIFT_COUNTi<=YY_ACTTAB_COUNTi+YYNTOKEN<=(int)YY_NLOOKAHEADiLookAhead < YYNTOKENi<(int)YY_NLOOKAHEADiLookAhead<sizeof(yyFallback)/sizeof(yyFallback[0])yyFallback[iFallback]==0j<(int)(sizeof(yy_lookahead)/sizeof(yy_lookahead[0]))i>=0 && i<(int)(sizeof(yy_action)/sizeof(yy_action[0]))const unsigned short[583]unsigned short[583]const unsigned short[2394]unsigned short[2394]iFallbackYYWILDCARDsqlite3ParserFinalizepParserYY_MIN_DSTRCTRyyStackEntry[100]YYSTACKDEPTHyy_pop_parser_stackpParser->yytos!=0pParser->yytos > pParser->yystackyy_destructorsqlite3ParserInityypyyminoryyLookaheadyyLookaheadTokenyyMajoryyMinorstatenoiLookAheadyypminoryypRawParseryyGrowStackoldSizesizeof(pNew[0])parserAddExprIdListTermsyntax error after column name "%.*s""syntax error after column name \"%.*s\""binaryToUnaryIfNullTK_NULLtokenExprsizeof(Expr)p->u.zToken[0]EP_LeafAggInfo *sizeof(p->x)sizeof(p->y)parserStackReallocattachWithToSelectparserDoubleLinkSelectpLoopmxSelectSF_Compound%s clause should come after %s not before"%s clause should come after %s not before"ORDER BY"ORDER BY"LIMIT"LIMIT"(SF_MultiValue|SF_Values)too many terms in compound SELECT"too many terms in compound SELECT"disableLookasidesizeof(pParse->u1.cr)parserSyntaxErrornear "%T": syntax error"near \"%T\": syntax error"sqlite3WindowCodeStepWhereInfo *pMWinpOrderBycsrWritecsrInputiInputaddrNeaddrGosubFlushaddrIntegeraddrEmptyregNewregRecordregNewPeerregPeerregFlushPartlblWhereEndregStartregEndpMWin->eStart==TK_PRECEDING || pMWin->eStart==TK_CURRENT || pMWin->eStart==TK_FOLLOWING || pMWin->eStart==TK_UNBOUNDEDpMWin->eEnd==TK_FOLLOWING || pMWin->eEnd==TK_CURRENT || pMWin->eEnd==TK_UNBOUNDED || pMWin->eEnd==TK_PRECEDINGpMWin->eExclude==0 || pMWin->eExclude==TK_CURRENT || pMWin->eExclude==TK_GROUP || pMWin->eExclude==TK_TIES || pMWin->eExclude==TK_NOWindowCodeArg *sizeof(WindowCodeArg)TK_FOLLOWINGTK_RANGEWINDOW_RETURN_ROWTK_PRECEDINGWINDOW_AGGSTEPWINDOW_AGGINVERSETK_ROWSnPeerOP_ColumnOP_MakeRecord(v, "call flush_partition")addrpPartnPartregNewPartKeyInfo *pKeyInfoOP_CompareP4_KEYINFOOP_JumpOP_Gosubcall flush_partitionOP_CopyOP_NewRowidOP_InsertOP_Neop==OP_Geop==OP_LeOP_GeOP_LeaddrGeOP_RewindOP_ResetSorterOP_GotopMWin->eEnd==TK_FOLLOWINGOP_SubtractlbladdrNextbRPSOP_IfPosOP_IntegeraddrStartaddrBreak1addrBreak2addrBreak3addrBreakOP_ReturnwindowExprGtZeroconst Exprconst Expr *SQLITE_AFF_NUMERICsqlite3WindowListDuppWinWindow **sqlite3WindowDupconst ExprListconst ExprList *windowCodeOpregaddrContinuebPeerlblDoneaddrNextRangeregCountdown==0 && jumpOnEof==0op==WINDOW_AGGINVERSE || op==WINDOW_AGGSTEPOP_GtpMWin->eStart==TK_PRECEDING || pMWin->eStart==TK_FOLLOWINGregRowid1regRowid2OP_RowidpMWin->regEndRowidop==WINDOW_AGGSTEPOP_AddImmOP_DeleteOPFLAG_SAVEPOSITIONOP_NextnRegregTmpwindowCodeRangeTestreg1reg2regStringarith OP_AddaddrDoneop==OP_Ge || op==OP_Gt || op==OP_LepOrderBy && pOrderBy->nExpr==1KEYINFO_ORDER_DESCOP_Ltop==OP_LtKEYINFO_ORDER_BIGNULLOP_NotNullOP_IsNullOP_String8P4_STATICOP_AddP4_COLLSEQSQLITE_NULLEQop==OP_Ge || op==OP_Gt || op==OP_Lt || op==OP_Le(v, "CodeRangeTest: if( R%d %s R%d %s R%d ) goto lbl", reg1, (arith==OP_Add ? "+" : "-"), regVal, ((op==OP_Ge) ? ">=" : (op==OP_Le) ? "<=" : (op==OP_Gt) ? ">" : "<"), reg2 )op==OP_Gt(v, "CodeRangeTest: end")windowIfNewPeerwindowCacheFrameconst char[10]const char[12]const char[4]windowInitAccumregArgpWin->regAccumwindowArgCount(pWin)pWin->eStart!=TK_UNBOUNDEDOP_NullSQLITE_FUNC_MINMAXwindowReturnOneRowExprUseXList(pWin->pOwner)tmpRegOP_SeekRowidiEphtmpReg2windowFullScanregCRowidregCPeerregRowidlblNextlblBrkpMWin!=0OP_SeekGEOP_EqTK_NOaddrEqTK_TIES(v, "windowFullScan begin")(v, "windowFullScan end")windowAggFinalpMWin->regStartRowid==0OP_LastOP_AggFinalP4_FUNCDEFOP_AggValuewindowAggStepbInverse==0 || pWin->eStart!=TK_UNBOUNDEDpWin==pMWin || sqlite3WindowCompare(pParse,pWin,pMWin,0)!=1pWin->bExprArgs || !nArg ||nArg==pWin->pOwner->x.pList->nExprpWin->bExprArgs || nArg ||pWin->pOwner->x.pList==0pWin->pFilter==0pFunc->zName==nth_valueName || pFunc->zName==first_valueNamebInverse==0 || bInverse==1nArg>0addrIfOP_IfNotaddrIsNullOP_SCopyOP_IdxInsertVdbeOp *SQLITE_FUNC_NEEDCOLLOP_CollSeqOP_AggInverseOP_AggStepwindowReadPeerValuesiColOffwindowArgCountwindowCheckValueazErrregZeroeCond>=0 && eCond<ArraySize(azErr)eCond==3 || eCond==4eCond==3eCond==4eCond==0 || eCond==1 || eCond==2eCond==0eCond==1eCond==2WINDOW_STARTING_NUMSQLITE_JUMPIFNULLOP_MustBeIntint[5]OP_Haltframe starting offset must be a non-negative integer"frame starting offset must be a non-negative integer"frame ending offset must be a non-negative integer"frame ending offset must be a non-negative integer"second argument to nth_value must be a positive integer"second argument to nth_value must be a positive integer"frame starting offset must be a non-negative number"frame starting offset must be a non-negative number"frame ending offset must be a non-negative number"frame ending offset must be a non-negative number"sqlite3WindowCodeInitnEphExprpSelect->pSrc->a[0].fg.isSubqueryOP_OpenEphemeralOP_OpenDuppKeyInfo->aSortFlags[0]==0sqlite3WindowCompareconst Windowconst Window *p1==0p2==0sqlite3WindowLinkSF_MultiPartsqlite3WindowAttachp->op==TK_FUNCTIONExprIsFullSize(p)EP_WinFunc|EP_FullSize0x1000000|0x02000016908288EP_DistinctDISTINCT is not supported for window functions"DISTINCT is not supported for window functions"sqlite3WindowChainpWin->pOrderBy==0pExistPARTITION clause"PARTITION clause"ORDER BY clause"ORDER BY clause"frame specification"frame specification"cannot override %s of window: %s"cannot override %s of window: %s"sqlite3WindowAssemblesqlite3WindowAllocbImplicitFrameeType==0 || eType==TK_RANGE || eType==TK_ROWS || eType==TK_GROUPSeStart==TK_CURRENT || eStart==TK_PRECEDING || eStart==TK_UNBOUNDED || eStart==TK_FOLLOWINGeEnd==TK_CURRENT || eEnd==TK_FOLLOWING || eEnd==TK_UNBOUNDED || eEnd==TK_PRECEDING(eStart==TK_PRECEDING || eStart==TK_FOLLOWING)==(pStart!=0)(eEnd==TK_FOLLOWING || eEnd==TK_PRECEDING)==(pEnd!=0)unsupported frame specification"unsupported frame specification"pParse->dbSQLITE_WindowFuncwindowAllocErrsqlite3WindowOffsetExprsqlite3WindowListDeletesqlite3WindowDeletesqlite3WindowUnlinkFromSelectsqlite3WindowRewrite(p->selFlags & SF_WinRewrite)==0(p->selFlags & 0x0100000)==0!IN_RENAME_OBJECT!(pParse->eParseMode>=2)pWin->pWFunc!=0("New window-function subquery in FROM clause of (%u/%p)\n", p->selId, p)pSub!=0 || p->pSrc==0pWherepGroupBypHavingpSortpSublistselFlagssizeof(Table)Walker *SF_Aggregate4294967287~SF_AggregateSF_WinRewriteExprList **pArgs"0"pTab2SF_ExpandedSF_OrderByReqd134217792SQLITE_AFF_NONETF_Ephemeralsizeof(w)rc==SQLITE_OK || pParse->nErr!=0disallowAggregatesInOrderByCb!ExprHasProperty(pExpr, EP_IntValue)TK_AGG_FUNCTIONmisuse of aggregate: %s()"misuse of aggregate: %s()"WRC_Continuesqlite3WindowExtraAggFuncDepthexprListAppendListpDupiDummyEP_IntValueEP_IsTrue268437504EP_IsFalse805308416(EP_IntValue|EP_IsTrue|EP_IsFalse)3489658879~(EP_IntValue|EP_IsTrue|EP_IsFalse)selectWindowRewriteEListsWalkersRewritepWin!=0sizeof(Walker)WindowRewrite *sizeof(WindowRewrite)selectWindowRewriteSelectCbWRC_PruneselectWindowRewriteExprCbp->pWin!=0TK_COLUMNnSrcEP_WinFunc0x1000000pWin->pOwner==pExprExprHasProperty(pExpr, EP_Static)==0EP_Static0x8000000TK_FUNCTIONTK_IF_NULL_ROWWRC_AbortEP_Collate4160749567sqlite3WindowUpdateaUpRANGE with offset PRECEDING/FOLLOWING requires one ORDER BY expression"RANGE with offset PRECEDING/FOLLOWING requires one ORDER BY expression"SQLITE_FUNC_WINDOWFILTER clause may only be used with aggregate window functions"FILTER clause may only be used with aggregate window functions"WindowUpdateWindowUpdate[]WindowUpdate[8]const char[13]TK_GROUPSconst char[6]WindowUpdate *ArraySize(aUp)windowFindno such window: %s"no such window: %s"sqlite3WindowFunctionsrow_numberdense_rankrankpercent_rankcume_distntilelast_valuenth_valuefirst_valueleadlagaWindowFuncsFuncDef[15]1080ArraySize(aWindowFuncs)8454145noopValueFuncnoopStepFunclast_valueFinalizeFuncLastValueCtx *last_valueValueFunclast_valueInvFunclast_valueStepFuncntileValueFuncNtileCtx *(nLarge*(nSize+1) + (p->nParam-nLarge)*nSize)==p->nTotalnLargeiSmallntileInvFuncntileStepFuncargument of ntile must be a positive integer"argument of ntile must be a positive integer"cume_distValueFuncCallCount *cume_distInvFuncnArg==0cume_distStepFuncpercent_rankValueFuncpercent_rankInvFuncpercent_rankStepFuncrankValueFuncrankStepFuncfirst_valueFinalizeFuncNthValueCtx *first_valueStepFuncnth_valueFinalizeFuncnth_valueStepFuncfValdense_rankValueFuncdense_rankStepFuncrow_numberValueFuncrow_numberStepFuncsqlite3WhereEndWhereLevel *pLevelWhereLoop *pTabListnRJop==OP_SeekLTop==OP_SeekGTpLevel->op==OP_NextpLevel->op==OP_PrevpLevel->op==OP_VNextsqlite3VdbeGetOp(v, pIn->addrInTop+1)->opcode==OP_IsNull || pParse->db->mallocFailedpIn->eEndLoopOp==OP_PrevpIn->eEndLoopOp==OP_Next(v, "next skip-scan on %s", pLoop->u.btree.pIndex->zName)(ws & WHERE_IDX_ONLY)==0 || (ws & WHERE_INDEXED)!=0pLevel->iTabCur==pSrc->iCursorpSrc->fg.isSubquerypSrc->pSTab!=0(v, "End WHERE-loop%d: %s", i, pWInfo->pTabList->a[pLevel->iFrom].pSTab->zName)WhereLevel[1]WhereRightJoin *pRJOP_NoopaddrSeekWHERE_DISTINCT_ORDEREDWHERE_INDEXEDLogEst *signed short *r1OP_PrevOP_SeekLTOP_SeekGTOP_DecrJumpZeroWHERE_IN_ABLEInLoop *bEarlyOutWHERE_VIRTUALTABLEWHERE_IN_EARLYOUTOP_IfNotOpenOP_IfNoHopenext skip-scan on %swsWHERE_IDX_ONLYOP_NullRowWHERE_MULTI_ORpIxOP_ReopenIdxpWInfo->nLevel<=pTabList->nSrcpParse->db->mallocFailedpTabItem->fg.isSubquerypTabItem->u4.pSubq->regResult>=0pIdx->pTablepOp<=pLastOppIdx->pTable==pTabx>=0x!=sqlite3StorageColumnToTable(pTab,x)lastpLastOppTabItem576(WHERE_INDEXED|WHERE_IDX_ONLY)ONEPASS_OFFIndexedExpr *OP_OffsetpPki16 *WHERE_EXPRIDX67108928(WHERE_IDX_ONLY|WHERE_EXPRIDX)internal query planner error"internal query planner error"4227858431~WHERE_EXPRIDXOP_IdxRowidOP_IfNullRow(v, "End WHERE-core")sqlite3WhereBeginnByteWInfonTabListpWInfonotReadysWLBWhereMaskSet *pMaskSetbFordelete(wctrlFlags & WHERE_ONEPASS_MULTIROW)==0 || ( (wctrlFlags & WHERE_ONEPASS_DESIRED)!=0 && (wctrlFlags & WHERE_OR_SUBCLAUSE)==0 )(wctrlFlags & WHERE_OR_SUBCLAUSE)==0 || (wctrlFlags & WHERE_USE_LIMIT)==0WhereLoopBuilder *sizeof(sWLB)BMSWHERE_WANT_DISTINCT~WHERE_WANT_DISTINCTWHERE_KEEP_ALL_JOINSat most %d tables in a join"at most %d tables in a join"WHERE_OR_SUBCLAUSEsizeof(WhereInfo)ROUND8P(sizeof(WhereInfo))nByteWInfo + (nTabList-1)*sizeof(WhereLevel)sizeof(WhereLoop)WhereInfosWCnOBSati8 *offsetof(WhereInfo,sWC)offsetof(WhereInfo,nOBSat)offsetof(WhereInfo,sWC) - offsetof(WhereInfo,nOBSat)sizeof(WhereLevel)pWInfo->eOnePass==ONEPASS_OFFint[64]-99WhereClause *EIGHT_BYTE_ALIGNMENT(sWLB.pNew)TK_ANDSQLITE_DistinctOptpWInfo->pSelect(pParse, 0, "SCAN CONSTANT ROW")WHERE_DISTINCT_UNIQUESCAN CONSTANT ROWpX!=0pT->prereqAll!=0 || !ExprHasProperty(pX, EP_OuterON)EP_InnerON0x000002WhereTerm *TERM_VIRTUALJT_LTORJTERM_CODEDWHERE_DISTINCTBYsWLB.pWC("nRowOut reduced from %d to %d due to DISTINCT\n", pWInfo->nRowOut, pWInfo->nRowOut-30)pWInfo->pTabList!=0db->mallocFailed==0(Bitmask)0~(Bitmask)0SQLITE_OmitNoopJoinnTabList>0WHERE_AGG_DISTINCT9216(WHERE_AGG_DISTINCT|WHERE_KEEP_ALL_JOINS)SQLITE_BloomFilterconst WhereInfoconst WhereInfo *(wctrlFlags & WHERE_ONEPASS_DESIRED)==0 || pWInfo->nLevel==1!(wsFlags&WHERE_VIRTUALTABLE) || IsVirtual(pTabList->a[0].pSTab)pTabList->a[0].pSTabSQLITE_OnePassWHERE_ONEPASS_DESIREDwsFlagsbOnerowWHERE_ONEROWWHERE_ONEPASS_MULTIROWWHERE_DUPLICATES_OKONEPASS_SINGLEONEPASS_MULTIOPFLAG_FORDELETE~WHERE_IDX_ONLYpTabItem->iCursor==pLevel->iTabCurpWInfo->eOnePass==ONEPASS_OFF && pTab->nCol==BMS-1pWInfo->eOnePass==ONEPASS_OFF && pTab->nCol==BMSn<=pTab->nColiAuxArg!=0 || (pWInfo->wctrlFlags & WHERE_ONEPASS_DESIRED)==0wctrlFlags & WHERE_ONEPASS_DESIREDpJSQLITE_IndexedExprpIx!=0pIx->pSchema==pTab->pSchemaiIndexCur>=0(v, "%s", pIx->zName)pTab==pTabItem->pSTabVTable *OP_VOpenP4_VTABJT_RIGHT(JT_LTORJ|JT_RIGHT) OP_OpenReadOP_OpenWriteTF_HasGenerated(TF_HasGenerated|TF_WithoutRowid)WHERE_AUTO_INDEXWHERE_BLOOMFILTER4210688(WHERE_AUTO_INDEX|WHERE_BLOOMFILTER)P4_INT32iIndexCurBitmask *WHERE_CONSTRAINTWHERE_COLUMN_RANGEWHERE_SKIPSCAN32770(WHERE_COLUMN_RANGE|WHERE_SKIPSCAN)WHERE_BIGNULL_SORTWHERE_IN_SEEKSCANWHERE_ORDERBY_MINOPFLAG_SEEKEQsizeof(WhereRightJoin)OP_BlobCollSeq *[1]CollSeq **WHERE_DISTINCT_UNORDERED(v, "materialize %!S", pSrc)pTabList == pWInfo->pTabListaddrExplainpSubqiOnceOP_Oncematerialize %!Sconst BitmaskwhereBeginErrorpOrderBy && pOrderBy->nExpr==BMS-1pTabList->nSrc==BMS(v, "Begin WHERE-core")whereReverseScanOrderpItem->fg.isSubquery==0pItemCteUse *whereAddIndexedExprpIdx->bHasExprXN_EXPRCOLFLAG_VIRTUALsizeof(IndexedExpr)JT_LEFT(JT_LEFT|JT_LTORJ|JT_RIGHT)IndexedExpr **whereCheckIfBloomFilterIsUsefulnSearchpWInfo->nLevel>=2OptimizationEnabled(pWInfo->pParse->db, SQLITE_BloomFilter)(pLoop->wsFlags & (WHERE_IPK|WHERE_INDEXED))!=0(pLoop->wsFlags & (0x00000100|0x00000200))!=0pItem->fg.jointype & JT_LEFT( "-> use Bloom-filter on loop %c because there are ~%.1e " "lookups into %s which has only ~%.1e rows\n", pLoop->cId, (double)sqlite3LogEstToInt(nSearch), pTab->zName, (double)sqlite3LogEstToInt(pTab->nRowLogEst))const WhereLevelconst WhereLevel *reqFlagsWHERE_SELFCULLWHERE_COLUMN_EQ(WHERE_SELFCULL|WHERE_COLUMN_EQ)TF_HasStat1TF_MaybeReanalyzewhereOmitNoopJointabUsedhasRightJoinOptimizationEnabled(pWInfo->pParse->db, SQLITE_OmitNoopJoin)pWInfo->pResultSet!=00==(pWInfo->wctrlFlags & WHERE_AGG_DISTINCT)pTerm->pExprEP_OuterON0x000001pTerm->pExpr->w.iJoin==pItem->iCursor("-> omit unused FROM-clause term %c\n",pLoop->cId)((pWInfo->revMask>>1) & ~m1)!=0pWInfo->nLevel>0(JT_LEFT|JT_RIGHT)exprIsDeterministicexprNodeIsDeterministicEP_ConstFunc0x100000whereShortCutpWCscanpWInfo->pTabList->nSrc>=1pItem->fg.isIndexedBypItem->fg.notIndexedWhereScan *WO_EQWO_ISpTerm->eOperator & WO_ISpLoop->aLTermSpace==pLoop->aLTermpLoop->aLTermSpaceWHERE_IPK4353WhereTerm **opMaskWhereTerm *[3]ArraySize(pLoop->aLTermSpace)(WO_EQ|WO_IS)40974609pWInfo->sMaskSet.n==1 && iCur==pWInfo->sMaskSet.ix[0](LogEst)1WHERE_TRANSCONSwhereInterstageHeuristicWHERE_COLUMN_NULLWHERE_COLUMN_IN(WHERE_COLUMN_EQ|WHERE_COLUMN_NULL|WHERE_COLUMN_IN)iTab16399(WHERE_CONSTRAINT|WHERE_AUTO_INDEX)ALLBITSwherePathSolvermxChoicenLoopiLoopmxImxCostmxUnsortnTonFromWherePath *aFromaTopTopWLoopWhereLoop **aSortCostnLoop<=pWInfo->pTabList->nSrcpPriorpIdTokenhasCollatesortOrderpYpWithregGosubaddrGosubpOwnerregCountdownjumpOnEofcsr1regValcsr2regOldbFinbInverseeCondbFilterpPartitionpBaseeStarteEndeExcludepWalkerpAppendbIntToNullpEListppSubpResultSetwctrlFlagsiAuxArgiIdxCurpBuildernRowEstsizeof(WherePath)sizeof(WhereLoop*)sizeof(LogEst)sizeof(aFrom[0])aSortCost==0 || &pSpace[nSpace]==(char*)&aSortCost[nOrderBy]aSortCost!=0 || &pSpace[nSpace]==(char*)pXpParse->nQueryLoop48==sqlite3LogEst(28)aFrom[0].isOrdered==010==sqlite3LogEst(2)("---- sort cost=%-3d (%d/%d) increases cost %3d to %-3d\n", aSortCost[isOrdered], (nOrderBy-isOrdered), nOrderBy, rUnsort, rCost)nTo==0jj==nTo-1pTo->rCost==rCostpTo->rCost==rCost+1rCostrUnsortisOrderedmaskNewrevMaskconst WhereLoopconst WhereLoop *no query solution"no query solution"pWInfo->nLevel==nLoopWHERE_DISTINCT_NOOPpWInfo->pSelect->pOrderBy==0 || pWInfo->nOBSat <= pWInfo->pSelect->pOrderBy->nExprwsFlags & WHERE_IPKwsFlags & WHERE_COLUMN_INpWInfo->sorted==0(WHERE_IPK|WHERE_COLUMN_IN)WHERE_ORDERBY_LIMITWHERE_ORDERBY_MAX(WHERE_ORDERBY_MIN|WHERE_ORDERBY_MAX)WHERE_SORTBYGROUPnOrder("---- begin solver.  (nRowEst=%d, nQueryLoop=%d)\n", nRowEst, pParse->nQueryLoop)whereLoopIsNoBettercomputeMxChoicepWInfo->pParse->dbSQLITE_StarQuery!pWInfo->bStarUsedmxRun<LOGEST_MAXmxRun<(32767)aFromTabsiFromIdxmSelfJoinnDepmxRunpFactTabJT_OUTERJT_CROSS(JT_OUTER|JT_CROSS)-32768LOGEST_MINwhereSortingCostrSortCostpWInfo->pSelect!=0pWInfo->pSelect->pEList!=0WHERE_USE_LIMITsqlite3WhereIsSortedpWInfo->wctrlFlags & (WHERE_GROUPBY|WHERE_DISTINCTBY)pWInfo->wctrlFlags & WHERE_SORTBYGROUPwherePathSatisfiesOrderByrevSetrevrevIdxisOrderDistinctdistinctColumnsisMatcheqOpMasknKeyColpOBExprobSatobDoneorderDistinctMaskreadypOrderBy!=0SQLITE_OrderByIdxJoinWO_ISNULL38620502051(WHERE_ORDERBY_LIMIT|WHERE_ORDERBY_MAX|WHERE_ORDERBY_MIN)WO_INpOBExpr==0wctrlFlags & (WHERE_ORDERBY_LIMIT|WHERE_ORDERBY_MIN|WHERE_ORDERBY_MAX)pColl1pTerm->pExpr->op==TK_ISSQLITE_OrderBySubqnColumn==nKeyCol+1 || !HasRowid(pIndex->pTable)pIndex->aiColumn[nColumn-1]==XN_ROWID || !HasRowid(pIndex->pTable)j>=pLoop->u.btree.nEq || (pLoop->aLTerm[j]==0)==(j<pLoop->nSkip)eOp & WO_ISNULLeOp & WO_ISeOp & WO_INeOp & 0x0001(pLoop->aLTerm[i]->eOperator & WO_IN)wctrlFlags & WHERE_GROUPBYwctrlFlags & WHERE_DISTINCTBYdistinctColumns==0isOrderDistinct!=0isOrderDistinct==0(WHERE_DISTINCTBY|WHERE_SORTBYGROUP)TK_AGG_COLUMNpColl2(WO_ISNULL|WO_IS)XN_ROWIDWHERE_GROUPBY(WHERE_GROUPBY|WHERE_DISTINCTBY)pIxExprmTermi<BMSi<((int)(sizeof(Bitmask)*8))nOrderBy==BMS-1wherePathMatchSubqueryOBiOBjSubpSubOBpSubOB!=0sfOBsfSubWHERE_COROUTINEwhereLoopAddAllmPrereqmPriorbFirstPastRJpNew->nLTerm==0pNew->wsFlags==0pNew->nLSlot>=ArraySize(pNew->aLTermSpace)pNew->aLTerm!=0SQLITE_QUERY_PLANNER_LIMITpItem->pSTabmUnusableSQLITE_QUERY_PLANNER_LIMIT_INCR(JT_OUTER|JT_CROSS|JT_LTORJ)abbreviated query algorithm search"abbreviated query algorithm search"whereLoopAddOrpWCEndtempWCsSubBuildsSumsCurWhereOrSet *sizeof(sSum)("Begin processing OR-clause %p\n", pTerm)rc==SQLITE_NOMEM && sCur.n>0rc==SQLITE_DONE("End processing OR-clause %p\n", pTerm)WO_ORWhereOrInfo *WhereClause *constpOrWCWhereTerm *constpOrWCEndpOrTermWO_ANDWhereAndInfo *sPrevWhereOrCost[3]N_OR_COSTWhereOrCost *sizeof(pNew->u)whereLoopAddVirtualbInmBestmNoOmitbRetry(mPrereq & mUnusable)==0IsVirtual(pSrc->pSTab)u16 *("  VirtualOne: all usable w/o IN\n")bIn==0mNext>0("  VirtualOne: mPrev=%04llx mNext=%04llx\n", (sqlite3_uint64)mPrev, (sqlite3_uint64)mNext)("  VirtualOne: all disabled\n")("  VirtualOne: all disabled and w/o IN\n")seenZeroseenZeroNoINmPrevmBestNoInmNextmThis("BEGIN %s.addVirtual()\n", pSrc->pSTab->zName)("  VirtualOne: all usable\n")("END %s.addVirtual(), rc=%d\n", pSrc->pSTab->zName, rc)sqlite3VtabUsesAllSchemaspParse->writeMaskHiddenIndexInfo *pHiddenpHidden->eDistinct>=0 && pHidden->eDistinct<=3pH->pParse->db167902sqlite3_value *[1]SQLITE_AFF_BLOBwhereLoopAddVirtualOnepIdxConspUsagemxTerm(mUsable & mPrereq)==mPrereqsqlite3_index_constraint **sizeof(pUsage[0])pIdxInfo->needToFreeIdxStr==09.999999999999999673e+98SQLITE_BIG_DBL(double)24.999999999999999837e+98("  ^^^^--- non-viable plan rejected!\n")pNew->nLSlot>=nConstraintsizeof(pNew->aLTerm[0])sizeof(pNew->u.vtab)iTerm==nConstraint-1j==0j==pWC->nTerm-1iTerm<pNew->nLSlotiTerm==15iTerm==16i!=iTerm(mExclude & WO_IN)==0pbRetryLimit || !isLimitTerm(pTerm)!isLimitTerm(pTerm) || i>=nConstraint-2!isLimitTerm(pTerm) || i==nConstraint-1 || isLimitTerm(pTerm+1)%s.xBestIndex malfunction"%s.xBestIndex malfunction"~SQLITE_INDEX_SCAN_UNIQUEpNew->nLTerm<=pNew->nLSlot4294963199~WHERE_ONEROW("  bIn=%d prereqIn=%04llx prereqOut=%04llx\n", *pbIn, (sqlite3_uint64)mPrereq, (sqlite3_uint64)(pNew->prereq & ~mPrereq))allConstraintsUsedisLimitTermpTerm->eOperator==WO_AUX || pTerm->eMatchOp==0whereLoopAddBtreesPkLogEst[2]signed short[2]aiRowEstPkaiColumnPkiSortIdxrSize!IsVirtual(pSrc->pSTab)pSrc->fg.isCte==0sizeof(Index)SQLITE_IDXTYPE_IPKpNew->rSetuppTab->costMult43==sqlite3LogEst(20)WHERE_RIGHT_JOIN4128(WHERE_RIGHT_JOIN|WHERE_OR_SUBCLAUSE)rLogSizeconst WhereTermconst WhereTerm *const SrcItemconst SrcItem *pNew->iTab!=pSrc->iCursor(pWInfo->wctrlFlags & WHERE_ONEPASS_DESIRED)==0 || b==0pNew->rRun("-> %s is not a covering index" " according to whereIsCoveringIndex()\n", pProbe->zName)m!=0("-> %s is a covering expression index" " according to whereIsCoveringIndex()\n", pProbe->zName)isCov==WHERE_EXPRIDX("-> %s might be a covering expression index" " according to whereIsCoveringIndex()\n", pProbe->zName)("-> %s a covering index according to bitmasks\n", pProbe->zName, m==0 ? "is" : "is not")SQLITE_CoverIdxScanTOPBITisCovnLookuppWC2SQLITE_BLDF1_INDEXEDwherePartIdxExprpItem==0 || (pItem->fg.jointype & JT_RIGHT)==0(pItem==0 || pMask==0) && (pMask!=0 || pItem!=0)affSQLITE_AFF_TEXTbNullRow(JT_LEFT|JT_LTORJ)(BMS-1)(Bitmask)1whereIndexedExprCleanupwhereIsCoveringIndexckCoveringIndexCheck *whereIsCoveringIndexWalkCallbackconst Indexconst Index *const i16const i16 *aiColumnexprIsCoveredByIndexwhereUsablePartialIndexTERM_VNULLindexMightHelpWithOrderBypOBaColExprpExpr==0whereLoopAddBtreeIndexsaved_prereqsaved_nLTermsaved_nEqsaved_nBtmsaved_nTopsaved_nSkipsaved_wsFlagssaved_nOutpToppBtmdb->mallocFailed==0 || pParse->nErr>0(pNew->wsFlags & WHERE_VIRTUALTABLE)==0(pNew->wsFlags & WHERE_TOP_LIMIT)==0pNew->u.btree.nBtm==0WHERE_BTM_LIMITWO_LTWO_LEWO_GTWO_GE447(WO_GT|WO_GE|WO_LT|WO_LE)-61~(WO_GT|WO_GE|WO_LT|WO_LE)(WO_EQ|WO_IN|WO_IS)-132~(WO_EQ|WO_IN|WO_IS)pNew->u.btree.nEq<pProbe->nColumnpNew->u.btree.nEq<pProbe->nKeyCol || pProbe->idxType!=SQLITE_IDXTYPE_PRIMARYKEYnInMul==0 || (pNew->wsFlags & WHERE_COLUMN_NULL)!=0 || (pNew->wsFlags & WHERE_COLUMN_IN)!=0 || (pNew->wsFlags & WHERE_SKIPSCAN)!=046==sqlite3LogEst(25)pExpr->x.pList && pExpr->x.pList->nExpr("IN operator (N=%d M=%d logK=%d nIn=%d rLogSize=%d x=%d) " "prefers indexed lookup\n", saved_nEq, M, logK, nIn, rLogSize, x)SQLITE_SeekScan("IN operator (N=%d M=%d logK=%d nIn=%d rLogSize=%d x=%d" " nInMul=%d) prefers skip-scan\n", saved_nEq, M, logK, nIn, rLogSize, x, nInMul)("IN operator (N=%d M=%d logK=%d nIn=%d rLogSize=%d x=%d" " nInMul=%d) prefers normal scan\n", saved_nEq, M, logK, nIn, rLogSize, x, nInMul)saved_nEq==pNew->u.btree.nEqeOp & WO_GTeOp & WO_GE(pTop-(pTerm->pWC->a))<pTerm->pWC->nTermpTop->wtFlags & TERM_LIKEOPTpTop->eOperator==WO_LTeOp & (WO_LT|WO_LE)eOp & WO_LTeOp & WO_LEpNew->nOut==saved_nOuteOp & (WO_ISNULL|WO_EQ|WO_IN|WO_IS)(eOp & WO_IN) || nIn==0pSrc->pSTab->szTabRow>0pProbe->pTable->costMultrCostIdxnOutUnadjustedTERM_LIKEOPTSQLITE_BLDF1_UNIQUElogKWHERE_UNQ_WANTEDnVecLen(WO_GT|WO_GE)WHERE_TOP_LIMIT67109184(WHERE_IDX_ONLY|WHERE_IPK|WHERE_EXPRIDX)SQLITE_IDXTYPE_PRIMARYKEY42==sqlite3LogEst(18)SQLITE_SkipScannIter("BEGIN %s.addBtreeIdx(%s), nEq=%d, nSkip=%d, rRun=%d\n", pProbe->pTable->zName,pProbe->zName, pNew->u.btree.nEq, pNew->nSkip, pNew->rRun)("END %s.addBtreeIdx(%s), nEq=%d, rc=%d\n", pProbe->pTable->zName, pProbe->zName, saved_nEq, rc)whereRangeVectorLen(pIdx->nColumn - nEq)ExprUseXList(pTerm->pExpr->pLeft)pLhs->iColumn==XN_ROWIDidxaffconst Tableconst Table *whereLoopOutputAdjustnotAllowediReduce(pLoop->wsFlags & WHERE_AUTO_INDEX)==0pTerm!=0TERM_HIGHTRUTHTERM_HEURTRUTHwhereLoopInsertppPrev("=== query planner search limit reached ===\n")ppTailpToDelwhereLoopFindLesserp->rSetup==0 || pTemplate->rSetup==0 || p->rSetup==pTemplate->rSetupp->rSetup>=pTemplate->rSetupwhereLoopAdjustCost("subset cost adjustment %d,%d to %d,%d\n", pTemplate->rRun, pTemplate->nOut, MIN(p->rRun, pTemplate->rRun), MIN(p->nOut - 1, pTemplate->nOut))p->rRunpTemplate->rRunp->nOut - 1pTemplate->nOut("subset cost adjustment %d,%d to %d,%d\n", pTemplate->rRun, pTemplate->nOut, MAX(p->rRun, pTemplate->rRun), MAX(p->nOut + 1, pTemplate->nOut))p->nOut + 1whereLoopCheaperProperSubset(pX->wsFlags & WHERE_VIRTUALTABLE)==0(pY->wsFlags & WHERE_VIRTUALTABLE)==0whereInfoFreepWInfo!=0db!=0WhereMemBlock *whereLoopDeletewhereLoopXferWhereLoopnLSlotsizeof(pTo->aLTerm[0])whereLoopResizepaNew~7sizeof(p->aLTerm[0])whereLoopClearp->aLTermSpaceArraySize(p->aLTermSpace)whereLoopClearUnion17408(WHERE_VIRTUALTABLE|WHERE_AUTO_INDEX)whereLoopInitwhereRangeScanEstpLower || pUpperpUpper==0 || (pUpper->wtFlags & TERM_VNULL)==0 || pParse->nErr>0whereRangeAdjust20==sqlite3LogEst(4)vtabBestIndexIsVirtual(pTab)freeIndexInfopIdxInfo!=0pHidden->pParse!=0pHidden->pParse->db==dbfreeIdxStrallocateIndexInfopIdxOrderByeDistinctpSrc!=0IsPowerOfTwo(pTerm->eOperator & ~WO_EQUIV)pTerm->eOperator & WO_INpTerm->eOperator & WO_ISNULLpTerm->eOperator & WO_ALL(pTerm->eOperator & (WO_OR|WO_AND))==0pTerm->u.x.leftColumn>=XN_ROWIDpTerm->u.x.leftColumn<pTab->nColTERM_OK~TERM_OKWO_EQUIV(WO_EQUIV)-2049~(WO_EQUIV)pExpr->iColumn>=XN_ROWID && pExpr->iColumn<pTab->nColpExpr->u.zToken!=0pE2->iColumn>=XN_ROWID && pE2->iColumn<pTab->nColpE2TK_COLLATEsizeof(*pIdxInfo)sizeof(*pIdxCons)sizeof(*pUsage)sizeof(*pIdxCons) + sizeof(*pUsage)(sizeof(*pIdxCons) + sizeof(*pUsage))sizeof(*pIdxOrderBy)sizeof(*pHidden)pPk!=0WO_EQ==SQLITE_INDEX_CONSTRAINT_EQWO_LT==SQLITE_INDEX_CONSTRAINT_LTWO_LE==SQLITE_INDEX_CONSTRAINT_LEWO_GT==SQLITE_INDEX_CONSTRAINT_GTWO_GE==SQLITE_INDEX_CONSTRAINT_GEpTerm->eOperator&(WO_IN|WO_EQ|WO_LT|WO_LE|WO_GT|WO_GE|WO_AUX)j!=inLastWO_ALLTERM_SLICEWO_AUX(WO_LT|WO_LE|WO_GT|WO_GE)j==nTermpExpr->op==TK_COLUMN || (pExpr->op==TK_COLLATE && pExpr->pLeft->op==TK_COLUMN && pExpr->iColumn==pExpr->pLeft->iColumn)termFromWhereClausesqlite3ConstructBloomFilteraddrOnceaddrTopaddrContsaved_pIdxEprsaved_pIdxPartExprpLoop!=0v!=0pLoop->wsFlags & WHERE_BLOOMFILTER(pLoop->wsFlags & WHERE_IDX_ONLY)==0pItem!=0pIdx->pTable==pItem->pSTabSQLITE_BloomPulldownpLoop==0const SrcListconst SrcList *iSrcOP_FilterAdd4290772991~WHERE_BLOOMFILTER4194308(WHERE_BLOOMFILTER|WHERE_COLUMN_IN)constructAutomaticIndexaddrInitmxBitColidxColsextraColssentWarninguseBloomFilterpPartialiContinueaddrCounterregBaseBMS-1((int)(sizeof(Bitmask)*8))-1iCol==BMSiCol==BMS-1cMaskMASKBIT(BMS-1)automatic index on %s(%s)"automatic index on %s(%s)"nKeyCol>0 || pParse->db->mallocFailed57716961pTable->nColauto-index"auto-index"pColl!=0 || pParse->nErr>0pX->pLeft!=0(u32)n==pLoop->u.btree.nEqn==nKeyColpLevel->iIdxCur>=0OP_OpenAutoindex(v, "for %s", pTable->zName)for %spSrc == &pWC->pWInfo->pTabList->a[pLevel->iFrom]pSubq!=0(v, "next row of %s", pSrc->pSTab->zName)regYieldOP_InitCoroutineOP_Yieldnext row of %sWHERE_PARTIALIDXOPFLAG_USESEEKRESULTpSrc->fg.isSubquery && pSrc->u4.pSubq!=0pLevel->iIdxCur>0end_auto_index_createpTable->nCol==BMS-1pTable->nCol==BMS-2pPartial!=0&addrExpaddrExpsqlite3VdbeCurrentAddr(v)termCanDriveIndexleftCol(pSrc->fg.jointype & JT_RIGHT)==0columnIsGoodIndexCandidateconstraintCompatibleWithOuterJoin(pSrc->fg.jointype&(JT_LEFT|JT_LTORJ|JT_RIGHT))!=0EP_OuterON|EP_InnerON0x000001|0x000002ExprHasProperty(pTerm->pExpr, EP_InnerON)(((pTerm->pExpr)->flags&(0x000002))!=0)(pSrc->fg.jointype & (JT_LEFT|JT_LTORJ|JT_RIGHT))==JT_LEFT(pSrc->fg.jointype & (JT_LEFT|JT_LTORJ|JT_RIGHT))==JT_LTORJExprHasProperty(pTerm->pExpr, EP_OuterON)translateColumnToCopyOP_SequenceestLogisDistinctRedundantindexColumnNotNullpIdx!=0iCol>=0 && iCol<pIdx->nColumnj==(-2)findIndexColsqlite3WhereFindTermp->eOperator & WO_ISwhereScanIniti16[11]signed short[11]whereScanInitIndexExprwhereScanNextpScan->iEquiv<=pScan->nEquivpWC!=0iCur>=0(pTerm->eOperator & (WO_OR|WO_AND))==0 || pTerm->leftCursor<0pScan->aiCurpX->pLeftArraySize(pScan->aiCur)zCollNamepCandidatepBaselinenSortedpPathpRevMaskpOBSatmUsablemExcludepbInpbRetryLimitaUsagenConspMaskpObjectiTabCurpWalkjointypeiCursornInMulpTemplatepLowerpUpperpmNoOmitiRegisteriAutoidxCurpDistinctindexInAffinityOkinexprExprUseXSelect(pX)whereRightSubexprIsColumnEP_FixedCol0x000020createMaskpMaskSet->n < ArraySize(pMaskSet->ix)sqlite3WhereReallocpOldBlk->sz<nBytepOldBlksqlite3WhereMallocsizeof(*pBlock)sqlite3WhereGetMaskpMaskSet->n<=(int)sizeof(Bitmask)*8pMaskSet->n>0 || pMaskSet->ix[0]<0iCursor>=-1whereOrInsertwhereOrInsert_donewhereOrMovesizeof(pDest->a[0])sqlite3WhereUsesDeferredSeeksqlite3WhereOkOnePasssizeof(int)*2sqlite3WhereBreakLabelsqlite3WhereContinueLabelpWInfo->iContinue!=0sqlite3WhereMinMaxOptEarlyOutpInnersqlite3WhereOrderByLimitOptLabelpInner->addrNxt!=0sqlite3WhereIsOrderedsqlite3WhereIsDistinctsqlite3WhereOutputRowCountsqlite3WhereTabFuncArgspColRefExprUseYTab(pColRef)pItem->fg.jointype & JT_RIGHTpItem->fg.jointype & JT_LTORJjoinTypeCOLFLAG_HIDDENtoo many arguments on %s() - max %d"too many arguments on %s() - max %d"TERM_DYNAMICsqlite3WhereExprAnalyzesqlite3WhereExprListUsagesqlite3WhereExprUsagesqlite3WhereExprUsageNNEP_TokenOnly|EP_Leaf0x010000|0x800000p->op!=TK_IF_NULL_ROW8454144sqlite3WhereExprUsageFullp->x.pList==0EP_VarSelect0x000040p->y.pWin!=0sqlite3WhereClauseClearpWC->nTerm>=pWC->nBasea->eMatchOp==0 || a->eOperator==WO_AUX(a->wtFlags & TERM_ANDINFO)==0(a->wtFlags & TERM_ANDINFO)!=0aLastTERM_ORINFOTERM_ANDINFO(TERM_ORINFO|TERM_ANDINFO)sqlite3WhereClauseInitpWC->aStaticWhereTerm[8]ArraySize(pWC->aStatic)sqlite3WhereAddLimitp!=0 && p->pLimit!=0p->pSrc->a[0].pSTabpWC->a[ii].wtFlags & TERM_VIRTUALpWC->a[ii].eOperator==WO_ROWVALp->pLimit->op==TK_LIMIT(SF_Distinct|SF_Aggregate)whereAddLimitExpr0x000800TK_MATCHsqlite3WhereSplitpE2!=0 || pExpr==0exprAnalyzeprereqLeftprereqAllextraRightpStr1isCompleteeOp2pWC->nTerm > idxTermpExpr!=0pExpr->op!=TK_AS && pExpr->op!=TK_COLLATEpExpr->pRight==0EP_xIsSelect|EP_IfNullRow0x001000|0x040000266240TERM_VARSELECTpSrc->nSrc>0ON clause references tables to its right"ON clause references tables to its right"op==TK_INpLeft->op==TK_VECTORExprUseXList(pLeft)pTerm->u.x.iField==0(prereqLeft | extraRight) != prereqLeftExprUseXList(pExpr)pList!=0pList->nExpr==2idxNew==0pWC->op==TK_ANDpStr1==0 || !ExprHasProperty(pStr1, EP_IntValue)pStr2==0 || !ExprHasProperty(pStr2, EP_IntValue)*pC!=0xFFidxNew1==0idxNew2==0aiCurColTERM_ISeExtraOpidxNewTERM_COPIEDTK_TRUEFALSEopspNewExprTK_ORpNewTermExpr **pStr2pNewExpr1pNewExpr2idxNew1idxNew2zCollSeqNamewtFlagsTERM_LIKE'A'-10xBFExprUseXSelect(pExpr)(((pExpr)->flags&0x001000)!=0)Expr*EP_xIsSelect32769WO_ROWVALprereqColumnprereqExprpTerm!=&pWC->a[idxTerm]exprMightBeIndexedTK_GT+1==TK_LE && TK_GT+2==TK_LT && TK_GT+3==TK_GETK_IS<TK_GE && TK_ISNULL<TK_GE && TK_IN<TK_GEop<=TK_GEop<=58exprMightBeIndexed2exprSelectUsagetermIsEquivalenceaff1aff2SQLITE_TransitiveexprAnalyzeOrTermpOrWcpOrInfochngToINindexable(pTerm->wtFlags & (TERM_DYNAMIC|TERM_ORINFO|TERM_ANDINFO))==0pExpr->op==TK_ORsizeof(*pOrInfo)sizeof(pOrWc->aStatic)pOrWc->nTerm>=2(pOrTerm->wtFlags & (TERM_ANDINFO|TERM_ORINFO))==0pAndTerm->pExprWO_SINGLEpAndInfo488sizeof(*pAndInfo)pAndWCpAndTermsizeof(pAndWC->aStatic)pOtheriOnepOneiTwopTwopOrTerm->eOperator & WO_EQj==1pOrTerm->wtFlags & TERM_COPIEDpOrTerm->wtFlags & TERM_VIRTUALpOrTerm->wtFlags & (TERM_COPIED|TERM_VIRTUAL)(pOrTerm->eOperator & (WO_OR|WO_AND))==0IsPowerOfTwo(chngToIN)chngToIN==sqlite3WhereGetMask(&pWInfo->sMaskSet, iCursor)pOrTerm->leftCursor==iCursorpOrTerm->u.x.leftColumn==iColumnpLeft!=0ExprUseXList(pNew)okToChngToINaffLeftaffRightwhereCombineDisjuncts(WO_EQ|WO_LT|WO_LE|WO_GT|WO_GE)(WO_EQ|WO_LT|WO_LE)(WO_EQ|WO_GT|WO_GE)pOne->pExpr->pLeft!=0 && pOne->pExpr->pRight!=0pTwo->pExpr->pLeft!=0 && pTwo->pExpr->pRight!=0eOp & (WO_GT|WO_GE)(WO_LT|WO_LE)op<TK_GEwhereNthSubtermmarkTermAsChildtransferJoinMarkings(EP_OuterON|EP_InnerON)isAuxiliaryVtabOperatorpCol->op!=TK_COLUMN || (ExprUseYTab(pCol) && pCol->y.pTab!=0)pCol->op!=TK_COLUMN || ExprUseYTab(pCol)pVtab!=0pVtab->pModule!=0TK_NE < TK_EQTK_ISNOT < TK_EQTK_NOTNULL < TK_EQpLeft->op!=TK_COLUMN || (ExprUseYTab(pLeft) && pLeft->y.pTab!=0)pRight==0 || pRight->op!=TK_COLUMN || (ExprUseYTab(pRight) && pRight->y.pTab!=0)Op2const Op2const Op2[4]Op2[4]match"match"like"like"const Op2[]Op2[]const Op2 *Op2 *ArraySize(aOp)xNotUsedpNotUsedisLikeOrGlobu8[4]unsigned char[4]wcpRight->op==TK_VARIABLE || pRight->op==TK_REGISTER!ExprHasProperty(pRight, EP_IntValue)pReprepare255!=(u8)z[cnt-1]!ExprHasProperty(pPrefix, EP_IntValue)iTo>0ExprUseYTab(pLeft)(((pLeft)->flags&(0x1000000|0x2000000))==0)pLeft->y.pTabconst u8 **pPrefixiFromiTo50331648isNumrDummyoperatorMaskallowedOp(op)(WO_EQ<<(op-TK_EQ)) < 0x7fffop==TK_ISop!=TK_ISNULL || c==WO_ISNULLop!=TK_IN || c==WO_INop!=TK_EQ || c==WO_EQop!=TK_LT || c==WO_LTop!=TK_LE || c==WO_LEop!=TK_GT || c==WO_GTop!=TK_GE || c==WO_GEop!=TK_IS || c==WO_ISexprCommuteEP_CommutedpExpr->pRightpExpr->pLeftTK_LT==TK_GT+2TK_GE==TK_LE+2TK_GT>TK_EQTK_GT<TK_LEpExpr->op>=TK_GT && pExpr->op<=TK_GEallowedOpTK_GT>TK_EQ && TK_GT<TK_GETK_LT>TK_EQ && TK_LT<TK_GETK_LE>TK_EQ && TK_LE<TK_GETK_GE==TK_EQ+4TK_IN<TK_EQTK_IS<TK_EQTK_ISNULL<TK_EQwhereClauseInsertsizeof(pWC->a[0])EP_Unlikely0x080000WhereTermeOperatorsizeof(WhereTerm)offsetof(WhereTerm,eOperator)sizeof(WhereTerm) - offsetof(WhereTerm,eOperator)wtFlags & TERM_VIRTUALwhereAndInfoDeletewhereOrInfoDeletesqlite3WhereRightJoinLooppSubWherepSubWInfosFrommAll(pParse, 1, "RIGHT-JOIN %s", pTabItem->pSTab->zName)RIGHT-JOIN %spWInfo->a[k].pWLoop->iTab == pWInfo->a[k].iFrompRight->fg.isSubquery && pRight->u4.pSubq!=0pSubq->pSelect!=0 && pSubq->pSelect->pEList!=0(TERM_VIRTUAL|TERM_SLICE)sizeof(SrcItem)pParse->withinRJSubrtn < 100jmpOP_FilterOP_FoundpParse->withinRJSubrtn>0pRJ->addrSubrtnpRJ->endSubrtnpRJ->regReturnsqlite3WhereCodeOneLoopStartaddrNxtbRevaddrBrkaddrHaltiRowidRegiReleaseReg(pWInfo->wctrlFlags & (WHERE_OR_SUBCLAUSE|WHERE_RIGHT_JOIN)) || pLevel->iFrom>0 || (pTabItem[0].fg.jointype & JT_LEFT)==0(v, "init LEFT JOIN match flag")init LEFT JOIN match flagpTabItem->fg.isSubquery && pTabItem->u4.pSubq!=0(v, "next row of %s", pTabItem->pSTab->zName)pTerm==0pTerm->eOperator==WO_AUXpWInfo->pSelect->iOffset>0(v,"Zero OFFSET counter")(pLoop->wsFlags & WHERE_MULTI_OR)==0iIn<pLevel->u.in.nInpOp->opcode==OP_RowidiFld<=pLeft->x.pList->nExprpLoop->u.btree.nEq==1pTerm->pExpr!=0pTerm->wtFlags & TERM_VIRTUALpStart!=0 || pEnd!=0TK_LE==TK_GT+1TK_GE==TK_GT+3(pStart->wtFlags & TERM_VNULL)==0pStart->wtFlags & TERM_VIRTUALpStart->leftCursor!=iCurpX->op==TK_GTpX->op==TK_GEpX->op==TK_LTpX->op==TK_LEpX->op!=TK_GT || op==OP_SeekGEpX->op!=TK_GE || op==OP_SeekGEpX->op!=TK_LT || op==OP_SeekLEpX->op!=TK_LE || op==OP_SeekLE(v, "pk")bRev==0bRev!=0(pEnd->wtFlags & TERM_VNULL)==0pEnd->leftCursor!=iCurpEnd->wtFlags & TERM_VIRTUALpLevel->p5==0testOp==OP_LetestOp==OP_LttestOp==OP_GetestOp==OP_GtnEq>=pLoop->nSkipnExtraRegpLoop->u.btree.nBtm(pRangeStart->wtFlags & TERM_LIKEOPT)==0 || (pLoop->wsFlags & WHERE_TOP_LIMIT)!=0pLoop->u.btree.nToppRangeStart!=0pRangeStart->wtFlags & TERM_LIKEOPT(v, "LIKE loop counter")pIdx->aSortOrder[nEq]==SQLITE_SO_DESC(bRev & ~1)==0pRangeEnd==0 || (pRangeEnd->wtFlags & TERM_VNULL)==0bSeekPastNull==0 && nExtraReg==0 && nBtm==0 && nTop==0pRangeEnd==0 && pRangeStart==0pLoop->nSkip>0pRangeEndpRangeStartbSeekPastNullbStopAtNullnBtmnTopzStartAff==0 || sqlite3Strlen30(zStartAff)>=nEqpRangeStart && (pRangeStart->eOperator & WO_LE)!=0pRangeStart && (pRangeStart->eOperator & WO_GE)!=0pRangeEnd && (pRangeEnd->eOperator & WO_LE)!=0pRangeEnd && (pRangeEnd->eOperator & WO_GE)!=0pRangeStart->wtFlags & TERM_VIRTUAL(v, "NULL-scan pass ctr")op!=0regBignull==0op==OP_Rewindop==OP_Lastop==OP_SeekGEop==OP_SeekLEbSeekPastNull==0 || bStopAtNull==0bSeekPastNull==1 || bStopAtNull==1bSeekPastNull==!bStopAtNullbStopAtNull==startEqop==OP_Rewind || op==OP_Last || op==OP_SeekGE || op==OP_SeekLEpLevel->p2==0addrSeekScan==0pRangeEnd->wtFlags & TERM_VIRTUAL(v, "If NULL-scan 2nd pass")op==OP_IdxGTop==OP_IdxGEop==OP_IdxLTop==OP_IdxLEbSeekPastNull+bStopAtNull==1nConstraint+bSeekPastNull>0(v, "If NULL-scan 1st pass")pIdx->pPartIdxWhere(pWInfo->wctrlFlags & (WHERE_OR_SUBCLAUSE|WHERE_RIGHT_JOIN))==0pTerm->eOperator & WO_OR(pTerm->wtFlags & TERM_ORINFO)!=0pWC->a[iTerm].wtFlags & TERM_VIRTUALpWC->a[iTerm].wtFlags & TERM_CODEDpWC->a[iTerm].wtFlags & TERM_SLICEEP_Subquery0x400000(pParse, 1, "MULTI-INDEX OR")(pTabItem[0].fg.jointype & JT_LEFT)!=0 && !ExprHasProperty(pOrExpr, EP_OuterON)(pParse, 1, "INDEX %d", ii+1)("Subplan for OR-clause:\n")pSubWInfo || pParse->nErrpOrTab&pSubWInfo->a[0](pSubLoop->wsFlags & WHERE_AUTO_INDEX)==0pSubLoop->u.btree.pIndexpSubWInfo->a[0].iIdxCur==iCovCurpLevel->pWLoop==pLoop(pLoop->wsFlags & WHERE_MULTI_OR)!=0(pLoop->wsFlags & WHERE_IN_ABLE)==0pLevel->op==OP_ReturnbRev==0 || bRev==1iRegaddrNotFoundiCacheOP_VInitInZero OFFSET counterOP_VFilterP4_DYNAMICOP_VNextpCompareiFld(WHERE_COLUMN_IN|WHERE_COLUMN_EQ)testOp OP_NoopstartmemEndValuerTempaMoveOpconst u8[4]OP_SeekLEpkOP_IdxGEOP_IdxGTOP_IdxLEOP_IdxLTaStartOpaEndOpstartEqendEqstart_constraintszStartAffzEndAffomitTableregBignulladdrSeekScanLIKE loop counter(WHERE_TOP_LIMIT|WHERE_BTM_LIMIT)(WO_LE|WO_GE)NULL-scan pass ctrOP_SeekScanIf NULL-scan 2nd passOP_IfIf NULL-scan 1st passOP_SeekHit(WHERE_OR_SUBCLAUSE|WHERE_RIGHT_JOIN)OP_NotFoundpCoviCovCurregReturnregRowsetiLoopBodyiRetInituntestedTermspAndExprnNotReadyorigSrcsizeof(*pOrTab)sizeof(pOrTab->a[0])sizeof(*pTabItem)sizeof(pOrTab->a[k])32774(TERM_VIRTUAL|TERM_CODED|TERM_SLICE)65580MULTI-INDEX ORpOrExprjmp1INDEX %dpSubLoopiSetOP_RowSetTestaStepaStartpTerm->wtFlags & TERM_CODEDpWInfo->untestedTerms==0 && (pWInfo->wctrlFlags & WHERE_OR_SUBCLAUSE)!=0pE!=0(x&1)==1(x&1)==0skipLikeAddr(TERM_VIRTUAL|TERM_CODED)TERM_LIKECOND!ExprHasProperty(pE, EP_OuterON)(pTerm->prereqRight & pLevel->notReady)!=0pAlt->pExprpAlt->eOperator & WO_EQpAlt->eOperator & WO_ISpAlt->eOperator & WO_IN(v, "begin transitive constraint")sEAltpAlt(TERM_CODED)(v, "match against %s", pTab->zName)match against %s(v, "record LEFT JOIN hit")record LEFT JOIN hitpParse->withinRJSubrtn < 255pWInfo->untestedTermsOP_BeginSubrtncode_outer_join_constraints(v, "Begin WHERE-loop%d: %s", iLevel, pTabItem->pSTab->zName)whereLoopIsOneRow(WO_IS|WO_ISNULL)filterPullDownpLoop->prereq & notReadypLevel->addrBrk==0pParse->pVdbepLoop->wsFlags & WHERE_INDEXED(pLoop->wsFlags & WHERE_COLUMN_IN)==0whereApplyPartialIndexConstraintscodeExprOrVectornReg>0p->op==TK_SELECTExprUseXList(p)nReg<=pList->nExprnReg==1 || pParse->nErriSelectconst ExprList_itemconst ExprList_item *codeDeferredSeekiIdxCur>0pIdx->aiColumn[pIdx->nColumn-1]==-1OP_DeferredSeeksqlite3ParseToplevel(pParse)->writeMask((pParse)->pToplevel ? (pParse)->pToplevel : (pParse))->writeMaskpIdx->aiColumn[i]<pTab->nColx1!=x2ai-14P4_INTARRAYwhereLikeOptimizationStringFixuppLevel->iLikeRepCntr>0pOp!=0pOp->opcode==OP_String8 || pTerm->pWC->pWInfo->pParse->db->mallocFailedcodeAllEqualityTermszAff(pLoop->wsFlags & WHERE_VIRTUALTABLE)==0zAff!=0 || pParse->db->mallocFailed(v, "begin skip-scan on %s", pIdx->zName)pLevel->addrSkip==0pIdx->aiColumn[j]==XN_EXPR(v, "%s", explainIndexColumnName(pIdx, j))begin skip-scan on %szAff==0 || (int)strlen(zAff)>=nEq(pTerm->wtFlags & TERM_CODED)!=0pParse->db->mallocFailed==0codeEqualityTermpLevel->pWLoop->aLTerm[iEq]==pTermiTarget>0pX->op==TK_INcodeINTerm IN_INDEX_NOOPaiMapiEq==0pLoop->aLTerm[i]!=0EP_Subrtn0x2000000IN_INDEX_LOOPIN_INDEX_INDEX_DESCsizeof(pLevel->u.in.aInLoop[0])iEq>0 && (pLoop->wsFlags & WHERE_IN_SEEKSCAN)==0 && (pLoop->wsFlags & WHERE_VIRTUALTABLE)!=0iMapIN_INDEX_ROWID1049600(WHERE_IN_SEEKSCAN|WHERE_VIRTUALTABLE)!bRevremoveUnindexableInClauseTermsExprUseXSelect(pNew)pNew->pLeft!=0ExprUseXList(pNew->pLeft)(pLoop->aLTerm[i]->eOperator & (WO_OR|WO_AND))==0pOrigLhs->a[iField].pExpr!=0pRhs!=0 || db->mallocFailedpOrigRhspOrigLhsadjustOrderByColupdateRangeAffinityStrcodeApplyAffinitySQLITE_AFF_NONE<SQLITE_AFF_BLOBOP_AffinitydisableTermsqlite3WhereExplainBloomFilterSQLITE_MAX_LENGTHSQLITE_PRINTF_INTERNALBLOOM FILTER ON %S ("BLOOM FILTER ON %S ("%s=?"%s=?"rowid=?"rowid=?"OP_Explainsqlite3VdbeCurrentAddr(v)-1sqlite3WhereExplainOneScanIS_STMT_SCANSTATUS(pParse->db)sqlite3WhereAddExplainTextpLoop->u.btree.pIndex!=0!(flags&WHERE_AUTO_INDEX) || (flags&WHERE_IDX_ONLY)flags&WHERE_TOP_LIMITpOp->opcode==OP_ExplainpOp->p4type==P4_DYNAMIC || pOp->p4.z==0isSearch(WHERE_BTM_LIMIT|WHERE_TOP_LIMIT)%s %S"%s %S"SEARCH"SEARCH"SCAN"SCAN"(WHERE_IPK|WHERE_VIRTUALTABLE)PRIMARY KEY"PRIMARY KEY"AUTOMATIC PARTIAL COVERING INDEX"AUTOMATIC PARTIAL COVERING INDEX"AUTOMATIC COVERING INDEX"AUTOMATIC COVERING INDEX"COVERING INDEX %s"COVERING INDEX %s"INDEX %s"INDEX %s" USING " USING "cRangeOpzRowid USING INTEGER PRIMARY KEY (%s" USING INTEGER PRIMARY KEY (%s"(WHERE_COLUMN_EQ|WHERE_COLUMN_IN)WHERE_BOTH_LIMIT>? AND %s">? AND %s"%c?)"%c?)" VIRTUAL TABLE INDEX " VIRTUAL TABLE INDEX "0x%x:%s"0x%x:%s"%d:%s"%d:%s" LEFT-JOIN" LEFT-JOIN"explainIndexRange (" ("ANY(%s)"ANY(%s)"explainAppendTermnTerm>=1explainIndexColumnName<expr>"<expr>"VtabCtx *p->pTab==0 || IsVirtual(p->pTab)157870SQLITE_VTABRISK_LowSQLITE_VTABRISK_High157892const unsigned char[]OE_Rollback==1 && OE_Abort==2 && OE_Fail==3OE_Ignore==4 && OE_Replace==5db->vtabOnConflict>=1 && db->vtabOnConflict<=5const unsigned char[5]sqlite3VtabEponymousTableClearsqlite3VtabEponymousTableInitTABTYP_VTABpTab->u.vtab.nArg==0TF_Eponymoussqlite3VtabMakeWritablepToplevelapVtabLocksizeof(pToplevel->apVtabLock[0])sqlite3VtabOverloadFunctionExprUseYTab(pExpr)pTab==0SQLITE_FUNC_EPHEMsqlite3VtabSavepointop==SAVEPOINT_RELEASE||op==SAVEPOINT_ROLLBACK||op==SAVEPOINT_BEGINiSavepoint>=-1VTable **xMethodsavedFlags(u64)SQLITE_Defensive18446744073441116159~(u64)SQLITE_Defensivesqlite3VtabBeginprereqrRunaiCureMatchOpidxTermpSiParentpDerivedpeOp2ppLeftppRightppPrefixpisCompletepnoCasepTruthpzAffbAndiSvptsqlite3VtabCommitoffsetof(sqlite3_module,xCommit)sqlite3VtabRollbackoffsetof(sqlite3_module,xRollback)sqlite3VtabSyncaVTranscallFinalisersqlite3VtabCallDestroy((pTab)->eTabType==1)pTab->u.vtab.p!=0p->pVtabxDestroy!=0pTab->u.vtab.p==p && p->pNext==0initBusyconst u8[3]syntax error"syntax error"157373157375PARSE_MODE_DECLARE_VTABdb->init.busy==0sParse.pNewTable!=0IsOrdinaryTable(sParse.pNewTable)sParse.zErrMsg==0IsOrdinaryTable(pNew)pTab->pIndex==0HasRowid(pNew) || sqlite3PrimaryKeyIndex(pNew)!=0pIdx->pNext==0(TF_WithoutRowid|TF_NoVisibleRowid)PARSE_MODE_NORMAL(rc&0xff)==rcTK_CREATETK_TABLEsqlite3VtabCallCreatezModpTab && IsVirtual(pTab) && !pTab->u.vtab.pno such module: %s"no such module: %s"sqlite3GetVTable(db, pTab)addToVTransgrowVTransARRAY_INCRsizeof(sqlite3_vtab*)sizeof(sqlite3_vtab *)sizeof(sqlite3_vtab *)*ARRAY_INCRsqlite3VtabCallConnectvtabCallConstructorpVTablezModuleNamevtable constructor called recursively: %s"vtable constructor called recursively: %s"sizeof(VTable)SQLITE_VTABRISK_Normal&db->pVtabCtxxConstructpTab->nTabRef>1 || rc!=SQLITE_OKsCtx.pTab==pTabpVTable->pVtabzType[i-1]==' 'vtable constructor failed: %s"vtable constructor failed: %s"sizeof(pVTable->pVtab[0])vtable constructor did not declare schema: %s"vtable constructor did not declare schema: %s"oooHiddennType"hidden"TF_HasHiddenTF_OOOHiddensqlite3VtabArgExtendpArg->z <= p->zsqlite3VtabArgInitsqlite3VtabFinishParsezName!=0pTab==pOldCREATE VIRTUAL TABLE %T"CREATE VIRTUAL TABLE %T"UPDATE %Q.sqlite_master SET type='table', name=%Q, tbl_name=%Q, rootpage=0, sql=%Q WHERE rowid=#%d"UPDATE %Q." LEGACY_SCHEMA_TABLE " "
         "SET type='table', name=%Q, tbl_name=%Q, rootpage=0, sql=%Q "
       "WHERE rowid=#%d"char[99]OP_Expirename=%Q AND sql=%Q"name=%Q AND sql=%Q"OP_VCreateaddArgumentToVtabsqlite3VtabBeginParse0==pTable->pIndexpTable->u.vtab.nArg==0(pParse->sNameToken.z==pName2->z && pName2->z!=0) || (pParse->sNameToken.z==pName1->z && pName2->z==0)iDb>=0addModuleArgumentazModuleArgIsVirtual(pTable)too many columns on %s"too many columns on %s"sqlite3VtabClearIsVirtual(p)sqlite3VtabUnlockListsqlite3BtreeHoldsAllMutexes(db)sqlite3VtabDisconnectvtabDisconnectAlldb==0 || sqlite3SchemaMutexHeld(db, 0, p->pSchema)!db || pRetsqlite3VtabUnlockpVTab->nRef>0db->eOpenState==SQLITE_STATE_OPEN || db->eOpenState==SQLITE_STATE_ZOMBIEsqlite3GetVTablesqlite3VtabLocksqlite3VtabModuleUnrefpMod->nRefModule>0pMod->pEpoTab==0createModulesqlite3VtabCreateModulesizeof(Module)sqlite3RunVacuumpMainsaved_mDbFlagssaved_flagssaved_nChangesaved_nTotalChangesaved_openFlagssaved_mTraceisMemDbzDbMainpgflagsiRandomzDbVacuumcannot VACUUM from within a transaction"cannot VACUUM from within a transaction"cannot VACUUM - SQL statements in progress"cannot VACUUM - SQL statements in progress"non-text filename"non-text filename"~SQLITE_OPEN_READONLYSQLITE_IgnoreChecks513DBFLAG_PreferBuiltinDBFLAG_Vacuum0x00001204802684559364563423232(u64)(SQLITE_ForeignKeys | SQLITE_ReverseOrder
                   | SQLITE_Defensive | SQLITE_CountRows)18446744069146128383~(u64)(SQLITE_ForeignKeys | SQLITE_ReverseOrder
                   | SQLITE_Defensive | SQLITE_CountRows)sizeof(iRandom)sizeof(zDbVacuum)vacuum_%016llx"vacuum_%016llx"ATTACH %Q AS %s"ATTACH %Q AS %s"(db->nDb-1)==nDbstrcmp(pDb->zDbSName,zDbVacuum)==0output file already exists"output file already exists"DBFLAG_VacuumIntoPAGER_FLAGS_MASKPAGER_CACHESPILLPAGER_JOURNALMODE_WALdb->mallocFailedSELECT sql FROM "%w".sqlite_schema WHERE type='table'AND name<>'sqlite_sequence' AND coalesce(rootpage,1)>0"SELECT sql FROM \"%w\".sqlite_schema"
      " WHERE type='table'AND name<>'sqlite_sequence'"
      " AND coalesce(rootpage,1)>0"SELECT sql FROM "%w".sqlite_schema WHERE type='index'"SELECT sql FROM \"%w\".sqlite_schema"
      " WHERE type='index'"SELECT'INSERT INTO %s.'||quote(name)||' SELECT*FROM"%w".'||quote(name)FROM %s.sqlite_schema WHERE type='table'AND coalesce(rootpage,1)>0"SELECT'INSERT INTO %s.'||quote(name)"
      "||' SELECT*FROM\"%w\".'||quote(name)"
      "FROM %s.sqlite_schema "
      "WHERE type='table'AND coalesce(rootpage,1)>0"(db->mDbFlags & DBFLAG_Vacuum)!=04294967291~DBFLAG_VacuumINSERT INTO %s.sqlite_schema SELECT*FROM "%w".sqlite_schema WHERE type IN('view','trigger') OR(type='table'AND rootpage=0)"INSERT INTO %s.sqlite_schema"
      " SELECT*FROM \"%w\".sqlite_schema"
      " WHERE type IN('view','trigger')"
      " OR(type='table'AND rootpage=0)"char[123]const unsigned char[10]unsigned char[10]BTREE_SCHEMA_VERSIONBTREE_DEFAULT_CACHE_SIZEBTREE_TEXT_ENCODINGBTREE_USER_VERSIONBTREE_APPLICATION_IDmetaSQLITE_TXN_WRITE==sqlite3BtreeTxnState(pTemp)pOut!=0 || SQLITE_TXN_WRITE==sqlite3BtreeTxnState(pMain)ArraySize(aCopy)end_of_vacuumsqlite3VacuumToken **iIntoRegOP_Vacuumbuild_vacuum_endexecSqlFexecSqlsqlite3_strnicmp(zSql,"SELECT",6)==0zSubSqlCRE"CRE"INS"INS"rc!=SQLITE_ROWsqlite3UpsertDoUpdateiDataCurpUpsert!=0(v, "Begin DO UPDATE of UPSERT")Begin DO UPDATE of UPSERTpPk->aiColumn[i]>=0(v, "%s.%s", pIdx->zName, pTab->aCol[pPk->aiColumn[i]].zCnName)%s.%scorrupt database"corrupt database"SQLITE_AFF_REALOP_RealAffinity(v, "End DO UPDATE of UPSERT")End DO UPDATE of UPSERTsqlite3UpsertOfIndexsqlite3UpsertNextIsIPKpUpsert==0sqlite3UpsertAnalyzeTargetsNCExpr[2]sColnClausepTabList->nSrc==1pTabList->a[0].pSTab!=0pUpsert->pUpsertTarget!=0NameContext *sizeof(sNC)pUpsert->pUpsertIdx==0pIdx->aColExpr!=0pIdx->aColExpr->nExpr>iisizeof(sCol)zWhichsizeof(zWhich)%r "%r "%sON CONFLICT clause does not match any PRIMARY KEY or UNIQUE constraint"%sON CONFLICT clause does not match any "
                              "PRIMARY KEY or UNIQUE constraint"sqlite3UpsertNewsizeof(Upsert)sqlite3UpsertDupsqlite3UpsertDeleteupsertDeleteupdateVirtualTableephemTabregRecaDummyeOnePasspPk->nKeyCol==1(pTab->aCol[i].colFlags & COLFLAG_GENERATED)==0eOnePass==ONEPASS_OFF || eOnePass==ONEPASS_SINGLETK_ROWpRowExprOPFLAG_NOCHNGOP_VColumnOP_CloseOP_VUpdatesqlite3UpdatenAllIdxiBaseCuraRegIdxaXRefaToOpenchngPkchngRowidchngKeypRowidExpriRowidExprsContexthasFKlabelBreaklabelContinueisViewpTriggertmasknewmaskaiCurOnePassaddrOpenbReplacebFinishSeeknChangeFromregRowCountregOldRowidregNewRowidregRowSetregKeyAuthContext *sizeof(sContext)db->pParse==pParsepTrigger || tmask==0nChangeFrom==0 || pUpsert==0NC_UUpsertpTab->aCol[j].colFlags & COLFLAG_VIRTUALpTab->aCol[j].colFlags & COLFLAG_STOREDCOLFLAG_GENERATEDcannot UPDATE generated column "%s""cannot UPDATE generated column \"%s\""ROWID"ROWID"(chngRowid & chngPk)==0chngRowid==0 || chngRowid==1chngPk==0 || chngPk==1pTab->tabFlags & TF_HasVirtualpTab->tabFlags & TF_HasStoredbProgress99999aRegIdx[nAllIdx]==pParse->nMempPk!=0 || HasRowid(pTab)nEphColiCur!=iDataCur || !HasRowid(pTab)pPk==0iNotUsed1iNotUsed2OP_NotExistsOP_RowDatachngKey || pTrigger || hasFK || regOldRowid==regNewRowidiRowidExpr>=0oldmask!=0xffffffff && i==31TRIGGER_BEFORETRIGGER_AFTERcolFlagseOnePass==ONEPASS_OFFregOldRowid>0regNew==regNewRowid+1OP_FinishSeekOPFLAG_ISUPDATErows updated"rows updated"update_cleanuppPk!=0 && pPk!=pTab->pIndexupdateFromSelectpGrppLimit2pOrderBy2pWhere2eDestpLimitpTabList->nSrc>1pSrc->a[0].fg.notCteSRT_TableSRT_UpfrompChanges!=0 || pParse->db->mallocFailedSF_UFSrcCheckSF_IncludeHidden8519680SF_UpdateFrom276955136exprRowColumnindexWhereClauseMightChangeindexColumnIsBeingUpdatediIdxColiIdxCol!=XN_ROWIDiIdxCol==XN_EXPRpIdx->aColExpr->a[iCol].pExpr!=0sqlite3ColumnDefaultpTab->nCol>isqlite3VdbeDb(v)!IsView(pTab)(v, "%s.%s", pTab->zName, pCol->zCnName)i<pTab->nColP4_MEMsqlite3TriggerColmaskTK_DELETEisNew==1 || isNew==0TriggerPrg *pPrgu32[2]sqlite3CodeRowTriggerop==TK_UPDATE || op==TK_INSERT || op==TK_DELETEtr_tm==TRIGGER_BEFORE || tr_tm==TRIGGER_AFTER(op==TK_UPDATE)==(pChanges!=0)p->pSchema!=0p->pTabSchema!=0p->pSchema==p->pTabSchema || p->pSchema==pParse->db->aDb[1].pSchemaTK_INSERTsqlite3CodeRowTriggerDirectpPrg || pParse->nErr(v, "Call: %s.%s", (p->zName?p->zName:"fkey"), onErrorText(orconf))bRecursiveSQLITE_RecTriggersOP_ProgramSubProgram *P4_SUBPROGRAMCall: %s.%sfkeygetRowTriggerpTrigger->zName==0 || pTab==tableOfTrigger(pTrigger)codeRowTriggerpWhenpProgramiEndTriggersSubParsepTop->pVdbesizeof(TriggerPrg)sizeof(SubProgram)(v, "Start: %s.%s (%s %s%s%s ON %s)", pTrigger->zName, onErrorText(orconf), (pTrigger->tr_tm==TRIGGER_BEFORE ? "BEFORE" : "AFTER"), (pTrigger->op==TK_UPDATE ? "UPDATE" : ""), (pTrigger->op==TK_INSERT ? "INSERT" : ""), (pTrigger->op==TK_DELETE ? "DELETE" : ""), pTab->zName )(v, "Start: %s.%s (%s %s%s%s ON %s)", pTrigger->zName, onErrorText(orconf), (pTrigger->tr_tm==1 ? "BEFORE" : "AFTER"), (pTrigger->op==130 ? "UPDATE" : ""), (pTrigger->op==128 ? "INSERT" : ""), (pTrigger->op==129 ? "DELETE" : ""), pTab->zName )(v, "End: %s.%s", pTrigger->zName, onErrorText(orconf))Start: %s.%s (%s %s%s%s ON %s)BEFOREAFTER-- TRIGGER %s"-- TRIGGER %s"End: %s.%s!sSubParse.pTriggerPrg && !sSubParse.nMaxArgtransferParseErrorpFrom->zErrMsg==0 || pFrom->nErrpTo->zErrMsg==0 || pTo->nErronErrorText"abort"rollback"rollback"fail"fail"ignore"ignore"default"default"n/a"n/a"codeTriggerProgrampSteppParse->pTriggerTab && pParse->pToplevelpStepListpParse->okConstFactor==0pStep->op==TK_SELECTOP_Trace-- %s"-- %s"OP_ResetCountconst Selectconst Select *const IdListconst IdList *sDestSRT_DiscardcodeReturningTriggerReturning *pReturning!pParse->isCreatesizeof(sSelect)sizeof(sFrom)pCol!=0NC_UBaseRegsqlite3ProcessReturningSubqueriessqlite3ReturningSubqueryCorrelatedpSelect!=0pSelect->selFlags & SF_CorrelatedSF_Correlatedsqlite3ReturningSubqueryVarSelectExprHasProperty(pExpr, EP_VarSelect)sqlite3ExpandReturningpOldExpr==0pTab->aCol+jjpList->a[i].zEName!=0pOldExprENAME_NAMEisAsteriskTermpTerm->pRight!=0pTerm->pLeft!=0RETURNING may not use "TABLE.*" wildcards"RETURNING may not use \"TABLE.*\" wildcards"sqlite3TriggerStepSrcpSrc==0 || pSrc->nSrc==1zName || pSrc==0pSrc->a[0].fg.fixedSchema || pSrc->a[0].u4.zDatabase==0sqlite3TriggersExisttriggersReallyExistpList==0 || IsVirtual(pTab)==0 || (pList->bReturning && pList->pNext==0)p->pNextsqlite3IsToplevel(pParse)TK_RETURNING%s RETURNING is not available on virtual tables"%s RETURNING is not available on virtual tables"exit_triggers_existtempTriggersExistdb->aDb[1].pSchema==0&db->aDb[1].pSchema->trigHashcheckColumnOverlappEList==0sqlite3UnlinkAndDeleteTriggersqlite3SchemaMutexHeld(db, iDb, 0)Trigger **sqlite3DropTriggerPtriDb>=0 && iDb<db->nDb(pTable && pTable->pSchema==pTrigger->pSchema) || iDb==1code SQLITE_DROP_TRIGGERDELETE FROM %Q.sqlite_master WHERE name=%Q AND type='trigger'"DELETE FROM %Q." LEGACY_SCHEMA_TABLE " WHERE name=%Q AND type='trigger'"OP_DropTriggertableOfTriggersqlite3DropTriggerpName->nSrc==1pName->a[0].fg.fixedSchema==0 && pName->a[0].fg.isSubquery==0zDb!=0 || sqlite3BtreeHoldsAllMutexes(db)sqlite3SchemaMutexHeld(db, j, 0)OMIT_TEMPDBno such trigger: %S"no such trigger: %S"drop_trigger_cleanupsqlite3DeleteTriggersqlite3TriggerDeleteSteppTriggerStepEXPRDUP_REDUCEsqlite3TriggerUpdateStepsqlite3TriggerInsertSteppSelect != 0 || db->mallocFailedpColumnpUpserttriggerStepAllocatesizeof(TriggerStep)sqlite3TriggerSelectSteptriggerSpanDupsqlite3FinishTriggerpTrigsFixnameTokenpParse->nErrDbFixer *!db->init.busyz==0trigger "%s" may not write to shadow table "%s""trigger \"%s\" may not write to shadow table \"%s\""INSERT INTO %Q.sqlite_master VALUES('trigger',%Q,%Q,0,'CREATE TRIGGER %q')"INSERT INTO %Q." LEGACY_SCHEMA_TABLE
       " VALUES('trigger',%Q,%Q,0,'CREATE TRIGGER %q')"type='trigger' AND name='%q'"type='trigger' AND name='%q'"pLink!=0triggerfinish_cleanupIN_RENAME_OBJECT || !pParse->pNewTriggersqlite3BeginTriggerpName1!=0pName2!=0op==TK_INSERT || op==TK_UPDATE || op==TK_DELETEop>0 && op<0xfftemporary trigger may not have qualified name"temporary trigger may not have qualified name"pTableName->a[0].fg.fixedSchema==0pTableName->a[0].fg.isSubquery==0pTableName->nSrc==1cannot create triggers on virtual tables"cannot create triggers on virtual tables"TF_Shadowcannot create triggers on shadow tables"cannot create triggers on shadow tables"pParse->ifNotExists = 1;trigger %T already exists"trigger %T already exists"cannot create trigger on system table"cannot create trigger on system table"cannot create %s trigger on view: %S"cannot create %s trigger on view: %S""BEFORE""AFTER"cannot create INSTEAD OF trigger on table: %S"cannot create INSTEAD OF"
        " trigger on table: %S"iTabDb SQLITE_CREATE_TRIGGERzDbTrigsizeof(Trigger)trigger_cleanuppParse->pNewTrigger==pTriggertrigger_orphan_errorsqlite3TriggerListpTmpSchemapParse->disableTriggers==0&pTmpSchema->trigHashpParse->db->pVtabCtx==0pParse->bReturning&(pParse->u1.d.pReturning->retTrig) == pTrigsqlite3DeleteTriggerStepazResult!=0azResult[0]TabResult *sizeof(res.azResult[0])>= sizeof(res.nData)res.nDatasqlite3_get_table_cbneedsqlite3_get_table() called with two or more incompatible queries"sqlite3_get_table() called with two or more incompatible queries"malloc_failedsqlite3SelectisAggpAggInfosDistinctsSortpMinMaxOrderByminMaxFlagpParse==db->pParsep->pOrderBy==0 || pDest->eDest!=SRT_DistFifop->pOrderBy==0 || pDest->eDest!=SRT_Fifop->pOrderBy==0 || pDest->eDest!=SRT_DistQueuep->pOrderBy==0 || pDest->eDest!=SRT_QueuepDest->eDest==SRT_Exists || pDest->eDest==SRT_Union || pDest->eDest==SRT_Except || pDest->eDest==SRT_Discard || pDest->eDest==SRT_DistQueue || pDest->eDest==SRT_DistFifopParse->earlyCleanup~SF_DistinctSF_NoopOrderByp->pEList!=0p0target object/alias may not appear in FROM clause: %s"target object/alias may not appear in FROM clause: %s"4286578687~SF_UFSrcCheckSortCtx *sizeof(sSort)SQLITE_SimplifyJoin("FULL-JOIN simplifies to RIGHT-JOIN on term %d\n",i)("LEFT-JOIN simplifies to JOIN on term %d\n",i)("FULL-JOIN simplifies to LEFT-JOIN on term %d\n",j)("RIGHT-JOIN simplifies to JOIN on term %d\n",j)pSub->pGroupBy==0SQLITE_OmitOrderBy("omit superfluous ORDER BY on %r FROM-clause subquery\n",i+1)~JT_LEFT(JT_LEFT|JT_OUTER)-41~(JT_LEFT|JT_OUTER)-17~JT_RIGHT(JT_RIGHT|JT_OUTER)-49~(JT_RIGHT|JT_OUTER)~JT_LTORJexpected %d columns for '%s' but got %d"expected %d columns for '%s' but got %d"SF_Recursive134225920(SF_OrderByReqd|SF_Recursive)SF_ComplexResultSQLITE_PropagateConst("Constant propagation not helpful\n")SQLITE_QueryFlattener|SQLITE_CountOfView0x00000001|0x00000200SQLITE_PushDownpSubq->pSelect && (pSub->selFlags & SF_PushDown)!=0("WHERE-clause push-down not possible\n")SQLITE_NullUnusedCols(v, "%!S", pItem)(pParse, 1, "CO-ROUTINE %!S", pItem)(v, "end %!S", pItem)pPrior->fg.isSubquerypPriorSubq!=0(v, "materialize %!S", pItem)(pParse, 1, "MATERIALIZE %!S", pItem)zSavedAuthContext%!SSRT_CoroutineCO-ROUTINE %!Send %!SpCteUsepPriorSubqtopAddronceAddrSRT_EphemTabMATERIALIZE %!SSQLITE_GroupByOrdersDistinct.isTnctSF_FixedLimitOP_SorterOpenSORTFLAG_UseSorterBTREE_UNORDEREDWHERE_USE_LIMIT==SF_FixedLimit("WhereBegin\n")("WhereBegin returns\n")p->pEList==pEList(v, "inner-loop subroutine")(v, "end inner-loop subroutine")("WhereEnd\n")66==sqlite3LogEst(100)0==sqlite3LogEst(1)sNC.ncFlags = NC_UAggInfo;pWhere==p->pWherepHaving==p->pHavingpGroupBy==p->pGroupBypAggInfo->aFunc[0].pFExpr!=0ExprUseXList(pAggInfo->aFunc[0].pFExpr)(((pAggInfo->aFunc[0].pFExpr)->flags&0x001000)==0)pAggInfo->aFunc[0].pFExpr(v, "clear abort flag")(pParse, 0, "USE TEMP B-TREE FOR %s", (sDistinct.isTnct && (p->selFlags&SF_Distinct)==0) ? "DISTINCT" : "GROUP BY" )(pParse, 0, "USE TEMP B-TREE FOR %s", (sDistinct.isTnct && (p->selFlags&0x0000001)==0) ? "DISTINCT" : "GROUP BY" )sqlite3VdbeCurrentAddr(v)-2(v, "GROUP BY sort")sortPTabpAggInfo->sortingIdxpBase!=0(v, "output one row")(v, "check abort flag")(v, "reset accumulator")(v, "indicate data in accumulator")(v, "output final row")(v, "set abort flag")(v, "Groupby result generator entry point")(v, "end groupby result generator")(v, "indicate accumulator empty")pAggInfo->aFunc[i].pFExprp->pGroupBy==0minMaxFlag==WHERE_ORDERBY_NORMAL || pMinMaxOrderBy!=0pMinMaxOrderBy==0 || pMinMaxOrderBy->nExpr==1iContiBreakinner-loop subroutineDistinctCtx *end inner-loop subroutineiAMemiBMemiUseFlagiAbortFlaggroupBySortaddrEndsortOutorderByGrpsortFlagssizeof(*pAggInfo)AggInfo_func *WHERE_ORDERBY_NORMALaddr1addrOutputRowregOutputRowaddrSetAbortaddrTopOfLoopaddrSortingIdxaddrResetregResetdistFlageDist WHERE_DISTINCT_NOOP(WHERE_WANT_DISTINCT|WHERE_AGG_DISTINCT)clear abort flagnGroupByUSE TEMP B-TREE FOR %sDISTINCTGROUP BYAggInfo_col *OP_SorterInsertOP_OpenPseudoOP_SorterSortGROUP BY sortOP_SorterDataiOrderByColoutput one rowcheck abort flagreset accumulatorindicate data in accumulatorOP_SorterNextoutput final rowset abort flagGroupby result generator entry pointend groupby result generatorindicate accumulator emptypFpBestOP_OpenReadOP_CountregAccpName1pName2pModuleNameifNotExistsazNamespNmpIntopAllpTargetWherepChangesonErrorisNewtr_tmorconfignoreJumpregInpIdListnoErrpTableNamepColumnsisTempcolv"DISTINCT"select_enddb->mallocFailed==0 || db->mallocFailed==1db->mallocFailed==0 || pParse->nErr!=0fromClauseTermCanBeCoroutineconst CteUseconst CteUse *SQLITE_CoroutinessameSrcAliascountOfViewOptimizationExprUseUToken(pExpr)SF_CopyCtepSub->pHaving==0sizeof(*p->pSrc)~SF_CompoundagginfoFreeisSelfJoinViewpThis->fg.isSubquerypSel!=0SF_PushDownpItem->pSTab!=0pThis->pSTab!=0pS1havingToWheresizeof(sWalker)havingToWhereExprCbExpr*pNew*pExpr536870913explainSimpleCountbCoverSCAN %s%s%s"SCAN %s%s%s"updateAccumulatorregHitaddrHitTestpAggInfo->iFirstReg>0ExprUseXList(pF->pFExpr)!IsWindowFunc(pF->pFExpr)pF->pFunc!=0pF->pFExprpF->pFExpr->pLeft!=0pF->pFExpr->pLeft->op==TK_ORDERExprUseXList(pF->pFExpr->pLeft)pOBList!=0pOBList->nExpr>0regAggregAggSzregDistinctpOBListSQLITE_ECEL_DUPOP_GetSubtypefinalizeAggFunctionspF->pFExpr->pLeft->x.pList!=0!pF->bOBUniqueiTopregSubtypeiBaseColOP_SetSubtyperesetAccumulatorpParse->db->pParse==pParsepParse->db->mallocFailed==0 || pParse->nErr!=0ExprUseXList(pE)(pParse, 0, "USE TEMP B-TREE FOR %s(DISTINCT)", pFunc->pFunc->zName)pFunc->pFExpr->pLeft!=0pFunc->pFExpr->pLeft->op==TK_ORDERExprUseXList(pFunc->pFExpr->pLeft)pFunc->pFunc!=0ExprUseXList(pFunc->pFExpr)(pParse, 0, "USE TEMP B-TREE FOR %s(ORDER BY)", pFunc->pFunc->zName)DISTINCT aggregates must have exactly one argument"DISTINCT aggregates must have exactly one "
           "argument"USE TEMP B-TREE FOR %s(DISTINCT)USE TEMP B-TREE FOR %s(ORDER BY)assignAggregateRegisterspAggInfo!=0pAggInfo->iFirstReg==0aggregateConvertIndexedExprRefToColumnaggregateIdxEprRefToColCallbackpExpr->iAgg>=pAggInfo->nColumnpExpr->iAgg>=0EP_Skip|EP_Collate|EP_Unlikely0x002000|0x000200|0x08000087045329924294434303optimizeAggregateUseOfIndexedExprpSelect->pGroupBy!=0pAggInfo->nSortingColumn>0analyzeAggFuncArgsNC_InAggFuncpExpr->op==TK_FUNCTION || pExpr->op==TK_AGG_FUNCTIONpExpr->pLeft->op==TK_ORDERExprUseXList(pExpr->pLeft)!IsWindowFunc(pExpr)-131073~NC_InAggFuncsqlite3SelectPrepp!=0 || pParse->db->mallocFailedSF_HasTypeInfosqlite3SelectAddTypeInfoselectAddSubqueryTypeInfo(p->selFlags & SF_Resolved)sqlite3SelectExpandpParse->hasCompoundselectExpanderelistFlagsp->pSrc!=0SF_Viewsizeof(With)pFrom->fg.isRecursive==0 || pFrom->pSTab!=0pFrom->fg.isRecursive==0pFrom->fg.isSubquery && pFrom->u4.pSubq!=0pFrom->pSTab==0pFrom->fg.isSubquery==0SQLITE_VTABRISK_Normal==1 && SQLITE_VTABRISK_High==2too many references to "%s": max 65535"too many references to \"%s\": max 65535"eCodeOrigaccess to view "%s" prohibited"access to view \"%s\" prohibited"unsafe use of virtual table "%s""unsafe use of virtual table \"%s\""pE->op!=TK_DOT || pE->pRight!=0pE->op!=TK_DOT || (pE->pLeft!=0 && pE->pLeft->op==TK_ID)pE->op!=TK_DOT || pRight!=0(selFlags & SF_NestedFrom)==0pE->pLeft!=0!ExprHasProperty(pE->pLeft, EP_IntValue)ExprUseWOfst(pE->pLeft)ExprUseWOfst(pE)(int)pFrom->fg.isNestedFrom == IsNestedFrom(pFrom)pFrom->fg.isSubquery && pFrom->u4.pSubqpFrom->u4.pSubq->pSelect!=0pNestedFrom!=0pNestedFrom->nExpr==pTab->nColVisibleRowid(pTab)==0 || ViewCanHaveRowidpX->zEName==0&pTab->aCol[j]j<pNestedFrom->nExprlongNamesSQLITE_FullColNamestableSeenzTNameiErrOfstnAddpNestedFromzTabNamezSchemaNamepUsingzUNameIdList_item[1]IdList_item *..%s"..%s"ENAME_TABENAME_ROWIDCOLFLAG_NOEXPAND(SF_NestedFrom)ViewCanHaveRowid!ViewCanHaveRowid%s.%s.%s"%s.%s.%s""%s.%s"no such table: %s"no such table: %s"no tables specified"no tables specified"too many columns in result set"too many columns in result set"EP_HasFunc4194312(EP_HasFunc|EP_Subquery)inAnyUsingClausepBase->u3.pUsing==0sqlite3ExpandSubquerypFrom->fg.isSubquerypFrom->u4.pSubq!=0"%!S"Column **TABTYP_VIEW200==sqlite3LogEst(1048576)16896sqlite3SelectPopWithpParse->pWithpParse->pWith==pWith || pParse->nErrresolveFromTermToCtepCtepFrom->fg.hadSchema==0 || pFrom->fg.notCte!=0With **!pFrom->fg.isIndexedBypRecTerm->pPrior!=0!pItem->fg.isSubquerypRecTerm!=0(pRecTerm->selFlags & SF_Recursive)==0pRecTerm->pNext!=0(pRecTerm->pNext->selFlags & SF_Recursive)!=0pRecTerm->pWith==0pRecTermbMayRecursivepSavedWithiRecTabsizeof(pCteUse[0])no such index: "%s""no such index: \"%s\""TK_UNIONmultiple references to recursive table: %s"multiple references to recursive table: %s"circular reference: %s"circular reference: %s"table %s has %d values for %d columns"table %s has %d values for %d columns"multiple recursive references: %s"multiple recursive references: %s"recursive reference in a subquery: %s"recursive reference in a subquery: %s"sqlite3WithPushpParse->pWith!=pWithsearchWithpItem->fg.fixedSchema || pItem->u4.zDatabase==0Cte[1]cannotBeFunction'%s' is not a function"'%s' is not a function"convertCompoundSelectToSubquerypNewSrcsizeof(dummy)pNewSrc!=0 || pParse->nErr(p->selFlags & SF_Converted)==0SF_ConvertedpNew->pPrior!=0sqlite3IndexedByLookupzIndexedBypFrom->fg.isIndexedBy!=0no such index: %s"no such index: %s"pFrom->fg.isCte==0isSimpleCount!p->pGroupBySQLITE_FUNC_COUNTpAggInfo->aFunc[0].pFExpr==pExprEP_Distinct|EP_WinFunc0x000004|0x100000016777220ExprHasProperty(pExpr, EP_Distinct)ExprHasProperty(pExpr, EP_WinFunc)minMaxQueryeRet WHERE_ORDERBY_NORMAL*ppMinMax==0pFunc->op==TK_AGG_FUNCTION!IsWindowFunc(pFunc)ExprUseXList(pFunc)SQLITE_MinMaxOpt!ExprHasProperty(pFunc, EP_IntValue)"min"max"max"pOrderBy!=0 || db->mallocFaileddisableUnusedSubqueryResultColumnspItem->fg.isSubquerypSub->pEList->nExpr==pTab->nColpX->selFlags & SF_DistinctpX->selFlags & SF_Aggregate((Bitmask)1)EP_Skip|EP_Unlikely0x002000|0x0800005324804294434815pushDownWhereTerms33562624(SF_Recursive|SF_MultiPart)op==TK_ALL || op==TK_SELECT || op==TK_UNION || op==TK_INTERSECT || op==TK_EXCEPTnotUnionAllSubstContext *pushDownWindowCheckpSubq->pWin->pPartition(pSubq->selFlags & SF_MultiPart)==0pSubq->pPrior==0propagateConstantsWhereConst *propagateConstantExprRewritepConstTK_GT==TK_EQ+1TK_LE==TK_EQ+2TK_LT==TK_EQ+3propagateConstantExprRewriteOneEP_FixedCol|pConst->mExcludeOn0x000020|pConst->mExcludeOnExprHasProperty(pExpr, EP_FixedCol)ExprHasProperty(pExpr, EP_OuterON)ExprHasProperty(pExpr, EP_InnerON)0x800000pExpr->pLeft==0findConstInWherepConst->mExcludeOnpRight!=0constInsertpColumn->op==TK_COLUMNsqlite3ExprIsConstant(pConst->pParse, pValue)pE2->op==TK_COLUMNsizeof(Expr*)flattenSubquerypSub1pSubSrciNewParentisOuterJoinpSubitemaCsrMapp->pPrior==0SQLITE_QueryFlattenerpSrc && iFrom>=0 && iFrom<pSrc->nSrcpSubitem->fg.isSubquerypSub!=0(SF_Recursive)pSubSrc->a[0].pSTab(JT_OUTER|JT_LTORJ)pSubSrc->nSrc>0!pSubitem->fg.isCte || pSubitem->u2.pCteUse->eM10d!=M10d_Yes(pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct(pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_AggregatepSub->pSrc!=0(pSub->selFlags & SF_Recursive)==0pSub->pEList->nExpr==pSub1->pEList->nExprpSub1->pSrc->nSrc>1SQLITE_FlttnUnionAllpSubitem->fg.isSubquery==0pSubitem->fg.fixedSchema==0pSubitem->fg.isUsing!=0 || pSubitem->u3.pOn==0("compound-subquery flattener" " creates %u as peer\n",pNew->selId)pItemTabpSubitem->u4.zDatabase==0pSubitem->pSTab!=0pToplevel->earlyCleanuppTabToDelpItem->fg.isTabFunc==0pItem->fg.isSubquery || pItem->fg.fixedSchema || pItem->u4.zDatabase==0pParent->pOrderBy==0pSubSrc->nSrc==1(pSub->selFlags & SF_Distinct)==0nSubSrcltorjsizeof(pSubSrc->a[i])("flatten %u.%p from term %d\n", pSub->selId, pSub, iFrom)i =i==SQLITE_DENYcompoundHasDifferentAffinitiesp->pPrior!=0pList->a[ii].pExpr!=0pSub1->pEList!=0pSub1->pEList->nExpr>iipSub1->pEList->a[ii].pExpr!=0findLeftmostExprlistrenumberCursorsrenumberCursorsCbrenumberCursorDoMappingsrclistRenumberCursorspItem->iCursor < aCsrMap[0]recomputeColumnsUsedpSrcItem->pSTab==0recomputeColumnsUsedExprsubstSelectsubstExprListsubstExpriColumn>=0pSubst->pEList!=0 && iColumn<pSubst->pEList->nExprExprHasProperty(pCopy, EP_Subquery)EP_CanBeNull0x000200ifNullRowsizeof(ifNullRow)EP_IfNullRowpNatBINARY"BINARY"multiSelectOrderBynSelectdestAdestBregAddrAregAddrBaddrSelectAaddrSelectBregOutAregOutBaddrOutAaddrOutBaddrEofAaddrEofA_noBaddrEofBaddrAltBaddrAeqBaddrAgtBregLimitAregLimitBregPrevsavedLimitsavedOffsetlabelCmprlabelEndpKeyDuppKeyMergeaPermutep->pOrderBy!=0pKeyDup==0p->pPrior->pOrderBy==0pItem->u.x.iOrderByCol>0pItem->u.x.iOrderByCol<=p->pEList->nExprnOrderBy>=nExpr || db->mallocFailedsqlite3KeyInfoIsWriteable(pKeyDup)SQLITE_BalancedMergepSplit->pPrior->pNext==pSplitpPrior!=0p->pOrderBy == pOrderByORDER"ORDER"(pParse, 1, "MERGE (%s)", sqlite3SelectOpName(p->op))MERGE (%s)(v, "left SELECT")left SELECT(pParse, 1, "LEFT")LEFT(v, "right SELECT")right SELECT(pParse, 1, "RIGHT")RIGHT(v, "Output routine for A")Output routine for A(v, "Output routine for B")Output routine for B(v, "eof-A subroutine")TK_EXCEPTTK_INTERSECTeof-A subroutine(v, "eof-B subroutine")eof-B subroutine(v, "A-lt-B subroutine")A-lt-B subroutine(v, "A-eq-B subroutine")A-eq-B subroutine(v, "A-gt-B subroutine")A-gt-B subroutineOP_PermutationOPFLAG_PERMUTEgenerateOutputSubroutineaddr2pDest->eDest!=SRT_ExistspDest->eDest!=SRT_TablepIn->nSdst>1(pParse, 0, "CREATE BLOOM FILTER")pDest->eDest==SRT_OutputOPFLAG_APPENDSRT_SetCREATE BLOOM FILTERSRT_MemOP_ResultRowsqlite3SelectWrongNumTermsErrorall VALUES must have the same number of terms"all VALUES must have the same number of terms"SELECTs to the left and right of %s do not have the same number of result columns"SELECTs to the left and right of %s"
      " do not have the same number of result columns"multiSelectp && p->pPrior(p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNIONp->selFlags & SF_CompoundpPrior->pOrderBy==0pPrior->pLimit==0p->pEListp->pEList && pPrior->pEListp->pEList->nExpr==pPrior->pEList->nExpr(pParse, 1, "COMPOUND QUERY")(pParse, 1, "LEFT-MOST SUBQUERY")!pPrior->pLimit("multiSelect UNION ALL left...\n")(v, "Jump ahead if LIMIT reached")(pParse, 1, "UNION ALL")("multiSelect UNION ALL right...\n")p->op==TK_EXCEPTp->op==TK_UNIONp->pLimit==0p->pOrderBy==0p->addrOpenEphm[0] == -1!pPrior->pOrderBy("multiSelect EXCEPT/UNION left...\n")(pParse, 1, "%s USING TEMP B-TREE", sqlite3SelectOpName(p->op))("multiSelect EXCEPT/UNION right...\n")unionTab==dest.iSDParm || dest.eDest!=priorOpp->pEList || db->mallocFailedp->op==TK_INTERSECT("multiSelect INTERSECT left...\n")p->addrOpenEphm[1] == -1("multiSelect INTERSECT right...\n")COMPOUND QUERYLEFT-MOST SUBQUERYJump ahead if LIMIT reachedOP_OffsetLimitUNION ALLunionTabpriorOpuniondestSRT_UnionSF_UsesEphemeralSRT_Except%s USING TEMP B-TREEtab1tab2intersectdestp->pNext==0pLoop->addrOpenEphm[1]<0apCollmulti_select_endhasAnchormultiSelectValuesbShowAllp->selFlags & SF_MultiValuep->selFlags & SF_Valuesp->op==TK_ALL || (p->op==TK_SELECT && p->pPrior==0)p->pNext==0 || p->pEList->nExpr==p->pNext->pEList->nExprp->pPrior->pNext==p(pParse, 0, "SCAN %d CONSTANT ROW%s", nRow, nRow==1 ? "" : "S")SCAN %d CONSTANT ROW%sSgenerateWithRecursiveQuerypSetuppFirstRecregCurrentiQueueiDistinct SRT_FifodestQueueregLimitregOffsetcannot use window functions in recursive queries"cannot use window functions in recursive queries"i<pSrc->nSrcSRT_DistQueueSRT_DistFifoSRT_QueueSRT_Fifo(v, "Queue table")Queue tablepFirstRec!=0recursive aggregate queries not supported"recursive aggregate queries not supported"(pParse, 1, "SETUP")SETUP(pParse, 1, "RECURSIVE STEP")RECURSIVE STEPpFirstRec->pPrior==0end_of_recursive_querymultiSelectOrderByKeyInfosqlite3KeyInfoIsWriteable(pRet)multiSelectCollSeqiCol<p->pEList->nExprcomputeLimitRegisterspLimit->op==TK_LIMITpLimit->pLeft!=0(v, "LIMIT counter")(v, "OFFSET counter")(v, "LIMIT+OFFSET")LIMIT counterOFFSET counterLIMIT+OFFSETsqlite3GetVdbeSQLITE_FactorOutConstsqlite3ResultSetOfSelect(u64)SQLITE_FullColNames18446744073709551611~(u64)SQLITE_FullColNamessqlite3SubqueryColumnTypes(pSelect->selFlags & SF_Resolved)!=0pTab->nCol==pSelect->pEList->nExpr || pParse->nErr>0aff==SQLITE_AFF_NONE || aff==SQLITE_AFF_BLOB&sNCCOLFLAG_NOINSERTSQLITE_AFF_FLEXNUMNUM"NUM"SQLITE_N_STDTYPECOLFLAG_HASTYPECOLFLAG_HASCOLL(COLFLAG_HASTYPE|COLFLAG_HASCOLL)-517~(COLFLAG_HASTYPE|COLFLAG_HASCOLL)sqlite3ColumnsFromExprListhtaCol==0nCol>32767sizeof(aCol[0])nCol==(i16)nColpColExpr!=0ExprUseYTab(pColExpr)(((pColExpr)->flags&(0x1000000|0x2000000))==0)pColExprpColExpr->y.pTab!=0!ExprHasProperty(pColExpr, EP_IntValue)zName==pX->zENamezName[j]pCollidecolumn%d"column%d"%.*z:%u"%.*z:%u"sizeof(cnt)sqlite3GenerateColumnNamesfullNamesrcNamepTabList!=0p->op!=TK_AGG_COLUMNp->op!=TK_COLUMN || (ExprUseYTab(p) && p->y.pTab!=0)iCol==-1 || (iCol>=0 && iCol<pTab->nCol)COLNAME_NAME("generating column names\n")generateColumnTypesCOLNAME_DECLTYPEcolumnTypeImplpNC->pSrcList!=0pTab && ExprUseYTab(pExpr) && pExpr->y.pTab==pTab&zOrigDb&zOrigTab&zOrigCol!pSiCol==XN_ROWID || (iCol>=0 && iCol<pTab->nCol)generateSortTailiParmregRowiSortTabbSeqnRefKeyaOutEx(pParse, 0, "USE TEMP B-TREE FOR %sORDER BY", pSort->nOBSat?"LAST TERM OF ":"" )(pParse, 0, "USE TEMP B-TREE FOR LAST %d TERMS OF ORDER BY", nKey )USE TEMP B-TREE FOR %sORDER BYLAST TERM OF USE TEMP B-TREE FOR LAST %d TERMS OF ORDER BYaddrBreak<0p->iLimit==0 && p->iOffset==0regSortOutOP_Sort(v, "%s", aOutEx[i].zEName)nColumn==sqlite3Strlen30(pDest->zAffSdst)eDest==SRT_Output || eDest==SRT_CoroutineeDest==SRT_OutputeDest==SRT_CoroutinepSort->addrPushpSort->addrPushEndexplainTempTable(pParse, 0, "USE TEMP B-TREE FOR %s", zUsage)sqlite3SelectOpName"UNION ALL"INTERSECT"INTERSECT"EXCEPT"EXCEPT"UNION"UNION"sqlite3KeyInfoFromExprListsqlite3KeyInfoIsWriteable(pInfo)sqlite3KeyInfoRefsqlite3KeyInfoUnrefp->db!=0sqlite3KeyInfoAllocsizeof(CollSeq*)sizeof(CollSeq*)+1(sizeof(CollSeq*)+1)sizeof(KeyInfo)selectInnerLoophasDistinctnResultColnPrefixRegsRowLoadInforegResultregOrigiContinue!=0(v, "%s", p->pEList->a[i].zEName)eDest==SRT_SeteDest==SRT_MemeDest==SRT_Set || eDest==SRT_Mem || eDest==SRT_Coroutine || eDest==SRT_Output || eDest==SRT_UpfrompSort!=0hasDistinct==0SRT_ExistsecelFlagsSQLITE_ECEL_OMITREFSQLITE_ECEL_REF(SQLITE_ECEL_OMITREF|SQLITE_ECEL_REF)RowLoadInfo *nResultCol==p->pEList->nExpreDest==SRT_TableeDest==SRT_EphemTabeDest==SRT_FifoeDest==SRT_DistFifopSort==0regResult==regOrigsqlite3Strlen30(pDest->zAffSdst)==nResultColnResultCol<=pDest->nSdstnResultCol==pDest->nSdstregResult==iParmpSOeDest==SRT_DiscardOP_IdxDeleter3addrTestfixDistinctOpenEphcodeDistinctsqlite3VdbeCurrentAddr(v)==iJump || pParse->db->mallocFailediJumpcodeOffset(v, "OFFSET")OFFSETpushOntoSorteriSkipbSeq==0 || bSeq==1nData==1 || regData==regOrigData || regOrigData==0nPrefixReg==nExpr+bSeqpSelect->iOffset==0 || pSelect->iLimit!=0pKI->nAllField > pKI->nKeyField+2regPrevKeyaddrFirstaddrJmppKIOP_SequenceTestOP_IfNotZeromakeSorterRecordregOutinnerLoopLoadRowsqlite3ProcessJoinpLeft->pSTab==0 || pRightTab==0&pRightTab->aCol[j]pUsing->nId>0pUsing->a[pUsing->nId-1].zName==0pE2!=0 || pEq==0!ExprHasProperty(pEq, EP_TokenOnly|EP_Reduced)EP_NoReducepRightTabJT_NATURALa NATURAL join may not have an ON or USING clause"a NATURAL join may not have "
           "an ON or USING clause"iLeftColiRightColpE1cannot join using column %s - column not present in both tables"cannot join using column %s - column "
            "not present in both tables"coalesce"coalesce"tkCoalescepFuncArgsambiguous reference to %s in USING()"ambiguous reference to %s in USING()"unsetJoinExprp->pLeft==042949672924292870143sqlite3SetJoinExprjoinFlag==EP_OuterON || joinFlag==EP_InnerONjoinFlag!ExprHasProperty(p, EP_TokenOnly|EP_Reduced)tableAndColumnIndexiEnd<pSrc->nSrciStart>=0(piTab==0)==(piCol==0)&pSrc->a[i].pSTab->aCol[iCol]sqlite3SrcItemColumnUsed(int)pItem->fg.isNestedFrom == IsNestedFrom(pItem)pItem->u4.pSubq!=0pItem->u4.pSubq->pSelect!=0pResults!=0iCol>=0 && iCol<pResults->nExprpResultssqlite3ColumnIndexconst Columnconst Column *u8[16]unsigned char[16]sizeof(pTab->aHx)i<nColsqlite3JoinTypeToken *[3]apAllzKeyTextnaturaleftouterightfullinnercross"naturaleftouterightfullinnercross"j==0 || j==1 || j==2 || j==3 || j==4 || j==5 || j==6ArraySize(aKeyword)const char[34]JT_ERROR(JT_INNER|JT_OUTER)(JT_OUTER|JT_LEFT|JT_RIGHT)zSp1zSp2unknown join type: %T%s%T%s%T"unknown join type: "
       "%T%s%T%s%T"findRightmostsqlite3SelectDeleteGenericsqlite3SelectDeletesqlite3SelectNewpAllocatedstandinsizeof(*pSrc)pNew->pSrc!=0 || pParse->nErr>0sqlite3SelectDestInitclearSelectp->pWithp->pWinDefnp->pWin->ppThis==&p->pWinSQLITE_PREPARE_SAVESQLSQLITE_PREPARE_MASKrc==SQLITE_OK || ppStmt==0 || *ppStmt==0sqlite3Prepare16zTail8143750chars_parsedsqlite3Repreparesqlite3_mutex_held(sqlite3VdbeDb(p)->mutex)sqlite3LockAndPrepare143601rc==SQLITE_OK || *ppStmt==0SQLITE_MAX_PREPARE_RETRY(rc&db->errMask)==rcrc==SQLITE_OK || (*ppStmt)==0sqlite3Prepare&sParseParseaTempRegPARSE_HDR_SZsLastTokenPARSE_TAIL_SZsParse.pReprepare==0ppStmt && *ppStmt==0eDistinctTypepNCpOuterNCbFreeppContextppMinMaxpSrcListbIgnoreAffBlobiExceptpiCursorpSrcItempSubstdoPriorpaColsrcTabeTnctTypeiOpenEphAddraddrRepeatregElemregDataregOrigDataiTablenullablepiTabpiColbIgnoreHiddensqlite3BtreeHoldsMutex(pBt)db->flags & SQLITE_ReadUncommitdatabase schema is locked: %s"database schema is locked: %s"nBytes==mxLennBytes==mxLen+1zSqlCopymxLenstatement too long"statement too long"0==sParse.nQueryLoop0==(*ppStmt)end_preparesqlite3ParseObjectInitdb->pParse!=pParsesqlite3ParserAddCleanupParseCleanup *pCleanupsizeof(*pCleanup)sqlite3ParseObjectResetpParse->nested==0TableLock *db->lookaside.bDisable >= pParse->disableLookasidesqlite3SchemaToIndexi<db->nDbi>=0 && i<db->nDbschemaIsValidcookiepParse->checkSchemaopenedTransactionsqlite3ReadSchemaDBFLAG_SchemaKnownOksqlite3Initcommit_internalsqlite3BtreeHoldsMutex(db->aDb[0].pBt)db->nDb>0i==1 || sqlite3BtreeHoldsMutex(db->aDb[i].pBt)sqlite3InitOneinitDatazSchemaTabName~DBFLAG_EncodingFixed(db->mDbFlags & DBFLAG_SchemaKnownOk)==0db->aDb[iDb].pSchemaiDb==1 || sqlite3BtreeHoldsMutex(db->aDb[iDb].pBt)CREATE TABLE x(type text,name text,tbl_name text,rootpage int,sql text)"CREATE TABLE x(type text,name text,tbl_name text,"
                            "rootpage int,sql text)"InitData *iDb==1ArraySize(meta)sizeof(meta)attached databases must use the same text encoding as main database"attached databases must use the same"
            " text encoding as main database"-2000SQLITE_DEFAULT_CACHE_SIZEBTREE_FILE_FORMATSQLITE_MAX_FILE_FORMATunsupported file format"unsupported file format"(u64)SQLITE_LegacyFileFmt18446744073709551613~(u64)SQLITE_LegacyFileFmtdb->init.busySELECT*FROM"%w".%s ORDER BY rowid"SELECT*FROM\"%w\".%s ORDER BY rowid"pDb == &(db->aDb[iDb])initone_error_outsqlite3InitCallbackargc==5int rcprcp =(rc&0xFF)==(rcp&0xFF)saved_iDbPgno *invalid rootpage"invalid rootpage"orphan index"orphan index"sqlite3IndexHasDuplicateRootPagecorruptSchemaINITFLAG_AlterMask(INITFLAG_AlterMask)"rename"drop column"drop column"add column"add column"azAlterTypeerror in %s %s after %s: %s"error in %s %s after %s: %s"142794malformed database schema (%s)"malformed database schema (%s)"%z - %s"%z - %s"142801sqlite3PragmaVtabRegisterconst PragmaNameconst PragmaName *PragmaName *sqlite3_strnicmp(zName, "pragma_", 7)==0PragFlg_Result0PragFlg_Result1(PragFlg_Result0|PragFlg_Result1)sqlite3HashFind(&db->aModule, zName)==0pragmaVtabRowidPragmaVtabCursor *pragmaVtabColumnPragmaVtab *pragmaVtabEofpragmaVtabFilterj<ArraySize(pCsr->azArg)pCsr->azArg[j]==0PRAGMA "PRAGMA "%Q."%Q."=%Q"=%Q"pragmaVtabNextpCsr->pPragmapragmaVtabClosepragmaVtabCursorClearpCsr->azArgArraySize(pCsr->azArg)pragmaVtabOpensizeof(PragmaVtabCursor)pragmaVtabBestIndex(double)1j < 22147483647.0(double)214748364720.0(double)20pragmaVtabDisconnectpragmaVtabConnectpPragmaCREATE TABLE x"CREATE TABLE x"%c"%s""%c\"%s\""const char *const[57]char *[57]("%s""(\"%s\"",arg HIDDEN",arg HIDDEN"PragFlg_SchemaOptPragFlg_SchemaReq(PragFlg_SchemaOpt|PragFlg_SchemaReq),schema HIDDEN",schema HIDDEN"strlen(zBuf) < sizeof(zBuf)-1sizeof(PragmaVtab)sqlite3PragmapIdaFcntl-%T"-%T"pId2PragFlg_NeedSchemaPragFlg_NoColumnsPragFlg_NoColumns1ArraySize(getCacheSize)getCacheSizeaOp==0pBt!=0zLeft[0]pDb==&db->aDb[0]eMode==PAGER_LOCKINGMODE_NORMAL || eMode==PAGER_LOCKINGMODE_EXCLUSIVEeAuto>=0 && eAuto<=2ArraySize(setMeta6)setMeta6pCol->colFlags & COLFLAG_HIDDENpColExpr==0 || pColExpr->op==TK_SPAN || isHidden>=2pColExpr==0 || !ExprHasProperty(pColExpr, EP_IntValue) || isHidden>=2pParse->nMem<=pPragma->nPragCNamedb->aDb[i].zDbSName!=0p->funcFlags & SQLITE_FUNC_BUILTINaPragmaName&db->aDb[iDb].pSchema->tblHashIsOrdinaryTable(pTab)pParse->nErr>0 || pFK==0x==0 || db->mallocFailedpFK->nCol==1 || db->mallocFailediDb==0 || pId2->zsqlite3SchemaMutexHeld(db, i, 0)pParse->nMem>=8+jsqlite3NoTempsInRange(pParse,1,7+j)!IsVirtual(pTab)j!=sqlite3TableColumnToStorage(pTab, j)p3!=jpCol->eCType>=1 && pCol->eCType<=sizeof(aStdTypeMask)iCol!=XN_ROWID && iCol<pTab->nCol!isQuickpVTab==0pVTab->pModule==0endCodeencnames[SQLITE_UTF8].enc==SQLITE_UTF8encnames[SQLITE_UTF16LE].enc==SQLITE_UTF16LEencnames[SQLITE_UTF16BE].enc==SQLITE_UTF16BEArraySize(setCookie)setCookieArraySize(readCookie)readCookiedb->pWalArgpPragma->ePragTyp==PragTyp_BUSY_TIMEOUTPragTyp_DEFAULT_CACHE_SIZEconst VdbeOpListconst VdbeOpList[9]VdbeOpList[9]OP_TransactionOP_ReadCookieiLnVDBE_OFFSET_LINENO(2)const VdbeOpList[]VdbeOpList[]const VdbeOpList *VdbeOpList *ONLY_IF_REALLOC_STRESS(aOp==0)OP_SetCookiePragTyp_PAGE_SIZEPragTyp_SECURE_DELETEfast"fast"PragTyp_PAGE_COUNTOP_Pagecount0xfffffffeOP_MaxPgcntPragTyp_LOCKING_MODEnormal"normal"PAGER_LOCKINGMODE_QUERYPAGER_LOCKINGMODE_EXCLUSIVEexclusive"exclusive"PragTyp_JOURNAL_MODEPAGER_JOURNALMODE_QUERYPAGER_JOURNALMODE_OFFOP_JournalModePragTyp_JOURNAL_SIZE_LIMITPragTyp_AUTO_VACUUMeAutoconst VdbeOpList[5]VdbeOpList[5]BTREE_LARGEST_ROOT_PAGEBTREE_INCR_VACUUMPragTyp_INCREMENTAL_VACUUMOP_IncrVacuumPragTyp_CACHE_SIZEPragTyp_CACHE_SPILL(u64)SQLITE_CacheSpill18446744073709551583~(u64)SQLITE_CacheSpillPragTyp_MMAP_SIZEPragTyp_TEMP_STOREPragTyp_TEMP_STORE_DIRECTORYnot a writable directory"not a writable directory"SQLITE_TEMP_STOREPragTyp_SYNCHRONOUSSafety level may not be changed inside a transaction"Safety level may not be changed inside a transaction"PAGER_SYNCHRONOUS_MASKPragTyp_FLAG(SQLITE_ForeignKeys)18446744073709535231~(SQLITE_ForeignKeys)PragTyp_TABLE_INFOLOCATE_NOERRnHiddenisHiddenCOLFLAG_STOREDissisii"issisii"issisi"issisi"PragTyp_TABLE_LISTinitNColSELECT*FROM"%w""SELECT*FROM\"%w\""pDummyview"view"virtual"virtual"shadow"shadow"sssiii"sssiii"PragTyp_INDEX_INFOiIdxDbcnumiisX"iisX"isiX"isiX"PragTyp_INDEX_LISTazOrigin"c""u""pk"isisi"isisi"PragTyp_DATABASE_LISTiss"iss"PragTyp_COLLATION_LISTis"is"PragTyp_FUNCTION_LISTshowInternFuncSQLITE_FUNC_HASH_SZFuncDef *[23]FuncDef **PragTyp_MODULE_LISTPragTyp_PRAGMA_LISTconst PragmaName[66]PragmaName[66]1584ArraySize(aPragmaName)PragTyp_FOREIGN_KEY_LISTFKey *pFKiissssss"iissssss"sColMap[1]sColMap *u8[2]PragTyp_FOREIGN_KEY_CHECKaddrOkaiColsIndex **siX"siX"PragTyp_CASE_SENSITIVE_LIKEPragTyp_INTEGRITY_CHECKmxErrpObjTabSQLITE_INTEGRITY_CHECK_ERROR_MAXOP_IntegrityCk*** in database %s ***
"*** in database %s ***\n"OP_Concatwrong # of entries in index "wrong # of entries in index "loopTopbStrictmxColrow not in PRIMARY KEY order for %s"row not in PRIMARY KEY order for %s"labelErrorlabelOkp3p4doTypeCheckCOLTYPE_ANYpDfltValuejmp3jmp2OP_IsTypeNULL value in %s.%s"NULL value in %s.%s"unsigned char[6]0x180x110x130x14aStdTypeMasknon-%s value in %s.%s"non-%s value in %s.%s"0x1cNUMERIC value in %s.%s"NUMERIC value in %s.%s"0x1b"C"TEXT value in %s.%s"TEXT value in %s.%s"addrCkFaultaddrCkOkCHECK constraint failed in %s"CHECK constraint failed in %s"jmp4jmp5label6ckUniqrow "row " missing from index " missing from index "jmp7rowid not at end-of-record for row "rowid not at end-of-record for row " of index " of index "jmp6 values differ from index " values differ from index "uniqOknon-unique entry in index "non-unique entry in index "OP_VCheckP4_TABLEREFconst VdbeOpList[7]VdbeOpList[7]ArraySize(endCode)PragTyp_ENCODINGconst EncNameconst EncName[9]EncName[9]UTF8"UTF8"UTF-8"UTF-8"UTF-16le"UTF-16le"UTF-16be"UTF-16be"UTF16le"UTF16le"UTF16be"UTF16be"UTF-16"UTF-16"UTF16"UTF16"const EncName[]EncName[]encnamesconst EncName *EncName *pEncunsupported encoding: %s"unsupported encoding: %s"PragTyp_HEADER_VALUEiCookiePragFlg_ReadOnlyconst VdbeOpList[2]VdbeOpList[2]const VdbeOpList[3]VdbeOpList[3]PragTyp_COMPILE_OPTIONSPragTyp_WAL_CHECKPOINTiBt SQLITE_CHECKPOINT_PASSIVErestart"restart"OP_CheckpointPragTyp_WAL_AUTOCHECKPOINTPragTyp_SHRINK_MEMORYPragTyp_OPTIMIZEiDbLastszThresholdnBtree0xfffeSQLITE_DEFAULT_OPTIMIZE_LIMITconst LogEstiRangeOP_IfSizeBetweenANALYZE "%w"."%w""ANALYZE \"%w\".\"%w\""OP_SqlExecPragTyp_SOFT_HEAP_LIMITPragTyp_HARD_HEAP_LIMITiPriorPragTyp_THREADSPragTyp_ANALYSIS_LIMITpragma_outintegrityCheckResultRowpragmaFunclistLineSQLITE_FUNC_INTERNAL3934208SQLITE_FUNC_ENCMASK==0x3strcmp(azEnc[SQLITE_UTF8],"utf8")==0strcmp(azEnc[SQLITE_UTF16LE],"utf16le")==0strcmp(azEnc[SQLITE_UTF16BE],"utf16be")==0"utf8"azEncsissii"sissii"pragmaLocateuprlwrmidsqlite3JournalModenameazModeNamePAGER_JOURNALMODE_DELETE==0PAGER_JOURNALMODE_PERSIST==1PAGER_JOURNALMODE_OFF==2PAGER_JOURNALMODE_TRUNCATE==3PAGER_JOURNALMODE_MEMORY==4PAGER_JOURNALMODE_WAL==5eMode>=0 && eMode<=ArraySize(azModeName)char *const[6]ArraySize(azModeName)persist"persist"wal"wal"actionNameaction==OE_NoneSET NULL"SET NULL"SET DEFAULT"SET DEFAULT"CASCADE"CASCADE"RESTRICT"RESTRICT"NO ACTION"NO ACTION"setAllPagerFlagsSQLITE_FullFSync==PAGER_FULLFSYNCSQLITE_CkptFullFSync==PAGER_CKPT_FULLFSYNCSQLITE_CacheSpill==PAGER_CACHESPILL(PAGER_FULLFSYNC | PAGER_CKPT_FULLFSYNC | PAGER_CACHESPILL) == PAGER_FLAGS_MASK(pDb->safety_level & PAGER_SYNCHRONOUS_MASK)==pDb->safety_levelreturnSingleTextreturnSingleIntOP_Int64-13P4_INT64setPragmaResultColumnNameschangeTempStoragetsinvalidateTempStoragetemporary storage cannot be changed from within a transaction"temporary storage cannot be changed "
        "from within a transaction"getTempStoregetAutoVacuumnone"none"BTREE_AUTOVACUUM_NONEBTREE_AUTOVACUUM_FULLincremental"incremental"BTREE_AUTOVACUUM_INCRgetLockingModePAGER_LOCKINGMODE_NORMALsqlite3GetBooleangetSafetyLevelonoffalseyestruextrafull"onoffalseyestruextrafull"iLengthiValueArraySize(iLength)const char[25]sqlite3AutoLoadExtensionsgozErrmsgmutexpThunkautomatic extension loading failed: %s"automatic extension loading failed: %s"sizeof(wsdAutoext.aExt[0])SQLITE_LoadExtFunc196608(u64)(SQLITE_LoadExtension|SQLITE_LoadExtFunc)18446744073709355007~(u64)(SQLITE_LoadExtension|SQLITE_LoadExtFunc)sqlite3CloseExtensionssqlite3LoadExtensionhandlezEntryzAltEntryaHandlenMsgazEndingsnot authorized"not authorized"sqlite3_extension_init"sqlite3_extension_init"const char *[1]char *[1]ArraySize(azEndings)zAltFilezFile[iFile]iFileiEntryncFilesqlite3_"sqlite3_"lib"lib"_init"_init"nMsg<0x7fffffffno entry point [%s] in shared library [%s]"no entry point [%s] in shared library [%s]"error during initialization: %s"error during initialization: %s"sizeof(handle)extension_not_foundunable to open shared library [%.*s]"unable to open shared library [%.*s]"so"so"callbackIsInit137259azCols[i]!=0SQLITE_NullCallbackexec_outxferOptimizationpSrcIdxpDestIdxiDbSrciDestemptyDestTestemptySrcTestregAutoincdestHasUniqueIdxpSelect->pSrcpEList!=0pEList->a[0].pExprpSrc!=pDestpDestCol->colFlags & COLFLAG_VIRTUALpDestCol->colFlags & COLFLAG_STOREDpDestExpr==0 || pDestExpr->op==TK_SPANpDestExpr==0 || !ExprHasProperty(pDestExpr, EP_IntValue)pSrcExpr==0 || pSrcExpr->op==TK_SPANpSrcExpr==0 || !ExprHasProperty(pSrcExpr, EP_IntValue)pDestColpSrcColpDestExprpSrcExpr411IsOrdinaryTable(pDest)HasRowid(pDest) || destHasUniqueIdx(pDest->tabFlags & TF_Autoincrement)==0insFlagsOP_SeekEndOPFLAG_PREFORMATOPFLAG_NCHANGEOPFLAG_LASTROWIDOP_RowCellP4_TABLE(v, "%s", pSrcIdx->zName)(v, "%s", pDestIdx->zName)idxInsFlagsOPFLAG_BULKCSR(OPFLAG_USESEEKRESULT|OPFLAG_PREFORMAT)xferCompatibleIndexpDest && pSrcpDest->pTable!=pSrc->pTablepSrc->aColExpr!=0 && pDest->aColExpr!=0sqlite3OpenTableAndIndicesop==OP_OpenRead || op==OP_OpenWriteop==OP_OpenWrite || p5==0piDataCur!=0piIdxCur!=0999-999pIdx->pSchema==pTab->pSchema(v, "%s", pIdx->zName)sqlite3CompleteInsertionpik_flagsupdate_flags==0 || update_flags==OPFLAG_ISUPDATE || update_flags==(OPFLAG_ISUPDATE|OPFLAG_SAVEPOSITION)pIdx->onError!=OE_Replace || pIdx->pNext==0 || pIdx->pNext->onError==OE_ReplaceiIdxCur+iaRegIdx[i]sqlite3GenerateConstraintChecksseenReplacenPkFieldpUpsertClauseisUpdatebAffinityDoneupsertIpkReturnupsertIpkDelayipkTopipkBottomregTrigCntaddrRechecklblRecheckOknReplaceTrigsIdxIterpCol->colFlags & COLFLAG_VIRTUALpCol->colFlags & COLFLAG_STOREDpCol->colFlags & COLFLAG_GENERATED!isGeneratedonError==OE_Rollback || onError==OE_Abort || onError==OE_Fail || onError==OE_Ignore || onError==OE_Replacei!=sqlite3TableColumnToStorage(pTab, i)(pCol->colFlags & COLFLAG_GENERATED)==0zMsg==0 && db->mallocFailed==0onError==OE_IgnoreTF_HasNotNullb2ndPassnSeenReplacenGeneratedisGeneratedOP_HaltIfNull1299P5_ConstraintNotNullzName!=0 || pParse->db->mallocFailedallOkP4_TRANSIENTP5_ConstraintCheckIndexListTerm *pUpsert->pNextUpsert==0aRegIdx[nIdx]>0i==nIdxOE_UpdatebUsedsizeof(IndexListTerm)sizeof(IndexListTerm)+1(sizeof(IndexListTerm)+1)(v, "trigger count")24576(SQLITE_RecTriggers|SQLITE_ForeignKeys)trigger count(v, "defer IPK REPLACE until last")(v, "uniqueness check for ROWID")onError==OE_RollbackonError==OE_AbortonError==OE_FailaddrRowidOkdefer IPK REPLACE until lastSQLITE_NOTNULLuniqueness check for ROWID(v, "prep index %s", pIdx->zName)(v, "%s column %d", pIdx->zName, i)(v, "rowid")sqlite3TableColumnToStorage(pTab, iField)!=iField(v, "%s", pTab->aCol[iField].zCnName)(v, "for %s", pIdx->zName)regIdxpIdx->nColumn(v, "%s.%s", pTab->zName, pTab->aCol[pPk->aiColumn[i]].zCnName)op==OP_Eqop==OP_NeonError==OE_Rollback || onError==OE_Abort || onError==OE_Fail || onError==OE_Ignore || onError==OE_Replace || onError==OE_UpdateonError==OE_ReplacenConflictCk>0 || db->mallocFailednConflictCk<=0nConflictCk>1(v, "bypass recheck")x.p4.ip2!=x.p2regRiThisCuraddrUniqueOkaddrConflictCkprep index %s%s column %dOP_IntCopyOP_NoConflictaddrJump OP_NeregCmpnConflictCkOP_CursorLockOP_CursorUnlockaddrBypassbypass recheckzP4const unsigned char[190]unsigned char[190]OPFLG_JUMPIndexIterator *(v, "Do IPK REPLACE")ipkBottom>0Do IPK REPLACEregTrigCnt!=0 || nReplaceTrig==0(v, "BEGIN: GenCnstCks(%d,%d,%d,%d,%d)", iDataCur, iIdxCur, regNewData, regOldData, pkChng)regTrigCnt!=0 && nReplaceTrig==0(v, "END: GenCnstCks(%d)", seenReplace)indexIteratorNextindexIteratorFirstpIter->i==0sqlite3ExprReferencesUpdatedColumn(w.eCode & CKCNSTRNT_ROWID)!=0CKCNSTRNT_ROWID~CKCNSTRNT_ROWIDw.eCode==0w.eCode==CKCNSTRNT_COLUMNw.eCode==CKCNSTRNT_ROWIDw.eCode==(CKCNSTRNT_ROWID|CKCNSTRNT_COLUMN)checkConstraintExprNodepExpr->iColumn>=0 || pExpr->iColumn==-1CKCNSTRNT_COLUMNsqlite3InsertipkColumnendOfLoopaddrInsTopuseTempTableappendFlagwithoutRowidbIdListInOrderiRegStoreregFromSelectregInsaTabColMapiDb<db->nDb(pTrigger && tmask) || (pTrigger==0 && tmask==0)!pTriggerpList==0TF_HasStored(TF_OOOHidden|TF_HasStored)!withoutRowid(COLFLAG_STORED|COLFLAG_VIRTUAL)cannot INSERT into generated column "%s""cannot INSERT into generated column \"%s\""table %S has no column named %s"table %S has no column named %s"pSubq->pSelect!=0pSubq->pSelect->pEList!=0(pParse, 0, "SCAN %S", pItem)pSelect->pEListuseTempTable==0SCAN %SregTempRowidaddrLpTab->aCol[i].colFlags & COLFLAG_VIRTUALpTab->aCol[i].colFlags & COLFLAG_STOREDTF_HasHidden==COLFLAG_HIDDENTF_HasGenerated==COLFLAG_GENERATEDCOLFLAG_NOINSERT==(COLFLAG_GENERATED|COLFLAG_HIDDEN)(TF_HasGenerated|TF_HasHidden)table %S has %d columns but %d values were supplied"table %S has %d columns but %d values were supplied"%d values for %d columns"%d values for %d columns"pNxUPSERT not implemented for virtual table "%s""UPSERT not implemented for virtual table \"%s\""cannot UPSERT a view"cannot UPSERT a view"pTab->nColregData==regRowid+1i>=nHiddenj>=0 && j<=pColumn->nIdOP_SoftNullpSelect==0pTab->nNVCol>0 || pParse->nErr>0regColspIpkisReplacebUseSeekinsert_endrows inserted"rows inserted"insert_cleanupsqlite3MultiValuespLeft->pNext==0pRet->pNext==0!p->fg.isIndexedBy && !p->fg.isTabFuncpParse->nErr || dest.iSdst>0!p->fg.isTabFunc && !p->fg.isIndexedByp->fg.isSubqueryexprListIsNoAffinitypExpr->op!=TK_RAISEpExpr->affExpr==0exprListIsConstantsqlite3MultiValuesEnd(pItem->fg.isSubquery && pItem->u4.pSubq!=0) || pParse->nErrsqlite3AutoincrementEndAutoincInfo *autoIncrementEndsqlite3SchemaMutexHeld(db, 0, pDb->pSchema)autoIncEndiRecmemIdArraySize(autoIncEnd)autoIncStepOP_MemMaxsqlite3AutoincrementBeginpParse->pTriggerTab==0autoIncconst VdbeOpList[12]VdbeOpList[12]ArraySize(autoInc)autoIncBeginpParse->db->aDb[iDb].pSchema!=0pSeqTabIsVirtual(pSeqTab)((pSeqTab)->eTabType==1)523sqlite3ComputeGeneratedColumnspRedoeProgresspTab->tabFlags & TF_HasGeneratedzP4!=0pOp->p4type==P4_DYNAMICOP_TypeCheckCOLFLAG_NOTAVAILCOLFLAG_BUSY~COLFLAG_BUSY~COLFLAG_NOTAVAILgenerated column loop on "%s""generated column loop on \"%s\""exprColumnFlagUnionpExpr->iColumn < pWalker->u.pTab->nColreadsTablepOp->p4.pVtab!=0pOp->p4type==P4_VTABsqlite3TableAffinityzColAffpPrev->opcode==OP_MakeRecord || sqlite3VdbeDb(v)->mallocFailedzColAff!=0sqlite3VdbeGetLastOp(v)->opcode==OP_MakeRecord || sqlite3VdbeDb(v)->mallocFailedsqlite3TableAffinityStrsqlite3IndexAffinityStrcomputeIndexAffStrx==XN_EXPRSQLITE_AFF_INTEGERsqlite3OpenTablepParse->pVdbe!=0opcode==OP_OpenWrite || opcode==OP_OpenRead(v, "%s", pTab->zName)pPk->tnum==pTab->tnum || CORRUPT_DBsqlite3FkDeletepFKeydb==0 || sqlite3SchemaMutexHeld(db, 0, pTab->pSchema)pFKey->isDeferred==0 || pFKey->isDeferred==1Trigger *[2]sqlite3FkActionspActfkActionTriggeractioniActionxCleanuppInitazObjzExtrapId1minusFlagisBuiltinshowInternFuncszStorageTypedfltomitFulliDbDestp5piDataCurpiIdxCurregNewDataupdate_flagsappendBiasuseSeekResultregOldDatapkChngoverrideErrorignoreDestpbMayReplaceaiChngaChangebChngRowidaiCol || pFKey->nCol==1iFromCol>=0pIdx!=0 || (pTab->iPKey>=0 && pTab->iPKey<pTab->nCol)pIdx==0 || pIdx->aiColumn[i]>=0pSrc->nSrc==1pSrc->a[0].fg.fixedSchema==0 && pSrc->a[0].fg.isSubquery==0pStep!=0pTrigger!=0aiColtOldold"old"tNewtFromColtToColiFromColpDfltpRaiseFOREIGN KEY constraint failed"FOREIGN KEY constraint failed"sizeof(Trigger) +         /* struct Trigger */
        sizeof(TriggerStep)sqlite3FkRequiredbHaveFKsqlite3FkOldmaskp->aCol[i].iFrompIdx->aiColumn[i]>=0pIdx->aiColumn[i]sqlite3FkCheckisIgnoreErrors(regOld==0)!=(regNew==0)isIgnoreErrors==0 || (regOld!=0 && regNew==0)pFKey->nCol==1 || (aiFree && pIdx)aiFreeOP_FkCounterrcauthregOld==0 && regNew!=0eActionisSetNullAction(pTop->db->flags & SQLITE_FkNoAction)==0fkParentIsModifiedfkChildIsModifiediChildKeysqlite3FkDropTableOP_FkIfZero787P5_ConstraintFKsqlite3FkClearTriggerCachefkTriggerDeletesqlite3FkReferencesfkScanChildrensNameContextiFkIfZeropIdx==0 || pIdx->pTable==pTabpIdx==0 || pIdx->nKeyCol==pFKey->nColpIdx!=0 || pFKey->nCol==1pIdx!=0 || HasRowid(pTab)pNesizeof(NameContext)exprTableColumnexprTableRegisterfkLookupParentiOkaiCol[i]!=pTab->iPKeyiMustBeIntregTempnIncr==1(!pFKey->isDeferred && !(pParse->db->flags & SQLITE_DeferFKs) && !pParse->pToplevel && !pParse->isMultiWrite) ? OE_Abort : OE_Ignoresqlite3FkLocateIndexppIdx && *ppIdx==0!paiCol || *paiCol==0nCol>1zDfltCollzIdxColforeign key mismatch - "%w" referencing "%w""foreign key mismatch - \"%w\" referencing \"%w\""sqlite3RegisterBuiltinFunctionsimplies_nonnull_rowINLINEFUNC_implies_nonnull_rowexpr_compareINLINEFUNC_expr_compareexpr_implies_exprINLINEFUNC_expr_implies_expraffinityINLINEFUNC_affinityloadExtsqlite_compileoption_usedcompileoptionusedFuncsqlite_compileoption_getcompileoptiongetFuncunlikelyINLINEFUNC_unlikelySQLITE_FUNC_UNLIKELY0x0400likelihoodlikelysqlite_offsetINLINEFUNC_sqlite_offsetltrimtrimFuncrtrimtrimminmaxFuncminmaxStepminMaxFinalizeminMaxValueSQLITE_FUNC_MINMAX|SQLITE_FUNC_ANYORDER0x1000|0x08000000typeoftypeofFuncSQLITE_FUNC_TYPEOFsubtypesubtypeFuncSQLITE_FUNC_TYPEOF|SQLITE_SUBTYPE0x0080|0x000100000lengthFuncSQLITE_FUNC_LENGTH0x0040octet_lengthbytelengthFuncSQLITE_FUNC_BYTELEN0x00c0instrinstrFuncprintfFuncunicodeunicodeFunccharFuncabsFuncroundFuncupperupperFunclowerlowerFunchexhexFuncunhexunhexFuncconcatconcatFuncconcat_wsconcatwsFuncifnullINLINEFUNC_coalescerandomFuncrandomblobrandomBlobnullifnullifFuncsqlite_versionversionFuncsqlite_source_idsourceidFuncsqlite_logerrlogFuncquoteFunclast_insert_rowidtotal_changesreplaceFunczeroblobzeroblobFuncsubstrsubstrFuncsubstringsumsumStepsumFinalizesumInversetotaltotalFinalizeavgavgFinalizecountStepcountFinalizecountInverseSQLITE_FUNC_COUNT|SQLITE_FUNC_ANYORDER0x0100|0x08000000SQLITE_FUNC_ANYORDERgroup_concatgroupConcatStepgroupConcatFinalizegroupConcatValuegroupConcatInversestring_agg&globInfoSQLITE_FUNC_LIKE|SQLITE_FUNC_CASE0x0004|0x0008&likeInfoNormSQLITE_FUNC_LIKEunknownunknownFuncxCeilceilingFuncceilingxFloorlnlogFuncmath1Funcmath2FuncpowermodradiansdegToRaddegreesradToDegpiFuncsignFunciifINLINEFUNC_iififaBuiltinFuncFuncDef[104]7488ArraySize(aBuiltinFunc)865075386671371286144112863489891289711010049839680083968011258291312584961125859858390689838864183927371426104658390785943936183907218390849838886514260659314260633783906618390669const compareInfoconst compareInfo *compareInfo *type03.141592653589793116type1v0ans180.057.29577951308232286180.0/M_PI(180.0/M_PI)0.01745329251994329547(M_PI/180.0)sqlite3_user_data(context)sqlite3IsLikeFunctionpExpr->op==TK_FUNCTIONpDef==0(char*)&likeInfoAlt == (char*)&likeInfoAlt.matchAll&((char*)&likeInfoAlt)[1] == (char*)&likeInfoAlt.matchOne&((char*)&likeInfoAlt)[2] == (char*)&likeInfoAlt.matchSet!ExprHasProperty(pEscape, EP_IntValue)pEscapezEscapeSQLITE_FUNC_CASEsqlite3RegisterLikeFunctions~SQLITE_FUNC_UNSAFEsqlite3RegisterPerConnectionBuiltinFunctionsMATCH"MATCH"rc==SQLITE_NOMEM || rc==SQLITE_OKGroupConcatCtx *pGCCpAccumsizeof(*pGCC)pGCC->nAccum >= 0nVSpGCC->nAccum>0firstTermpnslminMaxValueFinalizeMem *sizeof(*pBest)const Memconst Mem *CountCtx *argc==1 || p==0 || p->n>0x7fffffff || p->bInverse || p->n==sqlite3_aggregate_count(context)SumCtx * 0.0integer overflow"integer overflow"p->cnt>0volatile SumCtxvolatile SumCtx *volatile doublekahanBabuskaNeumaierInit4503599627370496LL-4503599627370496-4503599627370496LL+4503599627370496LLiSmkahanBabuskaNeumaierStepInt64iBigkahanBabuskaNeumaierStepconcatFuncCorej<=nzCharSetaLenazCharnCharzIn==sqlite3_value_text(argv[0])unsigned char *constunsigned char *const[1]unsigned char *[1]const unsigned int[1]lenOneunsigned char *const[]unsigned char *[]azOneunsigned char *const *sizeof(unsigned)sizeof(char*)+sizeof(unsigned)(sizeof(char*)+sizeof(unsigned))zRepnPatternnReploopLimitcntExpandargc==3zStr==sqlite3_value_text(argv[0])sqlite3_value_type(argv[1])==SQLITE_NULL || sqlite3_context_db_handle(context)->mallocFailedsqlite3_value_type(argv[1])!=SQLITE_NULLzPattern==sqlite3_value_text(argv[1])zRep==sqlite3_value_text(argv[2])nOut<SQLITE_MAX_LENGTHnOut-1==db->aLimit[SQLITE_LIMIT_LENGTH]nOut-2==db->aLimit[SQLITE_LIMIT_LENGTH]zOldj+nStr-i+1<=nOutj<=nOutzPassnPasszHexnHexzHex<=zEnd*zEnd==0x00unhex_doneunhex_nullstrContainsChartstpBlob==sqlite3_value_blob(argv[0])0x1fffff0x000800x008000xE00xF0sqlite3QuoteValuepStr!=0 && pStr->nChar==0zBlob==sqlite3_value_blob(pValue)sqlite3_value_type(pValue)==SQLITE_NULL%!0.20e"%!0.20e"likeFuncescapenPatbackupInfoLIKE or GLOB pattern too complex"LIKE or GLOB pattern too complex"ESCAPE expression must be a single character"ESCAPE expression must be a single character"sizeof(backupInfo)SQLITE_MATCHnPat==db->aLimit[SQLITE_LIMIT_LIKE_PATTERN_LENGTH]nPat==db->aLimit[SQLITE_LIMIT_LIKE_PATTERN_LENGTH]+1patternComparematchOnematchAllzEscapedmatchOther<0x80zStringSQLITE_NOWILDCARDMATCHSQLITE_NOMATCHzStopz2==(char*)sqlite3_value_text(argv[0])z2[i]contextMallocnByte==db->aLimit[SQLITE_LIMIT_LENGTH]nByte==db->aLimit[SQLITE_LIMIT_LENGTH]+14503599627370496.0-4503599627370496.0+4503599627370496.0-0.5+0.5%!.*f"%!.*f"p0typeargc==3 || argc==2len==sqlite3_value_bytes(argv[0])p1>=0 && p2>=0p2>0SQLITE_PRINTF_SQLFUNCPrintfArguments *zHaystackzNeedlenHaystacknNeedletypeHaystacktypeNeedleisTextfirstCharpC1pC2endInstrendInstrOOMz0azTypei>=0 && i<ArraySize(azType)SQLITE_INTEGER==1SQLITE_FLOAT==2SQLITE_TEXT==3SQLITE_BLOB==4SQLITE_NULL==5real"real""text"blob"blob"argc>1mask==-1 || mask==0mask==0sqlite3SkipAccumulatorLoadcontext->isError<=0sqlite3GetFuncCollSeqcontext->pVdbe!=0Op *pOp->opcode==OP_CollSeqpOp->p4type==P4_COLLSEQsqlite3ResolvePartIdxLabelsqlite3GenerateIndexKeysqlite3GenerateRowIndexDeleteiPartIdxLabeliIdxCur+i!=iDataCur || pPk==pIdx(v, "GenRowIdxDel for %s", pIdx->zName)sqlite3GenerateRowDeleteiOldopSeekopSeek==OP_NotExistsopSeek==OP_NotFoundmask!=0xffffffff && iCol==31mask!=0xffffffff && iCol==32iIdxNoSeek>=0OPFLAG_AUXDELETE(v, "BEGIN: GenRowDel(%d,%d,%d,%d)", iDataCur, iIdxCur, iPk, (int)nPk)(v, "END: GenRowDel()")sqlite3DeleteFrommemCntiEphCuriRowSetaddrLoopaddrEphOpenrcauth==SQLITE_OK || rcauth==SQLITE_DENY || rcauth==SQLITE_IGNORE!isView || pTrigger!isViewnPk==1IsVirtual(pTab)==0 || eOnePass!=ONEPASS_MULTIIsVirtual(pTab) || bComplex || eOnePass!=ONEPASS_OFF || OptimizationDisabled(db, SQLITE_OnePass)pPk || IsVirtual(pTab) || iDataCur==iTabCurpPk || IsVirtual(pTab) || iIdxCur==iDataCur+1nKey==nPkpPk!=0 || IsView(pTab)nKey==1OP_ClearwcfNC_SubqueryOP_RowSetAddiAddrOnceOP_RowSetReadrows deleted"rows deleted"delete_from_cleanupsqlite3MaterializeViewpFrom->nSrc==1pFrom->a[0].fg.fixedSchema==0 && pFrom->a[0].fg.isSubquery==0pFrom->a[0].fg.isUsing==0pFrom->a[0].u3.pOn==0sqlite3IsReadOnlytable %s may not be modified"table %s may not be modified"cannot modify %s because it is a view"cannot modify %s because it is a view"tabIsReadOnlyTF_Readonly(TF_Readonly|TF_Shadow)pTab->tabFlags & TF_ShadowvtabIsReadOnlysqlite3CodeChangeCountOP_FkChecksqlite3SrcListLookuppItem && pSrc->nSrc>=1sqlite3SchemaGetsizeof(Schema)sqlite3SchemaClearxdbsizeof(xdb)&temp2&temp1DB_ResetWanted(DB_SchemaLoaded|DB_ResetWanted)~(DB_SchemaLoaded|DB_ResetWanted)sqlite3FindFunctionbestScorenArg>=(-2)nArg>=(-1) || createFlag==0scoresqlite3UpperToLower[(u8)zName[0]]FUNC_PERFECT_MATCHsqlite3InsertBuiltinFuncszName[0]aDef[i].funcFlags & SQLITE_FUNC_BUILTINpOther!=&aDef[i] && pOther->pNext!=&aDef[i]sqlite3FunctionSearchmatchQualityp->nArg>=(-4) && p->nArg!=(-2)sqlite3LocateCollSeqinitbusysqlite3GetCollSeq!p || p->xCmpno such collation sequence: %s"no such collation sequence: %s"sqlite3SetTextEncodingenc==SQLITE_UTF8 || enc==SQLITE_UTF16LE || enc==SQLITE_UTF16BEsqlite3FindCollSeqSQLITE_UTF8==1 && SQLITE_UTF16LE==2 && SQLITE_UTF16BE==3enc>=SQLITE_UTF8 && enc<=SQLITE_UTF16BEfindCollSeqEntrypDel==0 || pDel==pCollsizeof(*pColl)3*sizeof(*pColl)sqlite3CheckCollSeqp==pCollsynthCollSeqaEncsizeof(CollSeq)callCollNeeded!db->xCollNeeded || !db->xCollNeeded16zExternalsqlite3WithDeleteGenericsqlite3WithDeletesqlite3WithAddduplicate WITH table name: %s"duplicate WITH table name: %s"sizeof(*pWith)sizeof(pWith->a[1])(pNew!=0 && zName!=0) || db->mallocFailedsqlite3CteDeletepCte!=0cteClearsqlite3CteNewpNew!=0 || db->mallocFailedsqlite3KeyInfoOfIndexsqlite3KeyInfoIsWriteable(pKey)0==(pKey->aSortFlags[i] & KEYINFO_ORDER_BIGNULL)pParse->rc==SQLITE_ERROR_MISSING_COLLSEQsqlite3ReindexpObjNamepName2==0pName1->zunable to identify the object to be reindexed"unable to identify the object to be reindexed"reindexDatabases&pDb->pSchema->tblHashreindexTablecollationMatchzColl!=0z!=0 || pIndex->aiColumn[i]<0sqlite3RowidConstraint1555%s.rowid"%s.rowid"2579P5_ConstraintUniquesqlite3UniqueConstrainterrMsgpIdx->aiColumn[j]>=0index '%q'"index '%q'"2067sqlite3HaltConstraint(errCode&0xff)==SQLITE_CONSTRAINT || pParse->nestedsqlite3MayAbortsqlite3MultiWritesqlite3BeginWriteOperationpToplevel->writeMasksqlite3CodeVerifyNamedSchemasqlite3CodeVerifySchemasqlite3CodeVerifySchemaAtTopleveliDb>=0 && iDb<pToplevel->db->nDbpToplevel->db->aDb[iDb].pBt!=0 || iDb==1iDb<SQLITE_MAX_DBsqlite3SchemaMutexHeld(pToplevel->db, iDb, 0)pToplevel->cookieMask!OMIT_TEMPDBsqlite3OpenTempDatabasedb->aDb[1].pSchema542unable to open a temporary database file for storing temporary tables"unable to open a temporary database "
        "file for storing temporary tables"sqlite3Savepoint!SAVEPOINT_BEGIN && SAVEPOINT_RELEASE==1 && SAVEPOINT_ROLLBACK==2const char *const[3]RELEASE"RELEASE"ROLLBACK"ROLLBACK"OP_Savepointsqlite3EndTransactionisRollbackpParse!=0pParse->db!=0eType==TK_COMMIT || eType==TK_END || eType==TK_ROLLBACKTK_ROLLBACKOP_AutoCommitsqlite3BeginTransactioneTxnTypeTK_EXCLUSIVEsqlite3SrcListShiftJoinTypei>0allFlagssqlite3SrcListFuncArgspItem->fg.notIndexed==0pItem->fg.isIndexedBy==0sqlite3SrcListAppendListp1 && p1->nSrc==1sqlite3SrcListIndexedBypIndexedBy!=0p->nSrc>0pItem->fg.isCte==0sqlite3SrcListAppendFromTerma JOIN clause is required before %s"a JOIN clause is required before %s"USING"USING"(pTable==0)==(pDatabase==0)pItem->zName==0 || pDatabase!=0pDatabasepAlias!=0pSubquery==0 || pDatabase==0pOnUsing==0 || pOnUsing->pOn==0 || pOnUsing->pUsing==0pItem->fg.isUsing==0append_from_errorsqlite3SrcItemAttachSubquerysizeof(Subquery)offsetof(Subquery, pSelect)==0sizeof(p->pSelect)sizeof(*p)-sizeof(p->pSelect)sqlite3SrcListDelete!pItem->fg.isIndexedBy || !pItem->fg.isTabFunc!pItem->fg.isCte || !pItem->fg.isIndexedBy!pItem->fg.fixedSchema || !pItem->fg.isSubquery!pItem->fg.isSubquery || (pItem->u4.pSubq!=0 && pItem->u4.pSubq->pSelect!=0)sqlite3SubqueryDetachsqlite3SubqueryDeletepSubq!=0 && pSubq->pSelect!=0sqlite3SrcListAssignCursorspList || pParse->db->mallocFailedpItem->u4.pSubq->pSelect->pSrc!=0sqlite3SrcListAppendpDatabase==0 || pTable!=0sizeof(SrcList)sizeof(pList->a[0])pItem->fg.fixedSchema==0sqlite3SrcListEnlargenExtra>=1iStart<=pSrc->nSrcSQLITE_MAX_SRCLISTtoo many FROM clause terms, max: %d"too many FROM clause terms, max: %d"sizeof(pSrc->a[0])sqlite3IdListIndexsqlite3IdListDeletesqlite3IdListAppendsizeof(IdList)dbMemnIncrisIgnoreppIdxpaiColpIsNocaseaWccaseSensitivebValuepSumesczGlobPatternmatchOtherprefixOnlypiPartIdxLabelregPrioriIdxNoSeekonconfpViewregCounterzColNamecreateFlagaDefnDefpArglisteM10dp4typep5ErrmsgsetStatementpIndexedBypAliaspOnUsingdupSelectsizeof(pList->a)sqlite3ArrayAllocatesqlite3DropIndexpParse->nErr==0pName->a[0].fg.fixedSchema==0pName->a[0].fg.isSubquery==0no such index: %S"no such index: %S"index associated with UNIQUE or PRIMARY KEY constraint cannot be dropped"index associated with UNIQUE "
      "or PRIMARY KEY constraint cannot be dropped" SQLITE_DROP_INDEXDELETE FROM %Q.sqlite_master WHERE name=%Q AND type='index'"DELETE FROM %Q." LEGACY_SCHEMA_TABLE " WHERE name=%Q AND type='index'""idx"OP_DropIndexexit_drop_indexsqlite3DefaultRowEstconst LogEst[]signed short[]aValArraySize(aVal)((int)(sizeof(aVal)/sizeof(aVal[0])))pIdx->nKeyColconst LogEst[5]signed short[5]const LogEst *!pIdx->hasStat199==sqlite3LogEst(1000)23==sqlite3LogEst(5)sqlite3CreateIndexsortOrderMaskpListItemnExtraColpName1 && pName2pName && pName->zdb->mallocFailed==0 || pTab==0pName==0pStart==0cannot create a TEMP index on non-TEMP table "%s""cannot create a TEMP index on non-TEMP table \"%s\""table %s may not be indexed"table %s may not be indexed"views may not be indexed"views may not be indexed"virtual tables may not be indexed"virtual tables may not be indexed"pName->z!=0there is already a table named %s"there is already a table named %s"index %s already exists"index %s already exists"sqlite_autoindex_%s_%d"sqlite_autoindex_%s_%d"pList->nExpr==1prevColCOLFLAG_UNIQUEpList->nExpr + nExtraCol <= 32767EIGHT_BYTE_ALIGNMENT(pIndex->aiRowLogEst)EIGHT_BYTE_ALIGNMENT(pIndex->azColl)NC_PartIdxj<=0x7fff!ExprHasProperty(pListItem->pExpr, EP_IntValue)nExtra>=nCollpCExprrequestedSortOrderNC_IdxExprexpressions prohibited in PRIMARY KEY and UNIQUE constraints"expressions prohibited in PRIMARY KEY and "
                                "UNIQUE constraints"hasColumn(pIndex->aiColumn,pIndex->nKeyCol,x)i==pIndex->nColumnHasRowid(pTab) || pTab->iPKey<0 || sqlite3TableColumnToIndex(pIndex, pTab->iPKey)>=0IsUniqueIndex(pIdx)pIdx->idxType!=SQLITE_IDXTYPE_APPDEFIsUniqueIndex(pIndex)pIdx->aiColumn[k]>=0conflicting ON CONFLICT clauses specified"conflicting ON CONFLICT clauses specified"!IN_SPECIAL_PARSEsqlite3SchemaMutexHeld(db, 0, pIndex->pSchema)p==pIndexpName!=0 || pStart==0126492iMemOP_CreateBtreeBTREE_BLOBKEYCREATE%s INDEX %.*s"CREATE%s INDEX %.*s" UNIQUE" UNIQUE"INSERT INTO %Q.sqlite_master VALUES('index',%Q,%Q,#%d,%Q);"INSERT INTO %Q." LEGACY_SCHEMA_TABLE " VALUES('index',%Q,%Q,#%d,%Q);"name='%q' AND type='index'"name='%q' AND type='index'"pParse->pNewIndex==0exit_create_indexppFromsqlite3HasExplicitNullssfunsupported use of NULLS %s"unsupported use of NULLS %s"FIRST"FIRST"LAST"LAST"sqlite3AllocateIndexObjectsizeof(char*)*nColsizeof(LogEst)*(nCol+1) + sizeof(i16)*nCol + sizeof(u8)*nCol18446744073709551608ROUND8(sizeof(Index))sizeof(i16)sqlite3RefillIndexiSorterpKey!=0 || pParse->nErrOPFLAG_P2ISREGj2OP_SorterComparesqlite3DeferForeignKey!IsOrdinaryTable(pTab)!((pTab)->eTabType==0)isDeferred==0 || isDeferred==1sqlite3CreateForeignKeypNextTopTo!=0iCol<0foreign key on %s should reference only one column of table %T"foreign key on %s"
         " should reference only one column of table %T"number of columns in foreign key does not match the number of columns in the referenced table"number of columns in foreign key does not match the number of "
        "columns in the referenced table"sizeof(*pFKey)sizeof(pFKey->aCol[0])IsOrdinaryTable(p)unknown column "%s" in foreign key definition"unknown column \"%s\" in foreign key definition"sqlite3SchemaMutexHeld(db, 0, p->pSchema)pNextTo->pPrevTo==0fk_endsqlite3DropTableisView==0 || isView==LOCATE_VIEWzArg2table %s may not be dropped"table %s may not be dropped"use DROP TABLE to delete table %s"use DROP TABLE to delete table %s"use DROP VIEW to delete view %s"use DROP VIEW to delete view %s"tbl"tbl"exit_drop_tabletableMayNotBeDroppedparameters"parameters"sqlite3ReadOnlyShadowTablessqlite3CodeDropTableOP_VBeginpTrigger->pSchema==pTab->pSchema || pTrigger->pSchema==db->aDb[1].pSchemaDELETE FROM %Q.sqlite_sequence WHERE name=%Q"DELETE FROM %Q.sqlite_sequence WHERE name=%Q"DELETE FROM %Q.sqlite_master WHERE tbl_name=%Q and type!='trigger'"DELETE FROM %Q." LEGACY_SCHEMA_TABLE
      " WHERE tbl_name=%Q and type!='trigger'"OP_VDestroyOP_DropTablesqlite3ClearStatTablessizeof(zTab)sqlite_stat%d"sqlite_stat%d"DELETE FROM %Q.%s WHERE %s=%Q"DELETE FROM %Q.%s WHERE %s=%Q"destroyTableiDestroyediDb>=0 && iDb<pParse->db->nDbiLargestdestroyRootPagecorrupt schema"corrupt schema"OP_DestroyUPDATE %Q.sqlite_master SET rootpage=%d WHERE #%d AND rootpage=#%d"UPDATE %Q." LEGACY_SCHEMA_TABLE
     " SET rootpage=%d WHERE #%d AND rootpage=#%d"sqlite3RootPageMovedsqliteViewResetAllsqlite3SchemaMutexHeld(db, idx, 0)DB_UnresetViews&db->aDb[idx].pSchema->tblHashsqlite3ViewGetColumnNamespTable!=0viewGetColumnNamespSelTabpTable->nCol<=0view %s is circularly defined"view %s is circularly defined"pTable->nCol>=0IsView(pTable)pTable->aCol==0sqlite3SchemaMutexHeld(db, 0, pTable->pSchema)eParseModesqlite3CreateViewparameters are not allowed in views"parameters are not allowed in views"sEnd.z[0]!=0 || sEnd.n==0create_view_failsqlite3EndTableCOLTYPE_CUSTOMunknown datatype for %s.%s: "%s""unknown datatype for %s.%s: \"%s\""missing datatype for %s.%s"missing datatype for %s.%s"(p->tabFlags & TF_HasPrimaryKey)==0 || p->iPKey>=0 || sqlite3PrimaryKeyIndex(p)!=0(p->tabFlags & TF_HasPrimaryKey)!=0 || (p->iPKey<0 && sqlite3PrimaryKeyIndex(p)==0)AUTOINCREMENT not allowed on WITHOUT ROWID tables"AUTOINCREMENT not allowed on WITHOUT ROWID tables"TF_HasPrimaryKeyPRIMARY KEY missing on table %s"PRIMARY KEY missing on table %s"NC_IsCheckp->tabFlags & TF_HasVirtualp->tabFlags & TF_HasStoredcolFlags & COLFLAG_VIRTUALcolFlags & COLFLAG_STOREDnNGNC_GenColmust have at least one non-generated column"must have at least one non-generated column"v==0p->aCol==0zType2addrInsLoopCREATE %s %.*s"CREATE %s %.*s"UPDATE %Q.sqlite_master SET type='%s', name=%Q, tbl_name=%Q, rootpage=#%d, sql=%Q WHERE rowid=#%d"UPDATE %Q." LEGACY_SCHEMA_TABLE
      " SET type='%s', name=%Q, tbl_name=%Q, rootpage=#%d, sql=%Q"
      " WHERE rowid=#%d"char[98]CREATE TABLE %Q.sqlite_sequence(name,seq)"CREATE TABLE %Q.sqlite_sequence(name,seq)"tbl_name='%q' AND type!='trigger'"tbl_name='%q' AND type!='trigger'"SELECT*FROM"%w"."%w""SELECT*FROM\"%w\".\"%w\""HasRowid(p) || p->iPKey<0p==pOld!pParse->nestedpCons && pEndsqlite3ShadowTableNamesqlite3MarkAllShadowTablesOfpMod->pModule==0pTab->zName!=0&pTab->pSchema->tblHashpOther->zName!=0sqlite3IsShadowTableOfconvertToWithoutRowidTable!pParse->bReturningpParse->pNewTable==pTabhasColumn(pPk->aiColumn, j, pPk->aiColumn[i])ipkToken4294967167~TF_WithoutRowidhasColumn(pIdx->aiColumn, pIdx->nKeyCol, pPk->aiColumn[i])pIdx->nColumn>=pIdx->nKeyCol+npIdx->nColumn>=jj<pPk->nColumnpPk->nColumn==jpTab->nNVCol<=jrecomputeColumnsNotIndexedx==BMS-1x==BMS-2(pIdx->colNotIdxed>>63)==1isDupColumnnKey<=pIdx->nColumniCol<MAX(pPk->nColumn,pPk->nKeyCol)pPk->idxType==SQLITE_IDXTYPE_PRIMARYKEYpPk->pTable->tabFlags & TF_WithoutRowidpPk->pTable==pIdx->pTablej!=XN_ROWID && j!=XN_EXPRpIdx->aiColumn[i]>=0 || j>=0pPk==pIdxhasColumnestimateIndexWidthwIndexx<pIdx->pTable->nColestimateTableWidthwTablepTabColresizeIndexObjectpIdx->isResized==0sizeof(char*) + sizeof(LogEst)sizeof(char*) + sizeof(LogEst) + sizeof(i16)sizeof(char*) + sizeof(LogEst) + sizeof(i16) + 1(sizeof(char*) + sizeof(LogEst) + sizeof(i16) + 1)createTableStmt,
  ",\n  "
)"\n)"CREATE TABLE "CREATE TABLE "pCol->affinity-SQLITE_AFF_BLOB >= 0pCol->affinity-SQLITE_AFF_BLOB < ArraySize(azType)pCol->affinity==SQLITE_AFF_BLOBpCol->affinity==SQLITE_AFF_TEXTpCol->affinity==SQLITE_AFF_NUMERICpCol->affinity==SQLITE_AFF_INTEGERpCol->affinity==SQLITE_AFF_REALpCol->affinity==SQLITE_AFF_FLEXNUMpCol->affinity==SQLITE_AFF_BLOB || pCol->affinity==SQLITE_AFF_FLEXNUM || pCol->affinity==sqlite3AffinityType(zType, 0)k<=nconst char *const[6] TEXT" TEXT" NUM" NUM" INT" INT" REAL" REAL"identPutzIdentzIdent[j]zIdent[0]identLengthsqlite3ChangeCookiesqlite3AddGeneratedvirtual tables cannot use computed columns"virtual tables cannot use computed columns"stored"stored"TF_HasVirtual==COLFLAG_VIRTUALTF_HasStored==COLFLAG_STOREDgenerated_errorerror in generated column "%s""error in generated column \"%s\""generated_donesqlite3AddCollateTypepIdx->nKeyCol==1sqlite3AddCheckConstraintzStart[0]zEnd[-1]sqlite3AddPrimaryKeytable "%s" has more than one primary key"table \"%s\" has more than one primary key"pCExpr!=0!ExprHasProperty(pCExpr, EP_IntValue)autoInc==0 || autoInc==1COLTYPE_INTEGERAUTOINCREMENT is only allowed on an INTEGER PRIMARY KEY"AUTOINCREMENT is only allowed on an "
       "INTEGER PRIMARY KEY"primary_key_exitmakeColumnPartOfPrimaryKeygenerated columns cannot be part of the PRIMARY KEY"generated columns cannot be part of the PRIMARY KEY"sqlite3StringToIdsqlite3AddDefaultValuedefault value of column [%s] is not constant"default value of column [%s] is not constant"cannot use DEFAULT on a generated column"cannot use DEFAULT on a generated column"pDfltExprTK_SPANEP_Skipsqlite3AffinityTypezCharzIn!=01660944384'c'<<24('c'<<24)6815744'h'<<16('h'<<16)1667760128('c'<<24)+('h'<<16)24832'a'<<8('a'<<8)1667784960('c'<<24)+('h'<<16)+('a'<<8)1667785074('c'<<24)+('h'<<16)+('a'<<8)+'r'(('c'<<24)+('h'<<16)+('a'<<8)+'r')7077888'l'<<16('l'<<16)1668022272('c'<<24)+('l'<<16)28416'o'<<8('o'<<8)1668050688('c'<<24)+('l'<<16)+('o'<<8)1668050786('c'<<24)+('l'<<16)+('o'<<8)+'b'(('c'<<24)+('l'<<16)+('o'<<8)+'b')1946157056't'<<24('t'<<24)6619136'e'<<16('e'<<16)1952776192('t'<<24)+('e'<<16)30720'x'<<8('x'<<8)1952806912('t'<<24)+('e'<<16)+('x'<<8)1952807028('t'<<24)+('e'<<16)+('x'<<8)+'t'(('t'<<24)+('e'<<16)+('x'<<8)+'t')1644167168'b'<<24('b'<<24)1651245056('b'<<24)+('l'<<16)1651273472('b'<<24)+('l'<<16)+('o'<<8)1651273570('b'<<24)+('l'<<16)+('o'<<8)+'b'(('b'<<24)+('l'<<16)+('o'<<8)+'b')1912602624'r'<<24('r'<<24)1919221760('r'<<24)+('e'<<16)1919246592('r'<<24)+('e'<<16)+('a'<<8)1919246700('r'<<24)+('e'<<16)+('a'<<8)+'l'(('r'<<24)+('e'<<16)+('a'<<8)+'l')1711276032'f'<<24('f'<<24)1718353920('f'<<24)+('l'<<16)1718382336('f'<<24)+('l'<<16)+('o'<<8)1718382433('f'<<24)+('l'<<16)+('o'<<8)+'a'(('f'<<24)+('l'<<16)+('o'<<8)+'a')1677721600'd'<<24('d'<<24)7274496'o'<<16('o'<<16)1684996096('d'<<24)+('o'<<16)29952'u'<<8('u'<<8)1685026048('d'<<24)+('o'<<16)+('u'<<8)1685026146('d'<<24)+('o'<<16)+('u'<<8)+'b'(('d'<<24)+('o'<<16)+('u'<<8)+'b')167772150x00FFFFFF6881280'i'<<16('i'<<16)28160'n'<<8('n'<<8)6909440('i'<<16)+('n'<<8)6909556('i'<<16)+('n'<<8)+'t'(('i'<<16)+('n'<<8)+'t')zChar[0]sqlite3AddNotNullp->nCol<1pIdx->nKeyCol==1 && pIdx->onError!=OE_Nonesqlite3AddColumnszEstsType.n>0sType.z[sType.n-1]generated"generated"const unsigned char[6]duplicate column name: %s"duplicate column name: %s"sizeof(p->aCol[0])sizeof(p->aHx)sqlite3AddReturningpParse->bReturning==0 || pParse->ifNotExistscannot use RETURNING in a trigger"cannot use RETURNING in a trigger"sizeof(*pRet)sizeof(pRet->zName)sqlite_returning_%p"sqlite_returning_%p"sqlite3HashFind(pHash, pRet->zName)==0 || pParse->nErr || pParse->ifNotExistssqlite3DeleteReturningsqlite3StartTabletemporary table name must be unqualified"temporary table name must be unqualified"isTemp==0 || isTemp==1isView==0 || isView==1aCode!db->init.busy || CORRUPT_DB%s %T already exists"%s %T already exists"there is already an index named %s"there is already an index named %s"nullRowfileFormatreg3BTREE_INTKEYbegin_table_errorsqlite3ForceNotReadOnlysqlite3TableColumnToStorageiCol<pTab->nColTF_HasVirtualsqlite3StorageColumnToTablesqlite3TableColumnToIndexsqlite3PrimaryKeyIndexsqlite3CheckObjectNameobject name reserved for internal use: %s"object name reserved for internal use: %s"sqlite3WritableSchema268435457(SQLITE_WriteSchema|SQLITE_Defensive)(db->flags&(SQLITE_WriteSchema|SQLITE_Defensive))==0(db->flags&(SQLITE_WriteSchema|SQLITE_Defensive))== SQLITE_WriteSchema(db->flags&(SQLITE_WriteSchema|SQLITE_Defensive))== SQLITE_Defensive(db->flags&(SQLITE_WriteSchema|SQLITE_Defensive))== (SQLITE_WriteSchema|SQLITE_Defensive)sqlite3TwoPartNamedb->init.iDb==0 || db->init.busy || IN_SPECIAL_PARSE || (db->mDbFlags & DBFLAG_Vacuum)!=0unknown database %T"unknown database %T"sqlite3FindDbsqlite3FindDbNamesqlite3OpenSchemaTableSCHEMA_ROOTLEGACY_SCHEMA_TABLEsqlite3NameFromTokensqlite3UnlinkAndDeleteTablezTabName[0]==0sqlite3DeleteTableGenericsqlite3DeleteTabledeleteTablepIndex->pSchema==pTable->pSchema || (IsVirtual(pTable) && pIndex->idxType!=SQLITE_IDXTYPE_APPDEF)Index *pOld =db==0 || sqlite3SchemaMutexHeld(db, 0, pIndex->pSchema)pOld==pIndex || pOld==0nLookaside==0 || nLookaside==sqlite3LookasideUsed(db,0)sqlite3DeleteColumnNamespCol->zCnName==0 || pCol->hName==sqlite3StrIHash(pCol->zCnName)sqlite3ColumnCollsqlite3ColumnSetCollsqlite3ColumnExprpTab->u.tab.pDfltList==0pTab->u.tab.pDfltList->nExpr<pCol->iDfltsqlite3ColumnSetExprpList->nExpr<pCol->iDfltsqlite3CommitInternalChanges~DBFLAG_SchemaChangesqlite3ResetAllSchemasOfConnection(DBFLAG_SchemaChange|DBFLAG_SchemaKnownOk)4294967278~(DBFLAG_SchemaChange|DBFLAG_SchemaKnownOk)sqlite3ResetOneSchema4294967279~DBFLAG_SchemaKnownOksqlite3CollapseDatabaseArraysizeof(db->aDb[0])2*sizeof(db->aDb[0])sqlite3UnlinkAndDeleteIndexp && p->pNext==pIndexsqlite3FreeIndexsqlite3FindIndexsqlite3PreferredTableNamePREFERRED_SCHEMA_TABLELEGACY_TEMP_SCHEMA_TABLEPREFERRED_TEMP_SCHEMA_TABLEsqlite3LocateTableItem!p->fg.isSubquerysqlite3LocateTablepragma_"pragma_"LOCATE_VIEWno such view"no such view"no such table"no such table"%s: %s.%s"%s: %s.%s"%s: %s"%s: %s"sqlite3FindTablezDatabase!=0 || sqlite3BtreeHoldsAllMutexes(db)sqlite3NestedParsesavedDbFlagschar[136]saveBufpParse->nested<10sqlite3FinishCodingpParse->pToplevel==0!pParse->isMultiWrite || sqlite3VdbeAssertMayAbort(v, pParse->mayAbort)pParse->nErr>0 || sqlite3VdbeGetOp(v, 0)->opcode==OP_InitpParse->cookieMask(v, "usesStmtJournal=%d", pParse->mayAbort && pParse->isMultiWrite)pEL->a[i].u.iConstExprReg>0addrRewindusesStmtJournal=%dvtabpELv!=0 || pParse->nErrdb->mallocFailed==0 || pParse->nErrpParse->pAinc==0 || pParse->nTab>0codeTableLockspVdbepVdbe!=0OP_TableLocksqlite3TableLocklockTablesizeof(TableLock)sqlite3AuthContextPopsqlite3AuthContextPushsqlite3AuthCheck!IN_RENAME_OBJECT || db->xAuth==0zArg1==0zArg2==0zArg3==0pParse->zAuthContext==0sqlite3AuthReadpExpr->op==TK_COLUMN || pExpr->op==TK_TRIGGERpParse->db->xAuth!=0TK_TRIGGERpTab->iPKey<pTab->nColsqlite3AuthReadCol%s.%z"%s.%z"access to %z is prohibited"access to %z is prohibited"sqliteAuthBadReturnCodeauthorizer malfunction"authorizer malfunction"sqlite3FixTriggerStepsqlite3FixExprsqlite3FixSelectsqlite3FixSrcListsqlite3FixInitdb->nDb>iDbfixSelectCbpFix%s %T cannot reference objects in database %s"%s %T cannot reference objects in database %s"fixExprCbEP_FromDDL%s cannot use variables"%s cannot use variables"sqlite3Attachconst FuncDefattach_funcconst FuncDef *sqlite_attach"sqlite_attach"sqlite3Detachdetach_funcsqlite_detach"sqlite_detach"codeAttachsNameregArgspAuthArg!ExprHasProperty(pAuthArg, EP_IntValue)zAuthArgv || db->mallocFailedattach_enddetachFuncsizeof(zErr)cannot detach database %s"cannot detach database %s"database %s is locked"database %s is locked"detach_errorattachFunczErrDynpNew->pBtpNewBtmemdb"memdb"x "x\0"pNewSchematoo many attached databases - max %d"too many attached databases - max %d"database %s is already in use"database %s is already in use"sizeof(db->aDb[0])*3sizeof(db->aDb[0])*2(SQLITE_OPEN_CREATE|SQLITE_OPEN_READWRITE)4294967289~(SQLITE_OPEN_CREATE|SQLITE_OPEN_READWRITE)~SQLITE_OPEN_CREATEdatabase is already attached"database is already attached""attached databases must use the same text encoding as main database"PAGER_SYNCHRONOUS_FULLzErrDyn==0 || rc!=SQLITE_OK(DBFLAG_SchemaKnownOk)~(DBFLAG_SchemaKnownOk)!REOPEN_AS_MEMDB(db)!(db->init.reopenMemdb)iDb>=2unable to open database: %s"unable to open database: %s"attach_errorsqlite3DbIsNamedresolveAttachExprsqlite3AnalysisLoadpStat1db->aDb[iDb].pBt!=0~TF_HasStat1&pSchema->idxHashSELECT tbl,idx,stat FROM %Q.sqlite_stat1"SELECT tbl,idx,stat FROM %Q.sqlite_stat1"analysisInfo *sqlite3DeleteIndexSamplesanalysisLoadertRowcnt *aiRowEstfakeIdxdecodeIntArrayaOut==0aLog!=0pIndex!=0unordered*"unordered*"sz=[0-9]*"sz=[0-9]*"noskipscan*"noskipscan*"sqlite3Analyzesqlite3BtreeHoldsAllMutexes(pParse->db)pName2!=0 || pName1==0analyzeTableiStatCuranalyzeDatabaseiMem==sqlite3FirstAvailableRegister(pParse,iMem)loadAnalysisOP_LoadAnalysisanalyzeOneTablejZeroRowsneedTableCntregStatregChngregTemp2regTabnameregIdxnameregStat1sqlite3NoTempsInRange(pParse, regNewRowid, iMem)pParse->nTab(v, "Analysis for %s.%s", pTab->zName, zIdxName)iDb==sqlite3SchemaToIndex(db, pIdx->pSchema)regTemp2==regStat+4regRowid==regStat+2SQLITE_Stat4regChng==(regStat+1)"BBB"[0]==SQLITE_AFF_TEXTaddrGotoEndaddrNextRowzIdxNamenColTestAnalysis for %s.%sendDistinctTestaGotoChngIsStat42+IsStat4j3STAT_GET_STAT1BBB"BBB"analyzeVdbeCommentIndexWithColumnNamek>=0 && k<pIdx->nColumni==XN_ROWIDi==(-1)(v,"%s.rowid",pIdx->zName)(v,"%s.expr(%d)",pIdx->zName, k)(v,"%s.%s", pIdx->zName, pIdx->pTable->aCol[i].zCnName)%s.expr(%d)callStatGetiParamregOut!=regStat && regOut!=regStat+11+IsStat4statGetStatAccum *nDistinct %llu" %llu"statPushiChngp->nCol>0iChng<p->nColstatInitnColUpnCol>0sizeof(tRowcnt)sizeof(tRowcnt)<8~1nKeyCol<=nColnKeyCol>0statAccumDestructoropenStatTableaTableu32[3]unsigned int[3]const struct <unnamed>[3]struct <unnamed>[3]ArraySize(aTable)aCreateTblnToOpensqlite3VdbeDb(v)==dbpParse->isCreate || pParse->nErrpStatCREATE TABLE %Q.%s(%s)"CREATE TABLE %Q.%s(%s)"i<ArraySize(aTable)(v, aTable[i].zName)tbl,idx,stat"tbl,idx,stat"sqlite_stat3"sqlite_stat3"sqlite3AlterFunctionssqlite_rename_columnrenameColumnFuncsqlite_rename_tablerenameTableFuncsqlite_rename_testrenameTableTestsqlite_drop_columndropColumnFuncsqlite_rename_quotefixrenameQuotefixFuncaAlterTableFuncsFuncDef[5]360ArraySize(aAlterTableFuncs)86507528652801sqlite3AlterDropColumnno such column: "%T""no such column: \"%T\""(COLFLAG_PRIMKEY|COLFLAG_UNIQUE)cannot drop %s column: "%s""cannot drop %s column: \"%s\""UNIQUE"UNIQUE"cannot drop column "%s": no other columns exist"cannot drop column \"%s\": no other columns exist"UPDATE "%w".sqlite_master SET sql = sqlite_drop_column(%d, sql, %d) WHERE (type=='table' AND tbl_name=%Q COLLATE nocase)"UPDATE \"%w\"." LEGACY_SCHEMA_TABLE " SET "
      "sql = sqlite_drop_column(%d, sql, %d) "
      "WHERE (type=='table' AND tbl_name=%Q COLLATE nocase)"char[121]INITFLAG_AlterDropafter drop column"after drop column"iColPosexit_drop_columnRenameToken *119032RenameCtx *pCol->t.z[0]!=0%.*s%s"%.*s%s"drop_column_donebTempisLegacyzWhenbNoDQSsParse.pNewTable1610612736(SQLITE_DqsDML|SQLITE_DqsDDL)18446744072098938879~(SQLITE_DqsDML|SQLITE_DqsDDL)sizeof(RenameCtx)~SF_ViewrenameQuotefixExprCbEP_DblQuotedpSelect->selFlags & SF_ViewrenameTableSelectCbpSelect->selFlags & SF_CopyCte69206016(SF_View|SF_CopyCte)pSrc==0pWalker->pParse->db->mallocFailedrenameTableExprCb(((pExpr)->flags&(0x1000000|0x2000000))==0)bFKOnlypUpsertSetrenameColumnFunc_donerenameParseCleanuprenameWalkTriggerpFrom->a[i].u4.pSubq!=0renameResolveTriggerpNew->pTabSchemapParse->pTriggerTabpStep->pExprList==0 || pStep->pExprList==pSel->pEListpSrc==pSel->pSrcp->u4.pSubq!=0!pStep->pUpsert || (!pStep->pWhere && !pStep->pExprList)ENAME_SPANrenameSetENamesval==ENAME_NAME || pEList->a[i].fg.eEName==ENAME_NAMErenameEditSqlzQuotnQuotnQuot>=nNew"%w" "\"%w\" "nReplacezReplace%Q%s"%Q%s"renameParseSql118057PARSE_MODE_RENAMEp->pNewTable==0 && p->pNewIndex==0 && p->pNewTrigger==0118068renameColumnIdlistNamesconst IdList_itemconst IdList_item *renameColumnElistNamespEList->a[i].fg.eEName==ENAME_NAMEpEList->a[i].fg.eEName==0renameColumnParseErrorzTzNerror in %s %s%s%s: %s"error in %s %s%s%s: %s"renameColumnTokenNextRenameToken **renameColumnExprCbrenameColumnSelectCbp->selFlags & SF_Viewp->selFlags & SF_CopyCterenameTokenFindpPtr==0renameTokenFreesqlite3RenameExprlistUnmapsqlite3RenameExprUnmapPARSE_MODE_UNMAPrenameUnmapSelectCbp->pSrcunmapColumnIdlistNamespIdList!=0renameWalkWithpWith->nCte>0renameUnmapExprCbsqlite3RenameTokenRemapsqlite3RenameTokenMappPtr || pParse->db->mallocFailedpParse->eParseMode!=PARSE_MODE_UNMAPpParse->eParseMode!=3sizeof(RenameToken)sqlite3AlterRenameColumniSchema>=0pNew->n>0pNew->z[0]UPDATE "%w".sqlite_master SET sql = sqlite_rename_column(sql, type, name, %Q, %Q, %d, %Q, %d, %d) WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X'  AND (type != 'index' OR tbl_name = %Q)"UPDATE \"%w\"." LEGACY_SCHEMA_TABLE " SET "
      "sql = sqlite_rename_column(sql, type, name, %Q, %Q, %d, %Q, %d, %d) "
      "WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X' "
      " AND (type != 'index' OR tbl_name = %Q)"char[182]UPDATE temp.sqlite_master SET sql = sqlite_rename_column(sql, type, name, %Q, %Q, %d, %Q, %d, 1) WHERE type IN ('trigger', 'view')"UPDATE temp." LEGACY_SCHEMA_TABLE " SET "
      "sql = sqlite_rename_column(sql, type, name, %Q, %Q, %d, %Q, %d, 1) "
      "WHERE type IN ('trigger', 'view')"char[131]INITFLAG_AlterRenameafter rename"after rename"exit_rename_columnisRealTablevirtual table"virtual table"cannot %s %s "%s""cannot %s %s \"%s\""drop column from"drop column from"rename columns of"rename columns of"sqlite3AlterBeginAddColumnvirtual tables may not be altered"virtual tables may not be altered"Cannot add a column to a view"Cannot add a column to a view"pTab->u.tab.addColOffset>0pNew->nCol>0nAlloc>=pNew->nCol && nAlloc%8==0 && nAlloc-pNew->nCol<8sizeof(Column)sqlite_altertab_%s"sqlite_altertab_%s"pNew->nTabRef==1exit_begin_add_columnsqlite3AlterFinishAddColumnCannot add a PRIMARY KEY column"Cannot add a PRIMARY KEY column"Cannot add a UNIQUE column"Cannot add a UNIQUE column"pDflt==0 || pDflt->op==TK_SPANrc==SQLITE_OK || rc==SQLITE_NOMEMdb->mallocFailed == 1Cannot add a REFERENCES column with non-NULL default value"Cannot add a REFERENCES column with non-NULL default value"Cannot add a NOT NULL column with default value NULL"Cannot add a NOT NULL column with default value NULL"Cannot add a column with non-constant default"Cannot add a column with non-constant default"cannot add a STORED column"cannot add a STORED column"*zEndUPDATE "%w".sqlite_master SET sql = printf('%%.%ds, ',sql) || %Q || substr(sql,1+length(printf('%%.%ds',sql))) WHERE type = 'table' AND name = %Q"UPDATE \"%w\"." LEGACY_SCHEMA_TABLE " SET "
          "sql = printf('%%.%ds, ',sql) || %Q"
          " || substr(sql,1+length(printf('%%.%ds',sql))) "
        "WHERE type = 'table' AND name = %Q"char[146]INITFLAG_AlterAddSELECT CASE WHEN quick_check GLOB 'CHECK*' THEN raise(ABORT,'CHECK constraint failed') WHEN quick_check GLOB 'non-* value in*' THEN raise(ABORT,'type mismatch on DEFAULT') ELSE raise(ABORT,'NOT NULL constraint failed') END  FROM pragma_quick_check(%Q,%Q) WHERE quick_check GLOB 'CHECK*' OR quick_check GLOB 'NULL*' OR quick_check GLOB 'non-* value in*'"SELECT CASE WHEN quick_check GLOB 'CHECK*'"
        " THEN raise(ABORT,'CHECK constraint failed')"
        " WHEN quick_check GLOB 'non-* value in*'"
        " THEN raise(ABORT,'type mismatch on DEFAULT')"
        " ELSE raise(ABORT,'NOT NULL constraint failed')"
        " END"
        "  FROM pragma_quick_check(%Q,%Q)"
        " WHERE quick_check GLOB 'CHECK*'"
        " OR quick_check GLOB 'NULL*'"
        " OR quick_check GLOB 'non-* value in*'"char[353]sqlite3ErrorIfNotEmptySELECT raise(ABORT,%Q) FROM "%w"."%w""SELECT raise(ABORT,%Q) FROM \"%w\".\"%w\""sqlite3AlterRenameTablenTabNamethere is already another table or index with this name: %s"there is already another table or index with this name: %s"view %s may not be altered"view %s may not be altered"UPDATE "%w".sqlite_master SET sql = sqlite_rename_table(%Q, type, name, sql, %Q, %Q, %d) WHERE (type!='index' OR tbl_name=%Q COLLATE nocase)AND   name NOT LIKE 'sqliteX_%%' ESCAPE 'X'"UPDATE \"%w\"." LEGACY_SCHEMA_TABLE " SET "
      "sql = sqlite_rename_table(%Q, type, name, sql, %Q, %Q, %d) "
      "WHERE (type!='index' OR tbl_name=%Q COLLATE nocase)"
      "AND   name NOT LIKE 'sqliteX_%%' ESCAPE 'X'"char[184]UPDATE %Q.sqlite_master SET tbl_name = %Q, name = CASE WHEN type='table' THEN %Q WHEN name LIKE 'sqliteX_autoindex%%' ESCAPE 'X'      AND type='index' THEN 'sqlite_autoindex_' || %Q || substr(name,%d+18) ELSE name END WHERE tbl_name=%Q COLLATE nocase AND (type='table' OR type='index' OR type='trigger');"UPDATE %Q." LEGACY_SCHEMA_TABLE " SET "
          "tbl_name = %Q, "
          "name = CASE "
            "WHEN type='table' THEN %Q "
            "WHEN name LIKE 'sqliteX_autoindex%%' ESCAPE 'X' "
            "     AND type='index' THEN "
             "'sqlite_autoindex_' || %Q || substr(name,%d+18) "
            "ELSE name END "
      "WHERE tbl_name=%Q COLLATE nocase AND "
          "(type='table' OR type='index' OR type='trigger');"char[305]UPDATE "%w".sqlite_sequence set name = %Q WHERE name = %Q"UPDATE \"%w\".sqlite_sequence set name = %Q WHERE name = %Q"UPDATE sqlite_temp_schema SET sql = sqlite_rename_table(%Q, type, name, sql, %Q, %Q, 1), tbl_name = CASE WHEN tbl_name=%Q COLLATE nocase AND   sqlite_rename_test(%Q, sql, type, name, 1, 'after rename', 0) THEN %Q ELSE tbl_name END WHERE type IN ('view', 'trigger')"UPDATE sqlite_temp_schema SET "
            "sql = sqlite_rename_table(%Q, type, name, sql, %Q, %Q, 1), "
            "tbl_name = "
              "CASE WHEN tbl_name=%Q COLLATE nocase AND "
              "  sqlite_rename_test(%Q, sql, type, name, 1, 'after rename', 0) "
              "THEN %Q ELSE tbl_name END "
            "WHERE type IN ('view', 'trigger')"char[265]OP_VRenameexit_rename_tablerenameReloadSchemarenameFixQuotesUPDATE "%w".sqlite_master SET sql = sqlite_rename_quotefix(%Q, sql)WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X' AND sql NOT LIKE 'create virtual%%'"UPDATE \"%w\"." LEGACY_SCHEMA_TABLE
      " SET sql = sqlite_rename_quotefix(%Q, sql)"
      "WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X'"
      " AND sql NOT LIKE 'create virtual%%'"char[147]UPDATE temp.sqlite_master SET sql = sqlite_rename_quotefix('temp', sql)WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X' AND sql NOT LIKE 'create virtual%%'"UPDATE temp." LEGACY_SCHEMA_TABLE
      " SET sql = sqlite_rename_quotefix('temp', sql)"
      "WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X'"
      " AND sql NOT LIKE 'create virtual%%'"renameTestSchemaSELECT 1 FROM "%w".sqlite_master WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X' AND sql NOT LIKE 'create virtual%%' AND sqlite_rename_test(%Q, sql, type, name, %d, %Q, %d)=NULL "SELECT 1 "
      "FROM \"%w\"." LEGACY_SCHEMA_TABLE " "
      "WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X'"
      " AND sql NOT LIKE 'create virtual%%'"
      " AND sqlite_rename_test(%Q, sql, type, name, %d, %Q, %d)=NULL "char[175]SELECT 1 FROM temp.sqlite_master WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X' AND sql NOT LIKE 'create virtual%%' AND sqlite_rename_test(%Q, sql, type, name, 1, %Q, %d)=NULL "SELECT 1 "
        "FROM temp." LEGACY_SCHEMA_TABLE " "
        "WHERE name NOT LIKE 'sqliteX_%%' ESCAPE 'X'"
        " AND sql NOT LIKE 'create virtual%%'"
        " AND sqlite_rename_test(%Q, sql, type, name, 1, %Q, %d)=NULL "char[174]isAlterableTabletable %s may not be altered"table %s may not be altered"sqlite3TouchRegistersqlite3ClearTempRegCachesqlite3ReleaseTempRangesqlite3GetTempRangesqlite3ReleaseTempRegpParse->aTempRegArraySize(pParse->aTempReg)sqlite3GetTempRegsqlite3ExprAnalyzeAggListsqlite3ExprAnalyzeAggregatesanalyzeAggregatepNC->ncFlags & NC_UAggInfopParse->iSelfTab==0!ExprUseYTab(pExpr)!(((pExpr)->flags&(0x1000000|0x2000000))==0)pExpr->pAggInfo!=0pAggInfo->aCol!=0tmp.iAgg<pAggInfo->nColumnpExpr->op==TK_AGG_COLUMNpExpr->op==TK_COLUMNpExpr->op==TK_IF_NULL_ROWpSrcList!=0!ExprHasProperty(pExpr, EP_TokenOnly|EP_Reduced)pItem->pFExpr==pExpr!ExprHasProperty(pExpr, EP_xIsSelect)pItem->bOBUnique==00x000004pIEprfindOrCreateAggInfoColumnpGBfix_up_exprpExpr->pAggInfo==0 || pExpr->pAggInfo==pAggInfoaddAggInfoFuncsizeof(pInfo->aFunc[0])addAggInfoColumnsizeof(pInfo->aCol[0])sqlite3AggInfoPersistWalkerInitsizeof(*pWalker)agginfoPersistExprCb!(((pExpr)->flags&(0x010000|0x004000))!=0)EP_TokenOnly|EP_Reduced0x010000|0x004000iAgg>=0pExpr->op==TK_AGG_FUNCTIONiAgg<pAggInfo->nFunc81920pArrayszEntrypnEntryifExistspTblNamepPIWhereifNotExistidxTypeppExtramemRootPageisDeferredpFromColpToColpBeginpCNamestabOptszSignedIdentpCheckExprsTypeisVirtualzTblNamepUnqualisWriteLockzArg1zArg3pDbnamepFilenamezIntArrayaLogpOnlyIdxzWhereTypepRenamebDroppColDefsqlite3ReferencesSrcListRefSrcList *pExpr->pLeft->x.pList!=0exprRefToSrcListselectRefLeavep->nExclude>=pSrc->nSrcselectRefEnterpiNewsqlite3ExprCoveredByIndexxcovIdxCover *exprIdxCoversqlite3ExprImpliesNonNullRowimpliesNotNullRowpExpr->op==TK_ISNOTpExpr->op==TK_ISNULLpExpr->op==TK_NOTNULLpExpr->op==TK_ISpExpr->op==TK_VECTORpExpr->op==TK_TRUTHpExpr->op==TK_CASEpExpr->op==TK_ANDpExpr->x.pList->nExpr>0pExpr->x.pList->nExpr==2pExpr->op==TK_EQpExpr->op==TK_NEpExpr->op==TK_LTpExpr->op==TK_LEpExpr->op==TK_GTpExpr->op==TK_GEpLeft->op!=TK_COLUMN || ExprUseYTab(pLeft)pRight->op!=TK_COLUMN || ExprUseYTab(pRight)pLeft->y.pTab!=0pRight->y.pTab!=0pRight->y.pTabTK_TRUTHbothImplyNotNullRowsqlite3ExprImpliesExprsqlite3ExprIsIIFpDef->pUserDataSQLITE_FUNC_INLINEsqlite3ExprIsNotTrueexprImpliesNotNullpNN0x001000ExprUseXSelect(p) || (p->x.pList!=0 && p->x.pList->nExpr>0)sqlite3ExprCompareSkipsqlite3ExprListComparepExprApExprBsqlite3ExprComparecombinedFlags!ExprHasProperty(pA, EP_IntValue)!ExprHasProperty(pB, EP_IntValue)pA->op==pB->op1028(EP_Distinct|EP_Commuted)(combinedFlags & EP_TokenOnly)==0(combinedFlags & 0x010000)==0(combinedFlags & EP_Reduced)==0(combinedFlags & 0x004000)==0exprCompareVariablesqlite3ExprIfFalseDupsqlite3ExprIfFalseregFree1regFree2jumpIfNull==SQLITE_JUMPIFNULL || jumpIfNull==0!ExprHasVVAProperty(pExpr,EP_Immutable)(TK_ISNULL&1)pExpr->op!=TK_ISNULL || op==OP_NotNullpExpr->op!=TK_NOTNULL || op==OP_IsNullpExpr->op!=TK_NE || op==OP_EqpExpr->op!=TK_EQ || op==OP_NepExpr->op!=TK_LT || op==OP_GepExpr->op!=TK_LE || op==OP_GtpExpr->op!=TK_GT || op==OP_LepExpr->op!=TK_GE || op==OP_LtjumpIfNull==0isTrue && isNot!isTrue && isNot0x000400TK_LT==OP_LtTK_LE==OP_LeTK_GT==OP_GtTK_GE==OP_GeTK_EQ==OP_Eqop==OP_Eq && jumpIfNull!=SQLITE_NULLEQop==OP_Eq && jumpIfNull==SQLITE_NULLEQTK_NE==OP_Neop==OP_Ne && jumpIfNull!=SQLITE_NULLEQop==OP_Ne && jumpIfNull==SQLITE_NULLEQregFree1==0regFree2==0op==TK_ISNULLop==TK_NOTNULLisNotisTruedestIfNulldefault_exprsqlite3ExprIfTrue!ExprHasVVAProperty(pExpr, EP_Immutable)op==TK_ISNOTTK_ISNULL==OP_IsNullTK_NOTNULL==OP_NotNulldestIfFalseexprCodeBetweenexprAndcompLeftcompRightxJump==sqlite3ExprIfTrue && jumpIfNull==0 && regFree1==0xJump==sqlite3ExprIfTrue && jumpIfNull==0 && regFree1!=0xJump==sqlite3ExprIfTrue && jumpIfNull!=0 && regFree1==0xJump==sqlite3ExprIfTrue && jumpIfNull!=0 && regFree1!=0xJump==sqlite3ExprIfFalse && jumpIfNull==0 && regFree1==0xJump==sqlite3ExprIfFalse && jumpIfNull==0 && regFree1!=0xJump==sqlite3ExprIfFalse && jumpIfNull!=0 && regFree1==0xJump==sqlite3ExprIfFalse && jumpIfNull!=0 && regFree1!=0xJump==0sqlite3ExprCodeExprListcopyOptarget>0SQLITE_ECEL_FACTOR~SQLITE_ECEL_FACTORinRegsqlite3ExprCodeFactorablesqlite3ExprCodeCopysqlite3ExprCodepExpr==0 || !ExprHasVVAProperty(pExpr,EP_Immutable)target>0 && target<=pParse->nMempParse->pVdbe!=0 || pParse->db->mallocFailedpX!=pExprsqlite3ExprCodeTempsqlite3ExprCodeRunJustOnceConstFactorOk(pParse)regDest!=00x000008sqlite3ExprCodeTargettempXexpr_code_dooverop!=TK_ORDERpExpr->iAgg(v,"%s.rowid",pTab->zName)(v,"%s.%s", pTab->zName, pTab->aCol[pCol->iColumn].zCnName)pExpr->y.pTab!=0SQLITE_AFF_BLOB=='A'SQLITE_AFF_TEXT=='B'iCol>=XN_ROWIDiCol!=sqlite3TableColumnToStorage(pTab,iCol)op==TK_NULL || op==TK_ERROR || pParse->db->mallocFailedpExpr->u.zToken[0]=='x' || pExpr->u.zToken[0]=='X'pExpr->u.zToken[1]=='\''z[n]=='\''pExpr->u.zToken[0]!=0inReg==targetTK_AND==OP_Andop==TK_ANDTK_OR==OP_Orop==TK_ORTK_PLUS==OP_Addop==TK_PLUSTK_MINUS==OP_Subtractop==TK_MINUSTK_REM==OP_Remainderop==TK_REMTK_BITAND==OP_BitAndop==TK_BITANDTK_BITOR==OP_BitOrop==TK_BITORTK_SLASH==OP_Divideop==TK_SLASHTK_LSHIFT==OP_ShiftLeftop==TK_LSHIFTTK_RSHIFT==OP_ShiftRightop==TK_RSHIFTTK_CONCAT==OP_Concatop==TK_CONCAT&tempXTK_BITNOT==OP_BitNotop==TK_BITNOTTK_NOT==OP_Notop==TK_NOTisTrue && bNormal!isTrue && bNormalpExpr->iAgg<0pExpr->iAgg>=pInfo->nFunc!ExprHasProperty(pExpr, EP_TokenOnly)pFarg!=0(pDef->funcFlags & SQLITE_FUNC_UNSAFE)==0(pDef->funcFlags & SQLITE_FUNC_DIRECT)==0nFarg==1pFarg->a[0].pExpr!=0SQLITE_FUNC_LENGTH==OPFLAG_LENGTHARGSQLITE_FUNC_TYPEOF==OPFLAG_TYPEOFARGSQLITE_FUNC_BYTELEN==OPFLAG_BYTELENARG(OPFLAG_LENGTHARG|OPFLAG_TYPEOFARG)==OPFLAG_BYTELENARG(pDef->funcFlags & OPFLAG_BYTELENARG)==OPFLAG_LENGTHARG(pDef->funcFlags & OPFLAG_BYTELENARG)==OPFLAG_TYPEOFARG(pDef->funcFlags & OPFLAG_BYTELENARG)==OPFLAG_BYTELENARG0x000100nFargconstMaskop==TK_EXISTSop==TK_SELECTpLeft->op==TK_SELECT || pLeft->op==TK_ERRORpExpr->iTable==0 || pExpr->iTable==1iCol>=-1 && iCol<pTab->nColpTab->iPKey<0 || iCol!=pTab->iPKeyp1>=0 && p1<(pTab->nCol*2+2)(v, "r[%d]=%s.%s", target, (pExpr->iTable ? "new" : "old"), (pExpr->iColumn<0 ? "rowid" : pExpr->y.pTab->aCol[iCol].zCnName) )pExpr->iAgg>=0 && pExpr->iAgg<pAggInfo->nColumntarget==inRegExprUseXList(pExpr) && pExpr->x.pList!=0pExpr->x.pList->nExpr > 0pX->op==TK_COLUMNpTest!=0pTest->op==TK_COLUMNaListelem[i+1].pExpr->op==TK_COLUMNpExpr->affExpr==OE_Rollback || pExpr->affExpr==OE_Abort || pExpr->affExpr==OE_Fail || pExpr->affExpr==OE_IgnoreB C D E F"B\000C\000D\000E\000F"'B'(COLFLAG_BUSY|COLFLAG_NOTAVAIL)-385~(COLFLAG_BUSY|COLFLAG_NOTAVAIL)OP_VariableOP_CastOP_ZeroOrNullEP_TokenOnly67584bNormalOP_IsTruemisuse of aggregate: %#T()"misuse of aggregate: %#T()"pFarg"unknown"unknown function: %#T()"unknown function: %#T()"SQLITE_FUNC_DIRECT2621440(SQLITE_FUNC_DIRECT|SQLITE_FUNC_UNSAFE)(SQLITE_FUNC_LENGTH|SQLITE_FUNC_TYPEOF)exprOpOPFLAG_BYTELENARGTK_SELECT_COLUMN%d columns assigned %d values"%d columns assigned %d values"OP_ClrSubtypeOP_Paramr[%d]=%s.%srow value misused"row value misused"addrINRokConstFactorendLabelnextCaseaListelemopComparesizeof(opCompare)RAISE() may only be used within a trigger-program"RAISE() may only be used within a trigger-program"1811exprPartidxExprLookupsqlite3IndexedExprLookupp->aff>=SQLITE_AFF_BLOB && p->aff<=SQLITE_AFF_NUMERICEP_SubtArg(v, "%s expr-column %d", p->zIdxName, p->iIdxCol)exprAff%s expr-column %dsqlite3ExprCanReturnSubtypeexprNodeCanReturnSubtypepExpr->x.pListexprCodeInlineFunctionnFarg>0nFarg>=2nFarg==1 || nFarg==2nFarg==2aff<=SQLITE_AFF_NONE || (aff>=SQLITE_AFF_BLOB && aff<=SQLITE_AFF_FLEXNUM)endCoalescecaseExprsizeof(caseExpr)pA1azAffnumeric"numeric"flexnum"flexnum"setDoNotMergeFlagOnCopyexprCodeVectoriResultsqlite3ExprToRegisterp->iTable==iReg0x0020004294959103sqlite3ExprCodeMoveOP_Movesqlite3ExprCodeGetColumn(p5 & (OPFLAG_NOCHNG|OPFLAG_TYPEOFARG|OPFLAG_LENGTHARG))==p5IsVirtual(pTab) || (p5 & OPFLAG_NOCHNG)==0sqlite3ExprCodeGetColumnOfTableiCol!=XN_EXPR(v, "%s.rowid", pTab->zName)iCol!=sqlite3TableColumnToStorage(pTab, iCol)x!=iColsavedSelfTabsqlite3ExprCodeGeneratedColumnpParse->iSelfTab!=0sqlite3ExprCodeLoadIndexColumniTabColpIdx->aColExprpIdx->aColExpr->nExpr>iIdxColcodeInteger0x"0x"hex literal too big: %s%#T"hex literal too big: %s%#T"codeReal!sqlite3IsNaN(value)OP_Real-12P4_REALsqlite3ExprCodeINrRhsHasNullrLhsrLhsOrignVectordestStep2destStep6addrTruthOpdestNotNull(v, "begin IN expr")begin IN exprIN_INDEX_MEMBERSHIPIN_INDEX_NOOP_OKpParse->nErr || nVector==1 || eType==IN_INDEX_EPH || eType==IN_INDEX_INDEX_ASC || eType==IN_INDEX_INDEX_DESCpParse->okConstFactor==okConstFactorii<pList->nExpr-1 && op==OP_Eqii==pList->nExpr-1 && op==OP_Eqii<pList->nExpr-1 && op==OP_NotNullii==pList->nExpr-1 && op==OP_NotNulldestIfNull==destIfFalseop==OP_IsNullIN_INDEX_NOOPregToFreeregCkNullOP_BitAndpOp->opcode==OP_Once || pParse->nErrOptimizationEnabled(pParse->db, SQLITE_BloomFilter)const VdbeOpconst VdbeOp *sqlite3ExprCodeIN_finished(v, "end IN expr")end IN exprsqlite3ExprCodeIN_oom_errorsqlite3ExprCheckINsqlite3CodeSubselectrRegpExpr->op==TK_EXISTS || pExpr->op==TK_SELECT(pParse, 0, "REUSE SUBQUERY %d", pSel->selId)ExprUseYSub(pExpr)REUSE SUBQUERY %d!ExprUseYWin(pExpr)!ExprHasProperty(pExpr, EP_Reduced|EP_TokenOnly)(pParse, 1, "%sSCALAR SUBQUERY %d", addrOnce?"":"CORRELATED ", pSel->selId)%sSCALAR SUBQUERY %dCORRELATED (v, "Init subquery result")(v, "Init EXISTS result")Init subquery resultInit EXISTS resultTK_ERRORsqlite3VdbeGetOp(v,pExpr->y.sub.iAddr-1)->opcode==OP_BeginSubrtn || pParse->nErrpExpr->op==TK_EXISTSpExpr->op==TK_SELECTsqlite3CodeRhsOfINSubrtnSig *pSig!ExprUseXSelect(pExpr) || pExpr->x.pSelect!=0(pParse, 0, "REUSE LIST SUBQUERY %d", pExpr->x.pSelect->selId)iTab!=pExpr->iTablesizeof(pSig[0])REUSE LIST SUBQUERY %dP4_SUBRTNSIG(v, "Result of SELECT %u", pExpr->x.pSelect->selId)(v, "RHS of IN operator")Result of SELECT %uRHS of IN operator(pParse, 1, "%sLIST SUBQUERY %d", addrOnce?"":"CORRELATED ", pSelect->selId )pEList->nExpr==nVal(v, "Bloom filter")pSelect->selFlags & SF_DistinctpKeyInfo==0pKeyInfo!=0pEList->nExpr>0sqlite3KeyInfoIsWriteable(pKeyInfo)pExpr->x.pList!=0%sLIST SUBQUERY %daddrBloomregBloomBloom filter4261412863findCompatibleInRhsSubrtnpExpr->op==TK_IN!ExprUseYSub(pExpr)pExpr->x.pSelect!=0(pExpr->x.pSelect->selFlags & SF_All)==0pOp->opcode==OP_BeginSubrtnpSig!=0sqlite3VectorErrorMsgsqlite3SubselectErrorsub-select returns %d columns - expected %d"sub-select returns %d columns - expected %d"exprINAffinitysqlite3FindInIndexmustBeUniquep->pEList->a[0].pExpr!=0iDb>=0 && iDb<SQLITE_MAX_DB(pParse, 0, "USING ROWID SEARCH ON TABLE %s FOR IN-OPERATOR",pTab->zName)cmpaff==SQLITE_AFF_BLOBcmpaff==SQLITE_AFF_TEXTidxaff==SQLITE_AFF_TEXTpIdx->nColumn==BMS-2pIdx->nColumn==BMS-1pIdx->azColl[j]nExpr>0 && nExpr<BMSi==nExpr || colUsed!=(MASKBIT(nExpr)-1)(pParse, 0, "USING INDEX %s FOR IN-OPERATOR",pIdx->zName)IN_INDEX_INDEX_DESC == IN_INDEX_INDEX_ASC+1USING ROWID SEARCH ON TABLE %s FOR IN-OPERATORaffinity_okcmpaffmColpReqUSING INDEX %s FOR IN-OPERATORIN_INDEX_INDEX_ASCsavedNQueryLooprMayHaveNullIN_INDEX_EPHsqlite3InRhsIsConstantpLHS!ExprHasProperty(pIn, EP_xIsSelect)sqlite3SetHasNullFlagOPFLAG_TYPEOFARG(v, "first_entry_in(%d)", iCur)first_entry_in(%d)isCandidateForInOpt(p->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct(p->selFlags & (SF_Distinct|SF_Aggregate))==SF_AggregatepRes->iTable==pSrc->a[0].iCursorsqlite3RowidAliasazOptOID"OID"VisibleRowid(pTab)ArraySize(azOpt)sqlite3IsRowidsqlite3ExprNeedsNoAffinityChangeunaryMinusp->iTable>=0sqlite3ExprCanBeNullExprUseYTab(p)p->y.pTab==0p->iColumn<p->y.pTab->nColsqlite3ExprIsIntegerp->op!=TK_INTEGER || (p->flags & EP_IntValue)!=0 || sqlite3GetInt32(p->u.zToken, &rc)==0((unsigned int)v)!=0x80000000pParse->pVdbe==0vvsqlite3ExprIsConstantOrFunctionisInit==0 || isInit==1sqlite3ExprIsConstantOrGroupByexprNodeIsConstantOrGroupBysqlite3ExprIsSingleTableConstraintsqlite3ExprIsTableConstantexprSelectWalkTableConstantpWalker->eCode==3 || pWalker->eCode==0sqlite3ExprIsConstantNotJoinsqlite3ExprIsConstantexprIsConstexprNodeIsConstantpWalker->eCode>0pExpr->op==TK_IDpExpr->op==TK_REGISTERpExpr->op==TK_DOTpExpr->op==TK_RAISEexprNodeIsConstantFunction0x010000SQLITE_FUNC_CONSTANTSQLITE_FUNC_SLOCHNG10240(SQLITE_FUNC_CONSTANT|SQLITE_FUNC_SLOCHNG)sqlite3ExprSimplifiedAndOrsqlite3ExprTruthValuepExpr->op==TK_TRUEFALSEsqlite3StrICmp(pExpr->u.zToken,"true")==0 || sqlite3StrICmp(pExpr->u.zToken,"false")==0sqlite3ExprIdToTrueFalsepExpr->op==TK_ID || pExpr->op==TK_STRINGEP_Quoted|EP_IntValue0x4000000|0x00080067110912sqlite3IsTrueOrFalsesqlite3SelectWalkFailsqlite3ExprListFlagssqlite3ExprListDeleteGenericsqlite3ExprListDeleteexprListDeleteNNpList->nExpr>0sqlite3ExprListCheckLengthtoo many columns in %s"too many columns in %s"pEList && pEList->nExpr==mxpEList && pEList->nExpr==mx+1sqlite3ExprListSetSpanpList!=0 || db->mallocFailed!=0sqlite3ExprListSetNamepList!=0 || pParse->db->mallocFailed!=0pParse->eParseMode!=PARSE_MODE_UNMAP || dequote==0pItem->zEName==0pItem->fg.eEName==ENAME_NAMEsqlite3ExprListSetSortOrderp->nExpr>0SQLITE_SO_UNDEFINED<0 && SQLITE_SO_ASC==0 && SQLITE_SO_DESC>0iSortOrder==SQLITE_SO_UNDEFINED || iSortOrder==SQLITE_SO_ASC || iSortOrder==SQLITE_SO_DESCeNulls==SQLITE_SO_UNDEFINED || eNulls==SQLITE_SO_ASC || eNulls==SQLITE_SO_DESCpItem->fg.bNulls==0sqlite3ExprListAppendVectorpColumns==0pSubExpr!=0 || db->mallocFailedpList->nExpr==iFirst+i+1pSubExprpFirst!=0pFirst->op==TK_SELECT_COLUMNvector_append_errorsqlite3ExprListAppendsqlite3ExprListAppendGrowsizeof(*pList)sqlite3ExprListAppendNewsizeof(ExprList)sizeof(pList->a[0])*4sizeof(ExprList)+sizeof(pList->a[0])*4sqlite3SelectDupSelect **4294967263~SF_UsesEphemeralsqlite3IdListDuppNewItempOldItemsqlite3SrcListDuppNewItem->fg.isUsingpNewSubqsizeof(*pNewSubq)sqlite3ExprListDuppPriorSelectColOldpPriorSelectColNewsqlite3ExprDupflags==0 || flags==EXPRDUP_REDUCEEdupBuf *gatherSelectWindowsgatherSelectWindowsSelectCallbackgatherSelectWindowsCallbackIsWindowFunc(pExpr)pWin->ppThis==0sqlite3WithDupexprDupsEdupBufstaticFlagdupFlags==0 || dupFlags==EXPRDUP_REDUCEpEdupBuf==0 || dupFlags==EXPRDUP_REDUCEsEdupBuf.zAlloc!=0dupFlags==EXPRDUP_REDUCEp->u.zTokenEXPR_FULLSIZE + nTokensizeof(Expr) + nTokenEXPR_FULLSIZEnAlloc==ROUND8(nAlloc)ROUND8(EXPR_FULLSIZE)EIGHT_BYTE_ALIGNMENT(pNew)(int)(sEdupBuf.zEnd - sEdupBuf.zAlloc) >= nNewSize+nTokenExprHasProperty(p, EP_Reduced)==0(int)(sEdupBuf.zEnd - sEdupBuf.zAlloc) >= (int)EXPR_FULLSIZE+nTokenEP_ImmutablenToken>=0nNewSizeExprHasProperty(pNew, EP_WinFunc)p->pRight==0 || p->pRight==p->pLeft || ExprHasProperty(p->pLeft, EP_Subquery)nStructSize0xfffEP_Reduced134299648(EP_Reduced|EP_TokenOnly|EP_Static)4160667647~(EP_Reduced|EP_TokenOnly|EP_Static)(EP_Reduced|EP_TokenOnly)(EP_TokenOnly|EP_Leaf)TK_ORDERsizeof(sEdupBuf)sEdupBuf.zAlloc <= sEdupBuf.zEnddupedExprSizenByte==ROUND8(nByte)dupedExprNodeSizedupedExprStructSizeflags==EXPRDUP_REDUCE || flags==0EXPR_FULLSIZE<=0xfff(0xfff & (EP_Reduced|EP_TokenOnly))==0EP_FullSize0x020000!ExprHasProperty(p, EP_OuterON)!ExprHasVVAProperty(p, EP_NoReduce)p->pRight==01642865552exprStructSize0x004000sqlite3ExprUnmapAndDeletesqlite3ExprDeferredDeletesqlite3ClearOnOrUsingsqlite3ExprDeleteGenericsqlite3ExprDeletesqlite3ExprDeleteNNexprDeleteRestart!ExprUseUValue(p) || p->u.iValue>=0!ExprUseYWin(p) || !ExprUseYSub(p)!ExprUseYWin(p) || p->y.pWin!=0 || db->mallocFailedp->op!=TK_FUNCTION || !ExprUseYSub(p)(0x010000|0x800000)(ExprUseXList(p) && p->x.pList==0) || p->pRight==0!ExprHasProperty(p, EP_WinFunc)sqlite3ExprAssignVarNumber!ExprHasProperty(pExpr, EP_IntValue|EP_Reduced|EP_TokenOnly)z[0]!=0n==(u32)sqlite3Strlen30(z)z[0]=='?'i==0i==db->aLimit[SQLITE_LIMIT_VARIABLE_NUMBER]-1i==db->aLimit[SQLITE_LIMIT_VARIABLE_NUMBER]doAddvariable number must be between ?1 and ?%d"variable number must be between ?1 and ?%d"too many SQL variables"too many SQL variables"sqlite3ExprFunctionUsable(pDef->funcFlags & (SQLITE_FUNC_DIRECT|SQLITE_FUNC_UNSAFE))!=0unsafe use of %#T()"unsafe use of %#T()"sqlite3ExprAddFunctionOrderBypOrderBy==0pExpr->x.pList->nExpr==0(pExpr)ExprUseXList(pOB)sqlite3ExprOrderByAggregateErrorORDER BY may not be used with non-aggregate %#T()"ORDER BY may not be used with non-aggregate %#T()"sqlite3ExprFunction!ExprHasProperty(pNew, EP_InnerON|EP_OuterON)too many arguments on function %T"too many arguments on function %T"sqlite3ExprAnd536870915(EP_OuterON|EP_InnerON|EP_IsFalse)sqlite3ExprListToValuesnElem>1nExprElemIN(...) element has %d term%s - expected %d"IN(...) element has %d term%s - expected %d"sqlite3PExprAddSelectEP_xIsSelect|EP_Subquery0x001000|0x4000004198400sqlite3PExprsqlite3ExprAttachSubtreesExprUseXList(pRoot)pRoot->x.pSelect==0sqlite3Exprsqlite3ExprAllociValue>=0pToken->z!=0 || pToken->n==0pNew->u.zToken[0]sqlite3ExprSetErrorOffsetExprUseWJoin(pExpr)(((pExpr)->flags&(0x000002|0x000001))!=0)sqlite3SelectExprHeightsqlite3ExprSetHeightAndFlagsexprSetHeightp->pRightheightOfSelectheightOfExprListheightOfExprsqlite3ExprCheckHeightmxHeightExpression tree is too large (maximum depth %d)"Expression tree is too large (maximum depth %d)"codeVectorCompareregLeftregRightopxaddrCmpisCommutedpExpr->op==TK_EQ || pExpr->op==TK_NE || pExpr->op==TK_IS || pExpr->op==TK_ISNOT || pExpr->op==TK_LT || pExpr->op==TK_GT || pExpr->op==TK_LE || pExpr->op==TK_GEpExpr->op==op || (pExpr->op==TK_IS && op==TK_EQ) || (pExpr->op==TK_ISNOT && op==TK_NE)p5==0 || pExpr->op!=opp5==SQLITE_NULLEQ || pExpr->op==opi>=0 && i<nLeftopx==TK_LTopx==TK_GTop==TK_LT || op==TK_GT || op==TK_LE || op==TK_GEOP_ElseEqOP_NotexprVectorRegisterop==TK_VECTOR || op==TK_REGISTER || op==TK_SELECT || op==TK_ERRORExprUseXSelect(pVector)ExprUseXList(pVector)exprCodeSubselectsqlite3ExprForVectorFieldppVectorsqlite3VectorFieldSubexpri<sqlite3ExprVectorSize(pVector) || pVector->op==TK_ERRORpVector->op2==0 || pVector->op==TK_REGISTERsqlite3ExprVectorSizesqlite3ExprIsVectorcodeComparesqlite3ExprCompareCollSeqsqlite3BinaryCompareCollSeqbinaryCompareP5sqlite3IndexAffinityOkidx_affinitycomparisonAffinitypExpr->op==TK_EQ || pExpr->op==TK_IN || pExpr->op==TK_LT || pExpr->op==TK_GT || pExpr->op==TK_GE || pExpr->op==TK_LE || pExpr->op==TK_NE || pExpr->op==TK_IS || pExpr->op==TK_ISNOTsqlite3CompareAffinityaff1<=SQLITE_AFF_NONE || aff2<=SQLITE_AFF_NONEsqlite3ExprCollSeqMatchsqlite3ExprNNCollSeqsqlite3ExprCollSeqp->y.pTab!=0!ExprHasProperty(p, EP_IntValue)!ExprUseXList(p) || p->x.pList==0 || p->pRight==0p->x.pList->a[i].pExprsqlite3ExprSkipCollateAndLikelysqlite3ExprSkipCollatepExpr->op==TK_COLLATEsqlite3ExprAddCollateStringzC!=0sqlite3ExprAddCollateTokensqlite3ExprDataTypeExprUseXList(pExpr) && pList!=0pList->nExpr > 0sqlite3ExprAffinitypExpr->x.pSelect->pEList!=0pExpr->x.pSelect->pEList->a[0].pExpr!=0pExpr->pLeft!=0 && ExprUseXSelect(pExpr->pLeft)pExpr->iColumn < pExpr->iTablepExpr->iColumn >= 0pExpr->iTable==pExpr->pLeft->x.pSelect->pEList->nExprEP_Skip|EP_IfNullRow0x002000|0x040000pExpr->op==TK_COLLATE || pExpr->op==TK_IF_NULL_ROW || (pExpr->op==TK_REGISTER && pExpr->op2==TK_IF_NULL_ROW)op==TK_REGISTERop==176270336sqlite3TableColumnAffinityiCol>=pTab->nColsqlite3ResolveSelfReferencesSrctype==0 || pTab!=0type==NC_IsCheck || type==NC_PartIdx || type==NC_IdxExpr || type==NC_GenCol || pTab==0sizeof(sSrc)NC_FromDDLNC_IsDDLsqlite3ResolveSelectNamessqlite3ResolveExprListNamessavedHasAggNC_HasAggNC_MinMaxAgg4112NC_HasWin36880NC_OrderAgg134254608(NC_HasAgg|NC_MinMaxAgg|NC_HasWin|NC_OrderAgg)-134254609~(NC_HasAgg|NC_MinMaxAgg|NC_HasWin|NC_OrderAgg)EP_Agg==NC_HasAggEP_Win==NC_HasWinpNC->ncFlags & NC_HasAggpNC->ncFlags & NC_HasWinpNC->ncFlags & (NC_HasAgg|NC_HasWin)pNC->ncFlags & (0x000010|0x008000)32784sqlite3ResolveExprNamesNC_NoSelectresolveSelectStepisCompoundnCompoundpLeftmostSF_Resolved(p->selFlags & SF_Expanded)!=0(p->selFlags & SF_Resolved)==0p->pSrc->a[0].fg.isSubqueryp->pSrc->a[0].u4.pSubq!=0p->pSrc->nSrc==1 && p->pOrderBypSub->pPrior && pSub->pOrderBy==0pItem->zName!=0 || pItem->fg.isSubquerypItem->fg.isCorrelated==0 && pOuterNC->nRef>=nRefpOuterNC->nNestedSelect>0(p->selFlags & SF_Aggregate)==0NC_MinMaxAgg==SF_MinMaxAggNC_OrderAgg==SF_OrderByReqd(sNC.ncFlags & (NC_UAggInfo|NC_UUpsert|NC_UBaseReg))==0pItem->pExprEP_Agg0x000010zSavedContextNC_AllowAggNC_AllowWin16385-16385~NC_AllowWin134221824(NC_MinMaxAgg|NC_OrderAgg)~NC_AllowAggNC_UEListHAVING clause on a non-aggregate query"HAVING clause on a non-aggregate query"NC_Where-1048577~NC_WhereGROUP"GROUP"aggregate functions are not allowed in the GROUP BY clause"aggregate functions are not allowed in "
              "the GROUP BY clause"resolveOrderGroupBypE2==0'G'windowRemoveExprFromSelectresolveRemoveWindowsCbsqlite3ResolveOrderGroupBytoo many terms in %s BY clause"too many terms in %s BY clause"resolveCompoundOrderBymoreToDotoo many terms in ORDER BY clause"too many terms in ORDER BY clause"pE==0pParent->op==TK_COLLATEpParent->pLeft==pE%r ORDER BY term does not match any column in the result set"%r ORDER BY term does not match any "
            "column in the result set"resolveOutOfRangeError%r %s BY term out of range - should be between 1 and %d"%r %s BY term out of range - should be "
    "between 1 and %d"resolveOrderByTermToExprListsavedSuppErrsqlite3ExprIsInteger(pE, &i, 0)==0sizeof(nc)524417resolveAsName!ExprHasProperty(pE, EP_IntValue)resolveExprSteppNC!=0pParse==pWalker->pParsepSrcList && pSrcList->nSrc>=1anRefpNC->ncFlags & NC_IdxExprpNC->ncFlags & NC_GenCol"the \".\" operator"NC_IdxExpr|NC_GenCol0x000020|0x000008((0x000020|0x000008)&~(NC_IsCheck|NC_PartIdx|NC_IdxExpr|NC_GenCol))==0pRight->op==TK_DOTExprUseUToken(pLeft) && ExprUseUToken(pRight)!ExprHasProperty(pExpr, EP_xIsSelect|EP_IntValue)pExpr->pLeft==0 || pExpr->pLeft->op==TK_ORDERpList->a[ii].pExpr"non-deterministic functions"NC_IdxExpr|NC_PartIdx|NC_GenCol0x000020|0x000002|0x000008((0x000020|0x000002|0x000008)&~(NC_IsCheck|NC_PartIdx|NC_IdxExpr|NC_GenCol))==0(NC_SelfRef & 0xff)==NC_SelfRefis_agg==0 || (pDef->funcFlags & SQLITE_FUNC_MINMAX) || (pDef->xValue==0 && pDef->xInverse==0) || (pDef->xValue && pDef->xInverse && pDef->xSFunc && pDef->xFinalize)ExprUseYWin(pExpr) && pWin==pExpr->y.pWinpDef!=0 || IN_RENAME_OBJECTSQLITE_FUNC_MINMAX==NC_MinMaxAggSQLITE_FUNC_ANYORDER==NC_OrderAgg(pDef->funcFlags & SQLITE_FUNC_MINMAX)!=0(pDef->funcFlags & SQLITE_FUNC_ANYORDER)!=0pNC->ncFlags & NC_IsCheckpNC->ncFlags & NC_PartIdxpExpr->x.pSelectpNC->nRef>=nRefNC_IsCheck|NC_PartIdx|NC_IdxExpr|NC_GenCol0x000004|0x000002|0x000020|0x000008((0x000004|0x000002|0x000020|0x000008)&~(NC_IsCheck|NC_PartIdx|NC_IdxExpr|NC_GenCol))==0!ExprHasProperty(pExpr, EP_Reduced)pExpr->pLeft!=0pExpr->pRight!=0pExpr->op==TK_BETWEENArraySize(anRef)the "." operatorno_such_funcwrong_num_argsis_aggsavedAllowFlags(NC_AllowAgg | NC_AllowWin)second argument to %#T() must be a constant between 0.0 and 1.0"second argument to %#T() must be a "
                "constant between 0.0 and 1.0"125829120not authorized to use function: %#T"not authorized to use function: %#T"non-deterministic functionsNC_SelfRef%#T() may not be used as a window function"%#T() may not be used as a window function""window"aggregate"aggregate"misuse of %s function %#T()"misuse of %s function %#T()"no such function: %#T"no such function: %#T"wrong number of arguments to function %#T()"wrong number of arguments to function %#T()"FILTER may not be used with non-aggregate %#T()"FILTER may not be used with non-aggregate %#T()"pNC2(SQLITE_FUNC_MINMAX|SQLITE_FUNC_ANYORDER)subqueries"subqueries"exprProbabilityr>=0.0134217728.0notValidImplpartial index WHERE clauses"partial index WHERE clauses"index expressions"index expressions"CHECK constraints"CHECK constraints"generated columns"generated columns"%s prohibited in %s"%s prohibited in %s"sqlite3CreateColumnExprpTab->nCol==63pTab->nCol==64lookupNamecntTabnSubquerypTopNCeNewExprOp TK_COLUMNpFJMatchzDb==0 || zTab!=0db->aDb[i].zDbSName(NC_PartIdx|NC_IsCheck)pNC && cnt==0pTab!=0 && pTab->zName!=0pTab->nCol>0 || pParse->nErrpEList->nExpr==pTab->nColbRowid==0 || pEList->a[j].fg.bUsingTerm==0op==TK_DELETE || op==TK_UPDATE || op==TK_INSERTzTab==0 || sqlite3StrICmp(zTab,pParse->pTriggerTab->zName)==0 || isValidSchemaTableName(zTab, pParse->pTriggerTab, 0)iCol==(-1)iCol==31iCol==32VisibleRowid(pMatch->pSTab) || pMatch->fg.isNestedFrom(((pMatch->pSTab)->tabFlags & 0x00000200)==0) || pMatch->fg.isNestedFrompMatch->pSTabpExpr->pLeft==0 && pExpr->pRight==0ExprUseXList(pExpr)==0 || pExpr->x.pList==0ExprUseXSelect(pExpr)==0 || pExpr->x.pSelect==0EP_Win0x008000zTab==0 && zDb==0bRowidexcluded"excluded"EXCLUDED_TABLE_NUMBER(NC_IdxExpr|NC_GenCol)zAsmisuse of aliased aggregate %s"misuse of aliased aggregate %s"misuse of aliased window function %s"misuse of aliased window function %s"0x000080double-quoted string literal: "%w""double-quoted string literal: \"%w\""sizeof(pExpr->y)pFJMatch==0 || cnt>0no such column"no such column"ambiguous column name"ambiguous column name"%s: %s.%s.%s"%s: %s.%s.%s"%s: "%s" - should this be a string literal in single-quotes?"%s: \"%s\" - should this be a"
                              " string literal in single-quotes?"pFJMatch==0lookupname_endpTopNC!=0isValidSchemaTableNamezLegacypTab->tnum==1extendFJMatch(pMatch->fg.jointype & (JT_LEFT|JT_LTORJ))!=0sqlite3ExprColUsedpExTabpExTab!=0n < pExTab->nColpExTab->nCol==BMS-1pExTab->nCol==BMSpExTab->nColn==BMS-1n==BMSareDoubleQuotedStringsEnabledsqlite3MatchENamezSpaneENamepbRowid==0pbRowid==0 || *pbRowid==0zSpan[n]resolveAliasiCol>=0 && iCol<pEList->nExprpOrig!=0pExpr->y.pWin!=0incrAggFunctionDepthincrAggDepthsqlite3SelectWalkNoopsqlite3ExprWalkNoopsqlite3WalkerDepthDecreasesqlite3WalkerDepthIncreasesqlite3WalkSelectsqlite3WalkSelectFromsqlite3WalkSelectExprsqlite3WalkWinDefnDummyCallbacksqlite3WalkExprListsqlite3WalkExprsqlite3WalkExprNNpExpr->x.pList==0 || pExpr->pRight==0!ExprHasProperty(pExpr, EP_WinFunc)ExprHasProperty(pExpr, EP_TokenOnly)ExprHasProperty(pExpr, EP_Reduced)walkWindowListsqlite3JournalSizepVfs->szOsFile(int)sizeof(MemJournal)sqlite3JournalIsInMemorysqlite3MemJournalOpensqlite3JournalOpenMemJournal *zName || nSpill<0 || (flags & SQLITE_OPEN_EXCLUSIVE)sizeof(MemJournal)MEMJOURNAL_DFLT_FILECHUNKSIZE==fileChunkSize(p->nChunkSize)MEMJOURNAL_DFLT_FILECHUNKSIZE8 + MEMJOURNAL_DFLT_FILECHUNKSIZEsizeof(FileChunk)8 + MEMJOURNAL_DFLT_FILECHUNKSIZE - sizeof(FileChunk)memjrnlFileSizememjrnlSyncpJfdmemjrnlCloseFileChunk *memjrnlTruncatep->endpoint.pChunk==0 || p->endpoint.pChunk->pNext==0memjrnlWriteiOfst<=p->endpoint.iOffsetp->nChunkSize>iAmtp->nChunkSize - iChunkOffsetpChunk!=0 || iChunkOffset==0p->nChunkSizep->pFirst!p->pFirstpChunk!=0u8[8]pChunkiChunkOffsetiSpacememjrnlCreateFilecopynChunkmemjrnlFreeChunksmemjrnlReadp->readpoint.iOffset==0 || p->readpoint.pChunk!=0(p->nChunkSize - iChunkOffset)sqlite3VdbeBytecodeVtabInitbytecode"bytecode"tables_used"tables_used"bytecodevtabBestIndex SQLITE_CONSTRAINTbytecodevtab *(double)100bytecodevtabFilterbytecodevtab_cursor *stmt-pointer"stmt-pointer"argument to %s() is not a valid SQL statement"argument to %s() is not a valid SQL statement"bytecodevtabRowidbytecodevtabColumnaOp[0].opcode==OP_InitaOp[0].p4.z==0 || strncmp(aOp[0].p4.z,"-" "- ",3)==0zComconst Opconst Op *(FK)"(FK)"bytecodevtabEofbytecodevtabNextOp **VdbeOp **bytecodevtabClosebytecodevtabCursorClearbytecodevtabOpenbytecodevtabDisconnectbytecodevtabConnectisTabUsedazSchemaCREATE TABLE x(addr INT,opcode TEXT,p1 INT,p2 INT,p3 INT,p4 TEXT,p5 INT,comment TEXT,subprog TEXT,nexec INT,ncycle INT,stmt HIDDEN);"CREATE TABLE x("
      "addr INT,"
      "opcode TEXT,"
      "p1 INT,"
      "p2 INT,"
      "p3 INT,"
      "p4 TEXT,"
      "p5 INT,"
      "comment TEXT,"
      "subprog TEXT,"
      "nexec INT,"
      "ncycle INT,"
      "stmt HIDDEN"
    ");"char[133]CREATE TABLE x(type TEXT,schema TEXT,name TEXT,wr INT,subprog TEXT,stmt HIDDEN);"CREATE TABLE x("
      "type TEXT,"
      "schema TEXT,"
      "name TEXT,"
      "wr INT,"
      "subprog TEXT,"
      "stmt HIDDEN"
   ");"sqlite3VdbeSorterCompareconst VdbeCursorconst VdbeCursor *VdbeCursor *VdbeSorter *pSorterUnpackedRecord *pCsr->eCurType==CURTYPE_SORTERr2->nField==nKeyColconst VdbeSorterconst VdbeSorter *MEM_Nullsqlite3VdbeSorterRowkeyMEM_Blob0x00103519-3520vdbeSorterRowkeypSorter->list.pListPmaReader *MergeEngine *SorterRecord *sqlite3VdbeSorterNextpSorter->bUsePMA || (pSorter->pReader==0 && pSorter->pMerger==0)pSorter->pReader==0 || pSorter->pMerger==0pSorter->bUseThreads==0 || pSorter->pReaderpSorter->bUseThreads==1 || pSorter->pMergerpSorter->pMerger!=0pSorter->pMerger->pTask==(&pSorter->aTask[0])sqlite3VdbeSorterRewindSortSubtask *SorterList *SortSubtask[1]pSorter->pReader==0"rewind""rewinddone"vdbeSorterSetupMergepTask0MergeEngine **pSorter->bUseThreads==0 || pSorter->nTask>1pIncr->pTask!=pLastp->pIncr==0 || ( (p->pIncr->pTask==&pSorter->aTask[iTask]) && (iTask!=pSorter->nTask-1 || p->pIncr->bUseThread==0) )isRJseenNotpVarjumpIfNullxJumpsrcRegpRegregDestiFuncIdpiFreeablenegFlagnegateFlagpNewSiginFlagsprRhsHasNullregHasNullbAllowSubqinitFlagzObjectdequoteiSortOrdereNullsdupFlagspEdupBufpnHeightpVectorregSelectpRegFreein1in2pExpr1pExpr2zCpCollNamepErrorpbRowidbOneOnlynSpilliTaskpReadrsizeof(PmaReader)IncrMerger *IncrMerger **pIncrINCRINIT_TASKINCRINIT_ROOTINCRINIT_NORMALvdbeSorterMergeTreeBuildpSorter->bUseThreads || pSorter->nTask==1pTask->nPMA>0 || SQLITE_MAX_WORKER_THREADS>0pTask->nPMA - iSORTER_MAX_MERGE_COUNTpMain==0pTaskSQLITE_MAX_WORKER_THREADSnDepthiReadOffiSeqpMergervdbeSorterAddToTreenDivvdbeSorterTreeDepthvdbeMergeEngineLevel0nDummySorterFile *vdbePmaReaderIncrInitpIncr->bUseThread==0 || eMode==INCRINIT_TASKvdbePmaReaderBgIncrInitvdbePmaReaderIncrMergeInit(pReader,INCRINIT_TASK)vdbePmaReaderIncrMergeInit(pReader,1)vdbePmaReaderIncrMergeInitSQLITE_MAX_WORKER_THREADS>0 || eMode==INCRINIT_NORMALpTask->file2.iEof>0mxSzSorterFile[2]eMode==INCRINIT_ROOT || eMode==INCRINIT_TASKvdbeMergeEngineInitnTreepMerger!=0pMerger->pTask==0vdbeMergeEngineCompareiOut<pMerger->nTree && iOut>0pTask->pUnpacked!=0bCachedvdbeIncrMergerSetThreadsvdbeIncrMergerNewsizeof(*pIncr)pTask->pSorter->mxKeysize+9pTask->pSorter->mxPmaSize/2*ppOut!=0 || rc!=SQLITE_OKvdbeIncrSwapf0vdbeIncrBgPopulatepIncr->bUseThreadvdbeIncrPopulateThreadvdbeIncrPopulate(pIncr)vdbeIncrPopulatewriterpIncr->bEof==0PmaWriter *pIncr->pMerger->pTask==pTask"enter"sqlite3VdbeSorterWritebFlushnPMA(const u8*)&pVal->z[1]SORTER_TYPE_INTEGERSORTER_TYPE_TEXTsizeof(SorterRecord)rc!=SQLITE_OK || pSorter->list.pList==0iListOffvdbeSorterFlushPMAnWorkerSQLiteThread *pTask!=0pTask->pThread==0 && pTask->bDone==0pTask->list.pList==0pTask->list.aMemory==0 || pSorter->list.aMemory!=0aMemvdbeSorterFlushThreadpTask->bDone==0vdbeMergeEngineSteppReadr1pReadr20xFFFEvdbeSorterListToPMAsizeof(PmaWriter)pList->szPMA>0rc!=SQLITE_OK || pTask->file.pFdpTask->file.iEof==0pTask->nPMA==0rc!=SQLITE_OK || pList->pList==0rc!=SQLITE_OK || pTask->file.iEof==iSzvdbePmaWriteVarintu8[10]vdbePmaWriterFinishp->aBuffervdbePmaWriteBlobp->iBufEnd<p->nBuffervdbePmaWriterInitvdbeSorterSortSorterRecord *[64]SorterRecord **sizeof(aSlot)p->u.iNext<sqlite3MallocSize(pList->aMemory)ArraySize(aSlot)pTask->pUnpacked->errCode==SQLITE_OK || pTask->pUnpacked->errCode==SQLITE_NOMEMvdbeSorterGetComparevdbeSorterMergepFinalp1!=0 && p2!=0vdbeSortAllocUnpackedvdbeSorterOpenTempFile4098410241184126vdbeSorterExtendFilechunksize4*1024sqlite3VdbeSorterClosesqlite3VdbeSorterResetpSorter->bUseThreads || pSorter->pReader==0vdbeIncrFreevdbeMergeEngineFreevdbeMergeEngineNewnReader<=SORTER_MAX_MERGE_COUNTsizeof(MergeEngine)sizeof(int) + sizeof(PmaReader)(sizeof(int) + sizeof(PmaReader))vdbeSorterJoinAllvdbeSorterCreateThreadSQLiteThread **vdbeSorterJoinThread!bDonepTask->bDone==1SQLITE_INT_TO_PTR(SQLITE_ERROR)vdbeSortSubtaskCleanuppTask->list.aMemory==0sizeof(SortSubtask)vdbeSorterRecordFreesqlite3VdbeSorterInitszKeyInfopCsr->pKeyInfo!pCsr->isEphemeralsizeof(VdbeSorter)mxCacheSQLITE_MAX_PMASZ(1<<29)pSorter->mnPmaSize(int)mxCachepSorter->iMemory==0szPma-1024vdbeSorterCompareIntconst u8 *consts1s2(s1>0 && s1<7) || s1==8 || s1==9(s2>0 && s2<7) || s2==8 || s2==9res!=0const u8[10]!(pTask->pSorter->pKeyInfo->aSortFlags[0]&KEYINFO_ORDER_BIGNULL)vdbeSorterCompareTextvdbeSorterComparevdbeSorterCompareTailvdbePmaReaderInitpFile->iEof>iStartpReadr->aAlloc==0 && pReadr->nAlloc==0pReadr->aBuffer==0pReadr->aMap==0vdbePmaReaderNextvdbePmaReaderSeekpReadr->pIncr==0 || pReadr->pIncr->bEof==0iBufvdbeSorterMapFilevdbePmaReadVarintaVarintvdbePmaReadBlobnAvailnRead>0rc!=SQLITE_IOERR_SHORT_READ2*(sqlite3_int64)p->nAllocaNext!=p->aAllocaNext!=0aNextvdbePmaReaderClearIncrblob *103266rc!=SQLITE_SCHEMA(char*)0rc==SQLITE_OK || p->pStmt==0BtCursor *blobReadWrite103166db == v->dbnAttemptsizeof(Incrblob)pBlob->pStmt || db->mallocFailedsqlite3VdbeCurrentAddr(v)==2 || db->mallocFailedopenBlobaOp!=0cannot open virtual table: %s"cannot open virtual table: %s"cannot open table without rowid: %s"cannot open table without rowid: %s"cannot open table with generated columns: %s"cannot open table with generated columns: %s"cannot open view: %s"cannot open view: %s"no such column: "%s""no such column: \"%s\""zFaultforeign key"foreign key"indexed"indexed"cannot open %s column for writing"cannot open %s column for writing"const VdbeOpList[6]VdbeOpList[6]ArraySize(openBlob)SQLITE_MAX_SCHEMA_RETRYblob_open_outblobSeekToRowv->aOp[v->pc].opcode==OP_NotExistspC!=0pC->eCurType==CURTYPE_BTREEpC->nHdrParsed==p->iColpC->nHdrParsed==p->iCol+1VdbeCursor **cannot open value of type %s"cannot open value of type %s"no such rowid: %lld"no such rowid: %lld"rc!=SQLITE_OK || zErr==0rc!=SQLITE_ROW && rc!=SQLITE_DONEsqlite3VdbeExecresetSchemaOnFaultiComparenVmStepnProgressLimitpIn1pIn2pIn3colCacheCtrp->eVdbeState==VDBE_RUN_STATEp->lockMask0 < db->nProgressOpsu32[9]unsigned int[9]p->rc==SQLITE_OK || (p->rc&0xff)==SQLITE_BUSYp->bIsReader || p->readOnly!=0p->explain==0pOp>=aOp && pOp<&aOp[p->nOp]db->nProgressOps!=0pOp->p1>0 && pOp->p1<=(p->nMem+1 - p->nCursor)VdbeMemDynamic(pIn1)==0pOp->p1pOp->p3pOp->p2>=0 && pOp->p2<p->nOppOp->p3>=0 && pOp->p3<p->nOp!VdbeMemDynamic(pOut)pOp->p2>0pOp->p2<p->nOppIn1->flags==MEM_IntpIn1->u.i>=0 && pIn1->u.i<p->nOppCaller->opcode==OP_YieldpCaller->p2>=0 && pCaller->p2<p->nOppOp->p4type==P4_NOTUSED || pOp->p4type==P4_STATIC || pOp->p4type==P4_DYNAMICpOp->p1!=SQLITE_INTERNALpOp->p5<=4pOp->p3<=(p->nMem + 1 - p->nCursor)pOp->p5==1pOp->p5==2pOp->p5==3pOp->p5==4rc==SQLITE_BUSY || rc==SQLITE_OK || rc==SQLITE_ERRORrc==SQLITE_OK || (p->rc&0xff)==SQLITE_CONSTRAINTrc==SQLITE_OK || db->nDeferredCons>0 || db->nDeferredImmCons>0pOp->p4.pI64!=0!sqlite3IsNaN(*pOp->p4.pReal)pOp->p4.z!=0rc==SQLITE_OK || rc==SQLITE_TOOBIGpOut->szMalloc>0 && pOut->zMalloc==pOut->zVdbeMemDynamic(pOut)==0pOp->p3<=(p->nMem+1 - p->nCursor)pIn3->flags & MEM_IntpOp->p1 <= SQLITE_MAX_LENGTHpOp->p1>0 && pOp->p1<=p->nVarMemn>0 && p1>0 && p2>0p1+n<=p2 || p2+n<=p1pOut<=&aMem[(p->nMem+1 - p->nCursor)]pIn1<=&aMem[(p->nMem+1 - p->nCursor)]memIsValid(pIn1)p2++pOut!=pIn1pOp->p2+pOp->p3-n(pIn1->flags & MEM_Int)!=0p->nResColumn==pOp->p2pOp->p1>0 || CORRUPT_DBpOp->p1+pOp->p2<=(p->nMem+1 - p->nCursor)+1pOut==pIn2pIn1!=pOutflags1 & MEM_NullpIn2->flags & MEM_NullMEM_Str(pIn2->flags & MEM_Dyn) == (flags2 & MEM_Dyn)(pIn1->flags & MEM_Dyn) == (flags1 & MEM_Dyn)MEM_IntMEM_Realop==OP_ShiftRight || op==OP_ShiftLeftOP_ShiftRight==OP_ShiftLeft+1pIn1->flags & MEM_IntpIn1->flags & MEM_IntRealpOp->p2>=SQLITE_AFF_BLOB && pOp->p2<=SQLITE_AFF_REALpOp->p2==SQLITE_AFF_TEXTpOp->p2==SQLITE_AFF_BLOBpOp->p2==SQLITE_AFF_NUMERICpOp->p2==SQLITE_AFF_INTEGERpOp->p2==SQLITE_AFF_REAL(pOp->p5 & SQLITE_NULLEQ)?2:3iCompareIsInit = 1;(flags1 & MEM_Cleared)==0(pOp->p5 & SQLITE_JUMPIFNULL)==0 || CORRUPT_DB(pOp->p5 & SQLITE_JUMPIFNULL)!=0flags3==pIn3->flags || CORRUPT_DBpIn1->flags & MEM_Real(flags1&MEM_Dyn) != (pIn1->flags&MEM_Dyn)pIn1==pIn3pIn3->flags & MEM_RealpIn3->flags & MEM_IntReal(flags3&MEM_Dyn) != (pIn3->flags&MEM_Dyn)pOp->p4type==P4_COLLSEQ || pOp->p4.pColl==0OP_Eq==OP_Ne+1OP_Gt==OP_Ne+2OP_Le==OP_Ne+3OP_Lt==OP_Ne+4OP_Ge==OP_Ne+5(pIn3->flags & MEM_Dyn) == (flags3 & MEM_Dyn)res2!=0iCompareIsInitiCompare==0pOp->p4type==P4_INTARRAYpOp->p4.aipOp[1].opcode==OP_ComparepOp[1].p5 & OPFLAG_PERMUTEpOp>aOppOp[-1].opcode==OP_PermutationpOp[-1].p4type==P4_INTARRAYaPermute!=0memIsValid(&aMem[p1+idx])memIsValid(&aMem[p2+idx])p1+idx&aMem[p1+idx]p2+idx&aMem[p2+idx]i<pKeyInfo->nKeyFieldpOp[1].opcode==OP_JumppOp>aOp && pOp[-1].opcode==OP_ComparepOp->p4type==P4_INT32pOp->p4.i==0 || pOp->p4.i==1pOp->p3==0 || pOp->p3==1p->aOp[0].opcode==OP_Initc!=0(pIn1->flags & MEM_Null)!=0pOp->p1>=(-1) && pOp->p1<p->nCursorpOp->p1>=0 || (pOp->p3>=0 && pOp->p3<=(p->nMem+1 - p->nCursor))pOp->p3>=0serialType==0serialType==1serialType==2serialType==3serialType==4serialType==5serialType==6serialType==7serialType==8serialType==9serialType==10serialType==11typeMask==0x01typeMask==0x02typeMask==0x04typeMask==0x08typeMask==0x10memIsValid(&aMem[pOp->p3])(typeMask & pOp->p5)!=0(pIn1->flags & MEM_Null)==0pOp->p1>=0 && pOp->p1<p->nCursorpOp->p3>0 && pOp->p3<=(p->nMem+1 - p->nCursor)p2<(u32)pC->nField || (pC->eCurType==CURTYPE_PSEUDO && pC->seekResult==0)aOffset==pC->aType+pC->nFieldpC->eCurType!=CURTYPE_VTABpC->eCurType!=CURTYPE_PSEUDO || pC->nullRowpC->eCurType!=CURTYPE_SORTERpReg->flags & MEM_BlobmemIsValid(pReg)!pC->isEphemeralpCrsrsqlite3BtreeCursorIsValid(pCrsr)pC->szRow<=pC->payloadSizepC->szRow<=65536pC->nHdrParsed<=p2aOffset[0]==0zHdr>=zEndHdrp2<pC->nHdrParsedsqlite3VdbeCheckMemInvariants(pDest)t==pC->aType[p2]pDest->db==dbpOp->p4type==P4_TABLEpTab->tabFlags & TF_StrictpTab->nNVCol==pOp->p2pIn1 < &aMem[pOp->p1+pOp->p2](pIn1->flags & (MEM_Real|MEM_IntReal))==MEM_Real(pIn1->flags & MEM_IntReal)==0pIn1->u.i==140737488355328LLpIn1->u.i==140737488355327LLpIn1->u.i==-140737488355328LLpIn1->u.i==-140737488355329LL(int)(pIn1-aMem)pIn1 == &aMem[pOp->p1+pOp->p2]zAffinity!=0zAffinity[pOp->p2]==0pIn1 <= &p->aMem[(p->nMem+1 - p->nCursor)]zAffinity[0]==SQLITE_AFF_NONE || memIsValid(pIn1)nField>0 && pOp->p2>0 && pOp->p2+nField<=(p->nMem+1 - p->nCursor)+1pOp->p3<pOp->p1 || pOp->p3>=pOp->p1+pOp->p2pData0<=pLast(int)(pRec-aMem)pReczAffinity[0]==0 || pRec<=pLastmemIsValid(pRec)pOp->p5==OPFLAG_NOCHNG_MAGIC || CORRUPT_DBpRec->flags & MEM_IntpRec->flags & MEM_IntRealuu==127uu==128uu==32767uu==32768uu==8388607uu==8388608uu==2147483647uu==2147483648LLuu==140737488355327LLuu==140737488355328LLdb->mallocFailed || pRec->flags&(MEM_Str|MEM_Blob)pRec->n>=0nHdr==126nHdr==127sizeof(v)==sizeof(pRec->u.r)len>=1 && len<=8 && len!=5 && len!=7pRec->z!=0nHdr==(int)(zHdr - (u8*)pOut->z)nByte==(int)(zPayload - (u8*)pOut->z)p->apCsr[pOp->p1]->eCurType==CURTYPE_BTREEdb->pSavepoint==0 || db->autoCommit==0p1==SAVEPOINT_BEGIN||p1==SAVEPOINT_RELEASE||p1==SAVEPOINT_ROLLBACKdb->pSavepoint || db->isTransactionSavepoint==0checkSavepointCount(db)p->bIsReaderdb->autoCommit==0 || db->nVTrans==0p1==SAVEPOINT_RELEASE || p1==SAVEPOINT_ROLLBACKp1==SAVEPOINT_RELEASEpSavepoint==db->pSavepointp1==SAVEPOINT_ROLLBACKdesiredAutoCommit==1 || desiredAutoCommit==0desiredAutoCommit==1 || iRollback==0db->nVdbeActive>0desiredAutoCommit==1p->readOnly==0 || pOp->p2==0pOp->p2>=0 && pOp->p2<=2pOp->p1>=0 && pOp->p1<db->nDbDbMaskTest(p->btreeMask, pOp->p1)rc==SQLITE_BUSY_SNAPSHOTrc==SQLITE_BUSY_RECOVERYsqlite3BtreeTxnState(pBt)==SQLITE_TXN_WRITEdb->nStatement>=0 && db->nSavepoint>=0pOp->p5==0 || pOp->p4type==P4_INT32pOp->p3<SQLITE_N_BTREE_METADbMaskTest(p->btreeMask, iDb)pOp->p2<SQLITE_N_BTREE_METAp->readOnly==0pDb->pBt!=0sqlite3SchemaMutexHeld(db, pOp->p1, 0)pOp->p5==0 || pOp->p5==OPFLAG_SEEKEQpOp->p4type==P4_KEYINFOpCur->iDb==pOp->p3pCur->eCurType==CURTYPE_BTREEpOp->opcode==OP_OpenWrite || pOp->p5==0 || pOp->p5==OPFLAG_SEEKEQpOp->opcode==OP_OpenRead || pOp->opcode==OP_ReopenIdx || p->readOnly==0OPFLAG_FORDELETE==BTREE_FORDELETEp2<=(u32)(p->nMem+1 - p->nCursor)memIsValid(pIn2)(pIn2->flags & MEM_Int)!=0p2>=2(pOp->p5 & OPFLAG_P2ISREG)==0pKeyInfo->enc==ENC(db)pKeyInfo->db==dbpOp->p1>=0nField>=0nField==0OPFLAG_BULKCSR==BTREE_BULKLOADOPFLAG_SEEKEQ==BTREE_SEEK_EQpOp->p5 & OPFLAG_BULKCSRpOp->p2 & OPFLAG_SEEKEQpOrig->isEphemeralpOp->p2>=0pOp->p2==0pOp->opcode==OP_OpenEphemeralaMem[pOp->p3].flags & MEM_NullpOp->p2<=pCx->nFieldpCx->isEphemeralpCx->pgnoRoot==SCHEMA_ROOT+1p->apCsr[pOp->p1]==pCx!sqlite3BtreeClosesWithCursor(pCx->ub.pBtx, pCx->uc.pCursor)sqlite3BtreeClosesWithCursor(pCx->ub.pBtx, pCx->uc.pCursor)pCx->pKeyInfo->db==dbpCx->pKeyInfo->enc==ENC(db)isSorter(pC)pOp->p5==0pOp->p2!=0OP_SeekLE == OP_SeekLT+1OP_SeekGE == OP_SeekLT+2OP_SeekGT == OP_SeekLT+3pC->isOrderedpC->uc.pCursor!=0sqlite3BtreeCursorHasHint(pC->uc.pCursor, BTREE_SEEK_EQ)==0 || CORRUPT_DBOP_SeekGE==(OP_SeekGT-1)OP_SeekLT==(OP_SeekLE-1)(OP_SeekLE & 0x0001)==(OP_SeekGT & 0x0001)OP_SeekLE==(OP_SeekLT+1)OP_SeekGT==(OP_SeekGE+1)(OP_SeekLT & 0x0001)==(OP_SeekGE & 0x0001)pOp->opcode==OP_SeekGE || pOp->opcode==OP_SeekLEpOp[1].opcode==OP_IdxLT || pOp[1].opcode==OP_IdxGTpOp->opcode==OP_SeekGE || pOp[1].opcode==OP_IdxLTpOp->opcode==OP_SeekLE || pOp[1].opcode==OP_IdxGTpOp[1].p1==pOp[0].p1pOp[1].p2==pOp[0].p2pOp[1].p3==pOp[0].p3pOp[1].p4.i==pOp[0].p4.inField>0oc!=OP_SeekGT || r.default_rc==-1oc!=OP_SeekLE || r.default_rc==-1oc!=OP_SeekGE || r.default_rc==+1oc!=OP_SeekLT || r.default_rc==+1oc==OP_SeekGE || oc==OP_SeekGToc==OP_SeekLT || oc==OP_SeekLEpOp[1].opcode==OP_SeekGEpOp->p2>=(int)(pOp-aOp)+2pOp->p1>0!pC->isTablenStep>=1pOp->p3>=pOp->p2pCur==0 || pCur->nullRowpC->isTable==0r.aMem->flags & MEM_BlobpOp->opcode!=OP_NoConflictr.aMemalreadyExists!=0(pIn3->flags & (MEM_Str|MEM_Int))==MEM_Str(pIn3->flags & MEM_Int)!=0 || pOp->opcode==OP_SeekRowidpC->isTablepCrsr!=0rc==SQLITE_OK || res==0p->apCsr[pOp->p1]!=0p->apCsr[pOp->p1]->eCurType!=CURTYPE_VTABsqlite3BtreeCursorIsValid(pC->uc.pCursor)pOp->p3>0pOp->p3<=pFrame->nMempMemmemIsValid(pMem)(pMem->flags & MEM_Int)!=0pOp->p3==0v>0memIsValid(pData)pC->deferredMoveto==0(pOp->p5 & OPFLAG_ISNOOP) || pC->isTablepOp->p4type==P4_TABLE || pOp->p4type>=P4_STATICpOp->p2pKey->flags & MEM_IntmemIsValid(pKey)pC->iDb>=0(pOp->p5 & OPFLAG_ISNOOP) || HasRowid(pTab)(pOp->p5 & OPFLAG_LASTROWID)==0 || (pOp->p5 & OPFLAG_NCHANGE)!=0(pData->flags & (MEM_Blob|MEM_Str))!=0 || pData->n==0BTREE_PREFORMAT==OPFLAG_PREFORMATdb->xUpdateCallback!=0pTab->aCol!=0pOp[1].opcode==OP_Insert || pOp[1].opcode==OP_IdxInsertpOp[1].opcode==OP_Insert || pOp->p3==0pOp[1].opcode==OP_IdxInsert || pOp->p3>0pOp[1].p5 & OPFLAG_PREFORMATpOp->p4.pTab!=0(pOp->p5 & ~(OPFLAG_SAVEPOSITION|OPFLAG_AUXDELETE))==0OPFLAG_SAVEPOSITION==BTREE_SAVEPOSITIONOPFLAG_AUXDELETE==BTREE_AUXDELETErc!=SQLITE_OK || (pOut->flags & MEM_Blob)isSorter(pC)==0pC->nullRow==0pC->uc.pVCur!=0pModule->xRowidpOp->p3>=-1 && pOp->p3<=640*2pOp->p4.i>=-1 && pOp->p4.i<=640*2sz>0isSorter(pC)==(pOp->opcode==OP_SorterSort)pOp->p5==0 || pOp->p5==SQLITE_STMTSTATUS_FULLSCAN_STEP || pOp->p5==SQLITE_STMTSTATUS_AUTOINDEXpC->seekOp==OP_SeekLT || pC->seekOp==OP_SeekLE || pC->seekOp==OP_Last || pC->seekOp==OP_IfNoHope || pC->seekOp==OP_NullRowpC->seekOp==OP_SeekGT || pC->seekOp==OP_SeekGE || pC->seekOp==OP_Rewind || pC->seekOp==OP_Found || pC->seekOp==OP_NullRow|| pC->seekOp==OP_SeekRowid || pC->seekOp==OP_IfNoHope!isSorter(pC)(pIn2->flags & MEM_Blob) || (pOp->p5 & OPFLAG_PREFORMAT)pIn2->flags & MEM_BlobpOp->p2>0 && pOp->p2+pOp->p3<=(p->nMem+1 - p->nCursor)+1pC->eCurType==CURTYPE_BTREE || IsNullCursor(pC)pC->isTable==0 || IsNullCursor(pC)!pC->nullRow || pOp->opcode==OP_IdxRowidpOp->p3>=0 && pOp->p3<p->nCursorpTabCur!=0pTabCur->eCurType==CURTYPE_BTREEpTabCur->uc.pCursor!=0pTabCur->isTablepOp->p4type==P4_INTARRAY || pOp->p4.ai==0!pTabCur->isEphemeralpOp->opcode==OP_IdxRowidpOp->opcode==OP_IdxLE || pOp->opcode==OP_IdxGTpOp->opcode==OP_IdxGE || pOp->opcode==OP_IdxLTsqlite3BtreeCursorIsValid(pCur)(OP_IdxLE&1)==(OP_IdxLT&1) && (OP_IdxGE&1)==(OP_IdxGT&1)pOp->opcode==OP_IdxLE || pOp->opcode==OP_IdxLTpOp->opcode==OP_IdxGE || pOp->opcode==OP_IdxGTres>0pOp->p1>1resetSchemaOnFault==0 || resetSchemaOnFault==iDb+1DbMaskTest(p->btreeMask, pOp->p2)&aMem[pOp->p3]pC->isEphemeralpOp->p3==BTREE_INTKEY || pOp->p3==BTREE_BLOBKEYDbHasProperty(db, iDb, DB_SchemaLoaded) || db->mallocFailed || (CORRUPT_DB && (db->flags & SQLITE_NoSchemaError)!=0)nRoot>0aRoot!=0aRoot[0]==(Pgno)nRootpOp->p1>0 && (pOp->p1+1)<=(p->nMem+1 - p->nCursor)(pnErr->flags & MEM_Int)!=0(pnErr->flags & (MEM_Str|MEM_Blob))==0pOp->p5<db->nDbDbMaskTest(p->btreeMask, pOp->p5)sqlite3VdbeMemIsRowSet(pIn1)(pIn1->flags & MEM_Blob)==0 || sqlite3VdbeMemIsRowSet(pIn1)pIn3->flags&MEM_IntiSet==-1 || iSet>=0exists!=0pProgram->nOp>0nMem>0sizeof(VdbeFrame)pFramepRt->xDel==sqlite3VdbeFrameMemDelpProgram->nMem+pProgram->nCsr==pFrame->nChildMem || (pProgram->nCsr==0 && pProgram->nMem+1==pFrame->nChildMem)pProgram->nCsr==pFrame->nChildCsr(int)(pOp - aOp)==pFrame->pcpFrame->pAuxData==0db->nDeferredCons==0 && db->nDeferredImmCons==0p->nFkConstraint==0 && db->nDeferredImmCons==0pIn1->flags&MEM_IntpIn1->u.i>0pIn1->u.i<0pIn1->u.i==0pOp->p4type==P4_FUNCDEFn==0 || (pOp->p2>0 && pOp->p2+n<=(p->nMem+1 - p->nCursor)+1)pOp->p3<pOp->p2 || pOp->p3>=pOp->p2+nsizeof(pCtx[0]) + (n-1)*sizeof(sqlite3_value*)EIGHT_BYTE_ALIGNMENT(pCtx->pOut)pOp->p1==(pOp->opcode==OP_AggInverse)pOp->p4type==P4_FUNCCTXpCtx->pOut->flags==MEM_NullpCtx->isError==0pCtx->skipFlag==0pOp[-1].opcode==OP_CollSeqpOp->p3==0 || pOp->opcode==OP_AggValue(pMem->flags & ~(MEM_Null|MEM_Agg))==0(int)(pMem-aMem)pOp->p2==SQLITE_CHECKPOINT_PASSIVE || pOp->p2==SQLITE_CHECKPOINT_FULL || pOp->p2==SQLITE_CHECKPOINT_RESTART || pOp->p2==SQLITE_CHECKPOINT_TRUNCATEeNew==PAGER_JOURNALMODE_DELETE || eNew==PAGER_JOURNALMODE_TRUNCATE || eNew==PAGER_JOURNALMODE_PERSIST || eNew==PAGER_JOURNALMODE_OFF || eNew==PAGER_JOURNALMODE_MEMORY || eNew==PAGER_JOURNALMODE_WAL || eNew==PAGER_JOURNALMODE_QUERYsqlite3BtreeTxnState(pBt)!=SQLITE_TXN_WRITEpOp->p2==0 || pOp->p2==10x00004p1>=0 && p1<db->nDbDbMaskTest(p->btreeMask, p1)isWriteLock==0 || isWriteLock==1(aMem[pOp->p2].flags & MEM_Str)!=0(aMem[pOp->p2].flags & MEM_Static)!=0zTab || db->mallocFailedp->errorAction==OE_Abort && p->usesStmtJournalpVtab->pModule==0pOp->p4type==P4_TABLEREFpTab->nTabRef>0pModule!=0pModule->iVersion>=4pModule->xIntegrity!=0memIsValid(pQuery)pCur!=0pCur->eCurType==CURTYPE_VTAB(pQuery->flags&MEM_Int)!=0 && pArgc->flags==MEM_IntnArg<=p->napArgpModule->xColumnpOp->p5==OPFLAG_NOCHNG || pOp->p5==0pModule->xNext!respVtab->pModule->xRenamememIsValid(pName)pName->flags & MEM_StrpName->enc==SQLITE_UTF8pName->enc==SQLITE_UTF16BEpName->enc==SQLITE_UTF16LEpOp->p2==1 || pOp->p5==OE_Fail || pOp->p5==OE_Rollback || pOp->p5==OE_Abort || pOp->p5==OE_Ignore || pOp->p5==OE_ReplacepModule->xUpdatememIsValid(pX)nArg>1 && apArg[0] && (apArg[0]->flags&MEM_Null)pCtx->pVdbe==p(pOut->flags&MEM_Str)==0 || pOut->enc==encoding || db->mallocFailed!sqlite3VdbeMemTooBig(pOut)pIn1->flags & MEM_BlobpIn1->n>0(pIn1->flags & MEM_Blob)!=0pIn1->n >= 1pOp->p4.z==0 || strncmp(pOp->p4.z, "-" "- ", 3)==0pOp==p->aOp || pOp->opcode==OP_TracepOp->opcode==OP_Noop || pOp->opcode==OP_Explainjump_to_p2_and_check_for_interruptcheck_for_interruptjump_to_p2OP_EndCoroutinepCallerpcDestVdbeFrame *P4_NOTUSEDconst char *const[4]NOT NULL"NOT NULL"CHECK"CHECK"FOREIGN KEY"FOREIGN KEY"%s constraint failed"%s constraint failed"%z: %s"%z: %s"abort at %d in [%s]: %s"abort at %d in [%s]: %s"MEM_StaticOP_String8194MEM_Term870682088720nullFlagMEM_Cleared(MEM_Null|MEM_Cleared)MEM_UndefinedMEM_AffMask(MEM_Undefined|MEM_AffMask)~(MEM_Undefined|MEM_AffMask)36864MEM_DynMEM_Ephem(MEM_Dyn|MEM_Ephem)-20481~(MEM_Dyn|MEM_Ephem)MEM_FromBind8256MEM_Subtype~MEM_Subtypeflags1flags2(MEM_Str|MEM_Blob)~MEM_StrMEM_ZeroOP_MultiplyOP_DivideOP_Remaindertype2iAiBrArBint_mathfp_math(double)0arithmetic_result_is_nullOP_BitOrOP_ShiftLeftOP_ShiftRightuA2*OP_ShiftLeft2*OP_ShiftLeft + 1(-64)sizeof(uA)(u64)0xffffffff((u64)0xffffffff)((u64)0xffffffff)<<32(((u64)0xffffffff)<<32)(((u64)0xffffffff)<<32)|0xffffffff((((u64)0xffffffff)<<32)|0xffffffff)sizeof(iA)MEM_IntReal(MEM_Int|MEM_IntReal)res2flags3SQLITE_AFF_MASK(MEM_Int|MEM_IntReal|MEM_Real|MEM_Str)(MEM_Int|MEM_Real|MEM_IntReal)-45~(MEM_Int|MEM_Real|MEM_IntReal)MEM_TypeMask~MEM_TypeMaskconst KeyInfoconst KeyInfo *CollSeq *constCollSeq *const *OP_AndOP_Orconst unsigned char[9]and_logicor_logicOP_BitNottypeMaskserialTypeconst unsigned char[12]aMaskCURTYPE_BTREEaOffsetsMemzDatazEndHdroffset64op_column_restartCURTYPE_PSEUDO98307sizeof(sMem)op_column_read_headerconst u16[2]unsigned short[2]514aFlagop_column_outop_column_corrupt96769COLTYPE_BLOBCOLTYPE_INTCOLTYPE_TEXTCOLTYPE_REAL140737488355327140737488355327LL140737488355328140737488355328LL-140737488355328-140737488355328LL~MEM_Int(MEM_Real|MEM_IntReal)vdbe_type_errorcannot store %s value in %s column %s.%s"cannot store %s value in %s column %s.%s"3091zAffinity(MEM_Int|MEM_Str)~(MEM_Int|MEM_Str)nVarintserial_typepData0zPayload(MEM_Int)~(MEM_Int)uu8388607~MEM_IntRealsizeof(v)pSavepointcannot open savepoint - SQL statements in progress"cannot open savepoint - SQL statements in progress"sizeof(Savepoint)no such savepoint: %s"no such savepoint: %s"cannot release savepoint - SQL statements in progress"cannot release savepoint - "
                          "SQL statements in progress"isTransactionisSchemaChangeVDBE_HALT_STATEdesiredAutoCommitiRollbackcannot commit transaction - SQL statements in progress"cannot commit transaction - "
                          "SQL statements in progress"cannot start a transaction within a transaction"cannot start a transaction within a transaction"cannot rollback - no transaction is active"cannot rollback - no transaction is active"cannot commit - no transaction is active"cannot commit - no transaction is active"iMetaSQLITE_QueryOnly8590983168(SQLITE_QueryOnly|SQLITE_CorruptRdOnly)wrFlagBTREE_WRCSRopen_cursor_set_hints(OPFLAG_BULKCSR|OPFLAG_SEEKEQ)pCx1054vfsFlagsCACHE_STALEBTREE_OMIT_JOURNALBTREE_SINGLECURTYPE_SORTERoceqOnlynewType(MEM_Int|MEM_Real|MEM_IntReal|MEM_Str)(OP_SeekGT & 0x0001)(OP_SeekLT & 0x0001)BTREE_SEEK_EQseek_not_foundseekscan_search_failalreadyExistspIdxKeynotExistsWithKey99029MAX_ROWID(MAX_ROWID>>1)seekResultconst BtreePayloadconst BtreePayload *BtreePayload *(OPFLAG_APPEND|OPFLAG_SAVEPOSITION|OPFLAG_PREFORMAT)opflagsCURTYPE_VTABnext_tailBTREE_AUXDELETE779100121index corruption"index corruption"pTabCurnCellKey100326(OP_IdxLT&1)iMovednChangesavedAnalysisLimitOP_ParseSchemaSELECT*FROM"%w".%s WHERE %s ORDER BY rowid"SELECT*FROM\"%w\".%s WHERE %s ORDER BY rowid"100619pnErrRowSet *existsnMempRttoo many levels of trigger recursion"too many levels of trigger recursion"ROUND8(sizeof(VdbeFrame))sizeof(Mem)sizeof(VdbeCursor*)AuxData *P4_FUNCCTXOP_AggStep1int[3]eNeweOldconst Pagerconst Pager *cannot change %s wal mode from within a transaction"cannot change %s wal mode from within a transaction"into"into"out of"out of"PAGER_JOURNALMODE_MEMORY17179869184database table is locked: %s"database table is locked: %s"pVCurValueList *sizeof(*pRhs)ValueList"ValueList"iQuerypArgcMem **nullFunc1025(u64)SQLITE_LegacyAlter18446744073642442751~(u64)SQLITE_LegacyAltervtabOnConflictnewMaxOP_PureFuncOP_FunctionAuxData **OP_InitzTrace(SQLITE_TRACE_STMT|SQLITE_TRACE_LEGACY)abort_due_to_error84488458102681statement aborts at %d: [%s] %s"statement aborts at %d: [%s] %s"VDBE_RUN_STATEvdbe_returnrc!=SQLITE_OK || nExtraDelete==0 || sqlite3_strlike("DELETE%",p->zSql,0)!=0too_bigno_memabort_due_to_interruptAtomicLoad(&db->u1.isInterrupted)p->rc!=SQLITE_OKvdbeMemTypeNameazTypesINT"INT"REAL"REAL"TEXT"TEXT"BLOB"BLOB"vdbeColumnFromOverflowt>=124000VdbeTxtBlbCache *pCachesizeof(VdbeTxtBlbCache)~MEM_EphemfilterHash4093out2PrereleasepOp->p2<=(p->nMem+1 - p->nCursor)out2PrereleaseWithClearnumericType(pMem->flags & MEM_Null)==0 || pMem->db==0 || pMem->db->mallocFailedpMem->flags & MEM_IntpMem->flags & MEM_RealpMem->flags & MEM_IntReal(MEM_Int|MEM_Real|MEM_IntReal|MEM_Null)pMem->flags & (MEM_Str|MEM_Blob)pMem->flags & MEM_StrpMem->flags & MEM_BlobcomputeNumericType(pMem->flags & (MEM_Int|MEM_Real|MEM_IntReal))==0(pMem->flags & (MEM_Str|MEM_Blob))!=0sqlite3ValueApplyAffinityapplyAffinityaffinity==SQLITE_AFF_INTEGER || affinity==SQLITE_AFF_REAL || affinity==SQLITE_AFF_NUMERIC || affinity==SQLITE_AFF_FLEXNUMpRec->flags & MEM_Real(MEM_Real|MEM_Int|MEM_IntReal)~(MEM_Real|MEM_Int|MEM_IntReal)applyNumericAffinityrValue(pRec->flags & (MEM_Str|MEM_Int|MEM_Real|MEM_IntReal))==MEM_StralsoAnIntallocateCursorsizeof(VdbeCursor)ROUND8P(sizeof(VdbeCursor))2*sizeof(u32)iCur>=0 && iCur<p->nCursorpMem->flags==MEM_Undefined(pMem->flags & MEM_Dyn)==0pMem->szMalloc==0 || pMem->z==pMem->zMallocVdbeCursorpAltCursoroffsetof(VdbeCursor,pAltCursor)sqlite3VdbeExpandSqlnextIndex(zRawSql - zStart) > 0zRawSql[0] || nToken==0sqlite3Isdigit(zRawSql[1])zRawSql[0]==':' || zRawSql[0]=='$' || zRawSql[0]=='@' || zRawSql[0]=='#'zRawSql[0]==':'zRawSql[0]=='$'zRawSql[0]=='@'zRawSql[0]=='#'idx>0idx + 1idx>0 && idx<=p->nVarpVar->flags & MEM_Blob-- "-- "%!.15g"%!.15g"sizeof(utf8)'%.*q'"'%.*q'"zeroblob(%d)"zeroblob(%d)"findNextHostParametern>0 && tokenType!=TK_ILLEGALdb->lookaside.pEnd==db->lookaside.pTrueEndVDBE_READY_STATE(pTo->prepFlags & SQLITE_PREPARE_SAVESQL)!=0 || pTo->expmask==0(pFrom->prepFlags & SQLITE_PREPARE_SAVESQL)!=0 || pFrom->expmask==0sqlite3TransferBindingspTo->db==pFrom->dbpTo->nVar==pFrom->nVarsqlite3VdbeParameterIndex(n & 0x7FFFFFFF)==np!=0 && p->aVar!=0 && i>0 && i<=p->nVarpValue->flags & (MEM_Real|MEM_IntReal)~(u64)1xDel!=SQLITE_DYNAMIC(u16)1~(u16)1bindTextp->dbvdbeUnbind9230892312bind on a busy prepared statement: [%s]"bind on a busy prepared statement: [%s]"92316(p->prepFlags & SQLITE_PREPARE_SAVESQL)!=0 || p->expmask==0columnNameconst u16[60]unsigned short[60]const char *const[12]char *[12]prior_mallocFailedcolumnName_end~MEM_StaticcolumnMallocFailuresqlite3_mutex_held(p->db->mutex)columnMempVmpVm->dbcolumnNullValuenullMem(u16)MEM_Null(u8)0(sqlite3*)0(u32)0(void(*)(void*))0p && p->pMem && p->pFunc && p->pFunc->xFinalizepAuxDatasqlite3_mutex_held(pCtx->pOut->db->mutex)sizeof(AuxData)failedpCtx->pVdbe!=0p && p->pFunc && p->pFunc->xFinalizesqlite3_mutex_held(p->pOut->db->mutex)MEM_AggnByte<0createAggContext(pMem->flags & MEM_Agg)==0sqlite3StmtCurrentTimepiTimep->pVdbe!=0valueFromValueList91692(pVal->flags&(MEM_TypeMask|MEM_Term|MEM_Subtype)) == (MEM_Null|MEM_Term|MEM_Subtype)pVal->eSubtype=='p'pVal->u.zPType!=0 && strcmp(pVal->u.zPType,"ValueList")==0rc==SQLITE_OK || sqlite3BtreeEof(pRhs->pCsr)&zBuf[1]iSerialpOut->dbsqlite3VdbeValueListFreep && p->pOutp && p->pFunc91571v->expired==0savedPcsqlite3Stepdb->nVdbeWrite>0 || db->autoCommit==0 || ((db->nDeferredCons + db->nDeferredImmCons)==0)p->startTime==0p->eVdbeState==VDBE_HALT_STATEp->eVdbeState==3p->eVdbeState==VDBE_READY_STATErestart_step(SQLITE_TRACE_PROFILE|SQLITE_TRACE_XPROFILE)end_of_step(p->prepFlags & SQLITE_PREPARE_SAVESQL)!=0 || rc==SQLITE_ROW || rc==SQLITE_DONE || rc==SQLITE_ERROR || (rc&0xff)==SQLITE_BUSY || rc==SQLITE_MISUSEdoWalCallbackssqlite3ResultIntRealsqlite3_mutex_held(pOut->db->mutex)misuse of sqlite3_result_subtype() by %s()"misuse of sqlite3_result_subtype() by %s()"n>=0invokeValueDestructorpCtx!=0setResultStrOrErrorrc==SQLITE_NOMEM~MEM_Dyn(MEM_Static|MEM_Dyn)-12289~(MEM_Static|MEM_Dyn)(MEM_Term|MEM_Subtype)-2561~(MEM_Term|MEM_Subtype)(MEM_Null|MEM_Zero)aTypeconst u8[64]4031(MEM_TypeMask|MEM_Term|MEM_Subtype)2561(MEM_Null|MEM_Term|MEM_Subtype)p->flags==MEM_Null && p->z==0(MEM_Blob|MEM_Str)(rc & (db->errMask))==rcv->eVdbeState>=VDBE_READY_STATE90777invokeProfileCallbackiNowiElapsep->startTime>0p->zSql!=0vdbeSafetyNotNullAPI called with NULL prepared statement"API called with NULL prepared statement"vdbeSafetyAPI called with finalized prepared statement"API called with finalized prepared statement"sqlite3VtabImportErrmsgsqlite3NotPureFunca CHECK constraint"a CHECK constraint"a generated column"a generated column"an index"an index"non-deterministic use of %s() in %s"non-deterministic use of %s() in %s"sqlite3VdbeSetVarmaskiVar>0(v->db->flags & SQLITE_EnableQPSG)==0 || (v->db->mDbFlags & DBFLAG_InternalFunc)!=0sqlite3VdbeGetBoundValuesqlite3VdbePrepareFlagssqlite3VdbeDbsqlite3ExpirePreparedStatementssqlite3VdbeCountChangessqlite3VdbeSetChangessqlite3VdbeIdxKeyCompare90380sqlite3VdbeIdxRowidszHdrtypeRowidlenRowid(nCellKey & SQLITE_MAX_U32)==(u64)nCellKey(u8*)m.zm.n>=0szHdr<3 || szHdr>(unsigned)m.n(u8*)&m.z[szHdr-1]piOffsetpiEofnExtendppFdrcinxTaskpRecordpbKey2CachedxCallcacheStatusbTryForIntpiValueeCurTypezRawSqlpFromStmtpToStmtzPTtypeuseUtf16useTypebNextpToDeleteeSubtypezPTypepUnpackedtypeRowid<1 || typeRowid>9 || typeRowid==7(u32)m.n<szHdr+lenRowididx_rowid_corruption90347szHdr==3szHdr==(u32)m.nszHdr>0x7ffffffftypeRowid==1typeRowid==2typeRowid==3typeRowid==4typeRowid==5typeRowid==6typeRowid==8typeRowid==9(u32)m.n==szHdr+lenRowidm.szMalloc!=0sqlite3VdbeFindCompareflags & MEM_Realflags & MEM_Nullflags & MEM_Blobflags & MEM_Str(MEM_Real|MEM_IntReal|MEM_Null|MEM_Blob)vdbeRecordCompareStringaKey1pPKey2->aMem[0].flags & MEM_StrpPKey2->aMem[0].n == pPKey2->npPKey2->aMem[0].z == pPKey2->u.zvrcs_restartCORRUPT_DBpPKey2->n90189vdbeRecordCompareDebug(nKey1, pKey1, pPKey2, res) || CORRUPT_DB || pPKey2->pKeyInfo->db->mallocFailedpPKey2->pKeyInfovdbeRecordCompareIntaKey(*(u8*)pKey1)<=0x3F || CORRUPT_DBlhs<0aKey+2aKey+4(i64)1((i64)1)((i64)1)<<32(((i64)1)<<32)pPKey2->u.i == pPKey2->aMem[0].u.ivdbeRecordCompareDebug(nKey1, pKey1, pPKey2, res)sqlite3VdbeRecordComparesqlite3VdbeRecordCompareWithSkipszHdr1idx1mem189864pPKey2->pKeyInfo->nAllField>=pPKey2->nField || CORRUPT_DBpPKey2->pKeyInfo->aSortFlags!=0pPKey2->pKeyInfo->nKeyField>0idx1<=szHdr1 || CORRUPT_DBpRhs->flags & MEM_IntpRhs->flags & MEM_IntRealserial_type==12&aKey1[idx1](d1+mem1.n)==(unsigned)nKey1(d1+mem1.n+1)==(unsigned)nKey1mem1.npRhs->n(pRhs->flags & MEM_Zero)==0 || pRhs->n==0(d1+nStr)==(unsigned)nKey1(d1+nStr+1)==(unsigned)nKey1vdbeRecordCompareDebug(nKey1, pKey1, pPKey2, rc)mem1.szMalloc==0899458997590026CORRUPT_DB || vdbeRecordCompareDebug(nKey1, pKey1, pPKey2, pPKey2->default_rc) || pPKey2->pKeyInfo->db->mallocFailedmem1.szMalloc = 0;vdbeRecordDecodeIntCORRUPT_DB || (serial_type>=1 && serial_type<=9 && serial_type!=7)aKey[0]&0x80sqlite3MemComparef1f2combined_flags!sqlite3VdbeMemIsRowSet(pMem1) && !sqlite3VdbeMemIsRowSet(pMem2)combined_flags & MEM_Intcombined_flags & MEM_Realcombined_flags & MEM_IntRealf1 & f2 & MEM_Intf1 & f2 & MEM_IntRealf1 & MEM_Intf1 & MEM_IntRealf2 & MEM_Intf2 & MEM_IntRealpMem1->enc==pMem2->enc || pMem1->db->mallocFailedpMem1->enc==SQLITE_UTF8 || pMem1->enc==SQLITE_UTF16LE || pMem1->enc==SQLITE_UTF16BE!pColl || pColl->xCmpsqlite3IntFloatComparedoubleLt(((double)i),r)doubleLt(r,((double)i))doubleEq(r,((double)i))9223372036854775808.0-9223372036854775808.0sqlite3BlobCompare(pB1->flags & MEM_Zero)==0 || n1==0(pB2->flags & MEM_Zero)==0 || n2==0isAllZerovdbeCompareMemStringsqlite3VdbeRecordUnpackEIGHT_BYTE_ALIGNMENT(pMem)&aKey[idx]u<=pKeyInfo->nKeyField + 1sqlite3VdbeAllocUnpackedRecordsizeof(UnpackedRecord)ROUND8P(sizeof(UnpackedRecord))pKeyInfo->aSortFlags!=0sqlite3VdbeSerialGetpMem->u.i<0buf+21640016386serialGet7buf+4sizeof(x)==8 && sizeof(pMem->u.r)==8serialGetsqlite3VdbeOneByteSerialTypeLenserial_type<128sqlite3VdbeSerialTypeLenserial_type<12 || sqlite3SmallTypeSizes[serial_type]==(serial_type - 12)/2sqlite3VdbeCursorRestorep->eCurType==CURTYPE_BTREE || IsNullCursor(p)sqlite3VdbeHandleMovedCursorisDifferentRowp->eCurType==CURTYPE_BTREEp->uc.pCursor!=0sqlite3BtreeCursorHasMoved(p->uc.pCursor)sqlite3VdbeFinishMovetop->deferredMovetop->isTable88906sqlite3VdbeDeletep->ppVPrev!=0Vdbe **sqlite3VdbeClearObjectp->db==0 || p->db==dbCOLNAME_NVDBE_INIT_STATEsqlite3VdbeDeleteAuxDatapAux->iAuxArgpAux->iAuxArg==31sqlite3VdbeFinalizeVDBE_RUN_STATE>VDBE_READY_STATEVDBE_HALT_STATE>VDBE_READY_STATEVDBE_INIT_STATE<VDBE_READY_STATE(rc & p->db->errMask)==rcsqlite3VdbeResetsqlite3VdbeTransferErrorsqlite3VdbeResetStepResultsqlite3VdbeHaltp->readOnlymrceStatementOpisSpecialError18446744065119617023~SQLITE_CorruptRdOnly(u64)SQLITE_DeferFKs18446744073709027327~(u64)SQLITE_DeferFKsdb->nVdbeActive>=db->nVdbeReaddb->nVdbeRead>=db->nVdbeWritedb->nVdbeWrite>=0db->nVdbeActive>0 || db->autoCommit==0 || db->nStatement==0sqlite3VdbeCheckFksqlite3VdbeCloseStatementvdbeCloseStatementsqlite3 *consteOp==SAVEPOINT_ROLLBACK || eOp==SAVEPOINT_RELEASEdb->nStatement>0p->iStatement==(db->nStatement+db->nSavepoint)vdbeCommitnTransneedXcommiti!=1const u8[6]aMJNeeded531zSuper[sqlite3Strlen30(zSuper)-3]=='9'zMainFilezSuperzFile[0]!=0rc!=SQLITE_BUSYpSuperJrnlretryCountnMainFile%.4c%s%.16c"%.4c%s%.16c"MJ delete: %s"MJ delete: %s"MJ collide: %s"MJ collide: %s"-mj%06X9%02X"-mj%06X9%02X"0xffffff16406sqlite3VdbeSetColNamepColNameidx<p->nResAllocvar<COLNAME_N!zName || xDel!=SQLITE_DYNAMICp->aColName!=0rc!=0 || !zName || (pColName->flags&MEM_Term)!=0sqlite3VdbeSetNumColscloseAllCursorsp->nFrame==0p->pAuxData==0sqlite3VdbeFrameRestorecloseCursorsInFramesqlite3VdbeFreeCursorNNpCx->uc.pCursor!=0pVCur->pVtab->nRef>0freeCursorWithCachepCx->colCachesqlite3VdbeFreeCursorsqlite3VdbeMakeReadynCursorp->nOp>0p->eVdbeState==VDBE_INIT_STATEpParse==p->pParsepParse->db==p->dbsizeof(Op)*p->nOpEIGHT_BYTE_ALIGNMENT(x.pSpace)pParse->szOpAlloc - nx.nFree>=0EIGHT_BYTE_ALIGNMENT(&x.pSpace[x.nFree])ReusableSpace *sizeof(Mem*)sqlite3VdbeRewindp->eVdbeState==VDBE_INIT_STATE || p->eVdbeState==VDBE_READY_STATE || p->eVdbeState==VDBE_HALT_STATEallocSpaceEIGHT_BYTE_ALIGNMENT(p->pSpace)EIGHT_BYTE_ALIGNMENT(pBuf)sqlite3VdbeListbListSubprogsp->explainp->rc==SQLITE_OK || p->rc==SQLITE_BUSY || p->rc==SQLITE_NOMEMp->nMem>9p->nResColumn==4p->nResColumn==8sqlite3VdbeFrameDeleteapCsrsqlite3VdbeFrameIsValid(p)sqlite3VdbeNextOpcodenSubSubProgram **apSubiPcsizeof(Vdbe*)apSub!=0nSub>0i<apSub[j]->nOp || j+1<nSubeMode==1sizeof(SubProgram*)sqlite3VdbeFrameMemDelsqlite3VdbeFrameIsValid(pFrame)releaseMemArray(&p[1])==pEnd || p[0].db==p[1].dbsqlite3VdbeCheckMemInvariants(p)p->flags & MEM_Aggp->flags & MEM_Dyn(p->flags & MEM_Dyn)!=0 && p->xDel==sqlite3VdbeFrameMemDel(MEM_Agg|MEM_Dyn)initMemArraysqlite3VdbeLeavevdbeLeaveaDbaDb[i].pBt!=0sqlite3VdbeEntersqlite3VdbeUsesBtreei>=0 && i<p->db->nDb && i<(int)sizeof(yDbMask)*8i<(int)sizeof(p->btreeMask)*8p->btreeMasksqlite3VdbeDisplayP4pColl->enc<4k(%d"k(%d""B",%s%s%s",%s%s%s"N."N.""8"16LE"16LE"16BE"16BE"%.18s-%s"%.18s-%s"%s(%d)"%s(%d)"%.16g"%.16g"(blob)"(blob)"vtab:%p"vtab:%p"%c%u"%c%u"program"program"subrtnsig:%d,%s"subrtnsig:%d,%s"sqlite3VdbeDisplayCommentzOpNamezSynopsisnOpNamezAltx.nChar>2seenComIF "IF "sizeof(zAlt)if %s goto P2"if %s goto P2"@P"@P""+1"%d..%d"%d..%d"@NP"@NP"..P3"..P3"; %s"; %s"translatePsqlite3VdbeGetLastOpsqlite3VdbeGetOp(addr>=0 && addr<p->nOp) || p->db->mallocFailedsqlite3VdbeNoopCommentsqlite3VdbeCommentvdbeVCommentp->nOp>0 || p->aOp==0p->aOp==0 || p->aOp[p->nOp-1].zComment==0 || p->pParse->nErr>0p->aOpsqlite3VdbeSetP4KeyInfosqlite3VdbeAppendP4n!=P4_INT32 && n!=P4_VTABn<=0pP4!=0 || n==P4_DYNAMICpOp->p4type==P4_NOTUSEDsqlite3VdbeChangeP4p->aOp!=0 || db->mallocFailedaddr<p->nOpn<0vdbeChangeP4FullpOp->p4type > P4_FREE_IF_LEsqlite3VdbeDeletePriorOpcodesqlite3VdbeChangeToNoopaddr>=0 && addr<p->nOpsqlite3VdbeHasSubProgramsqlite3VdbeLinkSubProgramvdbeFreeOpArraynOp>=0P4_FREE_IF_LEfreeP4freeP4FuncCtxfreeP4MemfreeEphemeralFunctionsqlite3VdbeJumpHereOrPopInstp->aOp[addr].opcode==OP_Once || p->aOp[addr].opcode==OP_If || p->aOp[addr].opcode==OP_FkIfZerop->aOp[addr].p4type==0sqlite3VdbeJumpHeresqlite3VdbeTypeofColumnsqlite3VdbeChangeP5p->nOp>0 || p->db->mallocFailedsqlite3VdbeChangeP3addr>=0sqlite3VdbeChangeP2addr>=0 || p->db->mallocFailedsqlite3VdbeChangeP1sqlite3VdbeChangeOpcodesqlite3VdbeAddOpListnOp>0aOp->p2>=0sqlite3VdbeTakeOpArrayaOp && !p->db->mallocFailedDbMaskAllZero(p->btreeMask)sqlite3VdbeCurrentAddrresolveP2ValuesnMaxVtabArgs(pOp - p->aOp) >= 3pOp[-1].opcode==OP_IntegerpOp[-1].p2==pOp->p3+1(sqlite3OpcodeProperty[pOp->opcode] & OPFLG_JUMP)!=0ADDR(pOp->p2)<-pParse->nLabelaLabel!=0pOp->p2>0 || (sqlite3OpcodeProperty[pOp->opcode] & OPFLG_JUMP0)!=0pOp->p2<p->nOp || (sqlite3OpcodeProperty[pOp->opcode] & OPFLG_JUMP)==0(sqlite3OpcodeProperty[pOp->opcode]&OPFLG_JUMP)==0 || pOp->p2>=0pOp>p->aOpSQLITE_MX_JUMP_OPCODEresolve_p2_values_loop_exitp->bIsReader!=0 || DbMaskAllZero(p->btreeMask)sqlite3VdbeReusablei<p->nOpp->aOp[i].opcode==OP_Expirep->aOp[i].opcode==166sqlite3VdbeRunOnlyOncesqlite3VdbeResolveLabelv->eVdbeState==VDBE_INIT_STATEj<-p->nLabelj>=0p->aLabel[j]==(-1)resizeResolveLabelsizeof(p->aLabel[0])sqlite3VdbeMakeLabelsqlite3VdbeEndCoroutinesqlite3VdbeAddParseSchemaOpsqlite3VdbeExplainPop"POP"sqlite3VdbeExplainbPush?"PUSH":""sqlite3VdbeGetLastOp(v)->p4.zsqlite3VdbeExplainParentsqlite3VdbeAddOp4Dup8p4copysqlite3VdbeAddFunctionCallsizeof(*pCtx)sqlite3VdbeAddOp4sqlite3VdbeMultiLoadzTypesskip_op_resultrowsqlite3VdbeLoadStringsqlite3VdbeGotosqlite3VdbeAddOp4Intsqlite3VdbeAddOp3op>=0 && op<0xffp->aOp!=0sqlite3VdbeAddOp2sqlite3VdbeAddOp1sqlite3VdbeAddOp0addOp4IntSlowgrowOp3p->nOpAlloc<=p->nOpp->nOpAlloc>p->nOpgrowOpArraysizeof(Op)1024/sizeof(Op)(sqlite3_int64)(1024/sizeof(Op))nOpnOp<=(int)(1024/sizeof(Op))nNew>=(v->nOpAlloc+nOp)sqlite3VdbeSwapppTmpzTmppA->db==pB->dbsizeof(pB->aCounter)sqlite3VdbeSetSqlp->zSql==0sqlite3VdbeErrorsqlite3VdbeParsersqlite3VdbeCreatesizeof(Vdbe)Vdbeoffsetof(Vdbe,aOp)sizeof(Vdbe)-offsetof(Vdbe,aOp)pParse->aLabel==0pParse->nLabel==0p->nOpAlloc==0pParse->szOpAlloc==0sqlite3ValueBytes(p->flags & MEM_Null)==0 || (p->flags & (MEM_Str|MEM_Blob))==0valueBytessqlite3ValueFreesqlite3ValueSetStrsqlite3ValueFromExprValueNewStat4Ctx *valueFromExprnegIntzNeg(pExpr->flags & EP_TokenOnly)==0 || pCtx==0(ppVal[0][0].flags & MEM_Zero)==0pVal && pVal->z && pVal->flags==(MEM_Str|MEM_Term)(pVal->flags & MEM_IntReal)==0pVal->flags & MEM_IntpVal->flags & MEM_RealzVal[nVal]=='\''(MEM_Int|MEM_IntReal|MEM_Real)(double)SMALLEST_INT64-(double)SMALLEST_INT64*ppVal==0pCtx==0valueNewsqlite3ValueNewsqlite3ValueIsOfClasspVal!=0(pVal->flags & (MEM_Str|MEM_Blob))!=0(pVal->flags & (0x0002|0x0010))!=0sqlite3ValueTextpVal->db==0 || sqlite3_mutex_held(pVal->db->mutex)(enc&3)==(enc&~SQLITE_UTF16_ALIGNED)!sqlite3VdbeMemIsRowSet(pVal)sqlite3VdbeMemValidStrRep(pVal)(MEM_Str|MEM_Term)valueToText(pVal->flags & (MEM_Null))==0pVal->z(pVal->flags & (MEM_Ephem|MEM_Static))!=00==(1&SQLITE_PTR_TO_INT(pVal->z))pVal->enc==(enc & ~SQLITE_UTF16_ALIGNED) || pVal->db==0 || pVal->db->mallocFailedsqlite3VdbeMemFromBtreeZeroOffsetavailable!VdbeMemDynamic(pMem)!sqlite3VdbeMemIsRowSet(pMem)pMem->z!=0sqlite3VdbeMemFromBtree84328sqlite3VdbeMemSetStrpMem!=0pMem->db==0 || sqlite3_mutex_held(pMem->db->mutex)enc!=0 || n>=0enc!=0nAlloc==0nAlloc==31nAlloc==32sqlite3VdbeMemMovepFrom->db==0 || sqlite3_mutex_held(pFrom->db->mutex)pTo->db==0 || sqlite3_mutex_held(pTo->db->mutex)pFrom->db==0 || pTo->db==0 || pFrom->db==pTo->dbsqlite3VdbeMemCopy!sqlite3VdbeMemIsRowSet(pFrom)sqlite3VdbeMemShallowCopysrcType==MEM_Ephem || srcType==MEM_Static28672(MEM_Dyn|MEM_Static|MEM_Ephem)-28673~(MEM_Dyn|MEM_Static|MEM_Ephem)vdbeClrCopy!VdbeMemDynamic(pTo)sqlite3VdbeMemTooBigsqlite3VdbeMemSetRowSetsqlite3VdbeMemSetDoublesqlite3VdbeMemSetPointerpMem->flags==MEM_Null61456657sqlite3NoopDestructorsqlite3MemSetArrayInt64sqlite3VdbeMemSetInt64vdbeReleaseAndSetInt64sqlite3VdbeMemSetZeroBlob1040sqlite3ValueSetNullsqlite3VdbeMemSetNullsqlite3VdbeMemInit(flags & ~MEM_TypeMask)==0sqlite3VdbeMemCastpMem->flags & MEM_Str || pMem->db->mallocFailedaff==SQLITE_AFF_TEXTMEM_Str==(MEM_Blob>>3)~MEM_Blob3503(MEM_TypeMask&~MEM_Blob)-3504~(MEM_TypeMask&~MEM_Blob)1084(MEM_Int|MEM_Real|MEM_IntReal|MEM_Blob|MEM_Zero)-1085~(MEM_Int|MEM_Real|MEM_IntReal|MEM_Blob|MEM_Zero)sqlite3VdbeMemNumerify(pMem->flags & (MEM_Blob|MEM_Str))!=0(pMem->flags & (MEM_Int|MEM_Real|MEM_IntReal|MEM_Null))!=01042(MEM_Str|MEM_Blob|MEM_Zero)-1043~(MEM_Str|MEM_Blob|MEM_Zero)pMem->flags & MEM_Nullsqlite3RealToI649223372036854774784.0-9223372036854774784.0+9223372036854774784.0sqlite3RealSameAsIntsizeof(r1)22517998136852482251799813685248LL-2251799813685248-2251799813685248LLsqlite3VdbeMemRealifysqlite3VdbeMemIntegerifysqlite3VdbeIntegerAffinitypMem->flags & (MEM_Real|MEM_IntReal)sqlite3VdbeBooleanValuesqlite3VdbeRealValuememRealValuesqlite3VdbeIntValueflags & MEM_IntRealmemIntValuesqlite3VdbeMemReleaseMalloc!VdbeMemDynamic(p)sqlite3VdbeMemReleasevdbeMemClearvdbeMemClearExternAndSetNullp->db==0 || sqlite3_mutex_held(p->db->mutex)VdbeMemDynamic(p)(p->flags & MEM_Agg)==0p->xDel!=SQLITE_DYNAMIC && p->xDel!=0sqlite3VdbeMemAggValuepFunc!=0pFunc->xValue!=0(pAccum->flags & MEM_Null)!=0 || pFunc==pAccum->u.pDefpAccum->db!=0sqlite3_mutex_held(pAccum->db->mutex)sizeof(ctx)pAccum->dbsqlite3VdbeMemFinalizepMem->db!=0pFunc->xFinalize!=0(pMem->flags & MEM_Null)!=0 || pFunc==pMem->u.pDefsqlite3_mutex_held(pMem->db->mutex)sizeof(t)t.dbsqlite3VdbeMemStringify 32!(pMem->flags&MEM_Zero)!(pMem->flags&(MEM_Str|MEM_Blob))pMem->flags&(MEM_Int|MEM_Real|MEM_IntReal)pMem->n==(int)sqlite3Strlen30NN(pMem->z)sqlite3VdbeMemNulTerminate(MEM_Term|MEM_Str)(pMem->flags & (MEM_Term|MEM_Str))==(MEM_Term|MEM_Str)(pMem->flags & (MEM_Term|MEM_Str))==0sqlite3VdbeMemExpandBlobpMem->flags & MEM_Zero(pMem->flags&MEM_Blob)!=0 || MemNullNochng(pMem)sqlite3DbMallocSize(pMem->db,pMem->z) >= nByte(MEM_Zero|MEM_Term)-1537~(MEM_Zero|MEM_Term)sqlite3_value_nochange(pMem)sqlite3VdbeMemMakeWriteablevdbeMemAddTerminatorsqlite3VdbeMemZeroTerminateIfAble1689825090(MEM_Str|MEM_Term|MEM_Ephem|MEM_Static)sqlite3VdbeMemClearAndResizeCORRUPT_DB || szNew>0(pMem->flags & MEM_Dyn)==0 || pMem->szMalloc==0(MEM_Null|MEM_Int|MEM_Real|MEM_IntReal)sqlite3VdbeMemGrowsqlite3VdbeCheckMemInvariants(pMem)bPreserve==0 || pMem->flags&(MEM_Blob|MEM_Str)pMem->szMalloc==0 || (pMem->flags==MEM_Undefined && pMem->szMalloc<=sqlite3DbMallocSize(pMem->db,pMem->zMalloc)) || pMem->szMalloc==sqlite3DbMallocSize(pMem->db,pMem->zMalloc)pMem->z!=pMem->zMallocpMem->xDel!=0 && pMem->xDel!=SQLITE_DYNAMIC(MEM_Dyn|MEM_Ephem|MEM_Static)~(MEM_Dyn|MEM_Ephem|MEM_Static)pMem->db==0bPreserve && pMem->z==0sqlite3VdbeChangeEncodingdesiredEnc==SQLITE_UTF8 || desiredEnc==SQLITE_UTF16LE || desiredEnc==SQLITE_UTF16BErc==SQLITE_OK || pMem->enc!=desiredEncrc==SQLITE_NOMEM || pMem->enc==desiredEncvdbeMemRenderNump->flags & (MEM_Int|MEM_Real|MEM_IntReal)sz>22(p->flags&MEM_Int)*2==sizeof(x)acc.zText==zBuf && acc.mxAlloc<=0MemValue *sqlite3BtreeCopyFilesqlite3BtreeTxnState(pTo)==SQLITE_TXN_WRITEsizeof(b)b.rc!=SQLITE_OKBtShared *BTS_PAGESIZE_FIXED~BTS_PAGESIZE_FIXEDsqlite3BtreeTxnState(pTo)!=SQLITE_TXN_WRITEcopy_finishedsqlite3BackupRestartsqlite3_mutex_held(p->pSrc->pBt->mutex)sqlite3BackupUpdatebackupUpdatep->pDestDbrc!=SQLITE_BUSY && rc!=SQLITE_LOCKEDsqlite3_backup **pSrcDbpp!=0destModepgszSrcpgszDestnSrcPage>=0p->pSrc->pBtpgszSrc==sqlite3BtreeGetPageSize(p->pSrc)pgszDest==sqlite3BtreeGetPageSize(p->pDest)p->pDest->pBtnDestTruncate>0nDestTruncate==0 || (i64)nDestTruncate*(i64)pgszDest >= iSize || ( nDestTruncate==(int)(PENDING_BYTE_PAGE(p->pDest->pBt)-1) && iSize>=PENDING_BYTE && iSize<=PENDING_BYTE+pgszDest )PENDING_BYTE + pgszDestsqlite3PendingByte + pgszDestint rc2rc2 =rc2 |=rc2==SQLITE_OKPager *constpSrcPagerpDestPagernSrcPagebCloseTransTRANS_WRITEconst PgnoiSrcPgpSrcPgPAGER_GET_READONLYnDestTruncateratiosqlite3_file *constnDstPageattachBackupObjectsqlite3BtreeHoldsMutex(p->pSrc)backupTruncateFilebackupOnePagenSrcPgsznDestPgszsqlite3BtreeGetReserveNoMutex(p->pSrc)>=0p->bDestLocked!isFatalError(p->rc)iSrcPg!=PENDING_BYTE_PAGE(p->pSrc->pBt)zSrcDatanSrcPgsz==nDestPgsz || sqlite3PagerIsMemdb(pDestPager)==0pDestPgzDestDataisFatalErrorrc!=SQLITE_LOCKEDrc!=6source and destination must be distinct"source and destination must be distinct"sizeof(sqlite3_backup)checkReadTransactiondestination database is in use"destination database is in use"setDestPgszfindBtreeunknown database %s"unknown database %s"sqlite3BtreeConnectionCountp->sharablesqlite3BtreeSharablesqlite3BtreeClearCacheTRANS_NONEsqlite3HeaderSizeBtreesizeof(MemPage)ROUND8(sizeof(MemPage))sqlite3BtreeIsReadonlyBTS_READ_ONLYsqlite3BtreeCursorHasHintsqlite3BtreeSetVersioniVersion==1 || iVersion==2BTS_NO_WAL~BTS_NO_WALMemPage *sqlite3BtreeIncrblobCursorBTCF_Incrblobsqlite3BtreePutDatacursorOwnsBtShared(pCsr)sqlite3_mutex_held(pCsr->pBtree->db->mutex)pCsr->curFlags & BTCF_IncrblobpCsr->eState!=CURSOR_REQUIRESEEKCURSOR_VALIDBTCF_WriteFlag(pCsr->pBt->btsFlags & BTS_READ_ONLY)==0 && pCsr->pBt->inTransaction==TRANS_WRITEhasSharedCacheTableLock(pCsr->pBtree, pCsr->pgnoRoot, 0, 2)!hasReadConflicts(pCsr->pBtree, pCsr->pgnoRoot)pCsr->pPage->intKeyrc =sqlite3BtreeLockTablep->inTrans!=TRANS_NONEREAD_LOCK+1==WRITE_LOCKlockTypeREAD_LOCKsqlite3BtreeSchemaLockedrc==SQLITE_OK || rc==SQLITE_LOCKED_SHAREDCACHEsqlite3BtreeSchemasqlite3BtreeIsInBackupsqlite3BtreeCheckpointsqlite3BtreeTxnStatep==0 || sqlite3_mutex_held(p->db->mutex)sqlite3BtreeGetJournalnamep->pBt->pPager!=0sqlite3BtreeGetFilenamesqlite3BtreeIntegrityChecksCheckbPartialbCkFreelistaCnt!=0nRoot>1p->inTrans>TRANS_NONE && pBt->inTransaction>TRANS_NONEnRef>=0IntegrityCk *sizeof(sCheck)Freelist: "Freelist: "mxInHdrmax rootpage (%u) disagrees with header (%u)"max rootpage (%u) disagrees with header (%u)"incremental_vacuum enabled with a max rootpage of zero"incremental_vacuum enabled with a max rootpage of zero"SQLITE_CellSizeCk(u64)SQLITE_CellSizeCk18446744073707454463~(u64)SQLITE_CellSizeCkPTRMAP_ROOTPAGEPage %u: never used"Page %u: never used"Page %u: pointer map referenced"Page %u: pointer map referenced"integrity_ck_cleanupnRef==sqlite3PagerRefcount(pBt->pPager)int nRefnRef = sqlite3PagerRefcount(pBt->pPager)pBt->db->flags & SQLITE_CellSizeCkcheckTreePagedepthhdrcellStartdoCoverageCheckkeyCanBeEqualpCellIdxusableSizecontentOffsetheapsaved_zPfxsaved_v1saved_v2savedIsInitTree %u page %u: "Tree %u page %u: "MemPage **unable to get the page. error code=%d"unable to get the page. error code=%d"rc==SQLITE_CORRUPTbtreeInitPage() returns error code %d"btreeInitPage() returns error code %d"free space corruption"free space corruption"Tree %u page %u cell %u: "Tree %u page %u cell %u: "&data[hdr+5]contentOffset<=usableSize&data[hdr+3]pPage->nCell==nCellpPage->aCellIdx==&data[cellStart]Tree %u page %u right child: "Tree %u page %u right child: "PTRMAP_BTREEpCellIdx==&data[cellStart + i*2]pc + info.nSize - 4 <= usableSizeinfo__builtin_bswap16Offset %u out of range %u..%u"Offset %u out of range %u..%u"CellInfo *Extends off end of page"Extends off end of page"Rowid %lld out of order"Rowid %lld out of order"PTRMAP_OVERFLOW1Child page depth differs"Child page depth differs"&data[cellStart+i*2]heap!=0&data[hdr+1](u32)i<=usableSize-4&data[i+2](u32)(i+size)<=usableSize&data[i]j==0 || j>i+size(u32)j<=usableSize-4Multiple uses for byte %u of page %u"Multiple uses for byte %u of page %u"Fragmentation of %u bytes reported as %u on page %u"Fragmentation of %u bytes reported as %u on page %u"end_of_checkbtreeHeapPullbtreeHeapInsertaHeap!=0checkListexpectednErrAtStartpOvflPagepOvflDatafailed to get page %u"failed to get page %u"PTRMAP_FREEPAGEfreelist leaf count too big on page %u"freelist leaf count too big on page %u"iFreePagePTRMAP_OVERFLOW2%s is %u but should be %u"%s is %u but should be %u""size"overflow list length"overflow list length"checkPtrmapePtrmapTypeiPtrmapParentFailed to read ptrmap key=%u"Failed to read ptrmap key=%u"Bad ptr map entry key=%u expected=(%u,%u) got=(%u,%u)"Bad ptr map entry key=%u expected=(%u,%u) got=(%u,%u)"checkRefinvalid page number %u"invalid page number %u"2nd reference to page %u"2nd reference to page %u"setPageReferencedpCheck->aPgRef!=0iPg<=pCheck->nCkPage && sizeof(pCheck->aPgRef[0])==1getPageReferencedcheckAppendMsgcheckProgressdb->nProgressOps>0checkOomsqlite3BtreePagersqlite3BtreeCount&(pPage)->aCellIdx[2*(iIdx)]sqlite3BtreeUpdateMetapP1idx>=1 && idx<=15p->inTrans==TRANS_WRITEpBt->pPage1!=0pBt->autoVacuum || iMeta==0iMeta==0 || iMeta==1sqlite3BtreeGetMetap->inTrans>TRANS_NONESQLITE_OK==querySharedCacheTableLock(p, SCHEMA_ROOT, READ_LOCK)pBt->pPage1idx>=0 && idx<=15BTREE_DATA_VERSIONsqlite3BtreeDropTablebtreeDropTablesqlite3BtreeHoldsMutex(p)iTable>=281031maxRootPgno(pBt)(maxRootPgno)maxRootPgno!=PENDING_BYTE_PAGE(pBt)pMovesqlite3BtreeClearTableOfCursorsqlite3BtreeClearTableclearDatabasePagesqlite3_mutex_held(pBt->mutex)80920pPage->pgno80927&(pPage)->aCellIdx[2*(i)]!pPage->intKeyPTF_LEAFcleardatabasepage_outsqlite3BtreeCreateTablebtreeCreateTablepgnoRootptfFlagspBt->inTransaction==TRANS_WRITE(pBt->btsFlags & BTS_READ_ONLY)==0pgnoRoot>=3eType!=PTRMAP_ROOTPAGEeType!=PTRMAP_FREEPAGEsqlite3PagerIswriteable(pBt->pPage1->pDbPage)pgnoMovepPageMove80782BTALLOC_EXACTiPtrPage80830sqlite3PagerIswriteable(pRoot->pDbPage)PTF_INTKEYPTF_LEAFDATAPTF_ZERODATA(pBt->openFlags & BTREE_SINGLE)==0 || pgnoRoot==2sqlite3BtreeDeleteiCellIdxiCellDepthbPreservecursorOwnsBtShared(pCur)pCur->curFlags & BTCF_WriteFlaghasSharedCacheTableLock(p, pCur->pgnoRoot, pCur->pKeyInfo!=0, 2)!hasReadConflicts(p, pCur->pgnoRoot)(flags & ~(BTREE_SAVEPOSITION | BTREE_AUXDELETE))==0rc!=SQLITE_OK || CORRUPT_DB || pCur->eState==CURSOR_VALIDpCur->pgnoRootCURSOR_REQUIRESEEK80559pCur->eState==CURSOR_VALID80568&(pPage)->aCellIdx[2*(iCellIdx)]8057280575BTREE_SAVEPOSITIONBTCF_MultiplepLeaf->nCell-1&(pLeaf)->aCellIdx[2*(pLeaf->nCell-1)]pLeaf->pgnoMX_CELL_SIZE(pBt) >= nCellpTmp!=0MemPage *[19]BTCURSOR_MAX_DEPTH80666pCur->pPage->nOverflow==0pCur->pPage->nFree>=0(pCur->iPage==iCellDepth || CORRUPT_DB)pPage==pCur->pPage || CORRUPT_DB(pPage->nCell>0 || CORRUPT_DB) && iCellIdx<=pPage->nCellCURSOR_SKIPNEXTsqlite3BtreeTransferRowpSrc->pPagepSrc->pPage->pgno80438nOut>0pPgnoOutpBt->usableSize - 4ovflInpPageInpPageOut80463pgnoNewsqlite3BtreeInsertlocoldCellnewCell(flags & (BTREE_SAVEPOSITION|BTREE_APPEND|BTREE_PREFORMAT))==flags(flags & BTREE_PREFORMAT)==0 || seekResult || pCur->pKeyInfo==080141pCur->eState==CURSOR_REQUIRESEEKpCur->eState==CURSOR_FAULT(pCur->curFlags & BTCF_WriteFlag)!=0 && p->pBt->inTransaction==TRANS_WRITE && (p->pBt->btsFlags & BTS_READ_ONLY)==0(flags & BTREE_PREFORMAT) || (pX->pKey==0)==(pCur->pKeyInfo==0)pX->pKey==0pX->nData>=0 && pX->nZero>=0loc==0(flags & BTREE_SAVEPOSITION)==0 || loc==0BTCF_ValidNKeyBTREE_APPENDpCur->eState==CURSOR_VALID || (pCur->eState==CURSOR_INVALID && loc) || CORRUPT_DBpPage->intKey || pX->nKey>=0 || (flags & BTREE_PREFORMAT)pPage->leaf || !pPage->intKeypCur->eState>CURSOR_INVALIDpCur->eState>180264pPage->isInit || CORRUPT_DBnewCell!=0p->pBtBTREE_PREFORMATovflszNew==pPage->xCellSize(pPage, newCell)szNew <= MX_CELL_SIZE(p->pBt)idx>=0&(pPage)->aCellIdx[2*(idx)]pCur->curFlags & BTCF_ValidOvflpPage->leaf803068033380336BTCF_ValidOvfl(BTCF_ValidNKey|BTCF_ValidOvfl)~(BTCF_ValidNKey|BTCF_ValidOvfl)pPage->nOverflow==0 || rc==SQLITE_OKrc!=SQLITE_OK || pPage->nCell>0 || pPage->nOverflow>0pCur->pKey==0CURSOR_INVALIDpCur->iPage<0 || pCur->pPage->nOverflow==0end_insert("INSERT: table=%u nkey=%lld ndata=%u page=%u %s\n", pCur->pgnoRoot, pX->nKey, pX->nData, pPage->pgno, loc==0 ? "overwrite" : "new entry")btreeOverwriteCell80060btreeOverwriteOverflowCellovflPgnoovflPageSizepCur->info.nLocal<nTotalnTotal>=0iOffset>=080032btreeOverwriteContentbalanceu8[13]unsigned char[13]aBalanceQuickSpacepPage->nFree<0balance_deeper_called==0balance_deeper_called++pCur->pPage->nOverflowbalance_quick_called==0balance_quick_called++pCur->iPage>=0u16[19]unsigned short[19]79868MemPage *constu16[4]BTREE_BULKLOADint balance_quick_called = 0int balance_deeper_called = 0anotherValidCursorpCur->pPagepCur->pPage->pgno79808balance_deeperpgnoChildpRoot->nOverflow>0sqlite3PagerIswriteable(pChild->pDbPage)pChild->nCell==pRoot->nCell || CORRUPT_DBsizeof(pRoot->aiOvfl[0])u8 *[4]unsigned char *[4]sizeof(pRoot->apOvfl[0])~PTF_LEAF("BALANCE: copy root %u into %u\n", pRoot->pgno, pChild->pgno)balance_nonrootnMaxCellsnOldnxDivleafCorrectionleafDatausableSpacepageFlagsiSpace1iOvflSpaceszScratchMemPage *[3]NBapOldMemPage *[5]u8 *[2]unsigned char *[2]apDivcntNewcntOldaSpace1abDonePgno[5]aPgnosizeof(abDone)sizeof(b) - sizeof(b.ixNx) == offsetof(CellArray,ixNx)CellArray *sizeof(b.ixNx[0])sizeof(b)-sizeof(b.ixNx[0])sqlite3PagerIswriteable(pParent->pDbPage)pParent->nOverflow==0 || pParent->nOverflow==1pParent->nOverflow==0 || pParent->aiOvfl[0]==iParentIdxpParent->nFree>=0bBulk==0 || bBulk==1i+nxDiv-pParent->nOverflow&(pParent)->aCellIdx[2*(i+nxDiv-pParent->nOverflow)]pParent->apOvflapDiv[i]pParent->aDatasizeof(MemPage*)ArraySize(pParent->apOvfl)BTS_FAST_SECURE~3sizeof(u8*)sizeof(u16)szScratch<=7*(int)pBt->pageSizeEIGHT_BYTE_ALIGNMENT(aSpace1)int nCellAtStart = b.nCell;pOld->pgnolimit<pOld->aiOvfl[0]piCellk==0 || pOld->aiOvfl[k-1]+1==pOld->aiOvfl[k]b.nCell<nMaxCells(b.nCell-nCellAtStart)==(pOld->nCell+pOld->nOverflow)sz<=pBt->maxLocal+23iSpace1 <= (int)pBt->pageSizeleafCorrection==0 || leafCorrection==4leafCorrection==0pOld->hdrOffset==0 || CORRUPT_DBleafCorrection==4b.szCell[b.nCell]==3 || CORRUPT_DBb.apCell[b.nCell]==&aSpace1[iSpace1-3] || CORRUPT_DBmaskPage79140sizeof(b.szCell[0])79164p->nFree>=0u8 *[6]unsigned char *[6]7926579298d<nMaxCellsr<nMaxCellsszRightszLeftszRszD79342cntNew[0]>0 || (pParent->pgno==1 && pParent->nCell==0) || CORRUPT_DB79375apNew[i]->pDbPage->flags & PGHDR_WRITEABLEapNew[i]->pDbPage->flags & PGHDR_DIRTYpgnoApgnoBpgnoTempfgAfgBnNew>=1 && nNew<=ArraySize(apNew)apNew[nNew-1]!=0iOld<nNew || iOld<nOldiOld>=0 && iOld<NBpOld->aDatapOld->aDataEndcntOldNextj<nMaxCellsb.apCell[j]!=0iOvflSpace <= (int)pBt->pageSizeb.ixNx[NB*2-1]>jpSrcEndpCell+sz79576iPg>=0 && iPg<nNewiPg>=1 || i>=0iPg<ArraySize(cntOld)iPg==0 || cntOld[iPg-1]>=cntNew[iPg-1] || abDone[iPg-1]cntNew[iPg]>=cntOld[iPg] || abDone[iPg+1]apNew[iPg]->nOverflow==0apNew[iPg]->nCell==nNewCellnNewCellmemcmp(abDone, "\01\01\01\01\01", nNew)==0nOld>0nNew>0nNew==1 || CORRUPT_DBapNew[0]->nFree == (get2byteNotZero(&apNew[0]->aData[5]) - apNew[0]->cellOffset - apNew[0]->nCell*2) || rc!=SQLITE_OKpParent->isInitbalance_cleanupb.apCell("BALANCE: old: %u(nc=%u) %u(nc=%u) %u(nc=%u)\n", apOld[0]->pgno, apOld[0]->nCell, nOld>=2 ? apOld[1]->pgno : 0, nOld>=2 ? apOld[1]->nCell : 0, nOld>=3 ? apOld[2]->pgno : 0, nOld>=3 ? apOld[2]->nCell : 0 )("BALANCE: new: %u(%u nc=%u) %u(%u nc=%u) %u(%u nc=%u) " "%u(%u nc=%u) %u(%u nc=%u)\n", apNew[0]->pgno, szNew[0], cntNew[0], nNew>=2 ? apNew[1]->pgno : 0, nNew>=2 ? szNew[1] : 0, nNew>=2 ? cntNew[1] - cntNew[0] - !leafData : 0, nNew>=3 ? apNew[2]->pgno : 0, nNew>=3 ? szNew[2] : 0, nNew>=3 ? cntNew[2] - cntNew[1] - !leafData : 0, nNew>=4 ? apNew[3]->pgno : 0, nNew>=4 ? szNew[3] : 0, nNew>=4 ? cntNew[3] - cntNew[2] - !leafData : 0, nNew>=5 ? apNew[4]->pgno : 0, nNew>=5 ? szNew[4] : 0, nNew>=5 ? cntNew[4] - cntNew[3] - !leafData : 0 )("BALANCE: finished: old=%u new=%u cells=%u\n", nOld, nNew, b.nCell)copyNodeContentpFrom->isInitpFrom->nFree>=iToHdrget2byte(&aFrom[iFromHdr+5]) <= (int)pBt->usableSize&aFrom[iFromHdr+5]BtShared *constu8 *constiFromHdriToHdriDatabalance_quicksqlite3_mutex_held(pPage->pBt->mutex)pPage->nOverflow==178716pPage->nFree>=0sqlite3PagerIswriteable(pNew->pDbPage)CORRUPT_DB || pPage->aData[0]==(PTF_INTKEY|PTF_LEAFDATA|PTF_LEAF)pPage->nCell-1&(pPage)->aCellIdx[2*(pPage->nCell-1)]szCellpStopeditPagepCellptriOldEndiNewEndnCell>=0nShift>nCell78602nCell>=nTailnTail&aData[hdr+5]pData>pPg->aDataEndiOld-iNew(iOld-iNew)<nNew || nCell==0 || CORRUPT_DBnAdd>=0&aData[hdr+3]pPg->nCellpData - aDataeditpage_fail78676pageFreeArraynFreeaOfstaAfteriAftersizeof(aOfst)sizeof(aOfst[0])sizeof(aOfst)/sizeof(aOfst[0])(int)(sizeof(aOfst)/sizeof(aOfst[0]))pageInsertArrayCORRUPT_DB || pPg->hdrOffset==0pCArray->ixNx[NB*2-1]>ipCArray->szCell[i]!=0(pSlot+sz)<=pCArray->apCell[i] || pSlot>=(pCArray->apCell[i]+sz) || CORRUPT_DB(pSlot - aData)78480rebuildPagenCell>0i<iEndaData+j(pData - aData)sz==pPg->xCellSize(pPg, pCell) || CORRUPT_DB783837838878394&aData[hdr+1]cachedCellSizeN>=0 && N<p->nCellcomputeCellSizep->szCell[N]==0populateCellCachepRefidx>=0 && idx+N<=p->nCellp->apCell[idx]!=0CORRUPT_DB || szCell[idx]==pRef->xCellSize(pRef, p->apCell[idx])insertCellFasti>=0 && i<=pPage->nCell+pPage->nOverflowMX_CELL(pPage->pBt)<=10921pPage->nCell<=MX_CELL(pPage->pBt) || CORRUPT_DBpPage->nOverflow<=ArraySize(pPage->apOvfl)ArraySize(pPage->apOvfl)==ArraySize(pPage->aiOvfl)sz==pPage->xCellSize(pPage, pCell) || CORRUPT_DBpPage->nOverflow==0j < ArraySize(pPage->apOvfl)-1j==0 || pPage->aiOvfl[j-1]<(u16)ij==0 || i==pPage->aiOvfl[j-1]+1sqlite3PagerIswriteable(pPage->pDbPage)&data[pPage->cellOffset]==pPage->aCellIdxidx >= 0idx >= pPage->cellOffset+2*pPage->nCell+2 || CORRUPT_DBidx+sz <= (int)pPage->pBt->usableSizeget2byte(&data[pPage->hdrOffset+3])==pPage->nCell || CORRUPT_DBinsertCelliChild>0dropCellidx<pPage->nCellCORRUPT_DB || sz==cellSize(pPage, idx)pPage->pBt->usableSize > (u32)(ptr-data)77993pPage->pBt->usableSizepPage->nCellpc==(u32)get2byte(&data[hdr+5])pc+sz==pPage->pBt->usableSizefillInCellmnspaceLeftpToReleasepPayloadnHeaderpCell<pPage->aData || pCell>=&pPage->aData[pPage->pBt->pageSize] || sqlite3PagerIswriteable(pPage->pDbPage)pPage->intKeyLeaf&pCell[nHeader]pX->nKey<=0x7fffffff && pX->pKey!=0const sqlite3_int64const sqlite3_int64 *n==3nSrc<=nPayloadnSrc<nPayloadpToRelease==0 || sqlite3PagerIswriteable(pToRelease->pDbPage)pPayload<pPage->aData || pPayload>=&pPage->aData[pBt->pageSize] || sqlite3PagerIswriteable(pPage->pDbPage)(pgnoOvfl)pPrior<pPage->aData || pPrior>=&pPage->aData[pBt->pageSize] || sqlite3PagerIswriteable(pPage->pDbPage)pOvflpgnoPtrmapn==pPage->maxLocaln==pPage->maxLocal+1clearCellOverflowpInfo->nLocal!=pInfo->nPayload77700pBt->usableSize > 4nOvfl>0 || (CORRUPT_DB && (pInfo->nPayload + ovflPageSize)<ovflPageSize)7771777737pCell + pInfo->nSize == pPage->aDataEndpCell + (pInfo->nSize-1) == pPage->aDataEndfreePagefreePage2pTrunkiTrunkpPage1CORRUPT_DB || iPage>1!pMemPage || pMemPage->pgno==iPage77553BTS_SECURE_DELETEpBt->usableSize>32("FREE-PAGE: %u leaf on trunk page %u\n",pPage->pgno,pTrunk->pgno)7760077611freepage_out("FREE-PAGE: %u new trunk page replacing %u\n", pPage->pgno, iTrunk)allocateBtreePagepPrevTrunkmxPageeMode==BTALLOC_ANY || (nearby>0 && IfNotOmitAV(pBt->autoVacuum))77242nearby>0pBt->autoVacuumiTrunk==mxPagepPrevTrunk ? pPrevTrunk->pgno : 1pTrunk!=0pTrunk->aData!=0pPrevTrunk==0("ALLOCATE: %u trunk - %u free pages left\n", *pPgno, n-1)iNewTrunk==mxPagesqlite3PagerIswriteable(pPage1->pDbPage)iPage==mxPage("ALLOCATE: %u was leaf %u of %u on trunk %u" ": %u more free pages\n", *pPgno, closest+1, k, pTrunk->pgno, n-1)pBt->bDoTruncatepBt->nPage(pBt->nPage)("ALLOCATE: %u from end of file (pointer-map page)\n", pBt->nPage)pBt->nPage!=PENDING_BYTE_PAGE(pBt)*pPgno!=PENDING_BYTE_PAGE(pBt)("ALLOCATE: %u from end of file\n", *pPgno)searchListBTALLOC_LE7729877327pNewTrunkiNewTrunk77361closestdist77426noContentPAGER_GET_NOCONTENTbNoContentCORRUPT_DB || *pPgno!=PENDING_BYTE_PAGE(pBt)end_allocate_pagerc!=SQLITE_OK || sqlite3PagerPageRefcount((*ppPage)->pDbPage)<=1rc!=SQLITE_OK || (*ppPage)->isInit==0n==mxPage-1sqlite3BtreePreviousflags==0 || flags==1BTCF_AtLast(BTCF_AtLast|BTCF_ValidOvfl|BTCF_ValidNKey)~(BTCF_AtLast|BTCF_ValidOvfl|BTCF_ValidNKey)btreePrevious(pCur->curFlags & (BTCF_AtLast|BTCF_ValidOvfl|BTCF_ValidNKey))==0pCur->info.nSize==077152(pCur->curFlags & (BTCF_ValidOvfl))==0sqlite3BtreeNextbtreeNext(pCur->curFlags & BTCF_ValidOvfl)==077059sqlite3BtreeRowCountEstsqlite3_mutex_held(pCur->pBtree->db->mutex)pCur->pPage->leaf==0sqlite3BtreeEofsqlite3BtreeIndexMovetoxRecordComparepCur->pKeyInfo!=0pIdxKey->default_rc==1 || pIdxKey->default_rc==0 || pIdxKey->default_rc==-1(BTCF_ValidOvfl|BTCF_AtLast)~(BTCF_ValidOvfl|BTCF_AtLast)76797pCur->pgnoRoot==0 || pCur->pPage->nCell==0bypass_moveto_rootpCur->pPage->isInitpCur->pPage->nCell > 0pCur->curIntKey==0pIdxKey!=0pPage->nCell>0pPage->intKey==0pCell+nCell+1==pPage->aDataEndpCell+nCell+2==pPage->aDataEndnCell<0nCell==0nCell==1nCell==2(pIdxKey->errCode!=SQLITE_CORRUPT || c==0) && (pIdxKey->errCode!=SQLITE_NOMEM || pCur->pBtree->db->mallocFailed)c==0lwr+upr>=0lwr==upr+1 || (pPage->intKey && !pPage->leaf)pPage->isInitpCur->ix<pCur->pPage->nCell || CORRUPT_DB&(pPage)->aCellIdx[2*(lwr)]chldPgpCellKeypCellBodynOverrun 1876884~BTCF_ValidOvfl76916(BTCURSOR_MAX_DEPTH-1)7694776958moveto_index_finishcursorOnLastPageindexCellComparesqlite3BtreeTableMovetopCur->pKeyInfo==0pCur->eState!=CURSOR_VALID || pCur->curIntKey!=0cursorIsAtLastEntry(pCur) || CORRUPT_DBpCur->iPage==0 || pCur->apPage[0]->intKey==pCur->curIntKeypCur->curIntKeypPage->intKeybiasRight==0 || biasRight==1nCellKey==intKeylwr==upr+1 || !pPage->leafpCur->ix<pCur->pPage->nCell76601moveto_table_next_layermoveto_table_finishsqlite3BtreeLastbtreeLast~BTCF_AtLastsqlite3BtreeFirstpCur->pPage->nCell>0pCur->pgnoRoot==0 || (pCur->pPage!=0 && pCur->pPage->nCell==0)moveToRightmost(pCur->curFlags & BTCF_ValidNKey)==0moveToLeftmostpCur->ix<pPage->nCellpCur->ix&(pPage)->aCellIdx[2*(pCur->ix)]moveToRootCURSOR_INVALID < CURSOR_REQUIRESEEKCURSOR_VALID < CURSOR_REQUIRESEEKCURSOR_FAULT > CURSOR_REQUIRESEEKpCur->eState < CURSOR_REQUIRESEEK || pCur->iPage<0pCur->pgnoRoot>0 || pCur->iPage<0pCur->iPage==(-1)pCur->skipNext!=SQLITE_OKCURSOR_FAULTpRoot->pgno==pCur->pgnoRoot || CORRUPT_DBpRoot->intKey==1 || pRoot->intKey==076340skip_init(BTCF_AtLast|BTCF_ValidNKey|BTCF_ValidOvfl)~(BTCF_AtLast|BTCF_ValidNKey|BTCF_ValidOvfl)subpage76352moveToParentpCur->iPage>0pCur->apPage[pCur->iPage-1]pCur->aiIdx[pCur->iPage-1]pCur->aiIdx[pCur->iPage-1] > pCur->apPage[pCur->iPage-1]->nCellmoveToChildpCur->iPage<BTCURSOR_MAX_DEPTH76191pCur->pPage!=0 || rc!=SQLITE_OKnewPgno76205sqlite3BtreePayloadFetchfetchPayloadamtpCur!=0 && pCur->iPage>=0 && pCur->pPagepCur->info.nSize>0pCur->info.pPayload>pCur->pPage->aData || CORRUPT_DBpCur->info.pPayload<pCur->pPage->aDataEnd ||CORRUPT_DB(int)(pCur->pPage->aDataEnd - pCur->info.pPayload)sqlite3BtreePayloadCheckedaccessPayloadCheckedsqlite3BtreePayloadcursorHoldsMutex(pCur)pCur->iPage>=0 && pCur->pPageaccessPayloadpBufStarteOp==0 || eOp==175883offset+amt <= pCur->info.nPayloadaPayload > pPage->aData75898pCur->aOverflow[0]==nextPage || pCur->aOverflow[0]==0 || CORRUPT_DBpCur->aOverflow[0]!=0 || pCur->aOverflow[offset/ovflSize]==0rc==SQLITE_OK && amt>0pCur->aOverflow[iIdx]==0 || pCur->aOverflow[iIdx]==nextPage || CORRUPT_DBpCur->pBtree->db==pBt->dbaWrite>=pBufStartovflSizenextPage(int)sizeof(Pgno)413sizeof(Pgno)75969pPKey2bSkippMem1pMem2pB1pB2prcErrdeferredvarnResColumnpiPcpiAddrpaOppP4iNewOpcodeiLinenopnOppnMaxArgpMaxVtabArgsbPusheCallCtxsrcTypeifNullbForcedesiredEncpDestDbzDestDbzSrcDbpErrorDbaCntpzOutpiMinKeymaxKeyaHeapisFreeListpMetapiMovedpnChangefreePageFlagpiTablecreateTabFlagsppChildiParentIdxaOvflSpaceisRootbBulkpCArraypnSizepMemPagepPgnonearbyintKeybiasRightpAmtaSave76053copyPayloadgetOverflowPagepPgnoNextiGuess(iGuess)next==0 || rc==SQLITE_DONErc==SQLITE_OK || pPage==0sqlite3BtreeMaxRecordSizesqlite3BtreePayloadSizesqlite3BtreeOffsetsqlite3BtreeCursorUnpin(pCur->curFlags & BTCF_Pinned)!=0BTCF_Pinned~BTCF_Pinnedsqlite3BtreeCursorPin(pCur->curFlags & BTCF_Pinned)==0sqlite3BtreeIntegerKeysqlite3BtreeCursorIsValidNNgetCellInfosqlite3BtreeCloseCursorpBt->pCursor!=0pBtree->sharable==0sqlite3BtreeCursorZeroBtCursorBTCURSOR_FIRST_UNINIToffsetof(BtCursor, BTCURSOR_FIRST_UNINIT)sqlite3BtreeCursorSizesizeof(BtCursor)ROUND8(sizeof(BtCursor))sqlite3BtreeCursorbtreeCursorWithLockbtreeCursorwrFlag==0 || wrFlag==BTREE_WRCSR || wrFlag==(BTREE_WRCSR|BTREE_FORDELETE)hasSharedCacheTableLock(p, iTable, pKeyInfo!=0, (wrFlag?2:1)) || iTable<1wrFlag==0 || !hasReadConflicts(p, iTable)wrFlag==0 || p->inTrans==TRANS_WRITEpBt->pPage1 && pBt->pPage1->aDatawrFlag==0 || (pBt->btsFlags & BTS_READ_ONLY)==0wrFlag==075459sqlite3BtreeSavepointop==SAVEPOINT_RELEASE || op==SAVEPOINT_ROLLBACKiSavepoint>=0 || (iSavepoint==-1 && op==SAVEPOINT_ROLLBACK)CORRUPT_DB || pBt->nPage>0BTS_INITIALLY_EMPTYsqlite3BtreeBeginStmtiStatement>0iStatement>p->db->nSavepointsqlite3BtreeRollbackwriteOnly==1 || writeOnly==0tripCode==SQLITE_ABORT_ROLLBACK || tripCode==SQLITE_OKrc==SQLITE_OK || (writeOnly==0 && rc2==SQLITE_OK)p->pBt->inTransaction!=TRANS_NONE || p->pBt->nTransaction==0p->pBt->inTransaction>=p->inTransTRANS_WRITE==pBt->inTransactioncountValidCursors(pBt, 1)==0TRANS_READbtreeSetNPagenPage==0pBt->nPage!=(u32)nPagesqlite3BtreeTripAllCursors(writeOnly==0 || writeOnly==1) && BTCF_WriteFlag==1sqlite3BtreeCommitsqlite3BtreeCommitPhaseTwopBt->nTransaction>0btreeEndTransactionsqlite3BtreeCommitPhaseOneautoVacuumCommitnOrig(nOrig)nFinnVac7496874995nRef>=sqlite3PagerRefcount(pPager)nRef = sqlite3PagerRefcount(pPager);sqlite3BtreeIncrVacuumpBt->inTransaction==TRANS_WRITE && p->inTrans==TRANS_WRITE74917finalDbSizenPtrmap(nFin)incrVacuumStepnFreeListiLastPg>nFiniLastPg(iLastPg)iFreePg==iLastPgiFreePg<iLastPg74797iFreePgpFreePgpLastPgBTALLOC_ANYiNeardbSize74849relocatePagepPtrPageiDbPageeType==PTRMAP_OVERFLOW2 || eType==PTRMAP_OVERFLOW1 || eType==PTRMAP_BTREE || eType==PTRMAP_ROOTPAGEpDbPage->pBt==pBt74699nextOvfl("AUTOVACUUM: Moving %u to free page %u (ptr page %u type %u)\n", iDbPage, iFreePage, iPtrPage, eType)modifyPagePointer74624746437465274664setChildPtrmapschildPgnosqlite3BtreeBeginTransbtreeBeginTranspBt->inTransaction==TRANS_WRITE || IfNotOmitAV(pBt->bDoTruncate)==0~BTS_READ_ONLYBTS_PENDINGBtLock *~BTS_INITIALLY_EMPTY517p->lock.pBtree==p && p->lock.iTable==1!pBt->pWriterBTS_EXCLUSIVE~BTS_EXCLUSIVEtrans_begunsqlite3BtreeNewDbnewDatabasepP1!=0sizeof(zMagicHeader)sizeof(zMagicHeader)==16pBt->usableSize<=pBt->pageSize && pBt->usableSize+255>=pBt->pageSize100-24pBt->autoVacuum==1 || pBt->autoVacuum==0pBt->incrVacuum==1 || pBt->incrVacuum==04*436 + 4*47*436 + 7*4unlockBtreeIfUnusedcountValidCursors(pBt,0)==0 || pBt->inTransaction>TRANS_NONEpPage1->aDatasqlite3PagerRefcount(pBt->pPager)==1lockBtreenPageFilepBt->pPage1==0SQLITE_DEFAULT_WAL_SYNCHRONOUS+1SQLITE_DEFAULT_SYNCHRONOUS+1(pageSize & 7)==0pageSizepage1isOpen@  "\100\040\040"SQLITE_MAX_PAGE_SIZE74176480pBt->maxLeaf + 23 <= MX_CELL_SIZE(pBt)page1_init_failedsqlite3BtreeGetAutoVacuumsqlite3BtreeSetAutoVacuumsqlite3BtreeSecureDeleteBTS_OVERWRITE==BTS_SECURE_DELETE*2BTS_FAST_SECURE==(BTS_OVERWRITE|BTS_SECURE_DELETE)~BTS_FAST_SECUREsqlite3BtreeMaxPageCountsqlite3BtreeGetRequestedReservesqlite3BtreeGetReserveNoMutexsqlite3_mutex_held(p->pBt->mutex)sqlite3BtreeGetPageSizesqlite3BtreeSetPageSizenReserve>=0 && nReserve<=255!pBt->pCursorsqlite3BtreeSetPagerFlagssqlite3BtreeSetMmapLimitsqlite3BtreeSetSpillSizesqlite3BtreeSetCacheSizesqlite3BtreeClosep->wantToLock==0 && p->locked==0p->wantToLock==0p->locked==0freeTempSpaceallocateTempSpacepBt->pTmpSpace==0pBt->pCursor!=0 && (pBt->pCursor->curFlags & BTCF_WriteFlag)!=0removeFromSharingListremovedsqlite3_mutex_notheld(pBt->mutex)BtShared*sqlite3SharedCacheListsqlite3BtreeOpenmutexOpenzDbHeaderisTempDbisMemdbpVfs!=0(flags&0xff)==flags(flags & BTREE_UNORDERED)==0 || (flags & BTREE_SINGLE)!=0(flags & BTREE_SINGLE)==0 || isTempDbBTREE_MEMORY~SQLITE_OPEN_MAIN_DBsizeof(Btree)nFullPathnamenFilenamesqlite3_mutex *mutexShared;pBt->nRef>0zFullPathnamemutexSharedpExistingsizeof(u64)==8sizeof(Pgno)==4(pBt->pageSize & 7)==0mutexShared = sqlite3MutexAlloc(SQLITE_MUTEX_STATIC_MAIN);mutexShared = sqlite3MutexAlloc(2);sizeof(*pBt)Pager **sizeof(zDbHeader)SQLITE_DEFAULT_AUTOVACUUM(SQLITE_DEFAULT_AUTOVACUUM ? 1 : 0)(SQLITE_DEFAULT_AUTOVACUUM==2 ? 1 : 0)pSibbtree_open_outsqlite3_mutex_held(mutexOpen)rc!=SQLITE_OK || sqlite3BtreeConnectionCount(*ppBtree)>0btreeInvokeBusyHandlerpBt->dbsqlite3_mutex_held(pBt->db->mutex)pageReinitsqlite3PagerPageRefcount(pData)>0btreeGetUnusedPage73238releasePageOnepPage!=0pPage->aDatapPage->pBtpPage->pDbPage!=0sqlite3PagerGetExtra(pPage->pDbPage) == (void*)pPagesqlite3PagerGetData(pPage->pDbPage)==pPage->aDatareleasePagereleasePageNotNullgetAndInitPage73166pPage->pgno==pgno || CORRUPT_DBpPage->aData==sqlite3PagerGetData(pDbPage)sqlite3BtreeLastPagebtreePagecountbtreePageLookupbtreeGetPageflags==0 || flags==PAGER_GET_NOCONTENT || flags==PAGER_GET_READONLYbtreePageFromDbPagezeroPagefirstsqlite3PagerPagenumber(pPage->pDbPage)==pPage->pgno || CORRUPT_DBsqlite3PagerGetData(pPage->pDbPage) == datapBt->usableSizepBt->pageSize>=512 && pBt->pageSize<=65536btreeInitPagepPage->pBt!=0pPage->pBt->db!=0pPage->pgno==sqlite3PagerPagenumber(pPage->pDbPage)pPage == sqlite3PagerGetExtra(pPage->pDbPage)pPage->aData == sqlite3PagerGetData(pPage->pDbPage)pPage->isInit==073009&data[3]73023pPage->nCell>0 || get2byteNotZero(&data[5])==(int)pBt->usableSize || CORRUPT_DBpPage->nCell==MX_CELL(pBt)btreeCellSizeCheckiCellFirstiCellLastcellOffset&data[cellOffset+i*2]pc==iCellFirstpc==iCellLastpc+sz==usableSize7297272977btreeComputeFreeSpacetoppPage->isInit==1&data[pc]&data[pc+2]7291072915729257292972941decodeFlagspPage->hdrOffset==(pPage->pgno==1 ? 100 : 0)(PTF_ZERODATA | PTF_LEAF)(PTF_LEAFDATA | PTF_INTKEY | PTF_LEAF)72835(PTF_ZERODATA)(PTF_LEAFDATA | PTF_INTKEY)72859freeSpaceiFreeBlkiOrigSizeCORRUPT_DB || iStart>=pPage->hdrOffset+6+pPage->childPtrSizeCORRUPT_DB || iEnd <= pPage->pBt->usableSizeiSize>=4CORRUPT_DB || iStart<=pPage->pBt->usableSize-4&data[iPtr]iFreeBlk>iPtr || iFreeBlk==0 || CORRUPT_DB&data[iFreeBlk+2]&data[iFreeBlk]&data[iPtr+2]72727727327274472747iPtrEnd7276072766&data[iStart]&data[iStart+2]7278072781allocateSpacegapnByte>=0pPage->nFree>=nBytenByte < (int)(pPage->pBt->usableSize-8)pPage->cellOffset == hdr + 12 - 4*pPage->leafgap<=655367262872631pSpace+nByte<=data+pPage->pBt->usableSizeg272648pPage->nCell>0 || CORRUPT_DBpPage->nFree - (2+nByte)gap+2+nByte<=toptop+nByte <= (int)pPage->pBt->usableSizegap+2==topgap+1==topgap==topgap+2+nByte==toppageFindSlotmaxPCpc>0x==4x==3pPg->pgno&aData[pc+2]725587257372580defragmentPagecbrkiCellStartpPage->pBt->usableSize <= SQLITE_MAX_PAGE_SIZEnCell==get2byte(&data[hdr+3]) || CORRUPT_DB&data[iFree]&data[iFree+2]&data[iFree2+2]cbrk+(iFree-top) <= usableSizepAddrpc+szpc+sz272428iFree27243172439724427244472448pc>=0 && pc<=iCellLastcbrk+size<=usableSize && cbrk>=iCellStartcbrk+size==usableSizepc+size==usableSize7248172487defragment_out72501cbrk>=iCellFirstptrmapPutOvflPtrpCell!=0pSrc->aDataEndpCell+info.nLocalpSrc!=pPage72370cellSizePtrTableLeafnSize==pPage->maxLocalnSize==(u32)pPage->maxLocal+1minLocalnSize==debuginfo.nSize || CORRUPT_DBcellSizePtrNoPayloadpPage->childPtrSize==4debuginfo.nSize==(u16)(pIter - pCell) || CORRUPT_DBcellSizePtrIdxLeafpPage->childPtrSize==0cellSizePtrnSize>4btreeParseCell&(pPage)->aCellIdx[2*(iCell)]btreeParseCellPtrIndexpPage->leaf==0 || pPage->leaf==1pPage->intKeyLeaf==0nPayload==pPage->maxLocalnPayload==(u32)pPage->maxLocal+1btreeParseCellPtr2705489920x102040000x800021135360x204000btreeParseCellPtrNoPayloadpPage->leaf==0btreePayloadToLocalmaxLocalsurplusbtreeParseCellAdjustSizeForOverflowsurplus==maxLocalsurplus==maxLocal+1ptrmapGetiPtrmappPtrmap71922offset <= (int)pBt->usableSize-5pEType!=071930ptrmapPut0==PTRMAP_ISPAGE(pBt, PENDING_BYTE_PAGE(pBt))718597187271877("PTRMAP_UPDATE: %u->(%u,%u)\n", key, eType, parent)ptrmap_exitptrmapPagenonPagesPerMapPageiPtrMapsqlite3BtreeCursorHintFlagsx==BTREE_SEEK_EQ || x==BTREE_BULKLOAD || x==0sqlite3BtreeCursorRestorepCur->eState!=CURSOR_VALIDsqlite3BtreeFakeValidCursorfakeCursoroffsetof(BtCursor, eState)==0sqlite3BtreeCursorHasMovedEIGHT_BYTE_ALIGNMENT(pCur) || pCur==sqlite3BtreeFakeValidCursor()sizeof(pCur->eState)==1btreeRestoreCursorPositionskipNextpCur->eState>=CURSOR_REQUIRESEEK410pCur->eState==CURSOR_VALID || pCur->eState==CURSOR_INVALIDbtreeMovetonKey==(i64)(int)nKey71661sqlite3BtreeClearCursorsaveCursorsOnListp->iPage>=0saveAllCursorspExcept==0 || pExcept->pBt==pBt~BTCF_MultiplesaveCursorPositionCURSOR_VALID==pCur->eState || CURSOR_SKIPNEXT==pCur->eState0==pCur->pKey2835(BTCF_ValidNKey|BTCF_ValidOvfl|BTCF_AtLast)~(BTCF_ValidNKey|BTCF_ValidOvfl|BTCF_AtLast)saveCursorKeyCURSOR_VALID==pCur->eState9+8!pCur->curIntKey || !pCur->pKeybtreeReleaseAllCursorPagesbtreeClearHasContentBitvec *btreeGetHasContentbtreeSetHasContentpgno<=pBt->nPageinvalidateIncrblobCursorspBtree->hasIncrblobCursqlite3BtreeHoldsMutex(pBtree)invalidateAllOverflowCachedowngradeAllSharedCacheTableLockspLock->eLock==READ_LOCK || pLock->pBtree==ppLock(BTS_EXCLUSIVE|BTS_PENDING)-193~(BTS_EXCLUSIVE|BTS_PENDING)"downgradeLocks"clearAllSharedCacheTableLocksBtLock **p->sharable || 0==*ppIterp->inTrans>0(pBt->btsFlags & BTS_EXCLUSIVE)==0 || pBt->pWriter==pLock->pBtreepLock->pBtree->inTrans>=pLock->eLockpLock->iTable!=1 || pLock==&p->lock(pBt->btsFlags & BTS_PENDING)==0 || pBt->pWriter~BTS_PENDING"clearAllLocks"setSharedCacheTableLockeLock==READ_LOCK || eLock==WRITE_LOCK0==(p->db->flags&SQLITE_ReadUncommit) || eLock==WRITE_LOCKSQLITE_OK==querySharedCacheTableLock(p, iTable, eLock)sizeof(BtLock)WRITE_LOCK>READ_LOCK"setLock"querySharedCacheTableLock!(p->db->flags&SQLITE_ReadUncommit)||eLock==WRITE_LOCK||iTab==1eLock==READ_LOCK || (p==pBt->pWriter && p->inTrans==TRANS_WRITE)eLock==READ_LOCK || pBt->inTransaction==TRANS_WRITEpBt->pWriter->dbpIter->eLock==READ_LOCK || pIter->eLock==WRITE_LOCKeLock==READ_LOCK || pIter->pBtree==p || pIter->eLock==READ_LOCKpIter->pBtree->dbp==pBt->pWriterWRITE_LOCKsqlite3BtreeLeaveCursorsqlite3BtreeEnterCursorsqlite3BtreeLeaveAllbtreeLeaveAllsqlite3BtreeEnterAllbtreeEnterAllskipOksqlite3BtreeLeavep->wantToLock>0btreeLockCarefullypLaterpLater->sharablepLater->pNext==0 || pLater->pNext->pBt>pLater->pBt!pLater->locked || pLater->wantToLock>0sqlite3BtreeEnterp->pNext==0 || p->pNext->pBt>p->pBtp->pPrev==0 || p->pPrev->pBt<p->pBtp->pNext==0 || p->pNext->db==p->dbp->pPrev==0 || p->pPrev->db==p->dbp->sharable || (p->pNext==0 && p->pPrev==0)!p->locked || p->wantToLock>0p->sharable || p->wantToLock==0(p->locked==0 && p->sharable) || p->pBt->db==p->dbunlockBtreeMutexp->locked==1p->db==pBt->dblockBtreeMutexsqlite3_mutex_notheld(p->pBt->mutex)sqlite3WalFileWal *sqlite3WalHeapMemoryWAL_HEAPMEMORY_MODEsqlite3WalExclusiveModepWal->writeLock==0pWal->exclusiveMode!=WAL_HEAPMEMORY_MODE || op==-1pWal->readLock>=0 || pWal->lockErrorpWal->readLock>=0 || (op<=0 && pWal->exclusiveMode==0)pWal->readLockpWal->exclusiveMode==WAL_NORMAL_MODEpWal->readLock>=0WAL_NORMAL_MODEWAL_EXCLUSIVE_MODEsqlite3WalCallbacksqlite3WalCheckpointisChangedeMode2xBusy2pWal->ckptLock==0eMode!=SQLITE_CHECKPOINT_PASSIVE || xBusy==0pWalwalEnableBlocking(pWal)WAL_CKPT_LOCKWAL_WRITE_LOCKpWal->nSehTry>069479volatile WalCkptInfovolatile WalCkptInfo *WalCkptInfo *rc = walHandleException(pWal);pWal->nSehTry==0WalIndexHdr *sizeof(WalIndexHdr)("WAL%p: checkpoint begins\n", pWal)rc==SQLITE_BUSYrc!=SQLITE_OK && xBusy2!=0pWal->nSehTry++pWal->nSehTry--("WAL%p: checkpoint %s\n", pWal, rc ? "failed" : "ok")sqlite3WalFrameswalFramesiFrameszFramepLivepWal->writeLock(isCommit!=0)==(nTruncate!=0)volatile WalIndexHdrvolatile WalIndexHdr *("WAL%p: wal-header write %s\n", pWal, rc ? "failed" : "ok")sync_flagsu8[32]unsigned char[32]WAL_HDRSIZEaWalHdraCksum931071618WAL_MAGIC(WAL_MAGIC | SQLITE_BIGENDIAN)3007000WAL_MAX_VERSIONconst u32 *2*4sizeof(aWalHdr)69219iFrame+1WAL_FRAME_HDRSIZErc==SQLITE_OK || iWrite==0iOffset==walFrameOffset(iFrame, szPage)nDbSizePGHDR_WAL_APPEND~PGHDR_WAL_APPENDWalWriter *bSyncpLast!=0sectorSizeiFrame+nExtra+1pLast!=0 || nExtra==0szPage<=32768szPage>=655360xff00("WAL%p: frame write %s\n", pWal, rc ? "failed" : "ok")walRewriteChecksumsu8[24]unsigned char[24]aFrameiCksumOffpWal->iReCksum>0pWal->iReCksum-1sizeof(u32)*2sizeof(aFrame)walWriteOneFramewalWriteToLogWAL_SYNC_FLAGS(p->syncFlags)!=0p->syncFlagsiFirstAmtwalRestartLogpInfo->nBackfill==pWal->hdr.mxFrame(rc&0xff)!=SQLITE_BUSY(rc&0xff)==SQLITE_IOERRrc==SQLITE_PROTOCOLsalt1WAL_READ_LOCK(1)WAL_NREADERWAL_READ_LOCK(0)WAL_RETRYsqlite3WalSavepointUndoaWalData[3]!=pWal->nCkpt || aWalData[0]<=pWal->hdr.mxFramerc = SQLITE_IOERR_IN_PAGE;sqlite3WalSavepointsqlite3WalUndowalFramePgno(pWal, iFrame)!=1sqlite3WalEndWriteTransactionsqlite3WalBeginWriteTransactionpWal->writeLock==0 && pWal->iReCksum==0sqlite3WalDbsizesqlite3WalReadFrame650240xfe00sz<=32768sz>=65536sqlite3WalFindFramewalFindFrameiMinHash&sLoc.aHash[iKey]iFrame>iRead || CORRUPT_DBsLocnCollideiHWalHashLoc *HASHTABLE_NSLOT__atomic_load_2volatile ht_slotvolatile ht_slot *volatile u32volatile u32 *68696sqlite3WalEndReadTransactionsqlite3WalBeginReadTransactionwalBeginReadTransaction(rc&0xff)==SQLITE_BUSYwalTryBeginReadpWal->readLock<0(pWal->readOnly & WAL_SHM_RDONLY)==0 || useWal==0pWal->lockError = 1;nDelayWAL_RETRY_BLOCKED_MASK~WAL_RETRY_BLOCKED_MASKWAL_RETRY_PROTOCOL_LIMITvolatile u32 **WAL_RECOVER_LOCKpWal->nWiData>0pWal->apWiData[0]!=0mxReadMarkmxFrame&pInfo->nBackfillpInfo->aReadMark+ithisMark!=READMARK_NOT_USEDthisMarku32[5]WAL_SHM_RDONLYrc==SQLITE_BUSY || (pWal->readOnly & WAL_SHM_RDONLY)!=01288nBlockTmoutwalEnableBlockingMs(pWal, nBlockTmout)rc!=SQLITE_BUSY_TIMEOUT(rc&0xFF)!=SQLITE_BUSY||rc==SQLITE_BUSY||rc==SQLITE_BUSY_TIMEOUTpInfo->aReadMark+mxImxReadMark<=pWal->hdr.mxFramewalBeginShmUnreliableszWalaSaveCksumpWal->bShmUnreliablepWal->readOnly & WAL_SHM_RDONLYpWal->nWiData>0 && pWal->apWiData[0]WALINDEX_PGSZu32(*)[2]unsigned int(*)[2](pWal->szPage & (pWal->szPage-1))==0pWal->szPage>=512 && pWal->szPage<=65536pWal->hdr.mxFrame+1pWal->szPagenTruncatebegin_unreliable_shm_outwalIndexReadHdrbadHdrpage0pChangedrc!=SQLITE_READONLYpage0==0page0!=0page0!=0 || pWal->writeLock==0bWriteLockWALINDEX_MAX_VERSION67850pWal->nWiData>0 && pWal->apWiData[0]==0walIndexTryHdrh1h2sizeof(h1)sizeof(h2)sizeof(h1.aCksum)sizeof(h1)-sizeof(h1.aCksum)pWal->szPage<=32768pWal->szPage>=65536sqlite3WalClosewalAssertLockmask(pWal)("WAL%p: closed\n", pWal)isDeletebPersistwalLimitSizecannot limit WAL size: %s"cannot limit WAL size: %s"walCheckpointWalIterator *iDbpagemxSafeFramey<=pWal->hdr.mxFramerc==SQLITE_OK || pIter==0walFramePgno(pWal, iFrame)==iDbpageIS_BIG_INT(iOffset)IS_BIG_INT(szDb)READMARK_NOT_USEDWalIterator **nBackfill67406walcheckpoint_outwalRestartHdraSaltpInfo->aReadMark[0]==0walPagesizewalBusyLockwalIteratorInitht_slot *pWal->ckptLock && pWal->hdr.mxFrame>0sizeof(WalIterator)sizeof(struct WalSegment)sizeof(ht_slot)HASHTABLE_NPAGEWalSegment[1]WalSegment *walIteratorFreewalMergesortiListiSubSublist[13]aSubSublist *sizeof(aSub)nList<=HASHTABLE_NPAGE && nList>0HASHTABLE_NPAGE==(1<<(ArraySize(aSub)-1))iSub<ArraySize(aSub)p->aList && p->nList<=(1<<iSub)p->aList==&aList[iList&~((2<<iSub)-1)]ht_slot **p->nList<=(1<<iSub)p->aList==&aList[nList&~((2<<iSub)-1)]ArraySize(aSub)aMerge==aListwalMergenLeft>0 && nRight>0iLeft>=nLeft || aContent[aLeft[iLeft]]>dbpageiRight>=nRight || aContent[aRight[iRight]]>dbpagelogpagedbpagesizeof(aTmp[0])walIteratorNext 0xFFFFFFFFiMin<0xffffffffpSegmentsqlite3WalLimitsqlite3WalOpenWal **zWalName && zWalName[0]pDbFd48 == sizeof(WalIndexHdr)40 == sizeof(WalCkptInfo)120 == WALINDEX_LOCK_OFFSET136 == WALINDEX_HDR_SIZE4096 == HASHTABLE_NPAGE4062 == HASHTABLE_NPAGE_ONE8192 == HASHTABLE_NSLOT383 == HASHTABLE_HASH_132768 == WALINDEX_PGSZ8 == SQLITE_SHM_NLOCK5 == WAL_NREADER24 == WAL_FRAME_HDRSIZE32 == WAL_HDRSIZE120 == WALINDEX_LOCK_OFFSET + WAL_WRITE_LOCK121 == WALINDEX_LOCK_OFFSET + WAL_CKPT_LOCK122 == WALINDEX_LOCK_OFFSET + WAL_RECOVER_LOCK123 == WALINDEX_LOCK_OFFSET + WAL_READ_LOCK(0)124 == WALINDEX_LOCK_OFFSET + WAL_READ_LOCK(1)125 == WALINDEX_LOCK_OFFSET + WAL_READ_LOCK(2)126 == WALINDEX_LOCK_OFFSET + WAL_READ_LOCK(3)127 == WALINDEX_LOCK_OFFSET + WAL_READ_LOCK(4)UNIX_SHM_BASE==WALINDEX_LOCK_OFFSETsizeof(Wal)524294(SQLITE_OPEN_READWRITE|SQLITE_OPEN_CREATE|SQLITE_OPEN_WAL)WAL_RDONLY("WAL%d: opened\n", pRet)iDCwalIndexClosewalIndexRecoveraFrameCksumiLockpWal->ckptLock==1 || pWal->ckptLock==0WAL_ALL_BUT_WRITE==WAL_WRITE_LOCK+1WAL_CKPT_LOCK==WAL_ALL_BUT_WRITEWAL_ALL_BUT_WRITEiLastFrameHASHTABLE_NPAGE_ONE+iPg*HASHTABLE_NPAGE(4096 - ((sizeof(WalIndexHdr)*2+sizeof(WalCkptInfo))/sizeof(u32)))+iPg*4096aShare!=0 || rc!=SQLITE_OKaShareaPrivatemagicisValid0xFFFFFFFE665964062HASHTABLE_NPAGE_ONEnHdr32WALINDEX_HDR_SIZErecovered %d frames from WAL file %s"recovered %d frames from WAL file %s"recovery_error("WAL%p: recovery begin...\n", pWal)("WAL%p: recovery %s\n", pWal, rc ? "failed" : "ok")walIndexAppendidx <= HASHTABLE_NSLOT/2 + 1!sLoc.aPgno[idx-1](ht_slot)idx66464__atomic_store_2walCleanupHashpWal->nWiData>walFramePage(pWal->hdr.mxFrame)pWal->apWiData[walFramePage(pWal->hdr.mxFrame)]iLimit>0pWal->hdr.mxFrame==HASHTABLE_NPAGE_ONE-1pWal->hdr.mxFrame==HASHTABLE_NPAGE_ONEpWal->hdr.mxFrame==HASHTABLE_NPAGE_ONE+1walFramePgnowalFramePage(iHash==0 || iFrame>HASHTABLE_NPAGE_ONE) && (iHash>=1 || iFrame<=HASHTABLE_NPAGE_ONE) && (iHash<=1 || iFrame>(HASHTABLE_NPAGE_ONE+HASHTABLE_NPAGE)) && (iHash>=2 || iFrame<=HASHTABLE_NPAGE_ONE+HASHTABLE_NPAGE) && (iHash<=2 || iFrame>(HASHTABLE_NPAGE_ONE+2*HASHTABLE_NPAGE))walHashGetrc==SQLITE_OK || iHash>0walNextHash8191(HASHTABLE_NSLOT-1)walHashiPage>0(HASHTABLE_NSLOT & (HASHTABLE_NSLOT-1))==0383HASHTABLE_HASH_1walUnlockExclusive("WAL%p: release EXCLUSIVE-%s cnt=%d\n", pWal, walLockName(lockIdx), n)walLockExclusive("WAL%p: acquire EXCLUSIVE-%s cnt=%d %s\n", pWal, walLockName(lockIdx), n, rc ? "failed" : "ok")pWal->lockError = (u8)(rc!=SQLITE_OK && (rc&0xFF)!=SQLITE_BUSY);walUnlockShared("WAL%p: release SHARED-%s\n", pWal, walLockName(lockIdx))walLockShared("WAL%p: acquire SHARED-%s %s\n", pWal, walLockName(lockIdx), rc ? "failed" : "ok")walDecodeFramenativeCksumWAL_FRAME_HDRSIZE==24walEncodeFramewalIndexWriteHdrWalIndexHdrnCksumoffsetof(WalIndexHdr, aCksum)walShmBarrierwalChecksumBytesnByte>=8(nByte&0x00000007)==0nByte<=65536nByte%4==0aData[0]aData[1]167116804278190080aData==aEndwalIndexHdrwalCkptInfosizeof(WalIndexHdr)/2walIndexPagewalIndexPageReallocsizeof(u32*)pWal->apWiData[iPage]==0pWal->apWiData[iPage]!=0 || rc!=SQLITE_OK || (pWal->writeLock==0 && iPage==0)pWal->apWiData[iPage]==0 && rc==SQLITE_OK600iPage==0 || *ppPage || rc!=SQLITE_OKsqlite3PagerCloseWalpPager->journalMode==PAGER_JOURNALMODE_WALlogexistsSHARED_LOCKsqlite3PagerOpenWalassert_pager_state(pPager)pPager->eState==PAGER_OPEN || pbOpenpPager->eState==PAGER_READER || !pbOpenpbOpen==0 || *pbOpen==0pbOpen!=0 || (!pPager->tempFile && !pPager->pWal)PAGER_OPENpagerOpenWalpPager->pWal==0 && pPager->tempFile==0pPager->eLock==SHARED_LOCK || pPager->eLock==EXCLUSIVE_LOCKpagerExclusiveLockeOrigLockpPager->eLock>=SHARED_LOCKEXCLUSIVE_LOCKsqlite3PagerWalSupportedsqlite3PagerWalCallbacksqlite3PagerCheckpointPRAGMA table_list"PRAGMA table_list"sqlite3PagerClearCacheMEMDB==0 || pPager->tempFilesqlite3PagerBackupPtrsqlite3PagerJournalSizeLimitsqlite3PagerOkToChangeJournalModePAGER_WRITER_CACHEMODisOpen(pPager->jfd) && pPager->journalOff>0((pPager->jfd)->pMethods!=0) && pPager->journalOff>0pPager->jfdsqlite3PagerGetJournalModesqlite3PagerSetJournalModeeMode==PAGER_JOURNALMODE_DELETE || eMode==PAGER_JOURNALMODE_PERSIST || eMode==PAGER_JOURNALMODE_OFF || eMode==PAGER_JOURNALMODE_TRUNCATE || eMode==PAGER_JOURNALMODE_MEMORY || eMode==PAGER_JOURNALMODE_WALpPager->tempFile==0 || eMode!=PAGER_JOURNALMODE_WALeOld==PAGER_JOURNALMODE_MEMORY || eOld==PAGER_JOURNALMODE_OFFpPager->eState!=PAGER_ERROR(PAGER_JOURNALMODE_TRUNCATE & 5)==1(PAGER_JOURNALMODE_PERSIST & 5)==1(PAGER_JOURNALMODE_DELETE & 5)==0(PAGER_JOURNALMODE_MEMORY & 5)==4(PAGER_JOURNALMODE_OFF & 5)==0(PAGER_JOURNALMODE_WAL & 5)==5isOpen(pPager->fd) || pPager->exclusiveModestate==PAGER_OPEN || state==PAGER_READERstate==pPager->eStateRESERVED_LOCKPAGER_READERsqlite3PagerLockingModeeMode==PAGER_LOCKINGMODE_QUERY || eMode==PAGER_LOCKINGMODE_NORMAL || eMode==PAGER_LOCKINGMODE_EXCLUSIVEPAGER_LOCKINGMODE_QUERY<0PAGER_LOCKINGMODE_NORMAL>=0 && PAGER_LOCKINGMODE_EXCLUSIVE>=0pPager->exclusiveMode || 0==sqlite3WalHeapMemory(pPager->pWal)sqlite3PagerGetExtrasqlite3PagerGetDatapPg->nRef>0 || pPg->pPager->memDbsqlite3PagerRekeypPg->pgno!=iNewsqlite3PagerMovepagepPgOldneedSyncPgnoorigPgnopPg->nRef>0pPager->eState==PAGER_WRITER_CACHEMOD || pPager->eState==PAGER_WRITER_DBMODpPager->tempFile || !MEMDBPGHDR_DIRTYpPager->journalMode==PAGER_JOURNALMODE_OFF || pageInJournal(pPager, pPg) || pPg->pgno>pPager->dbOrigSizepPg->flags&PGHDR_DIRTYPGHDR_NEED_SYNC~PGHDR_NEED_SYNC!pPgOld || pPgOld->nRef==1 || CORRUPT_DBpPgOld->nRef>164537pPager->pTmpSpace!=0pPgHdr("MOVE %d page %d (needSync=%d) moves to %d\n", PAGERID(pPager), pPg->pgno, (pPg->flags&PGHDR_NEED_SYNC)?1:0, pgno)("MOVE %p %d %d\n", pPager, pPg->pgno, pgno)sqlite3PagerJournalnamesqlite3PagerJrnlFilesqlite3PagerFilesqlite3PagerVfssqlite3PagerFilenameconst char[8]const sqlite3_vfsconst sqlite3_vfs *sqlite3PagerSavepointiSavepoint>=0 || op==SAVEPOINT_ROLLBACKpPager->sjfdPagerSavepoint *pRelsqlite3PagerOpenSavepointpPager->eState>=PAGER_WRITER_LOCKEDpagerOpenSavepointnCurrentnSavepoint>nCurrent && pPager->useJournalsizeof(PagerSavepoint)u32[4]WAL_SAVEPOINT_NDATApPager->nSavepoint==nSavepointsqlite3PagerIsMemdbsqlite3PagerCacheStateStat==SQLITE_DBSTATUS_CACHE_HIT || eStat==SQLITE_DBSTATUS_CACHE_MISS || eStat==SQLITE_DBSTATUS_CACHE_WRITE || eStat==SQLITE_DBSTATUS_CACHE_WRITE+1SQLITE_DBSTATUS_CACHE_HIT+1==SQLITE_DBSTATUS_CACHE_MISSSQLITE_DBSTATUS_CACHE_HIT+2==SQLITE_DBSTATUS_CACHE_WRITEPAGER_STAT_HIT==0 && PAGER_STAT_MISS==1 && PAGER_STAT_WRITE==2 && PAGER_STAT_SPILL==3sqlite3PagerPageRefcountsqlite3PagerMemUsedperPageSizesizeof(PgHdr)5*sizeof(void*)sizeof(PgHdr) + 5*sizeof(void*)(int)(sizeof(PgHdr) + 5*sizeof(void*))PCache *sqlite3PagerIsreadonlysqlite3PagerRollbackPAGER_ERRORPAGER_WRITER_LOCKEDpPager->eState==PAGER_READER || rc!=SQLITE_OKrc==SQLITE_OK || rc==SQLITE_FULL || rc==SQLITE_CORRUPT || rc==SQLITE_NOMEM || (rc&0xFF)==SQLITE_IOERR || rc==SQLITE_CANTOPEN("ROLLBACK %d\n", PAGERID(pPager))sqlite3PagerCommitPhaseTwopPager->errCodepPager->eState==PAGER_WRITER_LOCKED || pPager->eState==PAGER_WRITER_FINISHED || (pagerUseWal(pPager) && pPager->eState==PAGER_WRITER_CACHEMOD)pPager->journalOff==JOURNAL_HDR_SZ(pPager) || !pPager->journalOffPAGER_JOURNALMODE_PERSIST("COMMIT %d\n", PAGERID(pPager))sqlite3PagerCommitPhaseOnepPager->eState==PAGER_WRITER_LOCKED || pPager->eState==PAGER_WRITER_CACHEMOD || pPager->eState==PAGER_WRITER_DBMOD || pPager->eState==PAGER_ERRORisOpen(pPager->fd) || pPager->tempFilerc!=SQLITE_IOERR_BLOCKEDpPager->eState==PAGER_WRITER_DBMOD("DBSYNC %p\n", pPager)pPageOnebBatchcommit_phase_one_exitPAGER_WRITER_FINISHED("DATABASE SYNC: File=%s zSuper=%s nSize=%d\n", pPager->zFilename, zSuper, pPager->dbSize)sqlite3PagerExclusiveLockpPager->eState==PAGER_WRITER_CACHEMOD || pPager->eState==PAGER_WRITER_DBMOD || pPager->eState==PAGER_WRITER_LOCKEDsqlite3PagerSync!MEMDBpager_incr_changecounterisDirectMode==0isDirectMode!pPager->tempFile && isOpen(pPager->fd)pPgHdr==0 || rc==SQLITE_OKpPager->dbFileSize>0DIRECT_MODE!DIRECT_MODEPAGER_STAT_WRITEchar(*)[16]sizeof(pPager->dbFileVers)sqlite3PagerDontWrite("DONT_WRITE page %d of %d\n", pPg->pgno, PAGERID(pPager))("CLEAN %p %d\n", pPager, pPg->pgno)pPg->flags & PGHDR_NEED_SYNCPGHDR_DONT_WRITEPGHDR_WRITEABLE~PGHDR_WRITEABLEsqlite3PagerWrite(pPg->flags & PGHDR_MMAP)==0pPager->tempFile==0pagerWriteLargeSectornPageCountpg1needSyncnPagePerSector(pPager->doNotSpill & SPILLFLAG_NOSYNC)==0SPILLFLAG_NOSYNCnPage>0pg1<=pPg->pgno(pg1+nPage)>pPg->pgnopg(pPager->doNotSpill & SPILLFLAG_NOSYNC)!=0~SPILLFLAG_NOSYNCpager_writepPager->eState==PAGER_WRITER_LOCKED || pPager->eState==PAGER_WRITER_CACHEMOD || pPager->eState==PAGER_WRITER_DBMODpPager->errCode==0pPager->readOnly==0pPager->eState>=PAGER_WRITER_CACHEMOD(pPager->pInJournal!=0) == isOpen(pPager->jfd)pagerUseWal(pPager)==0("APPEND %d page %d needSync=%d\n", PAGERID(pPager), pPg->pgno, ((pPg->flags&PGHDR_NEED_SYNC)?1:0))PAGER_WRITER_DBMODpagerAddPageToRollbackJournalpData2pPg->pgno!=PAGER_SJ_PGNO(pPager)pPager->journalHdr<=pPager->journalOffpPager->pInJournal!=0("JOUT %p %d %lld %d\n", pPager, pPg->pgno, pPager->journalOff, pPager->pageSize)sqlite3_pager_writej_count("JOURNAL %d page %d needSync=%d hash(%08x)\n", PAGERID(pPager), pPg->pgno, ((pPg->flags&PGHDR_NEED_SYNC)?1:0), pager_pagehash(pPg))sqlite3PagerBeginpPager->eState>=PAGER_READER && pPager->eState<PAGER_ERRORpPager->pInJournal==0rc==SQLITE_OK || pPager->eState==PAGER_READERrc!=SQLITE_OK || pPager->eState==PAGER_WRITER_LOCKED("TRANSACTION %d\n", PAGERID(pPager))pager_open_journalsqlite3_vfs *constpPager->eState==PAGER_WRITER_LOCKEDrc!=SQLITE_OK || isOpen(pPager->jfd)4104(SQLITE_OPEN_DELETEONCLOSE|SQLITE_OPEN_TEMP_JOURNAL)sqlite3PagerUnrefPageOnepPg!=0pPg->pgno==1sqlite3PagerUnrefsqlite3PagerUnrefNotNullpPg->pgno!=1PGHDR_MMAPsqlite3PcacheRefCount(pPager->pPCache)>0Pager *pPager = pPg->pPager;sqlite3PagerLookuppgno!=0pPager->pPCache!=0pPage==0 || pPager->hasHeldSharedLocksqlite3PagerGetgetPageErrorpPager->errCode!=SQLITE_OKgetPageMMapbMmapOkUSEFETCH(pPager)62971pPager->eState>=PAGER_READERpPager->hasHeldSharedLock==1pPager->errCode==SQLITE_OKgetPageNormal62856sqlite3_pcache_page **pPg==(*ppPage)pPg->pgno==pgnopPg->pPager==pPager || pPg->pPager==0pgno!=PAGER_SJ_PGNO(pPager)!isOpen(pPager->fd) || !MEMDBpPager->fd("ZERO %p %d\n", pPager, pgno)pPg->pPager==pPagerPAGER_STAT_HIT62888PAGER_STAT_MISSpager_acquire_errpagerUnlockIfUnusedpPager->nMmapOut==0sqlite3PagerSharedLocksqlite3PcacheRefCount(pPager->pPCache)==0pPager->eState==PAGER_OPEN || pPager->eState==PAGER_READERpPager->tempFile==0 || pPager->eLock==EXCLUSIVE_LOCKpPager->eLock==NO_LOCK || pPager->eLock==UNKNOWN_LOCK!pPager->tempFilepPager->eState==PAGER_OPEN(pPager->eLock==SHARED_LOCK) || (pPager->exclusiveMode && pPager->eLock>SHARED_LOCK)("CKVERS %p %d\n", pPager, sizeof(dbFileVers))pPager->pWal==0 || rc==SQLITE_OKbHotJournal776fout62643dbFileVerssizeof(dbFileVers)hasHotJournaljrnlOpenpPager->useJournalisOpen(pPager->fd)jrnlOpen==0 || ( sqlite3OsDeviceCharacteristics(pPager->jfd) & SQLITE_IOCAP_UNDELETABLE_WHEN_OPEN )locked2049sizeof(Pager*)EIGHT_BYTE_ALIGNMENT(p)sqlite3PagerOpentempFilememDbmemJMreadOnlyjournalFileSizezPathnamenPathnameuseJournalPAGER_OMIT_JOURNALpcacheSizeszPageDfltSQLITE_DEFAULT_PAGE_SIZEnUriBytesqlite3JournalSize(pVfs)PAGER_MEMORYnUriByte>=1155062122SQLITE_PTRSIZE==sizeof(Pager*)sizeof(*pPager)ROUND8(sizeof(*pPager))EIGHT_BYTE_ALIGNMENT(SQLITE_INT_TO_PTR(journalFileSize))EIGHT_BYTE_ALIGNMENT(pPager->jfd)-journal"-journal"8 + 1-wal"-wal"4 + 1!memDbSQLITE_DEFAULT_PAGE_SIZE<=SQLITE_MAX_DEFAULT_PAGE_SIZEiDcSQLITE_MAX_DEFAULT_PAGE_SIZEnolock"nolock"immutable"immutable"act_like_temp_filepPager->memDb==0nExtra>=8 && nExtra<1000SQLITE_MAX_PAGE_COUNTtempFile==PAGER_LOCKINGMODE_NORMAL || tempFile==PAGER_LOCKINGMODE_EXCLUSIVEPAGER_LOCKINGMODE_EXCLUSIVE==1useJournal || pPager->tempFile(SQLITE_DEFAULT_SYNCHRONOUS+1)(SQLITE_DEFAULT_SYNCHRONOUS+1)|PAGER_CACHESPILLSQLITE_DEFAULT_JOURNAL_SIZE_LIMITisOpen(pPager->fd) || tempFile("OPEN %d %s\n", FILEHANDLEID(pPager->fd), pPager->zFilename)("OPEN %p %s\n", pPager, pPager->zFilename)sqlite3PagerFlushpagerStressSPILLFLAG_ROLLBACKSPILLFLAG_OFF(SPILLFLAG_ROLLBACK|SPILLFLAG_OFF)PAGER_STAT_SPILL(pPg->flags&PGHDR_NEED_SYNC)==0("STRESS %d page %d\n", PAGERID(pPager), pPg->pgno)pPager->doNotSpill & SPILLFLAG_ROLLBACKpPager->doNotSpill & SPILLFLAG_OFFpPager->doNotSpill & SPILLFLAG_NOSYNCsubjournalPageIfRequiredsubjournalPageisOpen(pPager->jfd) || pagerUseWal(pPager)isOpen(pPager->sjfd) || pPager->nSubRec==0pagerUseWal(pPager) || pageInJournal(pPager, pPg) || pPg->pgno>pPager->dbOrigSize("STMT-JOURNAL %d page %d\n", PAGERID(pPager), pPg->pgno)pPager->nSavepoint>0openSubJournal819882148222nStmtSpillpager_write_pagelist!pagerUseWal(pPager)pPager->tempFile || pPager->eState==PAGER_WRITER_DBMODpPager->eLock==EXCLUSIVE_LOCKisOpen(pPager->fd) || pList->pDirty==0pPager->tempFile && rc==SQLITE_OKrc!=SQLITE_OK || isOpen(pPager->fd)(pList->flags&PGHDR_NEED_SYNC)==0("STORE %d page %d hash(%08x)\n", PAGERID(pPager), pgno, pager_pagehash(pList))("PGOUT %p %d\n", pPager, pgno)sqlite3_pager_writedb_count("NOSTORE %d page %d\n", PAGERID(pPager), pgno)syncJournalisOpen(pPager->jfd)&zHeader[sizeof(aJournalMagic)]pPager->nRec("SYNC journal of %d\n", PAGERID(pPager))("JSYNC %p\n", pPager)("JHDR %p %lld\n", pPager, pPager->journalHdr)iNextHdrOffsetaMagicu8[12]const unsigned char[8]sizeof(aJournalMagic)sizeof(aJournalMagic)+4zHeaderzerobytesizeof(zHeader)sqlite3PagerRefsqlite3PagerClosedb || pagerUseWal(pPager)==0db || pPager->pWal==0!pPager->aSavepoint && !pPager->pInJournal!isOpen(pPager->jfd) && !isOpen(pPager->sjfd)("CLOSE %d\n", PAGERID(pPager))("CLOSE %p\n", pPager)databaseIsUnmovedbHasMovedpPager->zFilename && pPager->zFilename[0]pagerFreeMapHdrspagerReleaseMapPagepPager->fd->pMethods->iVersion>=3pagerAcquireMapPagepPager->nExtra>=8EIGHT_BYTE_ALIGNMENT( p->pExtra )p->pExtra==(void *)&p[1]p->pPage==0p->flags==PGHDR_MMAPp->pPager==pPagerp->nRef==1pagerSyncHotJournalsqlite3PagerTruncateImagepPager->dbSize>=nPage || CORRUPT_DBpager_wait_on_lock(pPager->eLock>=locktype) || (pPager->eLock==NO_LOCK && locktype==SHARED_LOCK) || (pPager->eLock==RESERVED_LOCK && locktype==EXCLUSIVE_LOCK)sqlite3PagerPagecountpPager->eState!=PAGER_WRITER_FINISHEDsqlite3PagerReadFileheader("DBHDR %p 0 %d\n", pPager, N)sqlite3PagerMaxPageCountpPager->eState!=PAGER_OPENsqlite3PagerTempSpacesqlite3PagerSetPagesizepageSize==0 || (pageSize>=512 && pageSize<=SQLITE_MAX_PAGE_SIZE)nReserve>=0 && nReserve<1000sqlite3PagerSetBusyHandler((int(*)(void *))(ap[0]))==xBusyHandlerap[1]==pBusyHandlerArgpagerOpentemprc!=SQLITE_OK || isOpen(pFile)sqlite3PagerSetFlagsPAGER_SYNCHRONOUS_EXTRAPAGER_FULLFSYNCPAGER_CKPT_FULLFSYNC(SQLITE_SYNC_FULL<<2)~SPILLFLAG_OFFsqlite3PagerShrinksqlite3PagerSetMmapLimitpagerFixMaplimitsqlite3PagerSetSpillsizesqlite3PagerSetCachesizepagerPlaybackSavepointszJiHdrOffpDonepagerUseWal(pPager)==0 || szJ==0nJRecrc!=SQLITE_OK || pPager->journalOff>=szJoffset==(i64)ii*(4+pPager->pageSize)pagerOpenWalIfPresentsqlite3PcachePagecount(pPager->pPCache)==0isWalPAGER_JOURNALMODE_DELETEpagerPagecount((pPager->fd)->pMethods!=0)pagerBeginReadTransactionchangedpagerUseWal(pPager)pagerWalFramespPager->pWalpList->pDirty==0 || isCommitppNextpagerRollbackWalpagerUndoCallbackpager_write_changecounterchange_counter((char*)pPg->pData)+24((char*)pPg->pData)+92((char*)pPg->pData)+96readDbPagepPager->eState>=PAGER_READER && !MEMDBsqlite3_pager_readdb_countpPager->nRead("PGIN %p %d\n", pPager, pPg->pgno)("FETCH %d page %d hash(%08x)\n", PAGERID(pPager), pPg->pgno, pager_pagehash(pPg))pager_playbackmxPgneedPagerResetnPlaybacksavedPageSizepPager->journalOff==JOURNAL_HDR_SZ(pPager)end_playbackzSuper==&pPager->pTmpSpace[4]539recovered %d pages from %s"recovered %d pages from %s"setSectorSizesqlite3SectorSizeMAX_SECTOR_SIZE>=512MAX_SECTOR_SIZEpager_truncatepPager->eState!=PAGER_READER(newSize-szPage) == currentSize(newSize-szPage) > currentSizecurrentSize("Truncate %d npage %u\n", PAGERID(pPager), nPage)pager_delsuperpSuperpJournalzSuperJournalnSuperJournalzSuperPtrnSuperPtr(SQLITE_OPEN_READONLY|SQLITE_OPEN_SUPER_JOURNAL)delsuper_out!isOpen(pJournal)pager_playback_one_pagejfdisSynced(isMainJrnl&~1)==0(isSavepnt&~1)==0isMainJrnl || pDoneisSavepnt || pDone==0pagerUseWal(pPager)==0 || (!isMainJrnl && isSavepnt)pPager->eState>=PAGER_WRITER_CACHEMOD || (pPager->eState==PAGER_OPEN && pPager->eLock==EXCLUSIVE_LOCK)pPager->eState>=PAGER_WRITER_CACHEMOD || isMainJrnl!isSavepntpPg || !MEMDBpPager->eState!=PAGER_OPEN || pPg==0 || pPager->tempFile!isSavepnt && pPg!=0 && (pPg->flags&PGHDR_NEED_SYNC)!=0isSavepnt(pPager->doNotSpill & SPILLFLAG_ROLLBACK)==0(pPager->doNotSpill & SPILLFLAG_ROLLBACK)!=0~SPILLFLAG_ROLLBACK("PLAYBACK %d page %d hash(%08x) %s\n", PAGERID(pPager), pgno, pager_datahash(pPager->pageSize, (u8*)aData), (isMainJrnl?"main-journal":"sub-journal") )pager_cksumpagerUnlockAndRollbackpPager->eState==PAGER_READERpager_end_transactionisOpen(pPager->jfd) || pPager->pInJournal==0 || (sqlite3OsDeviceCharacteristics(pPager->fd)&SQLITE_IOCAP_BATCH_ATOMIC)sqlite3JournalIsInMemory(pPager->jfd)==0pPager->journalMode==PAGER_JOURNALMODE_DELETE || pPager->journalMode==PAGER_JOURNALMODE_MEMORY || pPager->journalMode==PAGER_JOURNALMODE_WALPAGER_JOURNALMODE_TRUNCATEpagerFlushOnCommitpager_errorrc==SQLITE_OK || !MEMDBpPager->errCode==SQLITE_FULL || pPager->errCode==SQLITE_OK || (pPager->errCode & 0xff)==SQLITE_IOERRpager_unlockpPager->eState==PAGER_READER || pPager->eState==PAGER_OPEN || pPager->eState==PAGER_ERROR!isOpen(pPager->jfd)(PAGER_JOURNALMODE_MEMORY & 5)!=1(PAGER_JOURNALMODE_OFF & 5)!=1(PAGER_JOURNALMODE_WAL & 5)!=1(PAGER_JOURNALMODE_DELETE & 5)!=1pPager->errCode || pPager->eState!=PAGER_ERRORNO_LOCKUNKNOWN_LOCKpPager->errCode==SQLITE_OK || !MEMDBaddToSavepointBitvecsreleaseAllSavepointssqlite3PagerDataVersionpager_resetwriteSuperJournalnSuperjrnlSizepPager->setSuper==0pPager->journalHdr <= pPager->journalOffreadJournalHdrsizeof(aMagic)iSectorSizewriteJournalHdrisOpen(pPager->fd) || pPager->noSyncsizeof(pPager->cksumInit)&zHeader[sizeof(aJournalMagic)+4]pPager->cksumInit&zHeader[sizeof(aJournalMagic)+8]pPager->dbOrigSize&zHeader[sizeof(aJournalMagic)+12]pPager->sectorSize&zHeader[sizeof(aJournalMagic)+16]pPager->pageSizesizeof(aJournalMagic)+20(sizeof(aJournalMagic)+20)("JHDR %p %lld %d\n", pPager, pPager->journalHdr, nHeader)zeroJournalHdr!sqlite3JournalIsInMemory(pPager->jfd)("JZEROHDR %p\n", pPager)const char[28]zeroHdrsizeof(zeroHdr)journalHdrOffsetoffset%JOURNAL_HDR_SZ(pPager)==0offset>=c(offset-c)<JOURNAL_HDR_SZ(pPager)readSuperJournaljrnlBufferSizepagerLockDbeLock==SHARED_LOCK || eLock==RESERVED_LOCK || eLock==EXCLUSIVE_LOCK("LOCK %p %d\n", pPager, eLock)pagerUnlockDb!pPager->exclusiveMode || pPager->eLock==eLockeLock==NO_LOCK || eLock==SHARED_LOCKeLock!=NO_LOCK || pagerUseWal(pPager)==0pPager->eLock>=eLock("UNLOCK %p %d\n", pPager, eLock)write32bitsacread32bitssizeof(ac)subjRequiresPagesetGetterMethodsqlite3PagerDirectReadOkpPager->fd!=0pPager->fd->pMethods->xDeviceCharacteristics!=0sqlite3RowSetTestRowSetEntry *pRowSet!=0 && (pRowSet->rsFlags & ROWSET_NEXT)==0RowSetEntry **ppPrevTreeROWSET_SORTEDsqlite3RowSetNextp->pForest==0ROWSET_NEXTrowSetListToTreerowSetNDeepTreerowSetTreeToListpIn!=0(*ppLast)->pRight==0rowSetEntrySortRowSetEntry *[40]aBucketsizeof(aBucket)sizeof(aBucket[0])sizeof(aBucket)/sizeof(aBucket[0])rowSetEntryMergepA!=0 && pB!=0pA->pRight==0 || pA->v<=pA->pRight->vpB->pRight==0 || pB->v<=pB->pRight->vsqlite3RowSetInsertp!=0 && (p->rsFlags & ROWSET_NEXT)==0~ROWSET_SORTEDrowSetEntryAllocRowSetChunk *RowSetEntry[42]ROWSET_ENTRY_PER_CHUNKsqlite3RowSetDeletesqlite3RowSetClearpNextChunksqlite3RowSetInitROUND8(sizeof(*p))sizeof(struct RowSetEntry)sqlite3Pcache1Mutexstruct PCacheGlobalpcache1_gsqlite3HeaderSizePcache1sizeof(PgHdr1)ROUND8(sizeof(PgHdr1))sqlite3PCacheSetDefaultconst sqlite3_pcache_methods2defaultMethodsconst sqlite3_pcache_methods2 *pcache1DestroyPCache1 *PGroup *pGrouppCache->bPurgeable || (pCache->nMax==0 && pCache->nMin==0)(pGroup)->mutex==0pGroup->nMaxPage >= pCache->nMaxpGroup->nMinPage >= pCache->nMinPgHdr1 *PgHdr1 **pcache1TruncatepCache->pGroup(pCache->pGroup)->mutex==0pcache1RekeyhOldhNewpPage->iKey==iOldpPage->pCache==pCacheiOld!=iNewpcache1FetchNoMutex(p, iOld, 0)==pPagepcache1FetchNoMutex(p, iNew, 0)==0pcache1UnpinpPage->pLruNext==0PAGE_IS_PINNED(pPage)ppFirstpcache1Fetchoffsetof(PgHdr1,page)==0pCache->bPurgeable || createFlag!=1pCache->bPurgeable || pCache->nMin==0pCache->bPurgeable==0 || pCache->nMin==10pCache->nMin==0 || pCache->bPurgeablepCache->nHash>0pcache1FetchNoMutexpcache1FetchStage2nPinnedpCache->nPage >= pCache->nRecyclablepGroup->mxPinned == pGroup->nMaxPage + 10 - pGroup->nMinPagepCache->n90pct == pCache->nMax*9/10pCache->nHash>0 && pCache->apHashPAGE_IS_UNPINNED(pPage)pcache1Pagecountpcache1ShrinksavedMaxPagepcache1CachesizenMax>=00x7fff0000pcache1Create(szPage & (szPage-1))==0 && szPage>=512 && szPage<=65536szExtra < 300sizeof(PCache1)sizeof(PGroup)pcache1Shutdownpcache1.isInit!=0PCacheGlobal *sizeof(pcache1)pcache1Initpcache1.isInit==0pcache1TruncateUnsafeiStopsqlite3_mutex_held(pCache->pGroup->mutex)pCache->iMaxKey >= iLimitpCache->nHash > 0nPage = -10;h<pCache->nHashif( nPage>=0 ) nPage++;nPage<0 || pCache->nPage==(unsigned)nPageint nPage = 0;pcache1EnforceMaxPagesqlite3_mutex_held(pGroup->mutex)p->pCache->pGroup==pGroupPAGE_IS_UNPINNED(p)pcache1RemoveFromHashpcache1PinPagepPage->pLruNextpPage->pLruPrevsqlite3_mutex_held(pPage->pCache->pGroup->mutex)pPage->isAnchor==0pPage->pCache->pGroup->lru.isAnchor==1pcache1ResizeHashsqlite3_mutex_held(p->pGroup->mutex)p->pGroup(p->pGroup)->mutex==0sizeof(PgHdr1 *)pcache1UnderMemoryPressuresqlite3PageFreesqlite3PageMallocsz<=65536+8pcache1FreePagesqlite3_mutex_held(p->pCache->pGroup->mutex)pcache1AllocPagepCache->pFree!=0EIGHT_BYTE_ALIGNMENT( p->page.pExtra )pcache1Freepcache1.pStart(pcache1_g).pStartpcache1.pEnd(pcache1_g).pEndpcache1.nFreeSlot<=pcache1.nSlotsqlite3MemdebugHasType(p, MEMTYPE_PCACHE)MEMTYPE_HEAPPgFreeslot *nFreedpcache1Allocsqlite3_mutex_notheld(pcache1.grp.mutex)pcache1.nFreeSlot>=0MEMTYPE_PCACHEpcache1InitBulkszBulkzBulksizeof(*pX)EIGHT_BYTE_ALIGNMENT( pX->page.pExtra )nBulkROUND8(sizeof(*pX))sqlite3PCacheBufferSetupsqlite3PCacheIsDirtysqlite3PCachePercentDirtypDirtynDirtynCachesqlite3HeaderSizePcacheROUND8(sizeof(PgHdr))sqlite3PcacheShrinkpCache->pCache!=0sqlite3PcacheSetSpillsizep->pCache!=0sqlite3PcacheSetCachesizesqlite3PcachePagecountsqlite3PcachePageRefcountsqlite3PcacheRefCountsqlite3PcacheDirtyListpcacheSortDirtyListPgHdr *[32]N_SORT_BUCKETi<N_SORT_BUCKET-1i<32-1i==N_SORT_BUCKET-1i==32-1pcacheMergeDirtyListsqlite3PcacheClearsqlite3PcacheClose("%p.CLOSE\n",pCache)sqlite3PcacheTruncate("%p.TRUNCATE %d\n",pCache,pgno)p->pgno>0p->flags&PGHDR_DIRTYsqlite3PcacheMovenewPgno>0sqlite3PcachePageSanity(p)pXPage->nRef==0pXPagePCACHE_DIRTYLIST_FRONT("%p.MOVE %d -> %d\n",pCache,p->pgno,newPgno)sqlite3PcacheClearSyncFlagssqlite3PcacheClearWritable(PGHDR_NEED_SYNC|PGHDR_WRITEABLE)~(PGHDR_NEED_SYNC|PGHDR_WRITEABLE)("%p.CLEAR-WRITEABLE\n",pCache)sqlite3PcacheCleanAll("%p.CLEAN-ALL\n",pCache)sqlite3PcacheMakeClean(p->flags & PGHDR_DIRTY)!=0(p->flags & PGHDR_CLEAN)==0PCACHE_DIRTYLIST_REMOVE(PGHDR_DIRTY|PGHDR_NEED_SYNC|PGHDR_WRITEABLE)~(PGHDR_DIRTY|PGHDR_NEED_SYNC|PGHDR_WRITEABLE)PGHDR_CLEAN("%p.CLEAN %d\n",p->pCache,p->pgno)sqlite3PcacheMakeDirty("%p.DIRTY %d\n",p->pCache,p->pgno)(p->flags & (PGHDR_DIRTY|PGHDR_CLEAN))==PGHDR_DIRTY(PGHDR_CLEAN|PGHDR_DONT_WRITE)~PGHDR_DONT_WRITE(PGHDR_DIRTY|PGHDR_CLEAN)PCACHE_DIRTYLIST_ADDsqlite3PcacheDropsqlite3PcacheRefsqlite3PcacheReleasesqlite3PcacheFetchFinishsqlite3PcachePageSanity(pPgHdr)pcacheFetchFinishWithInitpPgHdr->pPage==0PgHdroffsetof(PgHdr,pDirty)sizeof(PgHdr) - offsetof(PgHdr,pDirty)EIGHT_BYTE_ALIGNMENT( pPgHdr->pExtra )sqlite3PcacheFetchStress("%p.SPILL %d\n",pCache,pPg->pgno)sqlite3PcacheFetcheCreatepCache!=0createFlag==3 || createFlag==0pCache->eCreate==((pCache->bPurgeable && pCache->pDirty) ? 1 : 2)eCreate==0 || eCreate==1 || eCreate==2createFlag==0 || pCache->eCreate==eCreatecreateFlag==0 || eCreate==1+(!pCache->bPurgeable||!pCache->pDirty)("%p.FETCH %d%s (result: %p) ",pCache,pgno, createFlag?" create":"",pRes)sqlite3PcacheSetPageSizepCache->nRefSum==0 && pCache->pDirty==0("%p.PAGESIZE %d\n",pCache,szPage)sqlite3PcacheOpensizeof(PCache)szExtra>=8("%p.OPEN szPage %d bPurgeable %d\n",p,szPage,bPurgeable)sqlite3PcacheSizesqlite3PcacheShutdownsqlite3PcacheInitializesqlite3GlobalConfig.pcache2.xInit!=0numberOfCachePagespcacheUnpin("%p.UNPIN %d\n", p->pCache, p->pgno)p->pCachepcacheManageDirtyListpPage->pDirtyNext || pPage==p->pDirtyTailpPage->pDirtyPrev || pPage==p->pDirtypPage==p->pDirtyTailpPage==p->pDirtyp->bPurgeable || p->eCreate==2p->bPurgeable==0 || p->eCreate==1pPage->pDirtyNext->pDirtyPrev==0p->eCreate==2("%p.DIRTYLIST.%s %d\n", p, addRemove==1 ? "REMOVE" : addRemove==2 ? "ADD" : "FRONT", pPage->pgno)sqlite3BitvecBuiltinTestpBitvecnxpTmpSpaceBITVEC_SZ(i+1)iStatementwriteOnlybCleanupzSuperJrnlbCommitisCommitwrflagpSchemaVersionautoVacuumiFixpgFlagsppBtreebReadOnlyflagBytenMaxFragpETypepDifferentRowbiaspExceptisClearTableenablepBusyArgpContentaWalDataxUndopUndoCtxpiReaduseWalpCntlockIdxaContentpiPagepiFramezWalNamebNoShmmxWalSizeppWalpLociPriorHashpnTruncatepbOpennullIfMemDbnSavepointeStatpnValnoSyncexFlagsubjInMemorypExistsppPagerxReinitnewHdrlocktypepPageSizexBusyHandlerpBusyHandlerArgisHotpOffsetisMainJrnlhasSuperjournalSizepNRecpDbSizedoTruncatepJrnlpRowSetiBatchppLastreuseUnlikelybPurgeablefreeFlagbenignMallocxStresspStressaddRemovesizeof(i)bitvec_endsqlite3BitvecSizesqlite3BitvecDestroyBITVEC_NPTRBitvec *[62]Bitvec **sqlite3BitvecClearbinaiValues[j]-13968BITVEC_NBITu8[496]unsigned char[496]BITVEC_NELEMBITVEC_SZELEM(BITVEC_SZELEM-1)aiValuesu32[124]unsigned int[124]BITVEC_NINTsizeof(p->u.aHash)sqlite3BitvecSeti<=p->iSizei++(BITVEC_NINT-1)bitvec_set_rehashBITVEC_MXHASHsizeof(p->u.apSub)bitvec_set_endsqlite3BitvecTestsqlite3BitvecTestNotNullsqlite3BitvecCreatesizeof(*p)==BITVEC_SZsqlite3MemdbInitpLower==0sizeof(MemFile)sqlite3IsMemdbMemFile *ATTACH x AS %Q"ATTACH x AS %Q"MemStore *pStoreend_deserializepStore->pMutex==0PRAGMA "%w".page_count"PRAGMA \"%w\".page_count"BEGIN IMMEDIATE; COMMIT;"BEGIN IMMEDIATE; COMMIT;"memdbFromDbSchemaMemFile **memdbCurrentTimeInt64memdbGetLastErrormemdbSleepmemdbRandomnessmemdbDlClosememdbDlSymmemdbDlErrormemdbDlOpenmemdbFullPathnamememdbAccessmemdbOpenszNamesizeof(*pFile)pVfsMutexMemStore **sizeof(apNew[0])memdbUnfetchmemdbFetchmemdbDeviceCharacteristics5633memdbFileControl SQLITE_NOTFOUNDmemdb(%p,%lld)"memdb(%p,%lld)"memdbUnlockeLock==SQLITE_LOCK_SHARED || eLock==SQLITE_LOCK_NONEpThis->eLock>SQLITE_LOCK_SHAREDpThis->eLock>1memdbLockp->nWrLock==0 || p->nWrLock==1pThis->eLock<=SQLITE_LOCK_SHARED || p->nWrLock==1pThis->eLock==SQLITE_LOCK_NONE || p->nRdLock>=1pThis->eLock==SQLITE_LOCK_NONEpThis->eLock>=SQLITE_LOCK_SHAREDpThis->eLock==SQLITE_LOCK_SHAREDpThis->eLock==1eLock==SQLITE_LOCK_EXCLUSIVEmemdbFileSizememdbSyncmemdbTruncatememdbWritep->mFlags & SQLITE_DESERIALIZE_READONLYp->mFlags & 4memdbEnlargep->nMmap>0memdbReadmemdbClosei<memdb_g.nMemStorememdbLeavememdbEnter"unix"posixIoFinder"unix-none"nolockIoFinder"unix-dotfile"dotlockIoFinder"unix-excl"sqlite3_vfs[]aVfsArraySize(aSyscall)==29sqlite3_vfs[4]672sizeof(aVfs)sizeof(sqlite3_vfs)sizeof(aVfs)/sizeof(sqlite3_vfs)(sizeof(aVfs)/sizeof(sqlite3_vfs))SQLITE_SHM_NLOCK==8UNIX_SHM_BASE==120UNIX_SHM_DMS==128unixunixFile *unix-noneunix-dotfileunix-exclunixGetLastErrorNotUsed3unixCurrentTimeunixCurrentTimeInt64unixEpochsNow2108667600000008640000(sqlite3_int64)864000024405875*(sqlite3_int64)8640000unixSleepspunixRandomness(size_t)nBuf>=(sizeof(time_t)+sizeof(int))got/dev/urandom"/dev/urandom"sizeof(t)+sizeof(randomnessPid)<=(size_t)nBufpid_t *sizeof(randomnessPid)sizeof(t) + sizeof(randomnessPid)unix_syscall[29]unix_syscall *45418unixDlCloseunixDlSymunixDlErrorunixDlOpenRTLD_NOWRTLD_GLOBALunixFullPathnamepathSQLITE_CANTOPEN_BKPTsqlite3CantopenError(45311)char[4098]zPwdsizeof(zPwd)sizeof(zPwd)-245311DbPath *45317appendAllPathElementsappendOnePathElementnName>0pPath->zOut[0]=='/'sqlite3CantopenError(45242)"lstat"buf.st_mode(buf.st_mode)sqlite3CantopenError(45253)45242zLnkSQLITE_MAX_SYMLINK45248sizeof(zLnk)sizeof(zLnk)-2(ssize_t)sizeof(zLnk)(ssize_t)sizeof(zLnk)-245253unixAccesspResOut!=0flags==SQLITE_ACCESS_EXISTS || flags==SQLITE_ACCESS_READWRITEreturn SQLITE_IOERR_ACCESS;unixDelete(10 | (10<<8))"unlink"5888589845136(10 | (5<<8))"fsync"rc==SQLITE_CANTOPEN4514645148return SQLITE_IOERR_DELETEunixOpen10483200x0FFF00noLockctrlFlagsisExclusiveisReadonlyisReadWriteisNewJrnlchar[514]MAX_PATHNAMEzTmpname(isReadonly==0 || isReadWrite==0) && (isReadWrite || isReadonly)isCreate==0 || isReadWriteisExclusive==0 || isCreateisDelete==0 || isCreate(!isDelete && zName) || eType!=SQLITE_OPEN_MAIN_DB(!isDelete && zName) || eType!=SQLITE_OPEN_MAIN_JOURNAL(!isDelete && zName) || eType!=SQLITE_OPEN_SUPER_JOURNAL(!isDelete && zName) || eType!=SQLITE_OPEN_WALeType==SQLITE_OPEN_MAIN_DB || eType==SQLITE_OPEN_TEMP_DB || eType==SQLITE_OPEN_MAIN_JOURNAL || eType==SQLITE_OPEN_TEMP_JOURNAL || eType==SQLITE_OPEN_SUBJOURNAL || eType==SQLITE_OPEN_SUPER_JOURNAL || eType==SQLITE_OPEN_TRANSIENT_DB || eType==SQLITE_OPEN_WALsizeof(unixFile)(flags & SQLITE_OPEN_URI) || zName[strlen(zName)+1]==0isDelete && !isNewJrnlzName[strlen(zName)+1]==0UnixUnusedFd *sizeof(*pUnused)131200(O_EXCL|O_NOFOLLOW)O_BINARY(O_LARGEFILE|O_BINARY|O_NOFOLLOW)!p->pPreallocatedUnusedeType==SQLITE_OPEN_WAL || eType==SQLITE_OPEN_MAIN_JOURNAL("OPENX   %-3d %s 0%o\n", fd, zName, openFlags)!isExclusive || (openFlags & O_CREAT)!=0sqlite3CantopenError(44997)gidmode_t *uid_t *gid_t *1544pReadonly(SQLITE_OPEN_READWRITE|SQLITE_OPEN_CREATE)~(SQLITE_OPEN_READWRITE|SQLITE_OPEN_CREATE)(O_RDWR|O_CREAT)-67~(O_RDWR|O_CREAT)44997(SQLITE_OPEN_WAL|SQLITE_OPEN_MAIN_JOURNAL)fd>=0(SQLITE_OPEN_READONLY|SQLITE_OPEN_READWRITE)UNIXFILE_DELETEUNIXFILE_RDONLYUNIXFILE_NOLOCKUNIXFILE_DIRSYNCUNIXFILE_URIzPath==0 || zPath[0]=='/' || eType==SQLITE_OPEN_SUPER_JOURNAL || eType==SQLITE_OPEN_MAIN_JOURNALopen_finishedfindCreateFileModechar[513]0600modeof"modeof"getFileModefindReusableFdsqlite3_mutex_notheld(pInode->pLockMutex)unixInodeInfo *pInodeUnixUnusedFd **unixGetTempnamenBuf>2%s/etilqs_%llx%c"%s/"SQLITE_TEMP_FILE_PREFIX"%llx%c"return SQLITE_IOERRunixTempFileDir03sizeof(azTempDirs)sizeof(azTempDirs[0])sizeof(azTempDirs)/sizeof(azTempDirs[0])unixTempFileInitSQLITE_TMPDIR"SQLITE_TMPDIR"TMPDIR"TMPDIR"fillInUnixFilepLockingStylepNew->pInode==NULLzFilename!=0 || (ctrlFlags & UNIXFILE_NOLOCK)!=0SQLITE_POWERSAFE_OVERWRITEUNIXFILE_PSOWUNIXFILE_EXCLfinder_type *unixInodeInfo **44464zLockFile%s.lock"%s" DOTLOCK_SUFFIX44549("OPEN    %-3d %s\n", h, zFilename)dotlockIoFinderImpldotlockIoMethodsdotlockClosedotlockLockdotlockUnlockdotlockCheckReservedLocknolockIoFinderImplnolockIoMethodsnolockClosenolockLocknolockUnlocknolockCheckReservedLockposixIoFinderImplposixIoMethodsunixCloseunixLockunixUnlockunixCheckReservedLockunixShmMapunixUnfetch(p==0)==(pFd->nFetchOut==0)p==0 || p==&((u8 *)pFd->pMapRegion)[iOff]pFd->nFetchOut>=0unixFetchnEofBufferunixMapfilenMap>=0 || pFd->nFetchOut==0nMap>0 || (pFd->mmapSize==0 && pFd->pMapRegion==0)statbufunixRemapfilemmap"mmap" PROT_READpFd->nFetchOut==0nNew>pFd->mmapSizenNew<=pFd->mmapSizeMaxpFd->mmapSizeActual>=pFd->mmapSizeMAP_FAILED!=0nReuseMREMAP_MAYMOVEmremap"mremap"MAP_FAILEDMAP_SHAREDpFd->zPath43956unixUnmapfileunixShmUnmapunixShm *unixShmNode *pShmNodeunixShm **pShmNode==pDbFd->pInode->pShmNodepShmNode->pInode==pDbFd->pInodeunixFileMutexNotheld(pDbFd)pShmNode->nRef>0unixShmBarrierfd->pMethods->xLock==nolockLock || unixFileMutexNotheld((unixFile*)fd)unixShmLockaLockpShmNode==0ofst>=0 && ofst+n<=SQLITE_SHM_NLOCKn>=1flags==(SQLITE_SHM_LOCK | SQLITE_SHM_SHARED) || flags==(SQLITE_SHM_LOCK | SQLITE_SHM_EXCLUSIVE) || flags==(SQLITE_SHM_UNLOCK | SQLITE_SHM_SHARED) || flags==(SQLITE_SHM_UNLOCK | SQLITE_SHM_EXCLUSIVE)n==1 || (flags & SQLITE_SHM_EXCLUSIVE)!=0pShmNode->hShm>=0 || pDbFd->pInode->bProcessLock==1pShmNode->hShm<0 || pDbFd->pInode->bProcessLock==0flags!=(SQLITE_SHM_EXCLUSIVE|SQLITE_SHM_LOCK) || 0==(p->exclMask & mask)(p->exclMask & p->sharedMask)==0!(flags & SQLITE_SHM_EXCLUSIVE) || (p->exclMask & mask)==mask!(flags & SQLITE_SHM_SHARED) || (p->sharedMask & mask)==maskn==1aLock[ofst]>=1flags==(SQLITE_SHM_LOCK|SQLITE_SHM_EXCLUSIVE)(p->sharedMask & mask)==0(p->exclMask & mask)==0assertLockingArrayOk(pShmNode)(SQLITE_SHM_SHARED|SQLITE_SHM_LOCK)(SQLITE_SHM_EXCLUSIVE|SQLITE_SHM_LOCK)bUnlockUNIX_SHM_BASE("SHM-LOCK shmid-%d, pid-%d got %03x,%03x\n", p->id, osGetpid(0), p->sharedMask, p->exclMask)nShmPerMapnReqRegionszRegion==pShmNode->szRegion || pShmNode->nRegion==0(nByte % pgsz)==0(10 | (19<<8))(10 | (21<<8))pShmNode->zFilename43489nMapPROT_READPROT_WRITE43516shmpage_outunixOpenSharedMemoryzShmnShmFilenamepDbFd->pShm==0pDbFd->zPathsqlite3CantopenError(43345)zBasePathsizeof(*pShmNode)%s-shm"%s-shm"readonly_shm"readonly_shm"13113843345shm_open_errunixLockSharedMemoryUNIX_SHM_DMS(10 | (18<<8))"ftruncate"flock *43208lock.l_type==F_UNLCK || lock.l_type==F_RDLCKunixShmPurgeunixMutexHeld()p->nRef==0p->pInode==pFd->pInode43138unixShmRegionPerMapshmsz32*1024((pgsz-1)&pgsz)==0unixShmSystemLockpShmNode->nRef>=0(ofst==UNIX_SHM_DMS && n==1) || (ofst>=UNIX_SHM_BASE && ofst+n<=(UNIX_SHM_BASE+SQLITE_SHM_NLOCK))pShmNode->nRef>0 || unixMutexHeld()pShmNode->nRef==0 || sqlite3_mutex_held(pShmNode->pShmMutex)sqlite3_mutex_held(pShmNode->pShmMutex)n==1 || lockType!=F_RDLCKn>=1 && n<=SQLITE_SHM_NLOCKofst>=UNIX_SHM_BASE && ofst<=(UNIX_SHM_DMS+SQLITE_SHM_NLOCK)pShmNode->hShm&funixFcntlExternalReadersizeof(f)unixGetpagesize_SC_PAGESIZEunixDeviceCharacteristicsunixSectorSizesetDeviceCharacteristicspFd->deviceCharacteristics==0 || pFd->sectorSize!=0SQLITE_DEFAULT_SECTOR_SIZEunixFileControlUNIXFILE_PERSIST_WALzTFilesizeof(size_t)sizeof(size_t)<8unixModeBitfcntlSizeHintiWrite>=buf.st_size((iWrite+1)%nBlk)==0(10 | (6<<8))pFile->zPath42534unixFileSizerc=1unixTruncate42413return SQLITE_IOERR_TRUNCATEunixSyncisDataOnlyisFullsync(flags&0x0F)==SQLITE_SYNC_NORMAL || (flags&0x0F)==SQLITE_SYNC_FULL(10 | (4<<8))"full_fsync"full_fsync42368("DIRSYNC %s (have_fullfsync=%d fullsync=%d)\n", pFile->zPath, HAVE_FULLFSYNC, isFullsync)42382~UNIXFILE_DIRSYNCreturn SQLITE_FULL("SYNC    %-3d\n", pFile->h)openDirectoryzDirname("OPENDIR %-3d %s\n", fd, zDirname)sqlite3CantopenError(42327)"openDirectory"42327fullSyncOS_VXWORKSunixWritewroteamt>0( wrote=(-1), amt=1 )( wrote=0, amt=1 )seekAndWriteseekAndWriteFdnBuf==(nBuf&0x1ffff)fd>2piErrno!=01310710x1ffff("WRITE   %-3d %5d %7lld %llu\n", fd, rc, iOff, TIMER_ELAPSED)unixReadoffset>=0seekAndReadcnt==(cnt&0x1ffff)id->h>2got = -1("READ    %-3d %5d %7lld %llu\n", id->h, got+prior, offset-prior, TIMER_ELAPSED)id!=0eFileLock<=SHARED_LOCKeFileLock==NO_LOCKtErrno("UNLOCK  %d %d was %d pid=%d (dotlock)\n", pFile->h, eFileLock, pFile->eFileLock, osGetpid(0))return SQLITE_IOERR_CHECKRESERVEDLOCK;("TEST WR-LOCK %d %d %d (dotlock)\n", pFile->h, 0, *pResOut)pInode!=0unixFileMutexNotheld(pFile)pFile->pInode->nLock>0 || pFile->pInode->bProcessLock==0pFile->pShm==0closeUnixFile40746("CLOSE   %-3d\n", pFile->h)eFileLock==SHARED_LOCK || ((unixFile *)id)->nFetchOut==0posixUnlockpInode->nShared!=0pInode->eFileLock==pFile->eFileLockhandleNFSUnlock==0PENDING_BYTE+1==RESERVED_BYTE510SHARED_SIZE2LpInode->nLock>=0end_unlock("UNLOCK  %d %d was %d(%d,%d) pid=%d (unix)\n", pFile->h, eFileLock, pFile->eFileLock, pFile->pInode->eFileLock, pFile->pInode->nShared, osGetpid(0))setPendingFdunixFileMutexHeld(pFile)("LOCK    %d %s ok (already held) (unix)\n", pFile->h, azFileLock(eFileLock))pFile->eFileLock!=NO_LOCK || eFileLock==SHARED_LOCKeFileLock!=PENDING_LOCKeFileLock!=RESERVED_LOCK || pFile->eFileLock==SHARED_LOCKPENDING_LOCKeFileLock==SHARED_LOCKpFile->eFileLock==0pInode->nShared>0pInode->nShared==0pInode->eFileLock==00!=pFile->eFileLockeFileLock==RESERVED_LOCK || eFileLock==EXCLUSIVE_LOCKend_lock("LOCK    %d %s was %s(%s,%d) pid=%d (unix)\n", pFile->h, azFileLock(eFileLock), azFileLock(pFile->eFileLock), azFileLock(pFile->pInode->eFileLock), pFile->pInode->nShared, osGetpid(0))("LOCK    %d %s %s (unix)\n", pFile->h, azFileLock(eFileLock), rc==SQLITE_OK ? "ok" : "failed")unixFileLocksqlite3_mutex_held(pInode->pLockMutex)pFile->h&lock(UNIXFILE_EXCL|UNIXFILE_RDONLY)pFile->eFileLock<=SHARED_LOCK("TEST WR-LOCK %d %d %d (unix)\n", pFile->h, rc, reserved)verifyDbFilecannot fstat db file %s"cannot fstat db file %s"file unlinked while open: %s"file unlinked while open: %s"multiple links to file: %s"multiple links to file: %s"file renamed while open: %s"file renamed while open: %s"fileHasMovedfindInodeInfofileIdunixFileId *sizeof(fileId)sizeof(*pInode)releaseInodeInfopInode->pShmNode==0pInode->pPrev->pNext==pInodeinodeList==pInodepInode->pNext->pPrev==pInodeclosePendingFds39962storeLastErrnorobust_closeunixLogErrorAtLineiErrnoos_unix.c:%d: (%d) %s(%s) - %s"os_unix.c:%d: (%d) %s(%s) - %s"sqliteErrorFromPosixError(sqliteIOErr == SQLITE_IOERR_LOCK) || (sqliteIOErr == SQLITE_IOERR_UNLOCK) || (sqliteIOErr == SQLITE_IOERR_RDLOCK) || (sqliteIOErr == SQLITE_IOERR_CHECKRESERVEDLOCK)robust_ftruncateunixLeaveMutexsqlite3_mutex_held(unixBigLock)unixEnterMutexsqlite3_mutex_notheld(unixBigLock)robust_openSQLITE_DEFAULT_FILE_PERMISSIONSSQLITE_MINIMUM_FILE_DESCRIPTOR(O_EXCL|O_CREAT)attempt to open "%s" as file descriptor %d"attempt to open \"%s\" as file descriptor %d"/dev/null"/dev/null"unixNextSystemCallaSyscallArraySize(aSyscall)unixGetSystemCallsizeof(aSyscall)sizeof(aSyscall[0])sizeof(aSyscall)/sizeof(aSyscall[0])unixSetSystemCallrobustFchownposixOpensqlite3OpcodeName"iplan=r[P3] zplan='P4'""data=r[P3@P2]""Start at P2""if typeof(P1.P3) in P5 goto P2""r[P2]= !r[P1]""if P1.nullRow then r[P3]=NULL, goto P2""key=r[P3@P4]""if( !csr[P1] ) goto P2""intkey=r[P3]""r[P3]=(r[P1] || r[P2])""r[P3]=(r[P1] && r[P2])""r[P3]=rowset(P1)""if r[P3] in rowset(P1) goto P2""if fkctr[P1]==0 goto P2""if r[P1]>0 then r[P1]-=P3, goto P2""if r[P1]==NULL goto P2""if r[P1]!=NULL goto P2""IF r[P3]!=r[P1]""IF r[P3]==r[P1]""IF r[P3]>r[P1]""IF r[P3]<=r[P1]""IF r[P3]<r[P1]""IF r[P3]>=r[P1]""if r[P1]!=0 then r[P1]--, goto P2""if (--r[P1])==0 goto P2""if key(P3@P4) not in filter(P1) goto P2""r[P3]=func(r[P2@NP])""if r[P3]=null halt""r[P2]=P1""r[P2]=P4""r[P2]='P4' (len=P1)""r[P2]=NULL""r[P2..P3]=NULL""r[P1]=NULL""r[P2]=P4 (len=P1)""r[P2]=parameter(P1)""r[P2@P3]=r[P1@P3]""r[P2@P3+1]=r[P1@P3+1]""r[P2]=r[P1]""output=r[P1@P2]""r[P1]=r[P1]+P2""affinity(r[P1])""r[P1@P3] <-> r[P2@P3]""r[P2] = coalesce(r[P1]==TRUE,P3) ^ P4""r[P2] = 0 OR NULL""r[P3] = sqlite_offset(P1)""r[P3]=PX cursor P1 column P2""typecheck(r[P1@P2])""affinity(r[P1@P2])""r[P3]=mkrec(r[P1@P2])""r[P2]=count()""root=P2 iDb=P3""r[P3]=r[P1]&r[P2]""r[P3]=r[P1]|r[P2]""r[P3]=r[P2]<<r[P1]""r[P3]=r[P2]>>r[P1]""r[P3]=r[P1]+r[P2]""r[P3]=r[P2]-r[P1]""r[P3]=r[P1]*r[P2]""r[P3]=r[P2]/r[P1]""r[P3]=r[P2]%r[P1]""r[P3]=r[P2]+r[P1]""r[P2]= ~r[P1]""nColumn=P2""r[P2]='P4'""if( cursor[P1].ctr++ ) pc = P2""P3 columns in r[P2]""Scan-ahead up to P1 rows""set P2<=seekHit<=P3""r[P2]=cursor[P1].ctr++""r[P2]=rowid""intkey=r[P3] data=r[P2]""if key(P1)!=trim(r[P3],P4) goto P2""r[P2]=data""r[P2]=PX rowid of P1""key=r[P2]""key=r[P2@P3]""Move P3 to P1.rowid if needed""r[P2]=root iDb=P1 flags=P3""rowset(P1)=r[P2]""fkctr[P1]+=P2""r[P1]=max(r[P1],r[P2])""if r[P1]>0 then r[P2]=r[P1]+max(0,r[P3]) else r[P2]=(-1)""accum=r[P3] inverse(r[P2@P5])""accum=r[P3] step(r[P2@P5])""r[P3]=value N=P2""accum=r[P1] N=P2""iDb=P1 root=P2 write=P3""r[P2]=ValueList(P1,P3)""r[P3]=vcolumn(P2)""r[P1].subtype = 0""r[P2] = r[P1].subtype""r[P2].subtype = r[P1]""filter(P1) += key(P3@P4)""release r[P1@P2] mask P3"const char *const[190]char *[190]Savepoint "Savepoint"        OpHelp(""AutoCommit "AutoCommit"       OpHelp(""Transaction "Transaction"      OpHelp(""Checkpoint "Checkpoint"       OpHelp(""JournalMode "JournalMode"      OpHelp(""Vacuum "Vacuum"           OpHelp(""VFilter iplan=r[P3] zplan='P4'"VFilter"          OpHelp("iplan=r[P3] zplan='P4'"VUpdate data=r[P3@P2]"VUpdate"          OpHelp("data=r[P3@P2]"Init Start at P2"Init"             OpHelp("Start at P2"Goto "Goto"             OpHelp(""Gosub "Gosub"            OpHelp(""InitCoroutine "InitCoroutine"    OpHelp(""Yield "Yield"            OpHelp(""MustBeInt "MustBeInt"        OpHelp(""Jump "Jump"             OpHelp(""Once "Once"             OpHelp(""If "If"               OpHelp(""IfNot "IfNot"            OpHelp(""IsType if typeof(P1.P3) in P5 goto P2"IsType"           OpHelp("if typeof(P1.P3) in P5 goto P2"Not r[P2]= !r[P1]"Not"              OpHelp("r[P2]= !r[P1]"IfNullRow if P1.nullRow then r[P3]=NULL, goto P2"IfNullRow"        OpHelp("if P1.nullRow then r[P3]=NULL, goto P2"SeekLT key=r[P3@P4]"SeekLT"           OpHelp("key=r[P3@P4]"SeekLE key=r[P3@P4]"SeekLE"           OpHelp("key=r[P3@P4]"SeekGE key=r[P3@P4]"SeekGE"           OpHelp("key=r[P3@P4]"SeekGT key=r[P3@P4]"SeekGT"           OpHelp("key=r[P3@P4]"IfNotOpen if( !csr[P1] ) goto P2"IfNotOpen"        OpHelp("if( !csr[P1] ) goto P2"IfNoHope key=r[P3@P4]"IfNoHope"         OpHelp("key=r[P3@P4]"NoConflict key=r[P3@P4]"NoConflict"       OpHelp("key=r[P3@P4]"NotFound key=r[P3@P4]"NotFound"         OpHelp("key=r[P3@P4]"Found key=r[P3@P4]"Found"            OpHelp("key=r[P3@P4]"SeekRowid intkey=r[P3]"SeekRowid"        OpHelp("intkey=r[P3]"NotExists intkey=r[P3]"NotExists"        OpHelp("intkey=r[P3]"Last "Last"             OpHelp(""IfSizeBetween "IfSizeBetween"    OpHelp(""SorterSort "SorterSort"       OpHelp(""Sort "Sort"             OpHelp(""Rewind "Rewind"           OpHelp(""SorterNext "SorterNext"       OpHelp(""Prev "Prev"             OpHelp(""Next "Next"             OpHelp(""IdxLE key=r[P3@P4]"IdxLE"            OpHelp("key=r[P3@P4]"IdxGT key=r[P3@P4]"IdxGT"            OpHelp("key=r[P3@P4]"IdxLT key=r[P3@P4]"IdxLT"            OpHelp("key=r[P3@P4]"Or r[P3]=(r[P1] || r[P2])"Or"               OpHelp("r[P3]=(r[P1] || r[P2])"And r[P3]=(r[P1] && r[P2])"And"              OpHelp("r[P3]=(r[P1] && r[P2])"IdxGE key=r[P3@P4]"IdxGE"            OpHelp("key=r[P3@P4]"RowSetRead r[P3]=rowset(P1)"RowSetRead"       OpHelp("r[P3]=rowset(P1)"RowSetTest if r[P3] in rowset(P1) goto P2"RowSetTest"       OpHelp("if r[P3] in rowset(P1) goto P2"Program "Program"          OpHelp(""FkIfZero if fkctr[P1]==0 goto P2"FkIfZero"         OpHelp("if fkctr[P1]==0 goto P2"IfPos if r[P1]>0 then r[P1]-=P3, goto P2"IfPos"            OpHelp("if r[P1]>0 then r[P1]-=P3, goto P2"IsNull if r[P1]==NULL goto P2"IsNull"           OpHelp("if r[P1]==NULL goto P2"NotNull if r[P1]!=NULL goto P2"NotNull"          OpHelp("if r[P1]!=NULL goto P2"Ne IF r[P3]!=r[P1]"Ne"               OpHelp("IF r[P3]!=r[P1]"Eq IF r[P3]==r[P1]"Eq"               OpHelp("IF r[P3]==r[P1]"Gt IF r[P3]>r[P1]"Gt"               OpHelp("IF r[P3]>r[P1]"Le IF r[P3]<=r[P1]"Le"               OpHelp("IF r[P3]<=r[P1]"Lt IF r[P3]<r[P1]"Lt"               OpHelp("IF r[P3]<r[P1]"Ge IF r[P3]>=r[P1]"Ge"               OpHelp("IF r[P3]>=r[P1]"ElseEq "ElseEq"           OpHelp(""IfNotZero if r[P1]!=0 then r[P1]--, goto P2"IfNotZero"        OpHelp("if r[P1]!=0 then r[P1]--, goto P2"DecrJumpZero if (--r[P1])==0 goto P2"DecrJumpZero"     OpHelp("if (--r[P1])==0 goto P2"IncrVacuum "IncrVacuum"       OpHelp(""VNext "VNext"            OpHelp(""Filter if key(P3@P4) not in filter(P1) goto P2"Filter"           OpHelp("if key(P3@P4) not in filter(P1) goto P2"PureFunc r[P3]=func(r[P2@NP])"PureFunc"         OpHelp("r[P3]=func(r[P2@NP])"Function r[P3]=func(r[P2@NP])"Function"         OpHelp("r[P3]=func(r[P2@NP])"Return "Return"           OpHelp(""EndCoroutine "EndCoroutine"     OpHelp(""HaltIfNull if r[P3]=null halt"HaltIfNull"       OpHelp("if r[P3]=null halt"Halt "Halt"             OpHelp(""Integer r[P2]=P1"Integer"          OpHelp("r[P2]=P1"Int64 r[P2]=P4"Int64"            OpHelp("r[P2]=P4"String r[P2]='P4' (len=P1)"String"           OpHelp("r[P2]='P4' (len=P1)"BeginSubrtn r[P2]=NULL"BeginSubrtn"      OpHelp("r[P2]=NULL"Null r[P2..P3]=NULL"Null"             OpHelp("r[P2..P3]=NULL"SoftNull r[P1]=NULL"SoftNull"         OpHelp("r[P1]=NULL"Blob r[P2]=P4 (len=P1)"Blob"             OpHelp("r[P2]=P4 (len=P1)"Variable r[P2]=parameter(P1)"Variable"         OpHelp("r[P2]=parameter(P1)"Move r[P2@P3]=r[P1@P3]"Move"             OpHelp("r[P2@P3]=r[P1@P3]"Copy r[P2@P3+1]=r[P1@P3+1]"Copy"             OpHelp("r[P2@P3+1]=r[P1@P3+1]"SCopy r[P2]=r[P1]"SCopy"            OpHelp("r[P2]=r[P1]"IntCopy r[P2]=r[P1]"IntCopy"          OpHelp("r[P2]=r[P1]"FkCheck "FkCheck"          OpHelp(""ResultRow output=r[P1@P2]"ResultRow"        OpHelp("output=r[P1@P2]"CollSeq "CollSeq"          OpHelp(""AddImm r[P1]=r[P1]+P2"AddImm"           OpHelp("r[P1]=r[P1]+P2"RealAffinity "RealAffinity"     OpHelp(""Cast affinity(r[P1])"Cast"             OpHelp("affinity(r[P1])"Permutation "Permutation"      OpHelp(""Compare r[P1@P3] <-> r[P2@P3]"Compare"          OpHelp("r[P1@P3] <-> r[P2@P3]"IsTrue r[P2] = coalesce(r[P1]==TRUE,P3) ^ P4"IsTrue"           OpHelp("r[P2] = coalesce(r[P1]==TRUE,P3) ^ P4"ZeroOrNull r[P2] = 0 OR NULL"ZeroOrNull"       OpHelp("r[P2] = 0 OR NULL"Offset r[P3] = sqlite_offset(P1)"Offset"           OpHelp("r[P3] = sqlite_offset(P1)"Column r[P3]=PX cursor P1 column P2"Column"           OpHelp("r[P3]=PX cursor P1 column P2"TypeCheck typecheck(r[P1@P2])"TypeCheck"        OpHelp("typecheck(r[P1@P2])"Affinity affinity(r[P1@P2])"Affinity"         OpHelp("affinity(r[P1@P2])"MakeRecord r[P3]=mkrec(r[P1@P2])"MakeRecord"       OpHelp("r[P3]=mkrec(r[P1@P2])"Count r[P2]=count()"Count"            OpHelp("r[P2]=count()"ReadCookie "ReadCookie"       OpHelp(""SetCookie "SetCookie"        OpHelp(""ReopenIdx root=P2 iDb=P3"ReopenIdx"        OpHelp("root=P2 iDb=P3"OpenRead root=P2 iDb=P3"OpenRead"         OpHelp("root=P2 iDb=P3"BitAnd r[P3]=r[P1]&r[P2]"BitAnd"           OpHelp("r[P3]=r[P1]&r[P2]"BitOr r[P3]=r[P1]|r[P2]"BitOr"            OpHelp("r[P3]=r[P1]|r[P2]"ShiftLeft r[P3]=r[P2]<<r[P1]"ShiftLeft"        OpHelp("r[P3]=r[P2]<<r[P1]"ShiftRight r[P3]=r[P2]>>r[P1]"ShiftRight"       OpHelp("r[P3]=r[P2]>>r[P1]"Add r[P3]=r[P1]+r[P2]"Add"              OpHelp("r[P3]=r[P1]+r[P2]"Subtract r[P3]=r[P2]-r[P1]"Subtract"         OpHelp("r[P3]=r[P2]-r[P1]"Multiply r[P3]=r[P1]*r[P2]"Multiply"         OpHelp("r[P3]=r[P1]*r[P2]"Divide r[P3]=r[P2]/r[P1]"Divide"           OpHelp("r[P3]=r[P2]/r[P1]"Remainder r[P3]=r[P2]%r[P1]"Remainder"        OpHelp("r[P3]=r[P2]%r[P1]"Concat r[P3]=r[P2]+r[P1]"Concat"           OpHelp("r[P3]=r[P2]+r[P1]"OpenWrite root=P2 iDb=P3"OpenWrite"        OpHelp("root=P2 iDb=P3"OpenDup "OpenDup"          OpHelp(""BitNot r[P2]= ~r[P1]"BitNot"           OpHelp("r[P2]= ~r[P1]"OpenAutoindex nColumn=P2"OpenAutoindex"    OpHelp("nColumn=P2"OpenEphemeral nColumn=P2"OpenEphemeral"    OpHelp("nColumn=P2"String8 r[P2]='P4'"String8"          OpHelp("r[P2]='P4'"SorterOpen "SorterOpen"       OpHelp(""SequenceTest if( cursor[P1].ctr++ ) pc = P2"SequenceTest"     OpHelp("if( cursor[P1].ctr++ ) pc = P2"OpenPseudo P3 columns in r[P2]"OpenPseudo"       OpHelp("P3 columns in r[P2]"Close "Close"            OpHelp(""ColumnsUsed "ColumnsUsed"      OpHelp(""SeekScan Scan-ahead up to P1 rows"SeekScan"         OpHelp("Scan-ahead up to P1 rows"SeekHit set P2<=seekHit<=P3"SeekHit"          OpHelp("set P2<=seekHit<=P3"Sequence r[P2]=cursor[P1].ctr++"Sequence"         OpHelp("r[P2]=cursor[P1].ctr++"NewRowid r[P2]=rowid"NewRowid"         OpHelp("r[P2]=rowid"Insert intkey=r[P3] data=r[P2]"Insert"           OpHelp("intkey=r[P3] data=r[P2]"RowCell "RowCell"          OpHelp(""Delete "Delete"           OpHelp(""ResetCount "ResetCount"       OpHelp(""SorterCompare if key(P1)!=trim(r[P3],P4) goto P2"SorterCompare"    OpHelp("if key(P1)!=trim(r[P3],P4) goto P2"SorterData r[P2]=data"SorterData"       OpHelp("r[P2]=data"RowData r[P2]=data"RowData"          OpHelp("r[P2]=data"Rowid r[P2]=PX rowid of P1"Rowid"            OpHelp("r[P2]=PX rowid of P1"NullRow "NullRow"          OpHelp(""SeekEnd "SeekEnd"          OpHelp(""IdxInsert key=r[P2]"IdxInsert"        OpHelp("key=r[P2]"SorterInsert key=r[P2]"SorterInsert"     OpHelp("key=r[P2]"IdxDelete key=r[P2@P3]"IdxDelete"        OpHelp("key=r[P2@P3]"DeferredSeek Move P3 to P1.rowid if needed"DeferredSeek"     OpHelp("Move P3 to P1.rowid if needed"IdxRowid r[P2]=rowid"IdxRowid"         OpHelp("r[P2]=rowid"FinishSeek "FinishSeek"       OpHelp(""Destroy "Destroy"          OpHelp(""Clear "Clear"            OpHelp(""ResetSorter "ResetSorter"      OpHelp(""CreateBtree r[P2]=root iDb=P1 flags=P3"CreateBtree"      OpHelp("r[P2]=root iDb=P1 flags=P3"SqlExec "SqlExec"          OpHelp(""ParseSchema "ParseSchema"      OpHelp(""LoadAnalysis "LoadAnalysis"     OpHelp(""DropTable "DropTable"        OpHelp(""DropIndex "DropIndex"        OpHelp(""DropTrigger "DropTrigger"      OpHelp(""Real r[P2]=P4"Real"             OpHelp("r[P2]=P4"IntegrityCk "IntegrityCk"      OpHelp(""RowSetAdd rowset(P1)=r[P2]"RowSetAdd"        OpHelp("rowset(P1)=r[P2]"Param "Param"            OpHelp(""FkCounter fkctr[P1]+=P2"FkCounter"        OpHelp("fkctr[P1]+=P2"MemMax r[P1]=max(r[P1],r[P2])"MemMax"           OpHelp("r[P1]=max(r[P1],r[P2])"OffsetLimit if r[P1]>0 then r[P2]=r[P1]+max(0,r[P3]) else r[P2]=(-1)"OffsetLimit"      OpHelp("if r[P1]>0 then r[P2]=r[P1]+max(0,r[P3]) else r[P2]=(-1)"AggInverse accum=r[P3] inverse(r[P2@P5])"AggInverse"       OpHelp("accum=r[P3] inverse(r[P2@P5])"AggStep accum=r[P3] step(r[P2@P5])"AggStep"          OpHelp("accum=r[P3] step(r[P2@P5])"AggStep1 accum=r[P3] step(r[P2@P5])"AggStep1"         OpHelp("accum=r[P3] step(r[P2@P5])"AggValue r[P3]=value N=P2"AggValue"         OpHelp("r[P3]=value N=P2"AggFinal accum=r[P1] N=P2"AggFinal"         OpHelp("accum=r[P1] N=P2"Expire "Expire"           OpHelp(""CursorLock "CursorLock"       OpHelp(""CursorUnlock "CursorUnlock"     OpHelp(""TableLock iDb=P1 root=P2 write=P3"TableLock"        OpHelp("iDb=P1 root=P2 write=P3"VBegin "VBegin"           OpHelp(""VCreate "VCreate"          OpHelp(""VDestroy "VDestroy"         OpHelp(""VOpen "VOpen"            OpHelp(""VCheck "VCheck"           OpHelp(""VInitIn r[P2]=ValueList(P1,P3)"VInitIn"          OpHelp("r[P2]=ValueList(P1,P3)"VColumn r[P3]=vcolumn(P2)"VColumn"          OpHelp("r[P3]=vcolumn(P2)"VRename "VRename"          OpHelp(""Pagecount "Pagecount"        OpHelp(""MaxPgcnt "MaxPgcnt"         OpHelp(""ClrSubtype r[P1].subtype = 0"ClrSubtype"       OpHelp("r[P1].subtype = 0"GetSubtype r[P2] = r[P1].subtype"GetSubtype"       OpHelp("r[P2] = r[P1].subtype"SetSubtype r[P2].subtype = r[P1]"SetSubtype"       OpHelp("r[P2].subtype = r[P1]"FilterAdd filter(P1) += key(P3@P4)"FilterAdd"        OpHelp("filter(P1) += key(P3@P4)"Trace "Trace"            OpHelp(""CursorHint "CursorHint"       OpHelp(""ReleaseReg release r[P1@P2] mask P3"ReleaseReg"       OpHelp("release r[P1@P2] mask P3"Noop "Noop"             OpHelp(""Explain "Explain"          OpHelp(""Abortable "Abortable"        OpHelp(""sqlite3HashInsertpKey!=0sizeof(HashElem)_ht *sqlite3HashFindremoveElementpEntry->count>0findElementWithHashnullElementelem!=0rehashsizeof(struct _ht)SQLITE_MALLOC_SOFT_LIMITinsertElementstrHash0xdf26544357610x9e3779b1sqlite3HashClearsqlite3HashInitsqlite3VListNameToNumsqlite3VListNumToNamesqlite3VListAddpIn==0 || pIn[0]>=3pIn[1]<=pIn[0]sqlite3LogEstToInt(u64)LARGEST_INT64sqlite3LogEstFromDoublesizeof(x)==8 && sizeof(a)==820000000002000000000.0sqlite3LogEstLogEst[]__builtin_clzllLogEst[8]signed short[8]sqlite3LogEstAddconst unsigned char[32]sqlite3AbsInt32-2147483648(int)0x80000000sqlite3MulInt64__builtin_mul_overflowsqlite3SubInt64__builtin_sub_overflowsqlite3AddInt64__builtin_add_overflowsqlite3SafetyCheckSickOrOkeOpenStateinvalid"invalid"sqlite3SafetyCheckOkunopened"unopened"logBadConnectionAPI call with %s database connection pointer"API call with %s database connection pointer"sqlite3HexToBlobsqlite3HexToInt(h>='0' && h<='9') || (h>='a' && h<='f') || (h>='A' && h<='F')sqlite3Put4bytesqlite3Get4bytesqlite3VarintLeni<10sqlite3GetVarint32v64(p[0] & 0x80)!=0n>3 && n<=9SQLITE_MAX_U32sqlite3GetVarintSLOT_2_0 == ((0x7f<<14) | (0x7f))SLOT_4_2_0 == ((0xfU<<28) | (0x7f<<14) | (0x7f))2080895SLOT_2_04028612735SLOT_4_2_0sqlite3PutVarintputVarint640xff000000(u64)0xff000000((u64)0xff000000)18374686479671623680((u64)0xff000000)<<32(((u64)0xff000000)<<32)n<=9sqlite3GetUInt324294967296LLsqlite3FpDecodeFpDecode *double[2]rrmxRound>09.223372036854774784e+189.223372036854774163e+1189.223372036854774784e+118volatile double *1.00000000000000002e-1001.0e-1001.999189980260288281e-1171.99918998026028836196e-117-1.999189980260288281e-117-1.99918998026028836196e-1179.223372036854774049e+289.223372036854774784e+281.000000000000000036e-101.0e-103.643219731549774344e-273.6432197315497741579e-27-3.643219731549774344e-27-3.6432197315497741579e-270.10000000000000000561.0e-015.55111512312578301e-185.5511151231257827021e-18-5.55111512312578301e-18-5.5511151231257827021e-189.223372036854774822e-839.223372036854774784e-831.000000000000000016e+1001.0e+1001.590289110975991792e+831.5902891109759918046e+83-1.590289110975991792e+83-1.5902891109759918046e+8392233720.36854775259.223372036854774784e+0710000000000.01.0e+10922337203685477504.09.22337203685477478e+171.0e+01sizeof(p->zBuf)sizeof(p->zBuf)-1i>=0 && i<sizeof(p->zBuf)-1sizeof(p->zBuf) - 1p->n>0p->n<sizeof(p->zBuf)i+p->n < sizeof(p->zBuf)sqlite3Atoisqlite3GetInt32zNum[2]zNum[i]zNum[0]v-neg==2147483647sqlite3DecOrHexToI64+- 
	0123456789"+- \n\t0123456789"sqlite3Atoi64incrnonNumSQLITE_UTF16LE==2 && SQLITE_UTF16BE==3*zNumzNum[jj]u<=LARGEST_INT64u-1==LARGEST_INT64i==18*incri==19*incri==20*incrcompare2pow63pow63922337203685477580"922337203685477580"c==(-1)c==(+1)sqlite3Int64ToText((u64)1)((u64)1)<<63sizeof(zTemp)-2sizeof(zTemp)-1sqlite3AtoFesigneValidenc==SQLITE_UTF16LEenc==SQLITE_UTF16BE18446744073709551606(LARGEST_UINT64-9)1844674407370955160(LARGEST_UINT64-9)/10((LARGEST_UINT64-9)/10)do_atof_calc-0.0+0.018446744073709549568(LARGEST_UINT64-0x7ff)1844674407370954956(LARGEST_UINT64-0x7ff)/10((LARGEST_UINT64-0x7ff)/10)sizeof(s2)==sizeof(rr[0])1.844674407370954957e+1918446744073709549568.0rr[1]<=1.0e-10*rr[0]1.000000000000000053e+3001e3001e300*1e300!sqlite3IsNaN(*pResult)atof_returndekkerMul2txtycchxhy184467440736424427520xfffffffffc000000LLsqlite3StrIHashregistersqlite3StrICmpsqlite3TokenInitsqlite3DequoteTokenp->z[0]p->z[i]sqlite3DequoteNumberp->op==TK_QNUMBERpIn[-1]pIn[1]bHexunrecognized token: "%s""unrecognized token: \"%s\""sqlite3DequoteExprsqlite3Isquote(p->u.zToken[0])EP_Quoted67108992sqlite3Dequotesqlite3ErrorToParsersqlite3ErrorMsgdb->pParse==pParse || db->pParse->pToplevel==pParsesqlite3ProgressChecksqlite3ErrorWithMsgsqlite3SystemErrorsqlite3ErrorClearsqlite3Errorsqlite3ErrorFinishsqlite3ColumnTypepCol->eCType<=SQLITE_N_STDTYPEsqlite3Strlen30sqlite3IsOverflowsizeof(y)sqlite3IsNaN__builtin_isnansqlite3FaultSimsqlite3Utf16ByteLenz<=zEnd0xd80xdc(SQLITE_UTF16NATIVE==SQLITE_UTF16LE)sqlite3Utf16to8sizeof(m)(m.flags & MEM_Term)!=0 || db->mallocFailed(m.flags & MEM_Str)!=0 || db->mallocFailedm.z || db->mallocFailedsqlite3Utf8CharLen(const u8*)(-1)z<=zTermsqlite3VdbeMemHandleBombompMem->n>=0sqlite3VdbeMemTranslatepMem->flags&MEM_StrpMem->enc!=desiredEncpMem->enc!=0desiredEnc==SQLITE_UTF16BEdesiredEnc==SQLITE_UTF8573440xe0000x03FF0x003F9600x03C0(pMem->n+(desiredEnc==SQLITE_UTF8?1:2))<=len2111(MEM_AffMask|MEM_Subtype)translate_outsqlite3Utf8ReadLimitedsqlite3Utf8Read0xFFFFF8000xD8000xFFFDsqlite3ThreadJoinppOut!=0sqlite3ThreadCreateppThread!=0xTask!=0sqlite3GlobalConfig.bCoreMutex!=0pthread_t *pthread_t *__restrict__const pthread_attr_tconst pthread_attr_t *const pthread_attr_t *__restrict__sqlite3PrngRestoreStatestruct sqlite3PrngTypesqlite3Prngsqlite3SavedPrngsqlite3PrngType *sizeof(sqlite3Prng)sqlite3PrngSaveStateu32[16]pVfs==0const u32[4]16347608050x617078658577608780x3320646e20364772340x79622d3217972852360x6b206574const u32[]chacha20_initu8[64]chacha_blockx[0]x[4]x[ 8]x[12]x[1]x[5]x[ 9]x[13]x[2]x[6]x[10]x[14]x[3]x[7]x[11]x[15]sqlite3RCStrResizeRCStr *p->nRCRef==1sizeof(RCStr)sqlite3RCStrNewsqlite3RCStrUnrefp->nRCRef>0sqlite3RCStrRefrenderLogMsgchar[210]SQLITE_PRINT_BUF_SIZEsizeof(zMsg)sizeof(zBase)sqlite3MPrintfsqlite3VMPrintfsqlite3StrAccumInitSQLITE_PRINTF_MALLOCED~SQLITE_PRINTF_MALLOCEDsqlite3ResultStrAccumsqlite3StrAccumFinishstrAccumFinishReallocp->mxAlloc>0 && !isMalloced(p)z!=0 || N==0p->zText!=0 || p->nChar==0 || p->accErrorN>=0p->accError==0 || p->nAlloc==0 || p->mxAlloc==0p->zTextenlargeAndAppendp->nChar + (i64)N > 0x7fffffffsqlite3StrAccumEnlargep->nChar+N >= p->nAllocp->accError==SQLITE_TOOBIGp->accError==SQLITE_NOMEMp->zText!=0 || p->nChar==0N>=0 && N<=0x7fffffffsqlite3RecordErrorOffsetOfExprsqlite3RecordErrorByteOffsetdb==0pParse==0zText==0bufptprecisionflag_leftjustifyflag_prefixflag_alternateformflag_altform2flag_zeropadflag_longcThousandxtypeetINVALIDbArgListlongvaluerealvalueconst et_infoconst et_info *et_info *infope2flag_dpflag_rtzpArgListpAccum->nChar>0 || (pAccum->printfFlags&SQLITE_PRINTF_MALLOCED)==0PrintfArguments*wx>0x7fffffffpx>0x7ffffffffmtinfowidth>=0precision>=(-1)v==SMALLEST_INT64v==(-1)unsigned long intprecision>0bufpt>zOut(pAccum->printfFlags&SQLITE_PRINTF_MALLOCED)==0!ExprHasProperty(pExpr,EP_IntValue)!(((pExpr)->flags&(0x000800))!=0)Token*bArgList==0SrcItem*!pItem->fg.isTabFunc && !pItem->fg.isIndexedByxtype==etINVALID'!'-2147483647const et_info[23]et_info[23]ArraySize(fmtinfo)etPOINTERsizeof(i64)sizeof(char*)==sizeof(i64)sizeof(long int)sizeof(char*)==sizeof(long int)sizeof(char*)==sizeof(long int) ? 1 : 0sizeof(char*)==sizeof(i64) ? 2 :
                     sizeof(char*)==sizeof(long int) ? 1 : 0etORDINALetRADIXetDECIMALFLAG_SIGNEDzOrdthstndrd"thstndrd"const char[9]csetconst char[33]preetFLOATetEXPetGENERICiRoundSQLITE_FP_PRECISION_LIMIT"NaN"-Inf"-Inf"szBufNeedednPadetSIZEetPERCENTetCHARXnPriornCopyBytesetSTRINGetDYNSTRINGadjust_width_for_utf8etSQLESCAPEetSQLESCAPE2etSQLESCAPE3isnullescarg(NULL)"(NULL)"etTOKENetSRCITEM(join-%u)"(join-%u)"%u-ROW VALUES CLAUSE"%u-ROW VALUES CLAUSE"(subquery-%u)"(subquery-%u)"printfTempBufgetTextArggetDoubleArggetIntArgsqlite3StrAccumSetErroreError==SQLITE_NOMEM || eError==SQLITE_TOOBIGsqlite3ApiExitapiHandleErrorsqlite3OomCleardb->lookaside.bDisable>0sqlite3OomFaultsqlite3SetStringsqlite3DbSpanDupzStart[n-1]sqlite3DbStrNDupz!=0 || n==0(n&0x7fffffff)==nsqlite3DbStrDupsqlite3DbReallocOrFreedbReallocFinishsqlite3MemdebugHasType(p, (MEMTYPE_LOOKASIDE|MEMTYPE_HEAP))sqlite3MemdebugNoType(p, (u8)~(MEMTYPE_LOOKASIDE|MEMTYPE_HEAP))(db->lookaside.bDisable==0 ? MEMTYPE_LOOKASIDE : MEMTYPE_HEAP)sqlite3DbReallocsqlite3DbMallocRawNNdb->pnBytesFreed==0sqlite3DbMallocRawdbMallocRawFinish(db->lookaside.bDisable==0) ? MEMTYPE_LOOKASIDE : MEMTYPE_HEAPsqlite3DbMallocZerosqlite3MallocZerosqlite3Reallocsqlite3MemdebugHasType(pOld, MEMTYPE_HEAP)sqlite3MemdebugNoType(pOld, (u8)~MEMTYPE_HEAP)struct Mem0Globalmem0sqlite3DbFreedb==0 || sqlite3_mutex_held(db->mutex)sqlite3DbNNFreeNNsqlite3DbFreeNNdb!=0 || sqlite3MemdebugNoType(p, MEMTYPE_LOOKASIDE)measureAllocationSizesqlite3MemdebugHasType(p, MEMTYPE_HEAP)sqlite3MemdebugNoType(p, (u8)~MEMTYPE_HEAP)sqlite3DbMallocSizelookasideMallocSizesqlite3MallocSizeisLookasidedb->lookaside.pStartdb->lookaside.pTrueEndsqlite3Malloc2147483391SQLITE_MAX_ALLOCATION_SIZEmallocWithAlarmnFullsqlite3_mutex_held(mem0.mutex)&mem0.nearlyFullsqlite3MallocAlarmsqlite3MallocEndMem0Global *sizeof(mem0)sqlite3HeapNearlyFullsqlite3MallocInitpriorLimitexcessn>0 && n<=nUsedsqlite3MallocMutexconst sqlite3_mutex_methodsconst sqlite3_mutex_methods *sqlite3DefaultMutexsMutexpthreadMutexLeavepthreadMutexHeld(p)p->nRef==0 || p->id==SQLITE_MUTEX_RECURSIVEpthread_mutex_t *pthreadMutexTryp->id==SQLITE_MUTEX_RECURSIVE || pthreadMutexNotheld(p)pthreadMutexEnterpthreadMutexFreepthreadMutexAllocPTHREAD_MUTEX_TIMED_NPsqlite3_mutex[]staticMutexesrecursiveAttrpthread_mutexattr_t *PTHREAD_MUTEX_RECURSIVEconst pthread_mutexattr_tconst pthread_mutexattr_t *sqlite3_mutex[12]pthreadMutexEndpthreadMutexInitsqlite3MemoryBarrier__sync_synchronizesqlite3NoopMutexnoopMutexLeavenoopMutexTrynoopMutexEnternoopMutexFreenoopMutexAlloc(sqlite3_mutex*)8noopMutexEndnoopMutexInitsqlite3GlobalConfig.mutex.xMutexLeavesqlite3GlobalConfig.mutex.xMutexTrysqlite3GlobalConfig.mutex.xMutexEntersqlite3GlobalConfig.mutex.xMutexFreesqlite3MutexAllocGLOBAL(int, mutexIsInit)sqlite3GlobalConfig.mutex.xMutexAllocsqlite3MutexEndsqlite3MutexInitsqlite3GlobalConfig.mutex.xMutexInitsqlite3MemSetDefaultconst sqlite3_mem_methodsconst sqlite3_mem_methods *sqlite3MemShutdownsqlite3MemInitsqlite3MemRoundupsqlite3MemReallocfailed memory resize %u to %u bytes"failed memory resize %u to %u bytes"sqlite3MemSizesqlite3MemFreesqlite3MemMallocfailed to allocate %u bytes of memory"failed to allocate %u bytes of memory"ROUND8(nByte)==nBytesqlite3EndBenignMallocsqlite3BeginBenignMallocsqlite3BenignMallocHookssqlite3_mutex *mutex;mutex = sqlite3MutexAlloc(SQLITE_MUTEX_STATIC_MAIN);mutex = sqlite3MutexAlloc(2);vfsListvfsUnlinksqlite3_mutex_held(sqlite3MutexAlloc(SQLITE_MUTEX_STATIC_MAIN))sqlite3OsInitsqlite3OsCloseFreesqlite3OsOpenMalloc*ppFile!=0 || rc!=SQLITE_OKsqlite3OsCurrentTimeInt64sqlite3OsGetLastErrorsqlite3OsSleepsqlite3OsRandomnessnByte>(signed)sizeof(unsigned)sqlite3OsDlClosesqlite3OsDlSymsqlite3OsDlErrorsqlite3OsDlOpenzPath!=0strlen(zPath)<=SQLITE_MAX_PATHLENsqlite3OsFullPathnamesqlite3OsAccesssqlite3OsDeletedirSync==0 || dirSync==1sqlite3OsOpenzPath || (flags & SQLITE_OPEN_EXCLUSIVE)173341430x1087f7frc==SQLITE_OK || pFile->pMethods==0sqlite3OsUnfetchsqlite3OsFetchsqlite3OsShmMapsqlite3OsShmUnmapsqlite3OsShmBarriersqlite3OsShmLocksqlite3OsDeviceCharacteristicsid->pMethods==0sqlite3OsSectorSizesqlite3OsFileControlHintsqlite3OsFileControlsqlite3OsCheckReservedLocksqlite3OsUnlocklockType==SQLITE_LOCK_NONE || lockType==SQLITE_LOCK_SHAREDsqlite3OsLocklockType>=SQLITE_LOCK_SHARED && lockType<=SQLITE_LOCK_EXCLUSIVEsqlite3OsFileSizesqlite3OsSyncsqlite3OsTruncatesqlite3OsWritesqlite3OsReadsqlite3OsClosesqlite3RegisterDateTimeFunctionsjuliandayjuliandayFuncunixepochunixepochFuncdatedateFunctimeFuncdatetimedatetimeFuncstrftimeFunctimedifftimediffFunccurrent_timectimeFunccurrent_timestampctimestampFunccurrent_datecdateFuncaDateTimeFuncsFuncDef[10]720ArraySize(aDateTimeFuncs)8398849Sqlite3Config *sResNotUsed1DateTime *1486995408(u64)1486995408(u64)100000148699540800000(u64)1486995408 * (u64)100000%c%04d-%02d-%02d %02d:%02d:%06.3f"%c%04d-%02d-%02d %02d:%02d:%06.3f"s>59.999y.validJDcf%02d"%02d"%2d"%2d"59.9990000000000023359.999%06.3f"%06.3f"%04d-%02d-%02d"%04d-%02d-%02d"86400000%04d"%04d"'H''k''j'%03d"%03d"'J''M'PM"PM"pm"pm"AM"AM"am"am"'R'%02d:%02d"%02d:%02d"%.3f"%.3f"21086676(i64)1000000021086676*(i64)10000000(i64)1000021086676*(i64)10000%02d:%02d:%02d"%02d:%02d:%02d"'U''Y'daysAfterSundaypDate->validJD129600000daysAfterMonday43200000daysAfterJan01jan01jan01.validYMDjan01.validHMSisDatep->validJDparseModifierz[n]rc==1z[11]*z2aXformTypestrcmp(aXformType[4].zName,"month")==0strcmp(aXformType[5].zName,"year")==0p->M>=0 && p->M<=12"ceiling""floor""julianday""localtime""unixepoch"210866760000000.0464269060800000.0utc"utc"iOrigJDsizeof(new)weekday "weekday "7.0start of "start of "subsec"subsec"subsecond"subsecond"month"month"year"year""day"rRounder40f"40f"50f"50f"40f-20a-20d"40f-20a-20d"50f-20a-20d"50f-20a-20d"20c:20e"20c:20e"sizeof(tx)const struct <unnamed>[6]struct <unnamed>[6]ArraySize(aXformType)autoAdjustDate-21086676-210866760000.0-21086676*(i64)100002534023025340230000025340230*(i64)10000(25340230*(i64)10000)799253402300799.0(25340230*(i64)10000)+799toLocaltimesLocaliYearDiffsizeof(sLocal)2108667600(i64)1000002108667600*(i64)10000021301414562130141456000002130141456*(i64)100000local time unavailable"local time unavailable"1900osLocaltimeclearYMD_HMS_TZcomputeYMD_HMScomputeHMSday_msday_min60000computeYMDalpha32044.75validJulianDay108096464268784828416275971583464269060799999INT_464269060799999parseDateOrTimenow"now"setRawDateNumber5373484.5setDateTimeToCurrentparseYyyyMmDd40f-21a-21d"40f-21a-21d"*zDatecomputeFloorp->validYMD || p->isErrorp->D>=0 && p->D<=3155460x15aacomputeJD4713-4713999948003600000datetimeErrorparseHhMmSszDate[1]20e"20e"rScale 1.048.00.99899999999999999910.999parseTimezonesgnnHrnMn20b:20e"20b:20e"zulu_timegetDigitsaMxnextCzFormat[2]>='a' && zFormat[2]<='f'const u16[6]unsigned short[6]end_getDigits14712op==SQLITE_DBSTATUS_LOOKASIDE_HITop==SQLITE_DBSTATUS_LOOKASIDE_MISS_SIZEop==SQLITE_DBSTATUS_LOOKASIDE_MISS_FULL(op-SQLITE_DBSTATUS_LOOKASIDE_HIT)>=0(op-SQLITE_DBSTATUS_LOOKASIDE_HIT)<3pSchema!=0&pSchema->trigHashSQLITE_DBSTATUS_CACHE_MISS==SQLITE_DBSTATUS_CACHE_HIT+1SQLITE_DBSTATUS_CACHE_WRITE==SQLITE_DBSTATUS_CACHE_HIT+2totalUsedsqlite3LookasideUsedcountLookasideSlotsiHwtrpMutexwsdStat.nowValuesqlite3Stat.nowValuesqlite3StatValueType[10]long long[10]sqlite3StatValueType *ArraySize(wsdStat.nowValue)24295sqlite3StatusHighwaternewValueX>=0op>=0 && op<ArraySize(wsdStat.nowValue)op>=0 && op<ArraySize(statMutex)sqlite3_mutex_held(statMutex[op] ? sqlite3Pcache1Mutex() : sqlite3MallocMutex())op==SQLITE_STATUS_MALLOC_SIZE || op==SQLITE_STATUS_PAGECACHE_SIZE || op==SQLITE_STATUS_PARSER_STACKsqlite3StatusDownsqlite3StatusUpsqlite3StatusValuesqlite2BtreeKeyComparesqliteVdbePopStacksqlite3CompileOptionsconst char *const[50]char *[50]sizeof(sqlite3azCompileOpt)sizeof(sqlite3azCompileOpt[0])sizeof(sqlite3azCompileOpt) / sizeof(sqlite3azCompileOpt[0])sqliteViewTriggerssqlite3_mutex_heldstmt_cursorstmt_vtabStmtRowDbpageCursorDbpageTableStatCursorStatPageStatCellStatTableRtreeCheckRtreeGeomCallbackRtreeCellRtreeCoordRtreeValueRtreeCursorRtreeSearchPointRtreeConstraintRtreeDValueRtreeRtreeNodeJsonEachConnectionJsonEachCursorJsonParentJsonPrettyNanInfNameJsonStringJsonCacheJsonParseunicode_cursorunicode_tokenizerTermOffsetCtxTermOffsetLcsIteratorStrBufferMatchInfoSnippetFragmentSnippetIterSnippetPhraseLoadDoclistCtxNodeReaderIncrmergeWriterNodeWriterBlobSegmentWriterSegmentNodeFts3tokCursorFts3tokTablesimple_tokenizer_cursorsimple_tokenizerporter_tokenizer_cursorporter_tokenizerParseContextFts3auxCursorFts3auxColstatsFts3auxTableFts3TokenAndCostTokenDoclistTermSelectFts3HashWrapperFts3CursorMatchinfoBufferFts3ExprFts3PhraseFts3PhraseTokenFts3MultiSegReaderFts3SegFilterFts3SegReaderFts3DeferredTokenPendingListFts3DoclistFts3TableFts3IndexFts3Hash_fts3htFts3HashElemsqlite3_tokenizer_modulesqlite3_tokenizer_cursorsqlite3_tokenizeryyParseryyStackEntryYYMINORTYPEFrameBoundTrigEventWindowCodeArgWindowCsrAndRegWindowRewriteLastValueCtxNtileCtxNthValueCtxCallCountCoveringIndexCheckHiddenIndexInfoWhereScanWhereLoopBuilderWhereOrSetWhereOrCostWherePathTabResultWhereConstSubstContextRowLoadInfoSortCtxDistinctCtxPragmaVtabCursorPragmaVtabPragmaNamesqlite3AutoExtListsqlite3_loadext_entryIndexIteratorIndexListTermGroupConcatCtxCountCtxSumCtxcompareInfoanalysisInfoStatAccumStatSampleRenameCtxEdupBufMemJournalFilePointFileChunkbytecodevtab_cursorbytecodevtabPmaWriterIncrblobReusableSpaceValueNewStat4CtxCellArrayIntegrityCkWalWriterWalHashLocWalCkptInfoWalIteratorWalSegmentht_slotPCacheGlobalPgFreeslotPCache1PGroupPgHdr1MemFSMemFileMemStoreMemVfsDbPathfinder_typevxworksFileIdunix_syscallunixFileunixShmunixShmNodeunixInodeInfoUnixUnusedFdunixFileIdsqlite3PrngTypeet_infoetByteMem0GlobalBenignMallocHooksDateTimesqlite3StatTypesqlite3StatValueTypeDblquoteStrScanStatusSqlite3ConfigInitDataRecordCompareVdbeOpListBtreePayloadWhereLevelInLoopWhereRightJoinWhereMaskSetWhereMemBlockWhereAndInfoWhereOrInfoWhereClauseTreeViewStrAccumSelectDestRowSetRowSetChunkRowSetEntryRCStrPrintfArgumentsPreUpdateOnOrUsingKeyClassIndexSampleFuncDefHashFpDecodeDbFixerWalkerIdxCoverRefSrcListCCurHintNameContextAuthContextuptrtRowcntDbClientDataSavepointBusyHandlerVtabCtxsqlite3_xauthLookasideLookasideSlotsqlite3InitInfoDbVdbeFrameAuxDataOpVdbeTxtBlbCacheVdbeSorterPmaReaderIncrMergerMergeEngineSortSubtaskSorterFileSorterCompareSorterListSorterRecordUnpackedRecordSQLiteThreadBtreeBtSharedBtLockMemPageCellInfoPagerWalDbPagePCachePagerSavepointBitvecBooli8RenameTokenVListReturningTokenParseCleanupTriggerPrgSubProgramVdbeOpp4unionSubrtnSigKeyInfoCollSeqAutoincInfoTableLockyDbMaskIndexedExprExprListExprList_itemAggInfoAggInfo_funcAggInfo_colynVarSelectWindowWithCteSrcListSrcItemSubqueryCteUseTableVTableModuleMemValueFuncDefFuncDestructorFKeysColMapTriggerTriggerStepUpsertIdListIdList_itemIndexBitmaskPgnoSchemaHash_htHashElemi16ColumnbftLogEstnRangeparenOnlyeFrmTypemxPgnopgnoTrunciDbTruncnMxPayloadzPagetypeiPagenoiRightChildPgnLastOvfliChildPgisEofnNonLeafaCheckMappingpGetNodenDimbIntcbsPointpReadAuxaPointnPointnPointAllociStrategybAuxValidbPointatEOFpWriteAuxpDeleteParentpWriteParentpReadParentpDeleteRowidpWriteRowidpReadRowidpDeleteNodepWriteNodepNodeBlobpDeletedisDirtyzReadAuxSqlnNodeRefnBusyzNodeNameinWrTransnBytesPerCellnDim2iNodeSizenParentAllocnParentiHeadszIndentzReplzMatchnReplzSpacebStatichasNonstdbJsonIsRCStrnJPRefnBlobAllocaiExceptionnExceptionaTermiPosOffsetaMatchinfoflagcoveredaPhraseiTailtermaNodeWriterbNoLeafDatanWorkzMallocnMallocnTokenAllocatednAllocatednOccnStoppFts3TabanOutputaaOutputhashpMIBufferaRefisMatchinfoNeedediMaxDocidiMinDocidnRowAvgeEvalmodepNextIdaMIbDeferredbStartaTokennCostbRestartiColFilternAdvancenOffsetListpOffsetListnTermAllocppNextElemnPopulateiCurrentBlockrootOnlyiLastPosiLastColiLastDocidiOrDocidpOrPoslistiDoclistTokendoclistbFreeListpNextDocidnAllaAllbSeekStmtisRequireSeekbPrevDeleteiPrevLangidiPrevDocidnPendingDatanMaxPendingDatahPendingpSegmentszSegmentsTblnPgszbIgnoreSavepointbHasDocsizebHasStatnNodeSizezWriteExprlistzReadExprlistpSeekStmtaStmtbLocknLeafAddnAutoincrmergezContentTblabNotindexedazColumnchainhtsizexLanguageidyystk0yystackyystackEndminormajoryy637yy590yy563yy502yy483yy481yy444yy421yy403yy402yy361yy342yy319yy205yy204yy125yy28yy9yy0yyinitcurrenteDeletenValueaRhsmHandleInmInnEquiviEquivpIdxExprpOrigWCiPlanLimitbldFlags2bldFlags1pOrSetaLooprevLoopmaskLooppCListiNewTablepDeferredRowLoadlabelOBLoptlabelDoneaddrSortIndexlabelBkOutiECursoraddrTncttabTnctisTnctiHiddennPragCNameiPragCNamemPragFlgePragTypaExtnExtlxpnSepLengthsnFirstSepLengthnAccumovrflapproxiSumrErrrSummatchSetanDLtnSkipAheadnEstzAllocreadpointendpointzChunknChunkSizeshowSubprogramsneedFinalizebTablesUsediWriteOffiBufEndiBufStarteFWErrUnpackedRecord **ppRecixNxapEndapCellzPfxnCkPageaPgRefsyncFlagsiSyncPointiZeronotUsed0nBackfillAttemptedaReadMarkaSegmentbUnderPressurenFreeSlotszSlotnInitPageseparateCachegrppBulkapHashnHashnRecyclablenPurgeableDummyiMaxKeyn90pctpnPurgeablelrupLruPrevpLruNextisAnchorisBulkLocalpagenPurgeablemxPinnednMinPagenMaxPageapMemStorenMemStorenWrLocknRdLocknMmapnSymlinkzCanonicalNamevxworksFileId *pDefaultdeviceCharacteristicspMapRegionmmapSizeMaxmmapSizeActualmmapSizenFetchOutszChunkpShmpPreallocatedUnusedlockingContextlastErrnoeFileLockexclMasksharedMaskhasMutexapRegionisUnlockednRegionhShmpShmMutexbProcessLocknLocknSharedpLockMutexinodevcharsetfmttypenearlyFullhardLimitalarmThresholdrXformrLimitisLocalisUtcuseSubsecisErrorrawSnFloorvalidHMSvalidYMDvalidJDtziJDmxValuenowValueDblquoteStr *pNextStriSelectIDaddrVisitaAddrRangeiPrngSeedszSorterRefiOnceResetThresholdxAltLocaltimebLocaltimeFaultxTestCallbackmxMemdbSizepInitMutexnRefInitMutexisPCacheInitisMallocInitisMutexInitinProgresssharedCacheEnabledmxParserStackmxReqmnReqnHeappHeappcache2nLookasideszLookasideneverCorruptmxStrlenbExtraSchemaChecksbSmallMallocbUseCisbFullMutexbCoreMutexbMemstatnInitRowmInitFlagspCoveringIdxaInLoopeEndLoopOpaddrInTopendSubrtnaddrSubrtniMatchregFilteraddrLikeRepiLikeRepCntraddrBignulladdrBodyaddrSkipiLeftJoinsMaskSetbVarSelectpMemToFreepLoopsaLTermSpacepNextLoopaLTermprereqRightleftColumnleftCursornChildtruthProbhasOrpOuternLTermomitMaskbIdxNumHexbOmitOffsetneedFreebtreenDistinctColrSetupmaskSelfiEndWherenRowOutbStarUsedbStarDonesortedbOrderedInnerLoopbDeferredSeeknLevelzAffSdstnSdstiSdstiSDParm2iSDParmrsFlagsnFreshpForestpFreshnRCRefapDfltoldipkiKey2iKey1iBlobWriteiNewRegpNewUnpackedkeyinfoaRecordpOnanLtanEqiDPisSpecialpCovIdxCkbUnidxbExprapExprmExcludeOnbHasAffBlobnConstpOomFaultpRewritepSubSelectpIdxCoverpRefSrcListaiExcludenExcludeCCurHint *pCCurHintpWinSelectnNestedSelectncFlagsnNcErruNCiBaseRegmWFlagseCodewalkerDepthxSelectCallback2xSelectCallbackxExprCallbackzAuthContextset_clientdataget_clientdatastmt_explainis_interruptedvalue_encodingdb_nameserializevtab_in_nextvtab_in_firstvtab_invtab_distinctvtab_rhs_valueerror_offsetautovacuum_pagestotal_changes64changes64txn_statedatabase_file_objectfree_filenamecreate_filenamefilename_walfilename_journalfilename_databaseuri_keyhard_heap_limit64drop_modulesvalue_frombindstmt_isexplainnormalized_sqlcreate_window_functionstr_valuestr_lengthstr_errcodestr_resetstr_appendcharstr_appendallstr_appendstr_vappendfstr_appendfstr_finishstr_newprintfFlagsaccErrormxAllockeyword_checkkeyword_namekeyword_countvtab_collationvalue_nochangevtab_nochangevalue_pointerresult_pointerbind_pointerprepare16_v3prepare_v3set_last_insert_rowidexpanded_sqltrace_v2system_errnodb_cacheflushstrlikestatus64result_subtypevalue_subtypebind_zeroblob64result_zeroblob64value_freevalue_dupstrglobresult_text64result_blob64reset_auto_extensionrealloc64msizemalloc64cancel_auto_extensionbind_text64bind_blob64auto_extensionwal_checkpoint_v2xvsnprintfuri_parameteruri_int64uri_booleanstricmpstmt_readonlystmt_busyerrstrdb_release_memorydb_readonlydb_filenameclose_v2vtab_on_conflictvtab_configblob_reopenwal_hookwal_checkpointwal_autocheckpointunlock_notifystrnicmpstmt_statussourceidsoft_heap_limit64extended_errcodedb_statusdb_mutexdb_configcreate_function_v2compileoption_usedcompileoption_getbackup_stepbackup_remainingbackup_pagecountbackup_initbackup_finishnext_stmtextended_result_codescontext_db_handletest_controlresult_error_coderesult_zeroblobxthreadsafevfs_unregistervfs_registervfs_findsoft_heap_limitresult_error_toobigresult_error_nomemrelease_memoryopen_v2mutex_trymutex_leavemutex_freemutex_entermutex_allocmemory_usedmemory_highwaterfile_controlcreate_collation_v2blob_writeblob_readblob_openblob_closeblob_bytesbind_zeroblobcreate_module_v2clear_bindingsprepare16_v2prepare_v2overload_functionvmprintfvalue_typevalue_text16levalue_text16bevalue_text16value_textvalue_numeric_typevalue_int64value_intvalue_doublevalue_bytes16value_bytesvalue_blobuser_dataupdate_hooktransfer_bindingsthread_cleanuptable_column_metadatastepxsnprintfset_auxdataset_authorizerrollback_hookresult_valueresult_text16leresult_text16beresult_text16result_textresult_nullresult_int64result_intresult_error16result_errorresult_doubleresult_blobprepare16prepareopen16mprintflibversion_numberlibversioninterruptxglobal_recoverget_tableget_auxdataget_autocommitfree_tablefinalizeexpiredexecerrmsg16errcodeenable_shared_cachedeclare_vtabdb_handledata_countcreate_modulecreate_function16create_functioncreate_collation16create_collationcomplete16completecommit_hookcolumn_valuecolumn_typecolumn_text16column_textcolumn_table_name16column_table_namecolumn_origin_name16column_origin_namecolumn_name16column_namecolumn_int64column_intcolumn_doublecolumn_decltype16column_decltypecolumn_database_name16column_database_namecolumn_countcolumn_bytes16column_bytescolumn_blobcollation_needed16collation_neededbusy_timeoutbusy_handlerbind_valuebind_text16bind_textbind_parameter_namebind_parameter_indexbind_parameter_countbind_nullbind_int64bind_intbind_doublebind_blobaggregate_countaggregate_contextpDbDatapnBytesFreednDeferredImmConsnDeferredConsnStatementbusyTimeoutnAnalysisLimitaDbStaticbusyHandleraCollSeqpDisconnectpVtabCtxbDeclaredaModulenVTransnProgressOpspProgressArglookasidepTrueEndpMiddlepSmallFreepSmallInitanStatbMallocedszTruebDisableu1isInterruptedpErrpWalArgxWalCallbackxAutovacPagesxAutovacDestrpAutovacPagesArgxUpdateCallbackpUpdateArgxRollbackCallbackpRollbackArgxCommitCallbackpCommitArgpProfileArgpTraceArgxV2xLegacyaExtensionnExtensionnVDestroynVdbeExecnVdbeWritenVdbeReadnVdbeActiveazInitreopenMemdbimposterTableorphanTriggerbusynewTnumnMaxSorterMmapnTotalChangenextPagesizenSqlExecnoSharedCacheisTransactionSavepointsuppressErrnextAutovacdfltLockModebBenignMallocmallocFailedtemp_storeautoCommitdbOptFlagsiSysErrnoerrMaskerrByteOffsetnSchemaLocklastRowidmDbFlagsbSyncSetsafety_levelzDbSNamepDfltCollexpmaskpDelFramenDbChangenChildCsrnChildMempNextAuxxDeleteAuxiAuxOpaOnceaCounterlockMaskbtreeMaskhaveEqpOpsbIsReaderusesStmtJournalchangeCntOneVdbeStateminWriteFileFormaterrorActionnResAllocstartTimepVListpResultRowaColNamenOpAllocaVarpCValuepayloadSizeaRowmovetoTargetnHdrParsediHdrOffsetucaTasknTaskbUseThreadsbUsePMAnMemoryiMemoryaFilebUseThreadiStartOffaReadraTreefile2szPMAaMemoryeqSeendefault_rcbDonepThreadtidaAllocmxKeysizemxPmaSizemnPmaSizeseqCountubaAltMappBtxiBDataVersionnBackupwantToLockhasIncrblobCursharablenPreformatSizepHasContentxFreeSchemanTransactionminLeafmaxLeafbtsFlagsnReserveWantedmax1bytePayloadinTransactionbDoTruncateincrVacuumapPagexParseCellxCellSizeaDataOfstaCellIdxaDataEndapOvflaiOvflnOverflowchildPtrSizehdrOffsetintKeyLeafaiIdxcurIntKeyaOverflowhintscurPagerFlagscurFlagsnCkptiReCksumminFramebigEndCksumiChangeunusedbShmUnreliablepadToSectorBoundarysyncHeadertruncateOnCommitckptLockwriteLockexclusiveModereadLockapWiDataszFirstBlocknWiDataiCallbackpWalFdpPCachexGetxReiniterjournalSizeLimitlckPgnopMmapFreelistpDirtyPrevpDirtyNextszSpillszCachenRefSumpSyncedpDirtyTailnMmapOutaSavepointbTruncateOnReleaseiSubRecpInSavepointisAttachednPagecountnRemainingbDestLockediDestSchemajournalHdrjournalOffsjfdpInJournalaBitmapiDivisornSetnSubReccksumInitdbHintSizedbOrigSizehasHeldSharedLockbUseFetchdoNotSpillsetSuperchangeCountDonememVfswalSyncFlagsextraSyncjournalModeseekHitcolCachenoReuseuseRandomRowidisEphemeralisTabledeferredMovetonStmtDefImmConsnStmtDefConsnFkConstraintiCurrentTimecacheCtrsArgpNewTriggerpNewIndexpNewTablenVtabLockiPkSortOrderiRetRegnRetColiRetCurretTStepretTrigpReturnELcrconstraintNameregRootaddrCrTabsNameTokenpOuterParsepTriggerPrgaColmasknCsrzCommentpSubrtnSigbCompleteselIdaSortFlagsnAllFieldnKeyFieldpI64pTriggerTabpAincregCtraTableLockzLockNamenTableLocknProgressStepsnMaxArgcookieMaskwriteMaskpIdxPartExprpIdxEprpIENextbMaybeNullRowpConstExpriConstExprRegiAliasfgbNoExpandbUsingTermbNullsbSorterRefreusablezENamebUseSubtypebOBUniquebOBPayloadiOBTabiDistAddrpFExprnAccumulatoriSorterColumniFirstRegsortingIdxPTabsortingIdxnSortingColumnuseSortingIdxdirectModeiJoinpWinDefnbExprArgsregEndRowidregStartRowidregOneiArgColnBufferColregPartregAppcsrAppregAccumiEphCsrpWFuncpNextWinppThiszCteErrpColsbViewnCteu4addrFillSubu3u2regRtnaddrM9enUsepIBIndexpFuncArghadSchemafixedSchemarowidUsedisNestedFromisSynthUsingisOnisUsingnotCteisCtefromDDLisRecursiveviaCoroutineisMaterializedisCorrelatedisTabFuncisSubqueryisIndexedBynotIndexedpSTabaHxeVtabRiskbAllSchemasbConstraintpEpoTabnRefModuleuTempszMallocxFinalizeskipFlagfuncFlagspDfltListapTriggerstep_listpUpsertSrcpUpsertIdxisDupisDoUpdatepNextUpsertpUpsertWherepUpsertTargetWherepUpsertTargetpExprListpTabSchemabReturningaActionpPrevTopNextFromaddColOffseteTabTypekeyConfszTabRownRowLogEstnNVColiPKeytabFlagsnTabRefcolNotIdxedbHasExprbHasVColbAscKeyBugbNoQuerybLowQualhasStat1noSkipScanisCoveringisResizeduniqNotNullbUnorderedszIdxRowpPartIdxWhereazCollaSortOrdercache_sizeschemaFlagsfile_formatfkeyHashtrigHashidxHashtblHashiGenerationschema_cookieaiRowLogEstiDflthNameeCTypenotNullzCnNameaddrOpenEphmnSelectRowop2affExprnLabelAllocnLabeliSelfTabszOpAllociRangeRegnRangeRegcheckSchemabHasWithcolNamesSetdisableTriggerseOrconfeTriggerOpmSubrtnSigwithinRJSubrtnhasCompoundmayAbortisMultiWritenTempRegnestednQueryLooppVNextppVPrevstmtModulezDbstatSchemaCREATE TABLE x( name       TEXT, path       TEXT, pageno     INTEGER, pagetype   TEXT, ncell      INTEGER, payload    INTEGER, unused     INTEGER, mx_payload INTEGER, pgoffset   INTEGER, pgsize     INTEGER, schema     TEXT HIDDEN, aggregate  BOOLEAN HIDDEN)"CREATE TABLE x("
  " name       TEXT,"          /*  0 Name of table or index */
  " path       TEXT,"          /*  1 Path to page from root (NULL for agg) */
  " pageno     INTEGER,"       /*  2 Page number (page count for aggregates) */
  " pagetype   TEXT,"          /*  3 'internal', 'leaf', 'overflow', or NULL */
  " ncell      INTEGER,"       /*  4 Cells on page (0 for overflow) */
  " payload    INTEGER,"       /*  5 Bytes of payload on this page */
  " unused     INTEGER,"       /*  6 Bytes of unused space on this page */
  " mx_payload INTEGER,"       /*  7 Largest payload size of all cells */
  " pgoffset   INTEGER,"       /*  8 Offset of page in file (NULL for agg) */
  " pgsize     INTEGER,"       /*  9 Size of the page (sum for aggregate) */
  " schema     TEXT HIDDEN,"   /* 10 Database schema being analyzed */
  " aggregate  BOOLEAN HIDDEN" /* 11 aggregate info for each table */
  ")"rtreeModulejsonTreeModulejsonEachModuleconst NanInfName[]NanInfName[]aNanInfNameinfinity"infinity"'N''Q'QNaN"QNaN"SNaN"SNaN"jsonIsOkjsonSpaces	
 "\011\012\015\040"jsonIsSpacejsonbTypearray"array"object"object"simpleTokenizerModuleporterTokenizerModuleporterIdCharcTypefts3ModuleaHardLimitSQLITE_MAX_SQL_LENGTHSQLITE_MAX_COLUMNSQLITE_MAX_COMPOUND_SELECT250000000SQLITE_MAX_VDBE_OPSQLITE_MAX_ATTACHED50000SQLITE_MAX_LIKE_PATTERN_LENGTH32766SQLITE_MAX_VARIABLE_NUMBERSQLITE_MAX_TRIGGER_DEPTH..(*const[])(..)..(*[])(..)aKWCodeaKWOffsetaKWLenaKWNextaKWHashzKWTextaiClassconst signed char[]yyRuleInfoNRhsyyRuleInfoLhsyyFallbackyy_defaultconst short[]short[]yy_reduce_ofstyy_shift_ofstyy_lookaheadyy_actionlagName"lag"leadName"lead"first_valueName"first_value"nth_valueName"nth_value"last_valueName"last_value"ntileName"ntile"cume_distName"cume_dist"percent_rankName"percent_rank"rankName"rank"dense_rankName"dense_rank"row_numberName"row_number"pragmaVtabModuleconst PragmaName[]PragmaName[]analysis_limit"analysis_limit"automatic_index"automatic_index""busy_timeout"PragTyp_BUSY_TIMEOUT"cache_size"cache_spill"cache_spill"case_sensitive_like"case_sensitive_like"cell_size_check"cell_size_check"checkpoint_fullfsync"checkpoint_fullfsync"SQLITE_CkptFullFSynccollation_list"collation_list"compile_options"compile_options"count_changes"count_changes"database_list"database_list"default_cache_size"default_cache_size"defer_foreign_keys"defer_foreign_keys"empty_result_callbacks"empty_result_callbacks"foreign_key_check"foreign_key_check"foreign_key_list"foreign_key_list"foreign_keys"foreign_keys"freelist_count"freelist_count"BTREE_FREE_PAGE_COUNTfull_column_names"full_column_names"fullfsync"fullfsync"SQLITE_FullFSyncfunction_list"function_list"hard_heap_limit"hard_heap_limit"ignore_check_constraints"ignore_check_constraints"incremental_vacuum"incremental_vacuum"index_info"index_info"index_list"index_list"index_xinfo"index_xinfo"integrity_check"integrity_check"journal_mode"journal_mode"journal_size_limit"journal_size_limit"locking_mode"locking_mode"max_page_count"max_page_count"mmap_size"mmap_size"module_list"module_list"page_count"page_count"pragma_list"pragma_list"query_only"query_only"quick_check"quick_check"read_uncommitted"read_uncommitted"recursive_triggers"recursive_triggers"reverse_unordered_selects"reverse_unordered_selects"schema_version"schema_version"secure_delete"secure_delete"short_column_names"short_column_names"shrink_memory"shrink_memory""soft_heap_limit"synchronous"synchronous"table_info"table_info"table_list"table_list"table_xinfo"table_xinfo""temp_store"newSzprNowpiNowpUidpGidpiErrnohandleNFSUnlockppInodeiLineposixErrorsqliteIOErrpNewFuncmxRoundpNumyyerr_codezDfltppThreadfmteErroriThresholdppFilepHdlenPathOutzPathOutpFlagsOutpDatepTmzDatepnOpttemp_store_directory"temp_store_directory"threads"threads""wal_autocheckpoint""wal_checkpoint"pragCName"id"seq"seq"from"from"to"to"on_update"on_update"on_delete"on_delete"cid"cid""type""notnull"dflt_value"dflt_value"ncol"ncol"wr"wr"seqno"seqno"coll"coll"builtin"builtin""enc"narg"narg""flags"wdth"wdth"hght"hght""flgs"unique"unique"origin"origin"partial"partial"fkid"fkid""busy"checkpointed"checkpointed"database"database"sqlite3Autoextsqlite3ApishexdigitslikeInfoAltlikeInfoNormglobInfostatGetFuncdefstat_get"stat_get"statPushFuncdefstat_push"stat_push"statInitFuncdefstat_init"stat_init"zeroItemMemJournalMethodsbytecodevtabModuleiExplainColNames16azExplainColNames16dataazExplainColNames8"addr""opcode""p1""p2""p3""p4""p5""comment"notused"notused"detail"detail"sqlite3SmallTypeSizeszMagicHeaderSQLITE_FILE_HEADERaJournalMagic0xd90xd50xf90xa10x630xd7memdb_io_methodsmemdb_vfsmemdb_gazTempDirs/var/tmp"/var/tmp"/usr/tmp"/usr/tmp"inodeListunixBigLockunix_syscall[]"fstat""fcntl"(sqlite3_syscall_ptr)0"pwrite""fchmod"fallocate"fallocate""mkdir""rmdir""fchown""geteuid"munmap"munmap""getpagesize"ioctl"ioctl"randomnessPidsqlite3Utf8Trans10x0e0x120x150x160x170x190x1a0x1d0x1esqlite3OomStrconst et_info[]et_info[]-x0 X0"-x0\000X0"aDigits0123456789ABCDEF0123456789abcdef"0123456789ABCDEF0123456789abcdef"SQLITE_MAX_MEMORYsqlite3Hookssecond"second"464270000000000.04.6427e+144.642699928e+14minute"minute"7737900000000.07.7379e+127.737900007e+1260.0hour"hour"128970000000.01.2897e+111.289699983e+113600.05373485.0176546.02592000.014713.031536000.0statMutexsqlite3Statsqlite3StdTypeANY"ANY"sqlite3StdTypeAffinitysqlite3StdTypeLensqlite3StrBINARYsqlite3OpcodePropertysqlite3WhereTracesqlite3TreeTracesqlite3PendingBytesqlite3BuiltinFunctionssqlite3ConfigSQLITE_DEFAULT_MEMSTATUSSQLITE_USE_URISQLITE_ALLOW_COVERING_INDEX_SCAN21474836460x7ffffffe1200SQLITE_STMTJRNL_SPILL(void*)0SQLITE_DEFAULT_PCACHE_INITSZSQLITE_SORTER_PMASZSQLITE_MEMDB_DEFAULT_MAXSIZESQLITE_DEFAULT_SORTERREF_SIZEsqlite3CtypeMapsqlite3aGTb256+12256+12-OP_Nesqlite3aEQb256+6256+6-OP_Nesqlite3aLTb256-OP_Nesqlite3UpperToLowersqlite3azCompileOptSQLITE_ATOMIC_INTRINSICSSQLITE_DEFAULT_FILE_FORMATSQLITE_DEFAULT_WAL_SYNCHRONOUSSQLITE_DQSATOMIC_INTRINSICS=1"ATOMIC_INTRINSICS=" CTIMEOPT_VAL(SQLITE_ATOMIC_INTRINSICS)COMPILER=gcc-EDG gcc 13.3 mode"COMPILER=gcc-" __VERSION__DEFAULT_AUTOVACUUM"DEFAULT_AUTOVACUUM"DEFAULT_CACHE_SIZE=-2000"DEFAULT_CACHE_SIZE=" CTIMEOPT_VAL(SQLITE_DEFAULT_CACHE_SIZE)DEFAULT_FILE_FORMAT=4"DEFAULT_FILE_FORMAT=" CTIMEOPT_VAL(SQLITE_DEFAULT_FILE_FORMAT)DEFAULT_JOURNAL_SIZE_LIMIT=-1"DEFAULT_JOURNAL_SIZE_LIMIT=" CTIMEOPT_VAL(SQLITE_DEFAULT_JOURNAL_SIZE_LIMIT)DEFAULT_MMAP_SIZE=0"DEFAULT_MMAP_SIZE=" CTIMEOPT_VAL(SQLITE_DEFAULT_MMAP_SIZE)DEFAULT_PAGE_SIZE=4096"DEFAULT_PAGE_SIZE=" CTIMEOPT_VAL(SQLITE_DEFAULT_PAGE_SIZE)DEFAULT_PCACHE_INITSZ=20"DEFAULT_PCACHE_INITSZ=" CTIMEOPT_VAL(SQLITE_DEFAULT_PCACHE_INITSZ)DEFAULT_RECURSIVE_TRIGGERS"DEFAULT_RECURSIVE_TRIGGERS"DEFAULT_SECTOR_SIZE=4096"DEFAULT_SECTOR_SIZE=" CTIMEOPT_VAL(SQLITE_DEFAULT_SECTOR_SIZE)DEFAULT_SYNCHRONOUS=2"DEFAULT_SYNCHRONOUS=" CTIMEOPT_VAL(SQLITE_DEFAULT_SYNCHRONOUS)DEFAULT_WAL_AUTOCHECKPOINT=1000"DEFAULT_WAL_AUTOCHECKPOINT=" CTIMEOPT_VAL(SQLITE_DEFAULT_WAL_AUTOCHECKPOINT)DEFAULT_WAL_SYNCHRONOUS=2"DEFAULT_WAL_SYNCHRONOUS=" CTIMEOPT_VAL(SQLITE_DEFAULT_WAL_SYNCHRONOUS)DEFAULT_WORKER_THREADS=0"DEFAULT_WORKER_THREADS=" CTIMEOPT_VAL(SQLITE_DEFAULT_WORKER_THREADS)DIRECT_OVERFLOW_READ"DIRECT_OVERFLOW_READ"DQS=0"DQS=" CTIMEOPT_VAL(SQLITE_DQS)ENABLE_BYTECODE_VTAB"ENABLE_BYTECODE_VTAB"ENABLE_DBPAGE_VTAB"ENABLE_DBPAGE_VTAB"ENABLE_DBSTAT_VTAB"ENABLE_DBSTAT_VTAB"ENABLE_EXPLAIN_COMMENTS"ENABLE_EXPLAIN_COMMENTS"ENABLE_FTS3"ENABLE_FTS3"ENABLE_FTS4"ENABLE_FTS4"ENABLE_MATH_FUNCTIONS"ENABLE_MATH_FUNCTIONS"ENABLE_OFFSET_SQL_FUNC"ENABLE_OFFSET_SQL_FUNC"ENABLE_RTREE"ENABLE_RTREE"ENABLE_STMTVTAB"ENABLE_STMTVTAB"ENABLE_UNKNOWN_SQL_FUNCTION"ENABLE_UNKNOWN_SQL_FUNCTION"HAVE_ISNAN"HAVE_ISNAN"MALLOC_SOFT_LIMIT=1024"MALLOC_SOFT_LIMIT=" CTIMEOPT_VAL(SQLITE_MALLOC_SOFT_LIMIT)MAX_ATTACHED=10"MAX_ATTACHED=" CTIMEOPT_VAL(SQLITE_MAX_ATTACHED)MAX_COLUMN=2000"MAX_COLUMN=" CTIMEOPT_VAL(SQLITE_MAX_COLUMN)MAX_COMPOUND_SELECT=500"MAX_COMPOUND_SELECT=" CTIMEOPT_VAL(SQLITE_MAX_COMPOUND_SELECT)MAX_DEFAULT_PAGE_SIZE=8192"MAX_DEFAULT_PAGE_SIZE=" CTIMEOPT_VAL(SQLITE_MAX_DEFAULT_PAGE_SIZE)MAX_EXPR_DEPTH=1000"MAX_EXPR_DEPTH=" CTIMEOPT_VAL(SQLITE_MAX_EXPR_DEPTH)MAX_FUNCTION_ARG=1000"MAX_FUNCTION_ARG=" CTIMEOPT_VAL(SQLITE_MAX_FUNCTION_ARG)MAX_LENGTH=1000000000"MAX_LENGTH=" CTIMEOPT_VAL(SQLITE_MAX_LENGTH)MAX_LIKE_PATTERN_LENGTH=50000"MAX_LIKE_PATTERN_LENGTH=" CTIMEOPT_VAL(SQLITE_MAX_LIKE_PATTERN_LENGTH)MAX_MMAP_SIZE=0x7fff0000"MAX_MMAP_SIZE=" CTIMEOPT_VAL(SQLITE_MAX_MMAP_SIZE)MAX_PAGE_COUNT=0xfffffffe"MAX_PAGE_COUNT=" CTIMEOPT_VAL(SQLITE_MAX_PAGE_COUNT)MAX_PAGE_SIZE=65536"MAX_PAGE_SIZE=" CTIMEOPT_VAL(SQLITE_MAX_PAGE_SIZE)MAX_SQL_LENGTH=1000000000"MAX_SQL_LENGTH=" CTIMEOPT_VAL(SQLITE_MAX_SQL_LENGTH)MAX_TRIGGER_DEPTH=1000"MAX_TRIGGER_DEPTH=" CTIMEOPT_VAL(SQLITE_MAX_TRIGGER_DEPTH)MAX_VARIABLE_NUMBER=32766"MAX_VARIABLE_NUMBER=" CTIMEOPT_VAL(SQLITE_MAX_VARIABLE_NUMBER)MAX_VDBE_OP=250000000"MAX_VDBE_OP=" CTIMEOPT_VAL(SQLITE_MAX_VDBE_OP)MAX_WORKER_THREADS=8"MAX_WORKER_THREADS=" CTIMEOPT_VAL(SQLITE_MAX_WORKER_THREADS)MUTEX_PTHREADS"MUTEX_PTHREADS"SYSTEM_MALLOC"SYSTEM_MALLOC"TEMP_STORE=1"TEMP_STORE=" CTIMEOPT_VAL(SQLITE_TEMP_STORE)THREADSAFE=1"THREADSAFE=" CTIMEOPT_VAL(SQLITE_THREADSAFE)3.50.0DBPAGE_COLUMN_DATADBPAGE_COLUMN_PGNO(1.0 + 1.0/8388608.0)(1.0 - 1.0/8388608.0)RTREE_QUEUE_TRACE(A,B)RTREE_DECODE_COORD(eInt,a,r){ RtreeCoord c; c.u = __builtin_bswap32(*(u32*)a); r = eInt ? (sqlite3_rtree_dbl)c.i : (sqlite3_rtree_dbl)c.f; }NCELL(pNode)readInt16(&(pNode)->zData[2])0x470x450x440x430x420x41DCOORD(coord)( (pRtree->eCoordType==RTREE_COORD_REAL32) ? ((double)coord.f) : ((double)coord.i) )RTREE_OF_CURSOR(X)((Rtree*)((X)->base.pVtab))RTREE_REINSERT(p)RTREE_MINCELLS(p)((((p)->iNodeSize-4)/(p)->nBytesPerCell)/3)RTREE_IS_CORRUPT(X)JEACH_ROOTJSON_LOOKUP_ISERROR(x)((x)>=JSON_LOOKUP_PATHERROR)0xfffffffd0x99999(-429938)jsonIsspace(x)(jsonIsSpace[(unsigned char)x])HIBIT((unsigned char)0x80)LCS_ITERATOR_FINISHED0x7FFFFFFF;"pcx"SQL_DELETE_ALL_TERMS_SEGDIRSQL_SELECT_ALL_PREFIX_LEVELSQL_SELECT_LEVEL_COUNTfts3SegReaderIsRootOnly(p)((p)->rootOnly!=0)fts3SegReaderIsPending(p)((p)->ppNextElem!=0)fts3LogMerge(x,y)(FTS3_NODE_CHUNKSIZE*4)(FTS3_VARINT_MAX*2)"CREATE TABLE x(input, token, start, end, position)"isDelim(C)(((ch=C)&0x80)==0 && (ch<0x30 || !porterIdChar[ch-0x30]))SQLITE_FTS3_DEFAULT_NEAR_PARAM"CREATE TABLE x(term, col, documents, occurrences, languageid HIDDEN)"DOCID_CMP(i1,i2)((bDescDoclist?-1:1) * (i1>i2?1:((i1==i2)?0:-1)))POSITION_LIST_ENDGETVARINT_INIT(v,ptr,shift,mask1,mask2,var,ret)v = (*ptr++); if( (v & mask2)==0 ){ var = v; return ret; }GETVARINT_STEP(v,ptr,shift,mask1,mask2,var,ret)v = (v & mask1) | ( (*(const unsigned char*)(ptr++)) << shift ); if( (v & mask2)==0 ){ var = v; return ret; }fts3GetVarint32(p,piVal)( (*(u8*)(p)&0x80) ? sqlite3Fts3GetVarint32(p, piVal) : (*piVal=*(u8*)(p), 1) )FTS3_EVAL_MATCHINFOFTS3_EVAL_NEXTFTS3_EVAL_FILTERMergeCount(P)FTS3_MERGE_COUNTFTS_CORRUPT_VTABassert_fts3_nc(x)assert(x)(0)FTS3_SEGDIR_MAXLEVEL_STR"1024"SizeofArray(X)((int)(sizeof(X)/sizeof(X[0])))(1*1024*1024)fts3HashCount(H)((H)->count)fts3HashKeysize(E)((E)->nKey)fts3HashKey(E)((E)->pKey)fts3HashData(E)((E)->data)fts3HashNext(E)((E)->next)fts3HashFirst(H)((H)->first)fts3HashFindElemfts3HashClearfts3HashFindfts3HashInsertfts3HashInitFTS3_HASH_BINARY_FTS3_HASH_H__FTS3_TOKENIZER_H__FTSINT_HNDELAYArraySize(delays)IdChar(C)((sqlite3CtypeMap[(unsigned char)C]&0x46)!=0)charMap(X)sqlite3UpperToLower[(unsigned char)X]CC_ILLEGALTOKENyyTraceShift(X,Y,Z)YY_REDUCE_MAX(1772)YY_REDUCE_MIN(-277)YY_REDUCE_COUNT(412)YY_SHIFT_MAX(2152)YY_SHIFT_MINYY_SHIFT_COUNT(582)YY_ACTTAB_COUNT(2207)YYGROWABLESTACKYY_NLOOKAHEAD((int)(sizeof(yy_lookahead)/sizeof(yy_lookahead[0])))YY_MAX_DSTRCTRYY_MAX_REDUCE1665YY_NO_ACTION1256YY_ERROR_ACTION1254YYNTOKENYYNRULE_WITH_ACTIONYYNRULE409YYNSTATE583YYFALLBACKsqlite3ParserCTX_STOREyypParser->pParse=pParse;sqlite3ParserCTX_FETCHParse *pParse=yypParser->pParse;sqlite3ParserCTX_PARAM,pParsesqlite3ParserCTX_PDECL,Parse *pParsesqlite3ParserCTX_SDECLParse *pParse;YYDYNSTACKYYFREEYYREALLOCsqlite3ParserARG_STOREsqlite3ParserARG_FETCHsqlite3ParserARG_PARAMsqlite3ParserARG_PDECLsqlite3ParserARG_SDECLsqlite3ParserTOKENTYPEYYACTIONTYPEYYNOCODEYYCODETYPEINTERFACEYYMALLOCARGTYPEsqlite3Parser_ENGINEALWAYSONSTACKYYPARSEFREENEVERNULLyytestcase(X)testcase(X)YYNOERRORRECOVERYASSERT_IS_CREATEassert(pParse->isCreate)WINDOW_ENDING_NUMWINDOW_NTH_VALUE_INTWINDOW_ENDING_INTWINDOW_STARTING_INTWINDOWFUNCX(name,nArg,extra){ nArg, (SQLITE_FUNC_BUILTIN|SQLITE_UTF8|SQLITE_FUNC_WINDOW|extra), 0, 0, name ## StepFunc, name ## ValueFunc, name ## ValueFunc, noopStepFunc, name ## Name, {0} }WINDOWFUNCNOOP(name,nArg,extra){ nArg, (SQLITE_FUNC_BUILTIN|SQLITE_UTF8|SQLITE_FUNC_WINDOW|extra), 0, 0, noopStepFunc, noopValueFunc, noopValueFunc, noopStepFunc, name ## Name, {0} }WINDOWFUNCALL(name,nArg,extra){ nArg, (SQLITE_FUNC_BUILTIN|SQLITE_UTF8|SQLITE_FUNC_WINDOW|extra), 0, 0, name ## StepFunc, name ## FinalizeFunc, name ## ValueFunc, name ## InvFunc, name ## Name, {0} }ntileFinalizeFunccume_distFinalizeFuncpercent_rankFinalizeFuncfirst_valueValueFuncfirst_valueInvFuncnth_valueValueFuncnth_valueInvFuncOpcodeRewriteTrace(D,K,P)WHERETRACE_ALL_LOOPS(W,C)ApplyCostMultiplier(C,T)explainAutomaticIndex(a,b,c,d)whereTraceIndexInfoOutputs(A,B)whereTraceIndexInfoInputs(A,B)codeCursorHint(A,B,C,D)WHERE_OMIT_OFFSET0x000000300x0000000f0x01ffWO_NOOP0x0800(WO_EQ<<(TK_GE-TK_EQ))(WO_EQ<<(TK_GT-TK_EQ))(WO_EQ<<(TK_LE-TK_EQ))(WO_EQ<<(TK_LT-TK_EQ))sqlite3WhereAddScanStatus(a,b,c,d)((void)d)SQLITE_BLDF2_2NDPASS0x0020WHERE_LOOP_XFER_SZoffsetof(WhereLoop,nLSlot)SQLITE_WHEREINT_HcolumnType(A,B,C,D,E)columnTypeImpl(A,B)explainSetInteger(a,b)a = bPragTyp_STATSPragTyp_LOCK_STATUSPragTyp_LOCK_PROXY_FILEPragTyp_DATA_STORE_DIRECTORYPragTyp_ACTIVATE_EXTENSIONSwsdAutoextwsdAutoextInitDirSep(X)((X)=='/')SQLITE_EXTENSION_INIT3SQLITE_EXTENSION_INIT2(v)(void)v;codeWithoutRowidPreupdate(a,b,c,d)COLUMN_MASK(x)(((x)>31) ? 0xffffffff : ((u32)1<<(x)))Utf8Read(A)(A[0]<0x80?*(A++):sqlite3Utf8Read(&A))noopFuncmarkExprListImmutable(X)REOPEN_AS_MEMDB(db)(db->init.reopenMemdb)STAT_GET_NDLTSTAT_GET_NLTSTAT_GET_NEQSTAT_GET_ROWIDSQLITE_STAT4_SAMPLESrenameTokenCheckAll(x,y)sqlite3ResolveNotValid(P,N,M,X,E,R)assert( ((X)&~(NC_IsCheck|NC_PartIdx|NC_IdxExpr|NC_GenCol))==0 ); if( ((N)->ncFlags & (X))!=0 ) notValidImpl(P,N,M,E,R);fileChunkSize(nChunkSize)(sizeof(FileChunk) + ((nChunkSize)-8))vdbeSorterBlockDebug(x,y,z)vdbeSorterPopulateDebug(x,y)vdbeSorterRewindDebug(y)vdbeSorterWorkDebug(x,y)SRVAL(p)((void*)((SorterRecord*)(p) + 1))(i64)( (((u64)0x7fffffff)<<32) | (u64)0xffffffff )REGISTER_TRACE(R,M)isSorter(x)((x)->eCurType==CURTYPE_SORTER)Deephemeralize(P)if( ((P)->flags&MEM_Ephem)!=0 && sqlite3VdbeMemMakeWriteable(P) ){ goto no_mem;}VdbeBranchTaken(I,M)UPDATE_MAX_BLOBSIZE(P)HAS_UPDATE_HOOK(DB)((DB)->xUpdateCallback)memAboutToChange(P,M)checkProfileCallback(DB,P)if( ((P)->startTime)>0 ){ invokeProfileCallback(DB,P); }vdbeAssertFieldCountWithinLimits(A,B,C)FOUR_BYTE_INT(x)(16777216*(i8)((x)[0])|((x)[1]<<16)|((x)[2]<<8)|(x)[3])FOUR_BYTE_UINT(x)(((u32)(x)[0]<<24)|((x)[1]<<16)|((x)[2]<<8)|(x)[3])THREE_BYTE_INT(x)(65536*(i8)((x)[0])|((x)[1]<<8)|(x)[2])TWO_BYTE_INT(x)(256*(i8)((x)[0])|(x)[1])ONE_BYTE_INT(x)((i8)(x)[0])vdbeInvokeSqllog(x)checkActiveVdbeCnt(x)valueFromFunction(a,b,c,d,e,f)ISPOWEROF2(X)(((X)&((X)-1))==0)NNBTREE_CLEAR_CELL(rc,pPage,pCell,sInfo)pPage->xParseCell(pPage, pCell, &sInfo); if( sInfo.nLocal!=sInfo.nPayload ){ rc = clearCellOverflow(pPage, pCell, &sInfo); }else{ rc = SQLITE_OK; }assertParentIndex(x,y,z)assertCellInfo(x)setDefaultSyncFlag(pBt,safety_level)findCellPastPtr(P,I)((P)->aDataOfst + ((P)->maskPage & get2byteAligned(&(P)->aCellIdx[2*(I)])))findCell(P,I)((P)->aData + ((P)->maskPage & get2byteAligned(&(P)->aCellIdx[2*(I)])))restoreCursorPosition(p)(p->eState>=CURSOR_REQUIRESEEK ? btreeRestoreCursorPosition(p) : SQLITE_OK)invalidateOverflowCache(pCur)(pCur->curFlags &= ~BTCF_ValidOvfl)SHARED_LOCK_TRACE(X,MSG,TAB,TYPE)SQLITE_CORRUPT_PAGE(pMemPage)SQLITE_CORRUPT_PGNO(pMemPage->pgno)IfNotOmitAV(expr)(expr)get2byteNotZero(X)(((((int)get2byte(X))-1)&0xffff)+1)TRACE(X)get2byteAligned(x)__builtin_bswap16(*(u16*)(x))put4byteget4byteput2byte(p,v)((p)[0] = (u8)((v)>>8), (p)[1] = (u8)(v))get2byte(x)((x)[0]<<8 | (x)[1])ISAUTOVACUUM(pBt)(pBt->autoVacuum)btreeIntegrity(p)assert( p->pBt->inTransaction!=TRANS_NONE || p->pBt->nTransaction==0 ); assert( p->pBt->inTransaction>=p->inTrans );PTRMAP_ISPAGE(pBt,pgno)(PTRMAP_PAGENO((pBt),(pgno))==(pgno))PTRMAP_PTROFFSET(pgptrmap,pgno)(5*(pgno-pgptrmap-1))PTRMAP_PAGENO(pBt,pgno)ptrmapPageno(pBt, pgno)PENDING_BYTE_PAGE(pBt)((Pgno)((PENDING_BYTE/((pBt)->pageSize))+1))0x000cBTS_OVERWRITEMX_CELL(pBt)((pBt->pageSize-8)/6)MX_CELL_SIZE(pBt)((int)(pBt->pageSize-8))walAssertLockmask(x)sqlite3WalDb(pWal,db)walEnableBlockingMs(pWal,ms)walDisableBlocking(x)walEnableBlocking(x)SQLITE_NO_TSANBYTESWAP32(x)( (((x)&0x000000FF)<<24) + (((x)&0x0000FF00)<<8) + (((x)&0x00FF0000)>>8) + (((x)&0xFF000000)>>24) )SEH_SET_ON_ERROR(X,Y)SEH_FREE_ON_ERROR(X,Y)SEH_INJECT_FAULTassert( pWal->nSehTry>0 );SEH_EXCEPT(X)VVA_ONLY(pWal->nSehTry--); assert( pWal->nSehTry==0 );SEH_TRYVVA_ONLY(pWal->nSehTry++);( sizeof(ht_slot)*HASHTABLE_NSLOT + HASHTABLE_NPAGE*sizeof(u32) )(HASHTABLE_NPAGE - (WALINDEX_HDR_SIZE/sizeof(u32)))(HASHTABLE_NPAGE*2)WAL_RDWRwalFrameOffset(iFrame,szPage)( WAL_HDRSIZE + ((iFrame)-1)*(i64)((szPage)+WAL_FRAME_HDRSIZE) )0x377f0682(sizeof(WalIndexHdr)*2+sizeof(WalCkptInfo))WALINDEX_LOCK_OFFSET(sizeof(WalIndexHdr)*2+offsetof(WalCkptInfo,aLock))(SQLITE_SHM_NLOCK-3)WAL_READ_LOCK(I)(3+(I))WALTRACE(X)assertTruncateConstraint(pPager)enable_simulated_io_errors()disable_simulated_io_errors()CHECK_PAGE(x)pager_set_pagehash(X)pager_pagehash(X)pager_datahash(X,Y)put32bits(A,B)sqlite3Put4byte((u8*)A,B)pagerUseWal(x)((x)->pWal!=0)USEFETCH(x)((x)->bUseFetch)MEMDBpPager->memDbJOURNAL_HDR_SZ(pPager)(pPager->sectorSize)JOURNAL_PG_SZ(pPager)((pPager->pageSize) + 8)PAGER_INCR(v)(EXCLUSIVE_LOCK+1)FILEHANDLEID(fd)(SQLITE_PTR_TO_INT(fd))PAGERID(p)(SQLITE_PTR_TO_INT(p->fd))PAGERTRACE(X)CKPT_SYNC_FLAGS(X)(((X)>>2)&0x03)WAL_SYNC_FLAGS(X)((X)&0x03)SQLITE_WAL_H((ROWSET_ALLOCATION_SIZE-8)/sizeof(struct RowSetEntry))ROWSET_ALLOCATION_SIZEPCACHE1_MIGHT_USE_GROUP_MUTEXpcache1LeaveMutex(X)assert((X)->mutex==0)pcache1EnterMutex(X)pcache1(GLOBAL(struct PCacheGlobal, pcache1_g))((p)->pLruNext!=0)PAGE_IS_PINNED(p)((p)->pLruNext==0)pageNotOnDirtyList(A,B)pageOnDirtyList(A,B)pcacheDump(X)pcachePageTrace(PGNO,X)pcacheTrace(X)TESTBIT(V,I)(V[I>>3]&(1<<(I&7)))!=0CLEARBIT(V,I)V[I>>3] &= ~(1<<(I&7))SETBIT(V,I)V[I>>3] |= (1<<(I&7))(BITVEC_USIZE/sizeof(Bitvec *))BITVEC_HASH(X)(((X)*1)%BITVEC_NINT)(BITVEC_NINT/2)(BITVEC_USIZE/sizeof(u32))(BITVEC_NELEM*BITVEC_SZELEM)(BITVEC_USIZE/sizeof(BITVEC_TELEM))BITVEC_TELEMBITVEC_USIZE(((BITVEC_SZ-(3*sizeof(u32)))/sizeof(Bitvec*))*sizeof(Bitvec*))UNIXVFS(VFSNAME,FINDER){ 3, sizeof(unixFile), MAX_PATHNAME, 0, VFSNAME, (void*)&FINDER, unixOpen, unixDelete, unixAccess, unixFullPathname, unixDlOpen, unixDlError, unixDlSym, unixDlClose, unixRandomness, unixSleep, unixCurrentTime, unixGetLastError, unixCurrentTimeInt64, unixSetSystemCall, unixGetSystemCall, unixNextSystemCall, }IOMETHODS(FINDER,METHOD,VERSION,CLOSE,LOCK,UNLOCK,CKLOCK,SHMMAP)static const sqlite3_io_methods METHOD = { VERSION, CLOSE, unixRead, unixWrite, unixTruncate, unixSync, unixFileSize, LOCK, UNLOCK, CKLOCK, unixFileControl, unixSectorSize, unixDeviceCharacteristics, SHMMAP, unixShmLock, unixShmBarrier, unixShmUnmap, unixFetch, unixUnfetch, }; static const sqlite3_io_methods *FINDER ## Impl(const char *z, unixFile *p){ UNUSED_PARAMETER(z); UNUSED_PARAMETER(p); return &METHOD; } static const sqlite3_io_methods *(*const FINDER)(const char*,unixFile *p) = FINDER ## Impl;(UNIX_SHM_BASE+SQLITE_SHM_NLOCK)((22+SQLITE_SHM_NLOCK)*4)HAVE_FULLFSYNCDOTLOCK_SUFFIX".lock"osSetPosixAdvisoryLock(h,x,t)osFcntl(h,F_SETLK,x)unixLogError(a,b,c)unixLogErrorAtLine(a,b,c,__LINE__)osLstat((int(*)(const char*,struct stat*))aSyscall[27].pCurrent)osReadlink((ssize_t(*)(const char*,char*,size_t))aSyscall[26].pCurrent)osGetpagesize((int(*)(void))aSyscall[25].pCurrent)osMremap((void*(*)(void*,size_t,size_t,int,...))aSyscall[24].pCurrent)osMunmap((int(*)(void*,size_t))aSyscall[23].pCurrent)osMmap((void*(*)(void*,size_t,int,int,int,off_t))aSyscall[22].pCurrent)osGeteuid((uid_t(*)(void))aSyscall[21].pCurrent)osFchown((int(*)(int,uid_t,gid_t))aSyscall[20].pCurrent)osRmdir((int(*)(const char*))aSyscall[19].pCurrent)osMkdir((int(*)(const char*,mode_t))aSyscall[18].pCurrent)osOpenDirectory((int(*)(const char*,int*))aSyscall[17].pCurrent)osUnlink((int(*)(const char*))aSyscall[16].pCurrent)osFallocate((int(*)(int,off_t,off_t))aSyscall[15].pCurrent)osFchmod((int(*)(int,mode_t))aSyscall[14].pCurrent)osPwrite64((ssize_t(*)(int,const void*,size_t,off64_t)) aSyscall[13].pCurrent)osPwrite((ssize_t(*)(int,const void*,size_t,off_t)) aSyscall[12].pCurrent)osWrite((ssize_t(*)(int,const void*,size_t))aSyscall[11].pCurrent)osPread64((ssize_t(*)(int,void*,size_t,off64_t))aSyscall[10].pCurrent)osPread((ssize_t(*)(int,void*,size_t,off_t))aSyscall[9].pCurrent)osRead((ssize_t(*)(int,void*,size_t))aSyscall[8].pCurrent)osFcntl((int(*)(int,int,...))aSyscall[7].pCurrent)osFtruncate((int(*)(int,off_t))aSyscall[6].pCurrent)osFstat((int(*)(int,struct stat*))aSyscall[5].pCurrent)osStat((int(*)(const char*,struct stat*))aSyscall[4].pCurrent)osGetcwd((char*(*)(char*,size_t))aSyscall[3].pCurrent)osAccess((int(*)(const char*,int))aSyscall[2].pCurrent)osClose((int(*)(int))aSyscall[1].pCurrent)osOpen((int(*)(const char*,int,int))aSyscall[0].pCurrent)F2FS_FEATURE_ATOMIC_WRITEF2FS_IOC_GET_FEATURES_IOR(F2FS_IOCTL_MAGIC, 12, u32)F2FS_IOC_ABORT_VOLATILE_WRITE_IO(F2FS_IOCTL_MAGIC, 5)F2FS_IOC_START_VOLATILE_WRITE_IO(F2FS_IOCTL_MAGIC, 3)F2FS_IOC_COMMIT_ATOMIC_WRITE_IO(F2FS_IOCTL_MAGIC, 2)F2FS_IOC_START_ATOMIC_WRITE_IO(F2FS_IOCTL_MAGIC, 1)F2FS_IOCTL_MAGIC0xf5HAVE_MREMAPthreadidpthread_self()IS_LOCK_ERROR(x)((x != SQLITE_OK) && (x != SQLITE_BUSY))osGetpid(X)(pid_t)getpid()HAVE_FCHMODSQLITE_MAX_SYMLINKSSQLITE_DEFAULT_PROXYDIR_PERMISSIONSSQLITE_FSFLAGS_IS_MSDOSHAVE_GETHOSTUUIDUSE_PREAD64USE_PREADHAVE_PWRITEHAVE_PREADSQLITE_ENABLE_LOCKING_STYLEOpHelp(X)"\0" X0xf01fc07f0x001fc07fUpperToLowerREAD_UTF8(zIn,zTerm,c)c = *(zIn++); if( c>=0xc0 ){ c = sqlite3Utf8Trans1[c-0xc0]; while( zIn<zTerm && (*zIn & 0xc0)==0x80 ){ c = (c<<6) + (0x3f & *(zIn++)); } if( c<0x80 || (c&0xFFFFF800)==0xD800 || (c&0xFFFFFFFE)==0xFFFE ){ c = 0xFFFD; } }WRITE_UTF16BE(zOut,c){ if( c<=0xFFFF ){ *zOut++ = (u8)((c>>8)&0x00FF); *zOut++ = (u8)(c&0x00FF); }else{ *zOut++ = (u8)(0x00D8 + (((c-0x10000)>>18)&0x03)); *zOut++ = (u8)(((c>>10)&0x003F) + (((c-0x10000)>>10)&0x00C0)); *zOut++ = (u8)(0x00DC + ((c>>8)&0x03)); *zOut++ = (u8)(c&0x00FF); } }WRITE_UTF16LE(zOut,c){ if( c<=0xFFFF ){ *zOut++ = (u8)(c&0x00FF); *zOut++ = (u8)((c>>8)&0x00FF); }else{ *zOut++ = (u8)(((c>>10)&0x003F) + (((c-0x10000)>>10)&0x00C0)); *zOut++ = (u8)(0x00D8 + (((c-0x10000)>>18)&0x03)); *zOut++ = (u8)(c&0x00FF); *zOut++ = (u8)(0x00DC + ((c>>8)&0x03)); } }WRITE_UTF8(zOut,c){ if( c<0x00080 ){ *zOut++ = (u8)(c&0xFF); } else if( c<0x00800 ){ *zOut++ = 0xC0 + (u8)((c>>6)&0x1F); *zOut++ = 0x80 + (u8)(c & 0x3F); } else if( c<0x10000 ){ *zOut++ = 0xE0 + (u8)((c>>12)&0x0F); *zOut++ = 0x80 + (u8)((c>>6) & 0x3F); *zOut++ = 0x80 + (u8)(c & 0x3F); }else{ *zOut++ = 0xF0 + (u8)((c>>18) & 0x07); *zOut++ = 0x80 + (u8)((c>>12) & 0x3F); *zOut++ = 0x80 + (u8)((c>>6) & 0x3F); *zOut++ = 0x80 + (u8)(c & 0x3F); } }SQLITE_THREADS_IMPLEMENTEDwsdPrngQR(a,b,c,d)( a += b, d ^= a, d = ROTL(d,16), c += d, b ^= c, b = ROTL(b,12), a += b, d ^= a, d = ROTL(d, 8), c += d, b ^= c, b = ROTL(b, 7))ROTL(a,b)(((a) << (b)) | ((a) >> (32 - (b))))etBUFSIZEFLAG_STRINGtest_oom_breakpoint(X)GLOBAL(struct Mem0Global, mem0)SQLITE3_MUTEX_INITIALIZER(id){ PTHREAD_MUTEX_INITIALIZER }SQLITE_MUTEX_NREFSQLITE_MALLOCSIZE(x)malloc_usable_size(x)SQLITE_USE_MALLOC_USABLE_SIZESQLITE_USE_MALLOC_HSQLITE_REALLOC(x,y)realloc((x),(y))SQLITE_FREE(x)free(x)SQLITE_MALLOC(x)malloc(x)wsdHookswsdHooksInitGLOBAL(sqlite3_vfs *, vfsList)DO_OS_MALLOC_TEST(x)((((i64)0x1a640)<<32)|0x1072fdff)wsdStatwsdStatInitExpandBlob(P)(((P)->flags&MEM_Zero)?sqlite3VdbeMemExpandBlob(P):0)sqlite3VdbeAssertAbortable(V)sqlite3VdbeIncrWriteCounter(V,C)swapMixedEndianFloat(X)MemNullNochng(X)(((X)->flags&MEM_TypeMask)==(MEM_Null|MEM_Zero) && (X)->n==0 && (X)->u.nZero==0)MemSetTypeFlag(p,f)((p)->flags = ((p)->flags&~(MEM_TypeMask|MEM_Zero))|f)VdbeMemDynamic(X)(((X)->flags&(MEM_Agg|MEM_Dyn))!=0)0x0dbf0x003f0x0000MEMCELLSIZEoffsetof(Mem,db)VdbeFrameMem(p)((Mem *)&((u8 *)p)[ROUND8(sizeof(VdbeFrame))])SQLITE_FRAME_MAGIC0x879fb71eIsNullCursor(P)((P)->eCurType==CURTYPE_PSEUDO && (P)->nullRow && (P)->seekResult==0)VDBE_DISPLAY_P4SQLITE_VDBEINT_HSQLITE_DEFAULT_LOOKASIDE1200,40CTIMEOPT_VAL2(opt)CTIMEOPT_VAL2_(opt)CTIMEOPT_VAL2_(opt1,opt2)#opt1 "," #opt2OpenCounter(X)SimulateDiskfullError(A)SimulateIOError(A)SimulateIOErrorBenign(X)TIMER_ELAPSED((sqlite_uint64)0)TIMER_ENDTIMER_START_OS_COMMON_H_IS_STMT_SCANSTATUS(db)MEMTYPE_LOOKASIDEsqlite3MemdebugNoType(X,Y)sqlite3MemdebugHasType(X,Y)sqlite3MemdebugSetType(X,Y)sqlite3VdbeIOTraceSql(X)IOTRACE(A)sqlite3ConnectionClosed(x)sqlite3ConnectionUnlocked(x)sqlite3ConnectionBlocked(x,y)SQLITE_FAULTINJECTOR_COUNTSQLITE_FAULTINJECTOR_MALLOCsqlite3VtabInSync(db)((db)->nVTrans>0 && (db)->aVTrans==0)sqlite3FileSuffix3(X,Y)putVarintgetVarintputVarint32(A,B)(u8)(((u32)(B)<(u32)0x80)?(*(A)=(unsigned char)(B)),1: sqlite3PutVarint((A),(B)))getVarint32NR(A,B)B=(u32)*(A);if(B>=0x80)sqlite3GetVarint32((A),(u32*)&(B))getVarint32(A,B)(u8)((*(A)<(u8)0x80)?((B)=(u32)*(A)),1:sqlite3GetVarint32((A),(u32 *)&(B)))sqlite3IsToplevel(p)((p)->pToplevel==0)sqlite3ParseToplevel(p)((p)->pToplevel ? (p)->pToplevel : (p))sqlite3SetMakeRecordP5(A,B)sqlite3CodecQueryParameters(A,B,C)sqlite3ColumnPropertiesFromName(T,C)IsOvfl(X)(((X)&EXP754)==EXP754)IsNaN(X)(((X)&EXP754)==EXP754 && ((X)&MAN754)!=0)MAN754((((u64)1)<<52)-1)EXP754(((u64)0x7ff)<<52)sqlite3MutexWarnOnContention(x)sqlite3StackFreeNN(D,P)sqlite3DbFreeNN(D,P)sqlite3StackFree(D,P)sqlite3DbFree(D,P)sqlite3StackAllocRawNN(D,N)sqlite3DbMallocRawNN(D,N)sqlite3StackAllocRaw(D,N)sqlite3DbMallocRaw(D,N)sqlite3StrNICmpsqlite3Strlen30NN(C)(strlen(C)&0x3fffffff)sqlite3JsonId2(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x46)sqlite3JsonId1(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x42)sqlite3Isquote(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x80)sqlite3Tolower(x)(sqlite3UpperToLower[(unsigned char)(x)])sqlite3Isxdigit(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x08)sqlite3Isdigit(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x04)sqlite3Isalpha(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x02)sqlite3Isalnum(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x06)sqlite3Isspace(x)(sqlite3CtypeMap[(unsigned char)(x)]&0x01)sqlite3Toupper(x)((x)&~(sqlite3CtypeMap[(unsigned char)(x)]&0x20))SQLITE_ENABLE_FTS3SQLITE_CORRUPT_PGNO(P)sqlite3CorruptError(__LINE__)SQLITE_IOERR_NOMEM_BKPTSQLITE_NOMEM_BKPTsqlite3CantopenError(__LINE__)SQLITE_MISUSE_BKPTsqlite3MisuseError(__LINE__)SQLITE_CORRUPT_BKPTSQLITE_SKIP_UTF8(zIn){ if( (*(zIn++))>=0xc0 ){ while( (*zIn & 0xc0)==0x80 ){ zIn++; } } }(sqlite3Config.neverCorrupt==0)Tuning(X)SQLITE_NTUNE0x0003isMalloced(X)(((X)->printfFlags & SQLITE_PRINTF_MALLOCED)!=0)OPFLAG_NOCHNG_MAGIC0x6dOPFLAG_LENGTHARGOPFLAG_ISNOOPOPFLAG_EPHEMIN_SPECIAL_PARSE(pParse->eParseMode!=PARSE_MODE_NORMAL)IN_RENAME_OBJECT(pParse->eParseMode>=PARSE_MODE_RENAME)IN_DECLARE_VTAB(pParse->eParseMode==PARSE_MODE_DECLARE_VTAB)PARSE_TAIL(X)(((char*)(X))+PARSE_RECURSE_SZ)(sizeof(Parse)-PARSE_RECURSE_SZ)PARSE_RECURSE_SZoffsetof(Parse,sLastToken)(offsetof(Parse,aTempReg)-offsetof(Parse,zErrMsg))PARSE_HDR(X)(((char*)(X))+offsetof(Parse,zErrMsg))DbMaskNonZero(M)((M)!=0)DbMaskAllZero(M)((M)==0)DbMaskSet(M,I)((M)|=(((yDbMask)1)<<(I)))DbMaskZero(M)((M)=0)DbMaskTest(M,I)(((M)&(((yDbMask)1)<<(I)))!=0)IgnorableOrderby(X)((X->eDest)<=SRT_Fifo)IgnorableDistinct(X)((X->eDest)<=SRT_DistQueue)IsNestedFrom(X)((X)->fg.isSubquery && ((X)->u4.pSubq->pSelect->selFlags&SF_NestedFrom)!=0)0x40000000x08000000x04000000x02000000x0100000SF_WhereBegin0x00800000x00400000x00200000x0010000SF_MaybeConvert0x00080000x00040000x0002000SF_MinMaxAgg0x00010000x00008000x00004000x00002000x00001000x00000800x00000400x0000020SF_HasAgg0x00000100x00000080x00000040x00000020x00000010x040000NC_UAggInfo0x00002eEU4_EXPREU4_IDXEU4_NONEIsWindowFunc(p)( ExprHasProperty((p), EP_WinFunc) && p->y.pWin->eFrmType!=TK_FILTER )EXPR_TOKENONLYSIZEoffsetof(Expr,pLeft)EXPR_REDUCEDSIZEoffsetof(Expr,iTable)ExprClearVVAProperties(E)ExprHasVVAProperty(E,P)ExprSetVVAProperty(E,P)ExprUseYSub(E)(((E)->flags&EP_Subrtn)!=0)ExprUseYWin(E)(((E)->flags&EP_WinFunc)!=0)ExprUseYTab(E)(((E)->flags&(EP_WinFunc|EP_Subrtn))==0)ExprUseXSelect(E)(((E)->flags&EP_xIsSelect)!=0)ExprUseXList(E)(((E)->flags&EP_xIsSelect)==0)ExprUseWJoin(E)(((E)->flags&(EP_InnerON|EP_OuterON))!=0)ExprUseWOfst(E)(((E)->flags&(EP_InnerON|EP_OuterON))==0)ExprUseUValue(E)(((E)->flags&EP_IntValue)!=0)ExprUseUToken(E)(((E)->flags&EP_IntValue)==0)ExprIsFullSize(E)(((E)->flags&(EP_Reduced|EP_TokenOnly))==0)ExprAlwaysFalse(E)(((E)->flags&(EP_OuterON|EP_IsFalse))==EP_IsFalse)ExprAlwaysTrue(E)(((E)->flags&(EP_OuterON|EP_IsTrue))==EP_IsTrue)ExprClearProperty(E,P)(E)->flags&=~(P)ExprSetProperty(E,P)(E)->flags|=(P)ExprHasAllProperty(E,P)(((E)->flags&(P))==(P))ExprHasProperty(E,P)(((E)->flags&(P))!=0)(EP_Collate|EP_Subquery|EP_HasFunc)AggInfoFuncReg(A,I)((A)->iFirstReg+(A)->nColumn+(I))AggInfoColumnReg(A,I)((A)->iFirstReg+(I))SQLITE_TOKEN_KEYWORDSQLITE_TOKEN_QUOTEDIsUniqueIndex(X)((X)->onError!=OE_None)IsPrimaryKeyIndex(X)((X)->idxType==SQLITE_IDXTYPE_PRIMARYKEY)VisibleRowid(X)(((X)->tabFlags & TF_NoVisibleRowid)==0)HasRowid(X)(((X)->tabFlags & TF_WithoutRowid)==0)IsOrdinaryHiddenColumn(X)IsHiddenColumn(X)(((X)->colFlags & COLFLAG_HIDDEN)!=0)ExprIsVtab(X)((X)->op==TK_COLUMN && (X)->y.pTab->eTabType==TABTYP_VTAB)IsVirtual(X)((X)->eTabType==TABTYP_VTAB)IsOrdinaryTable(X)((X)->eTabType==TABTYP_NORM)IsView(X)((X)->eTabType==TABTYP_VIEW)TABTYP_NORMTF_HasStat40x000000600x90sqlite3IsNumericAffinity(X)((X)>=SQLITE_AFF_NUMERIC)0x00620x0060COLFLAG_SORTERREFINTERNAL_FUNCTION(zName,nArg,xFunc){nArg, SQLITE_FUNC_BUILTIN| SQLITE_FUNC_INTERNAL|SQLITE_UTF8|SQLITE_FUNC_CONSTANT, 0, 0, xFunc, 0, 0, 0, #zName, {0} }WAGGREGATE(zName,nArg,arg,nc,xStep,xFinal,xValue,xInverse,f){nArg, SQLITE_FUNC_BUILTIN|SQLITE_UTF8|(nc*SQLITE_FUNC_NEEDCOLL)|f, SQLITE_INT_TO_PTR(arg), 0, xStep,xFinal,xValue,xInverse,#zName, {0}}LIKEFUNC(zName,nArg,arg,flags){nArg, SQLITE_FUNC_BUILTIN|SQLITE_FUNC_CONSTANT|SQLITE_UTF8|flags, (void *)arg, 0, likeFunc, 0, 0, 0, #zName, {0} }STR_FUNCTION(zName,nArg,pArg,bNC,xFunc){nArg, SQLITE_FUNC_BUILTIN| SQLITE_FUNC_SLOCHNG|SQLITE_UTF8|(bNC*SQLITE_FUNC_NEEDCOLL), pArg, 0, xFunc, 0, 0, 0, #zName, }FUNCTION2(zName,nArg,iArg,bNC,xFunc,extraFlags){nArg, SQLITE_FUNC_BUILTIN| SQLITE_FUNC_CONSTANT|SQLITE_UTF8|(bNC*SQLITE_FUNC_NEEDCOLL)|extraFlags, SQLITE_INT_TO_PTR(iArg), 0, xFunc, 0, 0, 0, #zName, {0} }PURE_DATE(zName,nArg,iArg,bNC,xFunc){nArg, SQLITE_FUNC_BUILTIN| SQLITE_FUNC_SLOCHNG|SQLITE_UTF8|SQLITE_FUNC_CONSTANT, (void*)&sqlite3Config, 0, xFunc, 0, 0, 0, #zName, {0} }DFUNCTION(zName,nArg,iArg,bNC,xFunc){nArg, SQLITE_FUNC_BUILTIN|SQLITE_FUNC_SLOCHNG|SQLITE_UTF8, 0, 0, xFunc, 0, 0, 0, #zName, {0} }TEST_FUNC(zName,nArg,iArg,mFlags){nArg, SQLITE_FUNC_BUILTIN| SQLITE_UTF8|SQLITE_FUNC_INTERNAL|SQLITE_FUNC_TEST| SQLITE_FUNC_INLINE|SQLITE_FUNC_CONSTANT|(mFlags), SQLITE_INT_TO_PTR(iArg), 0, noopFunc, 0, 0, 0, #zName, {0} }INLINE_FUNC(zName,nArg,iArg,mFlags){nArg, SQLITE_FUNC_BUILTIN| SQLITE_UTF8|SQLITE_FUNC_INLINE|SQLITE_FUNC_CONSTANT|(mFlags), SQLITE_INT_TO_PTR(iArg), 0, noopFunc, 0, 0, 0, #zName, {0} }JFUNCTION(zName,nArg,bUseCache,bWS,bRS,bJsonB,iArg,xFunc){nArg, SQLITE_FUNC_BUILTIN|SQLITE_DETERMINISTIC|SQLITE_FUNC_CONSTANT| SQLITE_UTF8|((bUseCache)*SQLITE_FUNC_RUNONLY)| ((bRS)*SQLITE_SUBTYPE)|((bWS)*SQLITE_RESULT_SUBTYPE), SQLITE_INT_TO_PTR(iArg|((bJsonB)*JSON_BLOB)),0,xFunc,0, 0, 0, #zName, {0} }MFUNCTION(zName,nArg,xPtr,xFunc){nArg, SQLITE_FUNC_BUILTIN|SQLITE_FUNC_CONSTANT|SQLITE_UTF8, xPtr, 0, xFunc, 0, 0, 0, #zName, {0} }SFUNCTION(zName,nArg,iArg,bNC,xFunc){nArg, SQLITE_FUNC_BUILTIN|SQLITE_UTF8|SQLITE_DIRECTONLY|SQLITE_FUNC_UNSAFE, SQLITE_INT_TO_PTR(iArg), 0, xFunc, 0, 0, 0, #zName, {0} }VFUNCTION(zName,nArg,iArg,bNC,xFunc){nArg, SQLITE_FUNC_BUILTIN|SQLITE_UTF8|(bNC*SQLITE_FUNC_NEEDCOLL), SQLITE_INT_TO_PTR(iArg), 0, xFunc, 0, 0, 0, #zName, {0} }FUNCTION(zName,nArg,iArg,bNC,xFunc){nArg, SQLITE_FUNC_BUILTIN| SQLITE_FUNC_CONSTANT|SQLITE_UTF8|(bNC*SQLITE_FUNC_NEEDCOLL), SQLITE_INT_TO_PTR(iArg), 0, xFunc, 0, 0, 0, #zName, {0} }SQLITE_FUNC_BUILTINSQLITE_FUNC_RUNONLYSQLITE_FUNC_TEST0xa70xba0xce0x76ConstFactorOk(P)((P)->okConstFactor)OptimizationEnabled(db,mask)(((db)->dbOptFlags&(mask))==0)OptimizationDisabled(db,mask)(((db)->dbOptFlags&(mask))!=0)SQLITE_AllOptsSQLITE_ReleaseRegSQLITE_CursorHintsSQLITE_CountOfViewSQLITE_CommentsHI(0x00040)SQLITE_AttachWriteHI(0x00020)SQLITE_AttachCreateHI(0x00010)SQLITE_FkNoActionHI(0x00008)SQLITE_ReadUncommitHI(0x00004)SQLITE_CorruptRdOnlyHI(0x00002)SQLITE_CountRowsHI(0x00001)HI(X)((u64)(X)<<32)ENC(db)((db)->enc)SCHEMA_ENC(db)((db)->aDb[0].pSchema->enc)(SQLITE_MAX_ATTACHED+2)SQLITE_FUNC_HASH(C,L)(((C)+(L))%SQLITE_FUNC_HASH_SZ)EnableLookasidedb->lookaside.bDisable--; db->lookaside.sz=db->lookaside.bDisable?0:db->lookaside.szTrueDisableLookasidedb->lookaside.bDisable++;db->lookaside.sz=0(SQLITE_LIMIT_WORKER_THREADS+1)DbClearProperty(D,I,P)(D)->aDb[I].pSchema->schemaFlags&=~(P)DbSetProperty(D,I,P)(D)->aDb[I].pSchema->schemaFlags|=(P)DbHasAnyProperty(D,I,P)(((D)->aDb[I].pSchema->schemaFlags&(P))!=0)DbHasProperty(D,I,P)(((D)->aDb[I].pSchema->schemaFlags&(P))==(P))MUTEX_LOGIC(X)SQLITE_MUTEX_PTHREADS0x0400x0200x0100x0080x004sqlite3VdbeScanStatusCounters(a,b,c,d)sqlite3VdbeScanStatusRange(a,b,c,d)sqlite3VdbeScanStatus(a,b,c,d,e,f)VDBE_OFFSET_LINENO(x)VdbeCoverageEqNe(v)VdbeCoverageNeverNullIf(v,x)VdbeCoverageNeverNull(v)VdbeCoverageNeverTaken(v)VdbeCoverageAlwaysTaken(v)VdbeCoverageIf(v,x)VdbeCoverage(v)VdbeModuleComment(X)VdbeNoopComment(X)sqlite3VdbeNoopComment XVdbeComment(X)sqlite3VdbeComment Xsqlite3VdbeReleaseRegisters(P,A,N,M,F)sqlite3ExplainBreakpoint(A,B)ExplainQueryPlanParent(P)sqlite3VdbeExplainParent(P)ExplainQueryPlanPop(P)sqlite3VdbeExplainPop(P)ExplainQueryPlan2(V,P)ExplainQueryPlan(P)sqlite3VdbeExplain Psqlite3VdbeNoJumpsOutsideSubrtn(A,B,C,D)sqlite3VdbeVerifyAbortable(A,B)sqlite3VdbeVerifyNoResultRow(A)sqlite3VdbeVerifyNoMallocRequired(A,B)OPFLG_INITIALIZER{ 0x00, 0x00, 0x00, 0x00, 0x10, 0x00, 0x41, 0x00, 0x81, 0x01, 0x01, 0x81, 0x83, 0x83, 0x01, 0x01, 0x03, 0x03, 0x01, 0x12, 0x01, 0xc9, 0xc9, 0xc9, 0xc9, 0x01, 0x49, 0x49, 0x49, 0x49, 0xc9, 0x49, 0xc1, 0x01, 0x41, 0x41, 0xc1, 0x01, 0x41, 0x41, 0x41, 0x41, 0x41, 0x26, 0x26, 0x41, 0x23, 0x0b, 0x81, 0x01, 0x03, 0x03, 0x03, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x0b, 0x01, 0x03, 0x03, 0x01, 0x41, 0x01, 0x00, 0x00, 0x02, 0x02, 0x08, 0x00, 0x10, 0x10, 0x10, 0x00, 0x10, 0x00, 0x10, 0x10, 0x00, 0x00, 0x10, 0x10, 0x00, 0x00, 0x00, 0x02, 0x02, 0x02, 0x00, 0x00, 0x12, 0x1e, 0x20, 0x40, 0x00, 0x00, 0x00, 0x10, 0x10, 0x00, 0x40, 0x40, 0x26, 0x26, 0x26, 0x26, 0x26, 0x26, 0x26, 0x26, 0x26, 0x26, 0x00, 0x40, 0x12, 0x40, 0x40, 0x10, 0x00, 0x00, 0x00, 0x40, 0x00, 0x40, 0x40, 0x10, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x50, 0x00, 0x40, 0x04, 0x04, 0x00, 0x40, 0x50, 0x40, 0x10, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x10, 0x00, 0x06, 0x10, 0x00, 0x04, 0x1a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x10, 0x50, 0x40, 0x00, 0x10, 0x10, 0x02, 0x12, 0x12, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,}OPFLG_JUMP0OPFLG_NCYCLEOPFLG_OUT3OPFLG_OUT2OPFLG_IN3OPFLG_IN2OPFLG_IN1OP_AbortableOP_ReleaseRegOP_CursorHintOP_ColumnsUsedADDR(X)(~(X))COLNAME_COLUMNCOLNAME_TABLECOLNAME_DATABASE(-17)(-16)(-15)(-14)(-13)(-12)(-11)(-10)P4_EXPR(-9)(-8)(-7)SQLITE_VDBE_Hsqlite3BtreeSeekCount(X)BTREE_FORDELETEBTREE_HINT_RANGESQLITE_N_BTREE_METASQLITE_BTREE_Hsqlite3PagerWalDb(x,y)sqlite3PagerWalWriteLock(y,z)0x38PAGER_SYNCHRONOUS_NORMALisOpen(pFd)((pFd)->pMethods!=0)isWalMode(x)((x)==PAGER_JOURNALMODE_WAL)PAGER_SJ_PGNO(x)((x)->lckPgno)PAGER_SJ_PGNO_COMPUTED(x)((Pgno)((PENDING_BYTE/((x)->pageSize))+1))SQLITE_PAGER_HSQLITE_FCNTL_DB_UNCHANGEDSHARED_FIRST(PENDING_BYTE+2)RESERVED_BYTE(PENDING_BYTE+1)PENDING_BYTESQLITE_TEMP_FILE_PREFIX"etilqs_"SQLITE_MAX_PATHLENSET_FULLSYNC(x,y)SQLITE_OS_WINSQLITE_OS_OTHERSQLITE_OS_KVSQLITE_OS_UNIXSQLITE_OS_SETUP_H_SQLITE_OS_H_(((Bitmask)1)<<(BMS-1))((Bitmask)-1)SMASKBIT32(n)((n)<=31?((unsigned int)1)<<(n):0)MASKBIT32(n)(((unsigned int)1)<<(n))MASKBIT64(n)(((u64)1)<<(n))MASKBIT(n)(((Bitmask)1)<<(n))((int)(sizeof(Bitmask)*8))UNUSED_PARAMETER2(x,y)UNUSED_PARAMETER(x),UNUSED_PARAMETER(y)sqlite3GlobalConfigGLOBAL(t,v)SQLITE_WSDSQLITE_DYNAMIC((sqlite3_destructor_type)sqlite3OomClear)IsPowerOfTwo(X)SCHEMA_TABLE(x)((!OMIT_TEMPDB)&&(x==1)?LEGACY_TEMP_SCHEMA_TABLE:LEGACY_SCHEMA_TABLE)WHERETRACE(K,X)TREETRACE_ENABLEDTREETRACE(K,P,S,X)EIGHT_BYTE_ALIGNMENT(X)((((uptr)(X) - (uptr)0)&7)==0)ROUNDDOWN8(x)((x)&~7)ROUND8P(x)(x)ROUND8(x)(((x)+7)&~7)(((i64)-1) - LARGEST_INT64)(0xffffffff|(((u64)0xffffffff)<<32))(0xffffffff|(((i64)0x7fffffff)<<32))SQLITE_UTF16NATIVESQLITE_OVERFLOW(P,S,E)(((uptr)(S)<(uptr)(P))&&((uptr)(E)>(uptr)(P)))SQLITE_WITHIN(P,S,E)(((uptr)(P)>=(uptr)(S))&&((uptr)(P)<(uptr)(E)))SQLITE_PTRSIZE__SIZEOF_POINTER__LOGEST_MAX(-32768)((((u64)1)<<32)-1)INT8_TYPEint8_tUINT8_TYPEINT16_TYPEint16_tSQLITE_ASCIISWAP(TYPE,A,B){TYPE t=A; A=B; B=t;}MAX(A,B)((A)>(B)?(A):(B))MIN(A,B)((A)<(B)?(A):(B))SQLITE_DEFAULT_RECURSIVE_TRIGGERS(1e99)TK_ADDTK_ALTERTK_INDEXTK_ELSETK_THENTK_WHENTK_NOTHINGTK_INTOTK_WHERETK_HAVINGTK_GROUPTK_USINGTK_JOINTK_FROMTK_DISTINCTTK_VALUESTK_DROPTK_FOREIGNTK_DEFERRABLETK_SETTK_AUTOINCRTK_REFERENCESTK_CHECKTK_UNIQUETK_PRIMARYTK_DEFAULTTK_CONSTRAINTTK_INDEXEDTK_ONTK_ANYTK_CTIME_KWTK_RENAMETK_REINDEXTK_MATERIALIZEDTK_ALWAYSTK_GENERATEDTK_OTHERSTK_EXCLUDETK_PARTITIONTK_LASTTK_FIRSTTK_NULLSTK_WITHTK_VIRTUALTK_VIEWTK_VACUUMTK_RESTRICTTK_REPLACETK_RECURSIVETK_PRAGMATK_OFFSETTK_OFTK_KEYTK_INITIALLYTK_IGNORETK_FORTK_DOTK_COLUMNKWTK_ESCAPETK_LIKE_KWTK_FAILTK_EACHTK_DETACHTK_DESCTK_DATABASETK_CONFLICTTK_CASCADETK_BYTK_ATTACHTK_ASCTK_ANALYZETK_AFTERTK_ACTIONTK_ABORTTK_WITHOUTTK_TEMPTK_IFTK_TOTK_RELEASETK_SAVEPOINTTK_ENDTK_COMMITTK_IMMEDIATETK_TRANSACTIONTK_BEGINTK_PLANTK_QUERYTK_EXPLAINsqliteHashCount(H)sqliteHashData(E)sqliteHashNext(E)sqliteHashFirst(H)SQLITE_HASH_Hunlikely(X)likely(X)IS_BIG_INT(X)(((X)&~(i64)0xffffffff)!=0)SQLITE_NEED_ERR_NAMESQLITE_HAVE_OS_TRACEOSTRACE(X)ONLY_IF_REALLOC_STRESS(X)OK_IF_ALWAYS_FALSE(X)OK_IF_ALWAYS_TRUE(X)VVA_ONLY(X)TESTONLY(X)SQLITE_SYSTEM_MALLOCSQLITE_DIRECT_OVERFLOW_READSQLITE_USE_SEHSQLITE_INLINE__attribute__((always_inline)) inlineSQLITE_NOINLINE__attribute__((noinline))SQLITE_PTR_TO_INT(X)((int)(intptr_t)(X))SQLITE_INT_TO_PTR(X)((void*)(intptr_t)(X))AtomicStore(PTR,VAL)__atomic_store_n((PTR),(VAL),__ATOMIC_RELAXED)AtomicLoad(PTR)__atomic_load_n((PTR),__ATOMIC_RELAXED)SQLITECONFIG_HSQLITE_MUTEX_STATIC_TEMPDIR__attribute__((fallthrough));SQLITE_HAVE_C99_MATH_FUNCSMSVC_VERSIONGCC_VERSION(__GNUC__*1000000+__GNUC_MINOR__*1000+__GNUC_PATCHLEVEL__)HAVE_LSTATHAVE_READLINKHAVE_FCHOWNSQLITE_MSVC_HSQLITE_TCLAPISQLITEINT_HSQLITE_PRIVATESQLITE_COREdefined(_MSC_VER) && !defined(_WIN64)!defined(HAVE_LOG2) && defined(_MSC_VER) && _MSC_VER<1800defined(__RTP__) || defined(_WRS_KERNEL)defined(__GNUC__) && !defined(SQLITE_DISABLE_INTRINSIC)defined(_MSC_VER) && !defined(SQLITE_DISABLE_INTRINSIC)MSVC_VERSION==0 || MSVC_VERSION>=1800defined(__GNUC__) && !defined(_GNU_SOURCE)defined(__OpenBSD__) && !defined(_BSD_SOURCE)defined(__has_attribute)__has_attribute(fallthrough)!defined(deliberate_fall_through)defined(_HAVE_MINGW_H)defined(_HAVE__MINGW_H)!defined(_USE_32BIT_TIME_T) && !defined(_USE_64BIT_TIME_T) && \defined(_HAVE_SQLITE_CONFIG_H) && !defined(SQLITECONFIG_H)SQLITE_DEFAULT_PAGE_SIZE>SQLITE_MAX_PAGE_SIZESQLITE_MAX_DEFAULT_PAGE_SIZE>SQLITE_MAX_PAGE_SIZEdefined(__BORLANDC__)GCC_VERSION>=4007000 || __has_extension(c_atomic)HAVE_STDINT_HHAVE_INTTYPES_Hdefined(HAVE_STDINT_H)defined(__PTRDIFF_TYPE__)!defined(__GNUC__)defined(__GNUC__)defined(_MSC_VER) && _MSC_VER>=1310defined(SQLITE_COVERAGE_TEST) || defined(__STRICT_ANSI__)!defined(SQLITE_DISABLE_INTRINSIC)defined(_MSC_VER) && _MSC_VER>=1400defined(_MSC_VER) && !defined(SQLITE_OMIT_SEH)defined(SQLITE_DIRECT_OVERFLOW_READ) && SQLITE_DIRECT_OVERFLOW_READ+1==1!defined(SQLITE_THREADSAFE)defined(THREADSAFE)!defined(SQLITE_DEFAULT_MEMSTATUS)defined(SQLITE_SYSTEM_MALLOC) \!defined(SQLITE_MALLOC_SOFT_LIMIT)!defined(_XOPEN_SOURCE) && !defined(__DARWIN__) && !defined(__APPLE__)!defined(NDEBUG) && !defined(SQLITE_DEBUG)defined(NDEBUG) && defined(SQLITE_DEBUG)!defined(SQLITE_ENABLE_EXPLAIN_COMMENTS) && defined(SQLITE_DEBUG)defined(SQLITE_COVERAGE_TEST) || defined(SQLITE_DEBUG)!defined(NDEBUG) || defined(SQLITE_COVERAGE_TEST)defined(SQLITE_MUTATION_TEST)defined(SQLITE_TEST_REALLOC_STRESS)defined(SQLITE_FORCE_OS_TRACE) || defined(SQLITE_TEST) || \defined(SQLITE_HAVE_OS_TRACE) || defined(SQLITE_TEST) || \SQLITE_OMIT_EXPLAINdefined(SQLITE_OMIT_VIRTUALTABLE) && !defined(SQLITE_OMIT_ALTERTABLE)SQLITE_INLINE_MEMCPYSQLITE_OMIT_TEMPDBSQLITE_TEMP_STORE==3 || SQLITE_THREADSAFE==0SQLITE_DEFAULT_WORKER_THREADS>SQLITE_MAX_WORKER_THREADSdefined(SQLITE_MMAP_READWRITE) && defined(SQLITE_ENABLE_BATCH_ATOMIC_WRITE)MINMAX'A' == '\301'HAVE_INT16_THAVE_UINT8_THAVE_INT8_Tdefined(__SIZEOF_POINTER__)SQLITE_PTRSIZE==4defined(__BYTE_ORDER__) && __BYTE_ORDER__==__ORDER_BIG_ENDIAN__defined(__BYTE_ORDER__) && __BYTE_ORDER__==__ORDER_LITTLE_ENDIAN__defined(__BIG_ENDIAN__) && __BIG_ENDIAN__==1defined(i386)    || defined(__i386__)      || defined(_M_IX86) ||    \defined(sparc)   || defined(__ARMEB__)     || defined(__AARCH64EB__)SQLITE_BYTEORDER==4321SQLITE_BYTEORDER==1234SQLITE_PTRSIZE==8SQLITE_4_BYTE_ALIGNED_MALLOCdefined(__OpenBSD__) || defined(__QNXNTO__)__APPLE__defined(__linux__) \SQLITE_DEFAULT_MMAP_SIZE>SQLITE_MAX_MMAP_SIZEdefined(SQLITE_DEBUG) \SQLITE_OMIT_WSDSQLITE_BITMASK_TYPE!defined(SQLITE_OS_KV) && !defined(SQLITE_OS_OTHER) && \defined(_WIN32) || defined(WIN32) || defined(__CYGWIN__) || \SQLITE_OS_OTHER+1>1SQLITE_OS_KV+1>1SQLITE_OS_UNIX+1>1SQLITE_OS_WIN+1>1SET_FULLSYNCSQLITE_OMIT_WALSQLITE_ENABLE_SNAPSHOT!defined(SQLITE_OMIT_WAL) && defined(SQLITE_ENABLE_SETLK_TIMEOUT)SQLITE_ENABLE_ZIPVFS!defined(NDEBUG) || defined(SQLITE_TEST)SQLITE_TESTdefined(SQLITE_USE_SEH) && !defined(SQLITE_OMIT_WAL)SQLITE_MAX_MMAP_SIZE>0SQLITE_OMIT_SHARED_CACHESQLITE_ENABLE_CURSOR_HINTSSQLITE_OMIT_INCRBLOB!defined(SQLITE_OMIT_SHARED_CACHE) && SQLITE_THREADSAFESQLITE_ENABLE_EXPLAIN_COMMENTSSQLITE_VDBE_COVERAGEdefined(SQLITE_ENABLE_STMT_SCANSTATUS) || defined(VDBE_PROFILE)defined(SQLITE_DEBUG) && !defined(SQLITE_TEST_REALLOC_STRESS)defined(SQLITE_DEBUG) && !defined(SQLITE_OMIT_EXPLAIN)SQLITE_ENABLE_BYTECODE_VTABSQLITE_ENABLE_MODULE_COMMENTSdefined(SQLITE_DEBUG) || defined(VDBE_PROFILE)defined(SQLITE_ENABLE_CURSOR_HINTS) && defined(SQLITE_DEBUG)_PCACHE_H_SQLITE_CHECK_PAGESdefined(SQLITE_CHECK_PAGES) || defined(SQLITE_DEBUG)SQLITE_ENABLE_MEMORY_MANAGEMENT!SQLITE_THREADSAFESQLITE_THREADSAFE && !defined(SQLITE_MUTEX_NOOP)SQLITE_MUTEX_OMITSQLITE_EXTRA_DURABLESQLITE_OMIT_TWOSIZE_LOOKASIDESQLITE_ENABLE_PREUPDATE_HOOKSQLITE_ENABLE_UNLOCK_NOTIFYSQLITE_ENABLE_COSTMULTdefined(SQLITE_ENABLE_HIDDEN_COLUMNS)!defined(SQLITE_OMIT_VIRTUALTABLE)SQLITE_ALLOW_ROWID_IN_VIEWSQLITE_ENABLE_STAT4SQLITE_MAX_VARIABLE_NUMBER<32767SQLITE_MAX_EXPR_DEPTH>0SQLITE_OMIT_WINDOWFUNCSQLITE_MAX_ATTACHED>30defined(SQLITE_DEBUG) || defined(SQLITE_COVERAGE_TEST)SQLITE_OMIT_ALTERTABLEdefined(SQLITE_OMIT_ALTERTABLE)defined(SQLITE_OMIT_VIRTUALTABLE) && defined(SQLITE_OMIT_ALTERTABLE)SQLITE_ENABLE_SQLLOGSQLITE_OMIT_CTEdefined(SQLITE_DEBUG) || defined(SQLITE_ENABLE_CORRUPT_PGNO)defined(SQLITE_OMIT_VIRTUALTABLE)defined(SQLITE_ENABLE_FTS4) && !defined(SQLITE_ENABLE_FTS3)SQLITE_USE_ALLOCASQLITE_ENABLE_MEMSYS5SQLITE_ENABLE_MEMSYS3!defined(SQLITE_MUTEX_OMIT) && !defined(SQLITE_MUTEX_NOOP)defined(SQLITE_ENABLE_MULTITHREADED_CHECKS) && !defined(SQLITE_MUTEX_OMIT)defined(SQLITE_DEBUG) || defined(SQLITE_HAVE_OS_TRACE)defined(SQLITE_TEST)SQLITE_OMIT_TRIGGERdefined(SQLITE_ENABLE_STAT4) || defined(SQLITE_DEBUG)SQLITE_OMIT_GENERATED_COLUMNSSQLITE_ENABLE_HIDDEN_COLUMNS!defined(SQLITE_OMIT_VIEW) || !defined(SQLITE_OMIT_VIRTUALTABLE)SQLITE_OMIT_AUTOINCREMENTdefined(SQLITE_ENABLE_UPDATE_DELETE_LIMIT) && !defined(SQLITE_OMIT_SUBQUERY)SQLITE_ENABLE_NULL_TRIM!defined(SQLITE_OMIT_VIRTUALTABLE) && !defined(SQLITE_OMIT_JSON)!defined(SQLITE_OMIT_VIEW) && !defined(SQLITE_OMIT_TRIGGER)!defined(SQLITE_OMIT_BLOB_LITERAL)defined(SQLITE_NEED_ERR_NAME)SQLITE_ENABLE_8_3_NAMESVDBE_PROFILESQLITE_OMIT_SUBQUERYSQLITE_OMIT_UPSERT!defined(SQLITE_OMIT_FOREIGN_KEY) && !defined(SQLITE_OMIT_TRIGGER)SQLITE_OMIT_FOREIGN_KEYdefined(SQLITE_ENABLE_ATOMIC_WRITE) \defined(YYCOVERAGE)SQLITE_MEMDEBUGSQLITE_MAX_WORKER_THREADS>0defined(SQLITE_ENABLE_DBPAGE_VTAB) || defined(SQLITE_TEST)defined(SQLITE_ENABLE_DBSTAT_VTAB) || defined(SQLITE_TEST)SQLITE_OS_UNIX && defined(SQLITE_OS_KV_OPTIONAL)defined(VDBE_PROFILE) \MEMORY_DEBUGSQLITE_PERFORMANCE_TRACESQLITE_32BIT_ROWIDSQLITE_ALLOW_COVERING_INDEX_SCAN != 1SQLITE_ALLOW_URI_AUTHORITYSQLITE_BUG_COMPATIBLE_20160819SQLITE_CASE_SENSITIVE_LIKESQLITE_COVERAGE_TESTSQLITE_DEFAULT_AUTOMATIC_INDEXSQLITE_DEFAULT_CKPTFULLFSYNCSQLITE_DEFAULT_FOREIGN_KEYSSQLITE_DEFAULT_LOCKING_MODESQLITE_DEFAULT_MEMSTATUS != 1SQLITE_DEFAULT_ROWESTSQLITE_DISABLE_DIRSYNCSQLITE_DISABLE_FTS3_UNICODESQLITE_DISABLE_FTS4_DEFERREDSQLITE_DISABLE_INTRINSICSQLITE_DISABLE_PAGECACHE_OVERFLOW_STATSSQLITE_DISABLE_SKIPAHEAD_DISTINCTSQLITE_ENABLE_API_ARMORSQLITE_ENABLE_ATOMIC_WRITESQLITE_ENABLE_BATCH_ATOMIC_WRITESQLITE_ENABLE_COLUMN_USED_MASKSQLITE_ENABLE_DBSTAT_VTABSQLITE_ENABLE_EXPENSIVE_ASSERTSQLITE_ENABLE_FTS3_PARENTHESISSQLITE_ENABLE_FTS3_TOKENIZERSQLITE_ENABLE_FTS4SQLITE_ENABLE_FTS5SQLITE_ENABLE_GEOPOLYSQLITE_ENABLE_ICUSQLITE_ENABLE_LOAD_EXTENSIONSQLITE_ENABLE_OFFSET_SQL_FUNCSQLITE_ENABLE_ORDERED_SET_AGGREGATESSQLITE_ENABLE_OVERSIZE_CELL_CHECKSQLITE_ENABLE_QPSGSQLITE_ENABLE_RBUSQLITE_ENABLE_RTREESQLITE_ENABLE_SESSIONSQLITE_ENABLE_STMTVTABSQLITE_ENABLE_TREETRACESQLITE_ENABLE_UNKNOWN_SQL_FUNCTIONSQLITE_ENABLE_UPDATE_DELETE_LIMITSQLITE_ENABLE_URI_00_ERRORSQLITE_ENABLE_VFSTRACESQLITE_ENABLE_WHERETRACESQLITE_EXPLAIN_ESTIMATED_ROWSSQLITE_EXTRA_AUTOEXTSQLITE_EXTRA_IFNULLROWSQLITE_EXTRA_INITSQLITE_EXTRA_SHUTDOWNSQLITE_FTS5_ENABLE_TEST_MISQLITE_FTS5_NO_WITHOUT_ROWIDHAVE_ISNAN || SQLITE_HAVE_ISNANSQLITE_HOMEGROWN_RECURSIVE_MUTEXSQLITE_HOMEGROWN_RECURSIVE_MUTEX != 1SQLITE_IGNORE_AFP_LOCK_ERRORSSQLITE_IGNORE_FLOCK_LOCK_ERRORSSQLITE_LEGACY_JSON_VALIDSQLITE_LIKE_DOESNT_MATCH_BLOBSSQLITE_LOCK_TRACESQLITE_LOG_CACHE_SPILLSQLITE_MAX_MMAP_SIZE_SQLITE_MIXED_ENDIAN_64BIT_FLOATSQLITE_MMAP_READWRITESQLITE_MUTEX_NOOPSQLITE_MUTEX_W32SQLITE_NO_SYNCSQLITE_OMIT_ANALYZESQLITE_OMIT_ATTACHSQLITE_OMIT_AUTOINITSQLITE_OMIT_AUTOMATIC_INDEXSQLITE_OMIT_AUTORESETSQLITE_OMIT_AUTOVACUUMSQLITE_OMIT_BETWEEN_OPTIMIZATIONSQLITE_OMIT_BLOB_LITERALSQLITE_OMIT_CASTSQLITE_OMIT_CHECKSQLITE_OMIT_COMPOUND_SELECTSQLITE_OMIT_CONFLICT_CLAUSEdefined(SQLITE_OMIT_DATETIME_FUNCS) || defined(SQLITE_OMIT_FLOATING_POINT)SQLITE_OMIT_DISKIOSQLITE_OMIT_FLAG_PRAGMASSQLITE_OMIT_GET_TABLESQLITE_OMIT_HEX_INTEGERSQLITE_OMIT_INTEGRITY_CHECKSQLITE_OMIT_JSONSQLITE_OMIT_LIKE_OPTIMIZATIONSQLITE_OMIT_LOCALTIMESQLITE_OMIT_LOOKASIDESQLITE_OMIT_OR_OPTIMIZATIONSQLITE_OMIT_PAGER_PRAGMASSQLITE_OMIT_PARSER_TRACESQLITE_OMIT_PRAGMASQLITE_OMIT_QUICKBALANCESQLITE_OMIT_REINDEXSQLITE_OMIT_SCHEMA_PRAGMASSQLITE_OMIT_SCHEMA_VERSION_PRAGMASSQLITE_OMIT_SEHSQLITE_OMIT_SHUTDOWN_DIRECTORIESSQLITE_OMIT_TCL_VARIABLESQLITE_OMIT_TRACE != 1SQLITE_OMIT_TRUNCATE_OPTIMIZATIONSQLITE_OMIT_VACUUMSQLITE_OMIT_VIEWSQLITE_OMIT_XFER_OPTSQLITE_POWERSAFE_OVERWRITE != 1SQLITE_PREFER_PROXY_LOCKINGSQLITE_PROXY_DEBUGSQLITE_REVERSE_UNORDERED_SELECTSSQLITE_SECURE_DELETESQLITE_SMALL_STACKSQLITE_SOUNDEXSQLITE_SUBSTR_COMPATIBILITY(!defined(SQLITE_WIN32_MALLOC) \SQLITE_TCLdefined(SQLITE_THREADSAFE)SQLITE_UNLINK_AFTER_CLOSESQLITE_USE_FCNTL_TRACESQLITE_WIN32_MALLOCSQLITE_ZERO_MALLOCSQLITE_EBCDIC!defined(SQLITE_ALLOW_COVERING_INDEX_SCAN)!SQLITE_ALLOW_COVERING_INDEX_SCAN!defined(SQLITE_OMIT_EXPLAIN) || !defined(NDEBUG) \!defined(SQLITE_OMIT_EXPLAIN) || defined(SQLITE_ENABLE_BYTECODE_VTAB)defined(SQLITE_ENABLE_EXPLAIN_COMMENTS)!defined(SQLITE_OMIT_EXPLAIN)!defined(SQLITE_OMIT_SHARED_CACHE)!defined(SQLITE_OMIT_SHARED_CACHE) && SQLITE_THREADSAFE>0SQLITE_PTRSIZE>4SQLITE_OMIT_DATETIME_FUNCS!defined(SQLITE_OMIT_LOCALTIME) && defined(_WIN32_WCE) && \!HAVE_LOCALTIME_R && !HAVE_LOCALTIME_S \!HAVE_LOCALTIME_R && !HAVE_LOCALTIME_SSQLITE_THREADSAFE>0HAVE_LOCALTIME_RHAVE_GMTIME_R!defined(SQLITE_OMIT_DATETIME_FUNCS) && defined(SQLITE_DEBUG)defined(__APPLE__) && !defined(SQLITE_WITHOUT_ZONEMALLOC)SQLITE_MIGHT_BE_SINGLE_COREHAVE_MALLOC_H && HAVE_MALLOC_USABLE_SIZEdefined(_MSC_VER) && !defined(SQLITE_WITHOUT_MSIZE)defined(SQLITE_USE_MALLOC_H)defined(SQLITE_USE_MALLOC_USABLE_SIZE)!defined(SQLITE_MALLOCSIZE)defined(SQLITE_USE_MSIZE)SQLITE_MALLOCSIZEdefined(SQLITE_DEBUG) || defined(SQLITE_TEST)defined(SQLITE_DEBUG) && !defined(SQLITE_MUTEX_OMIT)SQLITE_ENABLE_MULTITHREADED_CHECKSdefined(__has_feature)__has_feature(thread_sanitizer)defined(SQLITE_DEBUG) || defined(SQLITE_HOMEGROWN_RECURSIVE_MUTEX)SQLITE_MUTEX_NREF || defined(SQLITE_ENABLE_API_ARMOR)defined(SQLITE_ENABLE_API_ARMOR)!defined(NDEBUG) || defined(SQLITE_DEBUG)defined(SQLITE_MEMORY_BARRIER)defined(__GNUC__) && GCC_VERSION>=4001000SQLITE_OS_WIN_H__CYGWIN__SQLITE_OS_WIN && !defined(SQLITE_OS_WINNT)SQLITE_OS_WINCESQLITE_OS_WIN && !SQLITE_OS_WINCE && !SQLITE_OS_WINRT && \MSVC_VERSION>=1400defined(MemoryBarrier)SQLITE_WIN32_MUTEX_TRACE_DYNAMICSQLITE_WIN32_MUTEX_TRACE_STATICdefined(_WIN32_WINNT) && _WIN32_WINNT >= 0x0400SQLITE_MAX_ALLOCATION_SIZE>2147483391SQLITE_PRINTF_PRECISION_LIMITHAVE_STRCHRNULSQLITE_OS_TRACE_PROCSQLITE_OS_UNIX && defined(SQLITE_MUTEX_PTHREADS) && SQLITE_THREADSAFE>0SQLITE_OS_WIN_THREADS!defined(SQLITE_AMALGAMATION) && SQLITE_BYTEORDER==0defined(TRANSLATE_TRACE) && defined(SQLITE_DEBUG)SQLITE_REPLACE_INVALID_UTFdefined(SQLITE_TEST) && defined(SQLITE_DEBUG)!SQLITE_HAVE_ISNAN && !HAVE_ISNANSQLITE_BYTEORDER==1234 && GCC_VERSION>=4003000SQLITE_BYTEORDER==1234 && MSVC_VERSION>=1300GCC_VERSION>=5004000 && !defined(__INTEL_COMPILER)SQLITE_ENABLE_8_3_NAMES<2GCC_VERSION>=5004000SQLITE_MALLOC_SOFT_LIMIT>0!defined(SQLITE_OMIT_EXPLAIN) \defined(SQLITE_ENABLE_EXPLAIN_COMMENTS) || defined(SQLITE_DEBUG)SQLITE_OS_KV || (SQLITE_OS_UNIX && defined(SQLITE_OS_KV_OPTIONAL))SQLITE_WASMSQLITE_OS_KV_ALWAYS_LOCAL!defined(SQLITE_ENABLE_LOCKING_STYLE)defined(__APPLE__) || defined(__linux__)defined(HAVE_PREAD64) && defined(HAVE_PWRITE64)defined(HAVE_PREAD) && defined(HAVE_PWRITE)(!defined(SQLITE_OMIT_WAL) || SQLITE_MAX_MMAP_SIZE>0) \defined(__APPLE__) && ((__MAC_OS_X_VERSION_MIN_REQUIRED > 1050) || \(!defined(TARGET_OS_EMBEDDED) || (TARGET_OS_EMBEDDED==0)) \defined(__APPLE__) || SQLITE_ENABLE_LOCKING_STYLEHAVE_UTIMESQLITE_WASISQLITE_DEFAULT_UNIX_VFS__LONG_MAX == 0x7fffffffLSQLITE_ENABLE_LOCKING_STYLE || defined(__APPLE__)SQLITE_ENABLE_SETLK_TIMEOUT!defined(SQLITE_DISABLE_DIRSYNC) && !defined(_AIX)O_LARGEFILE!defined(HAVE_MREMAP)defined(__linux__) && defined(_GNU_SOURCE)__ANDROID____DJGPP__defined(USE_PREAD) || SQLITE_ENABLE_LOCKING_STYLEdefined(USE_PREAD64)defined(HAVE_FCHMOD)defined(HAVE_POSIX_FALLOCATE) && HAVE_POSIX_FALLOCATEdefined(HAVE_FCHOWN)HAVE_MREMAP && (!defined(SQLITE_OMIT_WAL) || SQLITE_MAX_MMAP_SIZE>0)!defined(SQLITE_OMIT_WAL) || SQLITE_MAX_MMAP_SIZE>0defined(HAVE_READLINK)defined(HAVE_LSTAT)defined(__linux__) && defined(SQLITE_ENABLE_BATCH_ATOMIC_WRITE)defined(O_CLOEXEC)defined(FD_CLOEXEC) && (!defined(O_CLOEXEC) || O_CLOEXEC==0)SQLITE_THREADSAFE && defined(HAVE_STRERROR_R)(defined(STRERROR_R_CHAR_P) || defined(__USE_GNU)) \defined(EOVERFLOW) && defined(SQLITE_DISABLE_LFS)!defined(__APPLE__) || !SQLITE_ENABLE_LOCKING_STYLEdefined(__APPLE__) && SQLITE_ENABLE_LOCKING_STYLE(!defined(USE_PREAD) && !defined(USE_PREAD64))defined(USE_PREAD)EDEVERRdefined(SQLITE_MMAP_READWRITE) && SQLITE_MAX_MMAP_SIZE>0!defined(fdatasync) && !HAVE_FDATASYNCF_FULLFSYNCSQLITE_ENABLE_LOCKING_STYLE && defined(__APPLE__)!defined(SQLITE_WASI) && !defined(SQLITE_OMIT_WAL)SQLITE_ENABLE_SETLK_TIMEOUT==1SQLITE_ENABLE_SETLK_TIMEOUT==2__QNXNTO__defined(_BSD_SOURCE)defined(SQLITE_ENABLE_SETLK_TIMEOUT) && SQLITE_ENABLE_SETLK_TIMEOUT==1SQLITE_SHM_DIRECTORY!OS_VXWORKSSQLITE_ASSERT_NO_FILESdefined(SQLITE_UNLINK_AFTER_CLOSE)defined(HAVE_READLINK) && defined(HAVE_LSTAT)!defined(SQLITE_TEST) && !defined(SQLITE_OMIT_RANDOMNESS)!defined(HAVE_NANOSLEEP) || HAVE_NANOSLEEP+0defined(HAVE_USLEEP) && HAVE_USLEEPdefined(NO_GETTOD)LOCKPROXYDIR_CS_DARWIN_USER_TEMP_DIRSQLITE_ENABLE_LOCKING_STYLE || OS_VXWORKSSQLITE_OS_KV_OPTIONAL!SQLITE_OS_WINNT && !defined(SQLITE_OMIT_WAL)!SQLITE_OS_WINNT && SQLITE_MAX_MMAP_SIZE>0!SQLITE_OS_WINCE && !SQLITE_OS_WINRT && !defined(SQLITE_WIN32_NO_ANSI)(SQLITE_OS_WINCE || SQLITE_OS_WINNT || SQLITE_OS_WINRT) && \!defined(SQLITE_WIN32_HAS_ANSI) && !defined(SQLITE_WIN32_HAS_WIDE)NTDDI_WIN8NTDDI_WINBLUENTDDI_WINTHRESHOLDSQLITE_WIN32_GETVERSIONEXdefined(NTDDI_VERSION) && NTDDI_VERSION >= NTDDI_WINBLUESQLITE_WIN32_CREATEFILEMAPPINGAdefined(NTDDI_VERSION) && NTDDI_VERSION >= NTDDI_WINTHRESHOLDMAX_PATHSQLITE_WIN32_MAX_PATH_CHARSUNICODE_STRING_MAX_CHARSSQLITE_WINNT_MAX_PATH_CHARSSQLITE_WIN32_MAX_PATH_BYTESSQLITE_WINNT_MAX_PATH_BYTESSQLITE_WIN32_MAX_ERRMSG_CHARSwinIsDirSepUNUSED_VARIABLE_VALUEwinGetDirSepSQLITE_WIN32_FILEMAPPING_API && \defined(SQLITE_WIN32_HAS_ANSI)defined(SQLITE_WIN32_HAS_WIDE)INVALID_FILE_ATTRIBUTESFILE_FLAG_MASKFILE_ATTRIBUTE_MASKSQLITE_WIN32_DBG_BUF_SIZESQLITE_WIN32_HEAP_CREATESQLITE_WIN32_HEAP_MAX_INIT_SIZESQLITE_WIN32_HEAP_INIT_EXTRASQLITE_WIN32_MAX_CACHE_SIZESQLITE_WIN32_CACHE_SIZESQLITE_DEFAULT_CACHE_SIZE>=0SQLITE_WIN32_CACHE_SIZE>SQLITE_WIN32_MAX_CACHE_SIZESQLITE_WIN32_HEAP_INIT_SIZESQLITE_WIN32_HEAP_MAX_SIZESQLITE_WIN32_HEAP_FLAGSSYSCALLSQLITE_OS_WINCE || SQLITE_OS_WINRT!SQLITE_OS_WINCE && !SQLITE_OS_WINRTosAreFileApisANSISQLITE_OS_WINCE && defined(SQLITE_WIN32_HAS_WIDE)!SQLITE_OS_WINRT && defined(SQLITE_WIN32_HAS_WIDE)!SQLITE_OS_WINRT && defined(SQLITE_WIN32_HAS_ANSI) && \SQLITE_OS_WINCE || (!SQLITE_OS_WINRT && defined(SQLITE_WIN32_HAS_WIDE) && \!defined(SQLITE_OMIT_LOAD_EXTENSION)!SQLITE_OS_WINCE && defined(SQLITE_WIN32_HAS_ANSI)!SQLITE_OS_WINCE && !SQLITE_OS_WINRT && defined(SQLITE_WIN32_HAS_WIDE)!SQLITE_OS_WINCEdefined(SQLITE_WIN32_HAS_ANSI) && SQLITE_WIN32_GETVERSIONEX!SQLITE_OS_WINRT && defined(SQLITE_WIN32_HAS_WIDE) && \defined(SQLITE_WIN32_HAS_ANSI) && !defined(SQLITE_OMIT_LOAD_EXTENSION)osLockFileosLockFileExSQLITE_OS_WINCE || (!SQLITE_OS_WINRT && \osUnlockFileSQLITE_OS_WINCE || !defined(SQLITE_OMIT_WAL) || SQLITE_MAX_MMAP_SIZE>0SQLITE_OS_WINRT && (!defined(SQLITE_OMIT_WAL) || SQLITE_MAX_MMAP_SIZE>0)SQLITE_OS_WINRT && !defined(SQLITE_OMIT_LOAD_EXTENSION)defined(InterlockedCompareExchange)!SQLITE_OS_WINCE && !SQLITE_OS_WINRT && SQLITE_WIN32_USE_UUID!defined(SQLITE_NO_SYNC) && SQLITE_MAX_MMAP_SIZE>0!SQLITE_OS_WINRT && defined(SQLITE_WIN32_MALLOC_VALIDATE)SQLITE_MAX_WORKER_THREADS>0 && !SQLITE_OS_WINCE && !SQLITE_OS_WINRT && \!SQLITE_WIN32_GETVERSIONEXSQLITE_OS_WINCE || SQLITE_OS_WINRT || !defined(SQLITE_WIN32_HAS_ANSI)!defined(SQLITE_WIN32_HAS_WIDE)!SQLITE_OS_WINRT && SQLITE_WIN32_HEAP_CREATESQLITE_WIN32_HAS_ANSISQLITE_WIN32_IOERR_RETRYSQLITE_WIN32_IOERR_RETRY_DELAY!defined(winIoerrCanRetry1)defined(winIoerrCanRetry2)INVALID_SET_FILE_POINTER!SQLITE_OS_WINCE && !defined(SQLITE_WIN32_NO_OVERLAPPED)SQLITE_OS_WINCE || defined(SQLITE_WIN32_NO_OVERLAPPED)!defined(NDEBUG) || !defined(SQLITE_NO_SYNC) || \LOCKFILE_FAIL_IMMEDIATELYLOCKFILE_EXCLUSIVE_LOCKSQLITE_LOCKFILE_FLAGSSQLITE_LOCKFILEEX_FLAGSdefined(SQLITE_WIN32_HAS_ANSI) && SQLITE_WIN32_CREATEFILEMAPPINGAdefined(__CYGWIN__)!SQLITE_OS_WINRT && !defined(__CYGWIN__)SQLITE_OS_WINCE==0!defined(NDEBUG) || SQLITE_OS_WINCE!SQLITE_OS_WINCE && !SQLITE_OS_WINRT && !defined(__CYGWIN__)(SQLITE_OS_WINCE || SQLITE_OS_WINRT) && !defined(__CYGWIN__)defined(SQLITE_TEST) || defined(SQLITE_OMIT_RANDOMNESS)defined(SQLITE_DEBUG) && 0defined(SQLITE_ENABLE_EXPENSIVE_ASSERT)!defined(SQLITE_ENABLE_MEMORY_MANAGEMENT) || SQLITE_THREADSAFE==0defined(SQLITE_ENABLE_MEMORY_MANAGEMENT)PCACHE1_MIGHT_USE_GROUP_MUTEX || defined(SQLITE_DEBUG)defined(__clang__) && !defined(SQLITE_NO_TSAN)SQLITE_SAFER_WALINDEX_RECOVERYWIN_SHM_BASETRANS_NONE!=SQLITE_TXN_NONETRANS_READ!=SQLITE_TXN_READTRANS_WRITE!=SQLITE_TXN_WRITESQLITE_BYTEORDER==1234 && GCC_VERSION>=4008000!defined(SQLITE_OMIT_SHARED_CACHE) && !defined(SQLITE_OMIT_DISKIO)defined(SQLITE_SECURE_DELETE)defined(SQLITE_FAST_SECURE_DELETE)SQLITE_DEFAULT_SYNCHRONOUS!=SQLITE_DEFAULT_WAL_SYNCHRONOUS \SQLITE_TEST_REALLOC_STRESS!defined(SQLITE_DEBUG)defined(SQLITE_ENABLE_STMT_SCANSTATUS)VDBE_DISPLAY_P4 && defined(SQLITE_ENABLE_CURSOR_HINTS)defined(VDBE_PROFILE) || defined(SQLITE_DEBUG)defined(SQLITE_ENABLE_BYTECODE_VTAB) || !defined(SQLITE_OMIT_EXPLAIN)!defined(SQLITE_OMIT_TRACE) && defined(SQLITE_ENABLE_IOTRACE)!defined(NDEBUG) && !defined(SQLITE_OMIT_FLOATING_POINT)__HP_ccdefined(SQLITE_STRICT_SUBTYPE) && SQLITE_STRICT_SUBTYPE+0!=0defined(SQLITE_DEBUG) && defined(__GNUC__)defined(SQLITE_OMIT_DECLTYPE) && defined(SQLITE_ENABLE_COLUMN_METADATA)SQLITE_TRACE_SIZE_LIMITdefined(VDBE_PROFILE)  \SQLITE_HWTIME_H!defined(__STRICT_ANSI__) && \!defined(__STRICT_ANSI__) && (defined(__GNUC__) && defined(__x86_64__))!defined(__STRICT_ANSI__) && (defined(__GNUC__) && defined(__ppc__))defined(SQLITE_TEST) && !defined(SQLITE_UNTESTABLE)!defined(SQLITE_VDBE_COVERAGE)defined(VDBE_PROFILE)!defined(SQLITE_OMIT_CAST) || !defined(SQLITE_OMIT_ANALYZE)!defined(SQLITE_OMIT_ANALYZE)!defined(SQLITE_OMIT_VACUUM) && !defined(SQLITE_OMIT_ATTACH)!defined(SQLITE_OMIT_AUTOVACUUM)SQLITE_MAX_WORKER_THREADS==0SQLITE_MAX_WORKER_THREADS>=SORTER_MAX_MERGE_COUNTSQLITE_DEBUG_SORTER_THREADSdefined(SQLITE_ENABLE_BYTECODE_VTAB) && !defined(SQLITE_OMIT_VIRTUALTABLE)defined(SQLITE_ENABLE_BYTECODE_VTAB)!defined(SQLITE_OMIT_WINDOWFUNC)!defined(SQLITE_OMIT_TRIGGER) || !defined(SQLITE_OMIT_UPSERT)SQLITE_ALLOW_ROWID_IN_VIEW+0==2!defined(SQLITE_OMIT_VIEW) || !defined(SQLITE_OMIT_TRIGGER) \!defined(SQLITE_UNTESTABLE)defined(SQLITE_ENABLE_STAT4)!defined(SQLITE_OMIT_VIEW) || !defined(SQLITE_OMIT_TRIGGER)defined(SQLITE_ENABLE_UPDATE_DELETE_LIMIT)defined(SQLITE_EBCDIC)defined(HAVE_LOG10) && HAVE_LOG10==0defined(HAVE_LOG2) && HAVE_LOG2==0!defined(SQLITE_CORE) && !defined(SQLITE_OMIT_LOAD_EXTENSION)defined(SQLITE_OMIT_TRACE) || defined(SQLITE_OMIT_DEPRECATED)defined(SQLITE_OMIT_TRACE)SQLITE_OS_UNIX || SQLITE_OS_WINdefined(SQLITE_ENABLE_CEROD)!defined(SQLITE_OMIT_SCHEMA_VERSION_PRAGMAS)!defined(SQLITE_OMIT_FLAG_PRAGMAS)!defined(SQLITE_OMIT_AUTOMATIC_INDEX)!defined(SQLITE_OMIT_PAGER_PRAGMAS)!defined(SQLITE_OMIT_CASE_SENSITIVE_LIKE_PRAGMA)!defined(SQLITE_OMIT_SCHEMA_PRAGMAS)!defined(SQLITE_OMIT_COMPILEOPTION_DIAGS)!defined(SQLITE_OMIT_PAGER_PRAGMAS) && SQLITE_OS_WIN!defined(SQLITE_OMIT_PAGER_PRAGMAS) && !defined(SQLITE_OMIT_DEPRECATED)!defined(SQLITE_OMIT_UTF16)!defined(SQLITE_OMIT_FOREIGN_KEY)!defined(SQLITE_OMIT_INTROSPECTION_PRAGMAS)!defined(SQLITE_OMIT_CHECK)!defined(SQLITE_OMIT_INTEGRITY_CHECK)!defined(SQLITE_OMIT_PAGER_PRAGMAS) && SQLITE_ENABLE_LOCKING_STYLE!defined(SQLITE_OMIT_SCHEMA_PRAGMAS) && defined(SQLITE_DEBUG)!defined(SQLITE_OMIT_WAL)!defined(SQLITE_OMIT_PRAGMA)SQLITE_OMIT_CASE_SENSITIVE_LIKE_PRAGMA!defined(SQLITE_ENABLE_NULL_TRIM) && defined(SQLITE_DEBUG)!defined(SQLITE_OMIT_TRIGGER)!defined(SQLITE_OMIT_SUBQUERY) || !defined(SQLITE_OMIT_VIEW)defined(SQLITE_DEBUG) && !defined(SQLITE_ENABLE_NULL_TRIM)WHERETRACE_ENABLEDdefined(SQLITE_SMALL_STACK)!defined(SQLITE_OMIT_OR_OPTIMIZATION) && !defined(SQLITE_OMIT_SUBQUERY)!defined(SQLITE_OMIT_VIRTUALTABLE) && defined(WHERETRACE_ENABLED)defined(WHERETRACE_ENABLED)defined(WHERETRACE_ENABLED) || defined(SQLITE_DEBUG)!defined(SQLITE_ENABLE_UPDATE_DELETE_LIMIT) \TK_SPAN>255yytestcaseYYSTACKDEPTH<=0 || YYDYNSTACKYYSTACKDEPTH<=0defined(YYCOVERAGE) || !defined(NDEBUG)!YYGROWABLESTACKYYERRORSYMBOL!defined(YYERRORSYMBOL) && !defined(YYNOERRORRECOVERY)defined(YYNOERRORRECOVERY)defined(SQLITE_ENABLE_ICU) || defined(SQLITE_ENABLE_ICU_COLLATIONS)SQLITE_DEBUG_OS_TRACEdefined(SQLITE_THREADSAFE) && SQLITE_THREADSAFE>0SQLITE_OS_WIN && defined(SQLITE_WIN32_MALLOC)SQLITE_OS_WIN || !defined(HAVE_NANOSLEEP) || HAVE_NANOSLEEPSQLITE_TEMP_STORE==1SQLITE_TEMP_STORE==2SQLITE_TEMP_STORE==3SQLITE_TEMP_STORE<1 || SQLITE_TEMP_STORE>3SQLITE_MAX_LENGTH<100SQLITE_MAX_SQL_LENGTH<100SQLITE_MAX_SQL_LENGTH>SQLITE_MAX_LENGTHSQLITE_MAX_COMPOUND_SELECT<2SQLITE_MAX_VDBE_OP<40SQLITE_MAX_FUNCTION_ARG<0 || SQLITE_MAX_FUNCTION_ARG>32767SQLITE_MAX_ATTACHED<0 || SQLITE_MAX_ATTACHED>125SQLITE_MAX_LIKE_PATTERN_LENGTH<1SQLITE_MAX_COLUMN>32767SQLITE_MAX_TRIGGER_DEPTH<1SQLITE_MAX_WORKER_THREADS<0 || SQLITE_MAX_WORKER_THREADS>50SQLITE_ENABLE_SORTER_MMAP!defined(SQLITE_TRUSTED_SCHEMA) || SQLITE_TRUSTED_SCHEMA+0!=0!defined(SQLITE_DQS)(SQLITE_DQS&1)==1(SQLITE_DQS&2)==2!defined(SQLITE_DEFAULT_AUTOMATIC_INDEX) || SQLITE_DEFAULT_AUTOMATIC_INDEXSQLITE_DEFAULT_FILE_FORMAT<4defined(SQLITE_DEFAULT_FOREIGN_KEYS) && SQLITE_DEFAULT_FOREIGN_KEYSdefined(SQLITE_REVERSE_UNORDERED_SELECTS)defined(SQLITE_ENABLE_OVERSIZE_CELL_CHECK)defined(SQLITE_ENABLE_FTS3_TOKENIZER)defined(SQLITE_ENABLE_QPSG)defined(SQLITE_DEFAULT_DEFENSIVE)defined(SQLITE_DEFAULT_LEGACY_ALTER_TABLE)SQLITE_OS_KV || defined(SQLITE_OS_KV_OPTIONAL)SQLITE_ENABLE_INTERNAL_FUNCTIONSdefined(SQLITE_DEBUG) && !defined(SQLITE_OMIT_WSD)!defined(SQLITE_CORE) || defined(SQLITE_ENABLE_FTS3)defined(SQLITE_ENABLE_FTS3) && !defined(SQLITE_CORE)fts3GetVarint32defined(SQLITE_DEBUG)||defined(SQLITE_TEST)SQLITE_VERSION_NUMBER>=3008002SQLITE_VERSION_NUMBER>=3008012!defined(SQLITE_CORE)!defined(SQLITE_MAX_EXPR_DEPTH)FTS3_LOG_MERGESdefined(SQLITE_ENABLE_FTS3) || defined(SQLITE_ENABLE_FTS4)SQLITE_JSON_MAX_DEPTHNEVER!defined(SQLITE_CORE) \!defined(SQLITE_RTREE_INT_ONLY)GEOPOLY_ENABLE_DEBUGsqlite3IsdigitJSON_NULL!defined(SQLITE_CORE)                  \!defined(SQLITE_CORE) || defined(SQLITE_ENABLE_ICU)!defined(SQLITE_CORE) || defined(SQLITE_ENABLE_RBU)_SQLITE3RBU_HRBU_ENABLE_DELTA_CKSUM(defined(SQLITE_ENABLE_DBSTAT_VTAB) || defined(SQLITE_TEST)) \get2bytedefined(SQLITE_ENABLE_DBSTAT_VTAB)(defined(SQLITE_ENABLE_DBPAGE_VTAB) || defined(SQLITE_TEST)) \defined(SQLITE_ENABLE_DBPAGE_VTAB)defined(SQLITE_ENABLE_SESSION) && defined(SQLITE_ENABLE_PREUPDATE_HOOK)SESSIONS_STRM_CHUNK_SIZE!defined(SQLITE_CORE) || defined(SQLITE_ENABLE_FTS5)_FTS5INT_HArraySizeUNUSED_PARAMUNUSED_PARAM2FTS5_ORfts5YYSTACKDEPTHfts5yytestcasefts5YYSTACKDEPTH<=0 || fts5YYDYNSTACKfts5YYSTACKDEPTH<=0fts5YYFALLBACKfts5YYTRACKMAXSTACKDEPTHfts5YYNOERRORRECOVERYdefined(fts5YYCOVERAGE) || !defined(NDEBUG)fts5YYGROWABLESTACK!fts5YYGROWABLESTACKfts5YYMALLOCARGTYPEsqlite3Fts5Parser_ENGINEALWAYSONSTACKfts5YYPARSEFREENEVERNULLdefined(fts5YYCOVERAGE)fts5YYWILDCARDfts5YYERRORSYMBOL!defined(fts5YYERRORSYMBOL) && !defined(fts5YYNOERRORRECOVERY)defined(fts5YYNOERRORRECOVERY)SQLITE_FTS5_MAX_EXPR_DEPTHdefined(SQLITE_TEST) || defined(SQLITE_FTS5_DEBUG)FTS5_MAX_PREFIX_INDEXES > 31FTS5_STMT_SCAN_ASC!=0FTS5_STMT_SCAN_DESC!=1FTS5_STMT_LOOKUP!=2!defined(SQLITE_CORE) || defined(SQLITE_ENABLE_STMTVTAB)__ATOMIC_RELAXED__GNUC_PATCHLEVEL__SQLITE_STRICT_SUBTYPE_HAVE_SQLITE_CONFIG_H__ORDER_LITTLE_ENDIAN____BYTE_ORDER____ORDER_BIG_ENDIAN__4321/************************** End of sqlite3.c ******************************//* Return the source-id for this library *//************** End of stmt.c ************************************************//* !defined(SQLITE_CORE) || defined(SQLITE_ENABLE_STMTVTAB) *//* SQLITE_CORE *//*
** This following structure defines all the methods for the
** stmt virtual table.
*//*
** SQLite will invoke this method one or more times while planning a query
** that uses the stmt virtual table.  This routine needs to create
** a query plan for each invocation and compute an estimated cost for that
** plan.
*//*
** This method is called to "rewind" the stmt_cursor object back
** to the first row of output.  This method is always called at least
** once prior to any call to stmtColumn() or stmtRowid() or
** stmtEof().
*//*
** Return values of columns for the row at which the stmt_cursor
** is currently pointing.
*//*
** Advance a stmt_cursor to its next row of output.
*//*
** Destructor for a stmt_cursor.
*//*
** Constructor for a new stmt_cursor object.
*//*
** This method is the destructor for stmt_cursor objects.
*//* SQLITE_STMTSTATUS_MEMUSED *//* SQLITE_STMTSTATUS_RUN *//* SQLITE_STMTSTATUS_REPREPARE *//* SQLITE_STMTSTATUS_VM_STEP *//* SQLITE_STMTSTATUS_AUTOINDEX *//* SQLITE_STMTSTATUS_SORT *//* SQLITE_STMTSTATUS_FULLSCAN_STEP *//* True if currently busy *//* True if read-only *//* SQL for the statement *//*
** The stmtConnect() method is invoked to create a new
** stmt_vtab that describes the stmt virtual table.
**
** Think of this routine as the constructor for stmt_vtab objects.
**
** All this routine needs to do is:
**
**    (1) Allocate the stmt_vtab object and initialize all fields.
**
**    (2) Tell SQLite (via the sqlite3_declare_vtab() interface) what the
**        result set of queries against stmt will look like.
*//* Current row *//* stmt_cursor is a subclass of sqlite3_vtab_cursor which will
** serve as the underlying representation of a cursor that scans
** over rows of the result
*//* Database connection for this stmt vtab *//* stmt_vtab is a subclass of sqlite3_vtab which will
** serve as the underlying representation of a stmt virtual table
*//* Next row to return *//* all other column values *//* column "sql" *//* Rowid value *//* #include <string.h> *//* #include <assert.h> *//*
** 2017-05-31
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file demonstrates an eponymous virtual table that returns information
** about all prepared statements for the database connection.
**
** Usage example:
**
**     .load ./stmt
**     .mode line
**     .header on
**     SELECT * FROM stmt;
*//************** Begin file stmt.c ********************************************//************** End of fts5.c ************************************************//* !defined(SQLITE_CORE) || defined(SQLITE_ENABLE_FTS5) *//* Here ends the fts5.c composite file. *//* xIntegrity    *//* xShadowName   *//* xRollbackTo   *//* xRelease      *//* xSavepoint    *//* xRename       *//* xFindFunction *//* xRollback     *//* xCommit       *//* xSync         *//* xBegin        *//* xUpdate       *//* xRowid        *//* xColumn       *//* xEof          *//* xNext         *//* xFilter       *//* xClose        *//* xOpen         *//* xDestroy      *//* xDisconnect   *//* xBestIndex    *//* xConnect      *//* xCreate       *//* iVersion      *//*
** This is the xRowid method. The SQLite core calls this routine to
** retrieve the rowid for the current row of the result set. The
** rowid should be written to *pRowid.
*//* Index of column to read value from *//* Context for sqlite3_result_xxx() calls *//* Cursor to retrieve value from *//*
** This is the xEof method of the virtual table. SQLite calls this
** routine to find out if it has reached the end of a result set.
*//* Arguments for the indexing scheme *//* Number of elements in apVal *//* Strategy index *//* The cursor used for this query *//*
** This is the xFilter implementation for the virtual table.
*//* noop *//* An instance - increment pCsr->aCnt[] *//* New column in the position list *//* Do not bother counting the number of instances if the "cnt"
            ** column is not being read (according to colUsed).  *//* Current offset within position list *//* 64-bit position read from poslist *//* Position list *//*
** Advance the cursor to the next row in the table.
*//*
** Close the cursor.  For additional information see the documentation
** on the xClose method of the virtual table interface.
*//*
** Implementation of xOpen method.
*//* This virtual table always delivers results in ascending order of
  ** the "term" column (column 0). So if the user has requested this
  ** specifically - "ORDER BY term" or "ORDER BY term ASC" - set the
  ** sqlite3_index_info.orderByConsumed flag to tell the core the results
  ** are already in sorted order.  *//* term column *//*
** Implementation of the xBestIndex method.
**
** Only constraints of the form:
**
**     term <= ?
**     term == ?
**     term >= ?
**
** are interpreted. Less-than and less-than-or-equal are treated
** identically, as are greater-than and greater-than-or-equal.
*//* OUT: sqlite3_malloc'd error message *//* OUT: New sqlite3_vtab object *//* xCreate/xConnect argument array *//* Number of elements in argv array *//* Pointer to tokenizer hash table *//* Database connection *//*
** The xConnect() and xCreate() methods for the virtual table. All the
** work is done in function fts5VocabInitVtab().
*//* Bytes of space to allocate *//* Write any error message here *//* Write the resulting vtab structure here *//* Pointer to Fts5Global object *//* The SQLite database connection *//*
** This function is the implementation of both the xConnect and xCreate
** methods of the FTS3 virtual table.
**
** The argv[] array contains the following:
**
**   argv[0]   -> module name  ("fts5vocab")
**   argv[1]   -> database name
**   argv[2]   -> table name
**
** then:
**
**   argv[3]   -> name of fts5 table
**   argv[4]   -> type of fts5vocab table
**
** or, for tables in the TEMP schema only.
**
**   argv[3]   -> name of fts5 tables database
**   argv[4]   -> name of fts5 table
**   argv[5]   -> type of fts5vocab table
*//*
** The xDestroy() virtual table method.
*//*
** The xDisconnect() virtual table method.
*//*
** Translate a string containing an fts5vocab table type to an
** FTS5_VOCAB_XXX constant. If successful, set *peType to the output
** value and return SQLITE_OK. Otherwise, set *pzErr to an error message
** and return SQLITE_ERROR.
*//*
** Bits for the mask used as the idxNum value by xBestIndex/xFilter.
*//* Output values Used by 'instance' tables only *//* Current value of 'term' column *//* This table's current rowid value *//* Output values used by all tables. *//* These are used by 'col' tables only *//* Copy of sqlite3_index_info.colUsed *//* (term <= $zLeTerm) paramater, or NULL *//* Size of zLeTerm in bytes *//* From sqlite3Fts5StructureRef() *//* Term/rowid iterator object *//* True if this cursor is at EOF *//* Associated FTS5 table *//* Statement holding lock on pIndex *//* True if busy *//* FTS5_VOCAB_COL, ROW or INSTANCE *//* FTS5 global object for this database *//* Db containing fts5 table *//* Name of fts5 table *//* #include "fts5Int.h" *//*
** 2015 May 08
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This is an SQLite virtual table module implementing direct access to an
** existing FTS5 index. The module may create several different types of
** tables:
**
** col:
**     CREATE TABLE vocab(term, col, doc, cnt, PRIMARY KEY(term, col));
**
**   One row for each term/column combination. The value of $doc is set to
**   the number of fts5 rows that contain at least one instance of term
**   $term within column $col. Field $cnt is set to the total number of
**   instances of term $term in column $col (in any row of the fts5 table).
**
** row:
**     CREATE TABLE vocab(term, doc, cnt, PRIMARY KEY(term));
**
**   One row for each term in the database. The value of $doc is set to
**   the number of fts5 rows that contain at least one instance of term
**   $term. Field $cnt is set to the total number of instances of term
**   $term in the database.
**
** instance:
**     CREATE TABLE vocab(term, doc, col, offset, PRIMARY KEY(<all-fields>));
**
**   One row for each term instance in the database.
*//*
** Write a 64-bit variable-length integer to memory starting at p[0].
** The length of data write will be between 1 and 9 bytes.  The number
** of bytes written is returned.
**
** A variable-length integer consists of the lower 7 bits of each byte
** for all bytes that have the 8th bit set and one byte with the 8th
** bit clear.  Except, if we get to the 9th byte, it stores the full
** 8 bits and is the last byte.
*//*
** The variable-length integer encoding is as follows:
**
** KEY:
**         A = 0xxxxxxx    7 bits of data and one flag bit
**         B = 1xxxxxxx    7 bits of data and one flag bit
**         C = xxxxxxxx    8 bits of data
**
**  7 bits - A
** 14 bits - BA
** 21 bits - BBA
** 28 bits - BBBA
** 35 bits - BBBBA
** 42 bits - BBBBBA
** 49 bits - BBBBBBA
** 56 bits - BBBBBBBA
** 64 bits - BBBBBBBBC
*//* a &= (0x7f<<29)|(0x7f<<15)|(0xff); *//* moved CSE2 up *//* a: p4<<29 | p6<<15 | p8 (unmasked) *//* a &= (0x7f<<14)|(0x7f); *//* b: p3<<28 | p5<<14 | p7 (unmasked) *//* CSE2 from below *//* a: p2<<28 | p4<<14 | p6 (unmasked) *//* b &= (0x7f<<28)|(0x7f<<14)|(0x7f); *//* we can skip this cause it was (effectively) done above in calc'ing s *//* b: p1<<28 | p3<<14 | p5 (unmasked) *//* s: p0<<21 | p1<<14 | p2<<7 | p3 (masked) *//* 2:save off p0<<21 | p1<<14 | p2<<7 | p3 (masked) *//* b &= (0x7f<<14)|(0x7f); *//* a &= (0x7f<<28)|(0x7f<<14)|(0x7f); *//* we can skip these cause they were (effectively) done above in calc'ing s *//* a: p0<<28 | p2<<14 | p4 (unmasked) *//* s: p0<<14 | p2 (masked) *//* moved CSE1 up *//* 1:save off p0<<21 | p1<<14 | p2<<7 | p3 (masked) *//* b: p1<<14 | p3 (unmasked) *//* a: p0<<14 | p2 (masked) *//* CSE1 from below *//* a: p0<<14 | p2 (unmasked) *//* Verify that constants are precomputed correctly *//* b: p1 (unmasked) *//* a: p0 (unmasked) *//*
** Read a 64-bit variable-length integer from memory starting at p[0].
** Return the number of bytes read.  The value is stored in *v.
*//*
** Bitmasks used by sqlite3GetVarint().  These precomputed constants
** are defined here rather than simply putting the constant expressions
** inline in order to work around bugs in the RVT compiler.
**
** SLOT_2_0     A mask for  (0x7f<<14) | 0x7f
**
** SLOT_4_2_0   A mask for  (0x7f<<28) | SLOT_2_0
*//* A 32-bit varint is used to store size information in btrees.
  ** Objects are rarely larger than 2MiB limit of a 3-byte varint.
  ** A 3-byte varint is sufficient, for example, to record the size
  ** of a 1048569-byte BLOB or string.
  **
  ** We only unroll the first 1-, 2-, and 3- byte cases.  The very
  ** rare larger cases can be handled by the slower 64-bit varint
  ** routine.
  *//* Values between 16384 and 2097151 *//* The 3-byte case *//* Values between 128 and 16383 *//* The 2-byte case *//* Values between 0 and 127 *//* The 1-byte case. Overwhelmingly the most common. *//*
** This is a copy of the sqlite3GetVarint32() routine from the SQLite core.
** Except, this version does handle the single byte case that the core
** version depends on being handled before its function is called.
*//*
** 2015 May 30
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** Routines for varint serialization and deserialization.
*//* 0x00 is never a token character *//* Each entry in the following array defines a rule for folding a range
  ** of codepoints to lower case. The rule applies to a range of nRange
  ** codepoints starting at codepoint iCode.
  **
  ** If the least significant bit in flags is clear, then the rule applies
  ** to all nRange codepoints (i.e. all nRange codepoints are upper case and
  ** need to be folded). Or, if it is set, then the rule only applies to
  ** every second codepoint in the range, starting with codepoint C.
  **
  ** The 7 most significant bits in flags are an index into the aiOff[]
  ** array. If a specific codepoint C does require folding, then its lower
  ** case equivalent is ((C + aiOff[flags>>1]) & 0xFFFF).
  **
  ** The contents of this array are generated by parsing the CaseFolding.txt
  ** file distributed as part of the "Unicode Character Database". See
  ** http://www.unicode.org for details.
  *//*
** Interpret the argument as a unicode codepoint. If the codepoint
** is an upper case character that has a lower case equivalent,
** return the codepoint corresponding to the lower case version.
** Otherwise, return a copy of the argument.
**
** The results are undefined if the value passed to this function
** is less than zero.
*//*
** Return true if the argument interpreted as a unicode codepoint
** is a diacritical modifier character.
*//*
** If the argument is a codepoint corresponding to a lowercase letter
** in the ASCII range with a diacritic added, return the codepoint
** of the ASCII letter only. For example, if passed 235 - "LATIN
** SMALL LETTER E WITH DIAERESIS" - return 65 ("LATIN SMALL LETTER
** E"). The resuls of passing a codepoint that corresponds to an
** uppercase letter are undefined.
*//*
** DO NOT EDIT THIS MACHINE GENERATED FILE.
*//*
** 2012-05-25
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
*//* To iterate through builtin functions *//*
** Register all built-in tokenizers with FTS5.
*//*
** Return true if the tokenizer described by p->azArg[] is the trigram
** tokenizer. This tokenizer needs to be loaded before xBestIndex is
** called for the first time in order to correctly handle LIKE/GLOB.
*//*
** Argument xCreate is a pointer to a constructor function for a tokenizer.
** pTok is a tokenizer previously created using the same method. This function
** returns one of FTS5_PATTERN_NONE, FTS5_PATTERN_LIKE or FTS5_PATTERN_GLOB
** indicating the style of pattern matching that the tokenizer can support.
** In practice, this is:
**
**     "trigram" tokenizer, case_sensitive=1 - FTS5_PATTERN_GLOB
**     "trigram" tokenizer, case_sensitive=0 (the default) - FTS5_PATTERN_LIKE
**     all other tokenizers - FTS5_PATTERN_NONE
*//* Update the aStart[] array *//* Remove the first character from buffer aBuf[]. Append the character
    ** with codepoint iCode.  *//* Pass the current trigram back to fts5 *//* Read characters from the input up until the first non-diacritic *//* Start of character following current tri *//* At the start of each iteration of this loop:
  **
  **  aBuf:      Contains 3 characters. The 3 characters of the next trigram.
  **  zOut:      Points to the byte following the last character in aBuf.
  **  aStart[3]: Contains the byte offset in the input text corresponding
  **             to the start of each of the three characters in the buffer.
  *//* Populate aBuf[] with the characters for the first trigram. *//* Input offset of each character in aBuf[] *//*
** Trigram tokenizer tokenize routine.
*//*
** Allocate a trigram tokenizer.
*//*
** Free a trigram tokenizer.
*//* Parameter to pass to Fts5UnicodeFold() *//* True to fold to lower-case *//**************************************************************************
** Start of trigram implementation.
*//*
** Tokenize using the porter tokenizer.
*//* Step 5b. *//* Step 5a. *//* Steps 2 through 4. *//* Step 1C. *//* Step 1. *//*
** GENERATED CODE ENDS HERE (mkportersteps.tcl)
***************************************************************************
**************************************************************************//**************************************************************************
***************************************************************************
** GENERATED CODE STARTS HERE (mkportersteps.tcl)
*//* porter rule condition: (*v*) *//* porter rule condition: (m > 1 and (*S or *T)) *//* porter rule condition: (*o) *//* porter rule condition: (m = 1) *//* porter rule condition: (m > 1) *//* porter rule condition: (m > 0) *//* Scan for a consonent *//* Scan for a vowel *//*
** Create a "porter" tokenizer.
*//*
** Delete a "porter" tokenizer.
*//* Parent tokenizer instance *//* Parent tokenizer module *//* Any tokens larger than this (in bytes) are passed through without
** stemming. *//**************************************************************************
** Start of porter stemmer implementation.
*//* Invoke the token callback *//* An ascii-range separator character. End of token. *//* An non-ascii-range character. Fold it into the output buffer if
        ** it is a token character, or break out of the loop if it is not. *//* Grow the output buffer so that there is sufficient space to fit the
      ** largest possible utf-8 character.  *//* Run through the tokenchars. Fold them into the output buffer along
    ** the way.  *//* A character outside of the ascii range. Skip past it if it is
        ** a separator character. Or break out of the loop if it is not. *//* Skip any separator characters. *//* non-ASCII codepoint read from input *//* Each iteration of this loop gobbles up a contiguous run of separators,
  ** then the next token.  *//* Output buffer *//*
** Return true if, for the purposes of tokenizing with the tokenizer
** passed as the first argument, codepoint iCode is considered a token
** character (not a separator).
*//* Search for a "categories" argument *//* New tokenizer object *//*
** Create a "unicode61" tokenizer.
*//*
** Delete a "unicode61" tokenizer.
*//*
** Return true if the p->aiException[] array contains the value iCode.
*//* 1 for 'tokenchars', 0 for 'separators' *//* Characters to treat as exceptions *//* Tokenizer object *//* Values for eRemoveDiacritic (must match internals of fts5_unicode2.c) *//* True for token char categories *//* True if remove_diacritics=1 is set *//* Size of aFold[] in bytes *//* Buffer to fold text into *//* ASCII range token characters *//* ifndef SQLITE_AMALGAMATION *//*
** The following two macros - READ_UTF8 and WRITE_UTF8 - have been copied
** from the sqlite3 source file utf.c. If this file is compiled as part
** of the amalgamation, they are not required.
*//**************************************************************************
** Start of unicode61 tokenizer implementation.
*//* Fold to lower case *//* Count the token characters *//* Skip any leading divider characters. *//*
** Tokenize some text using the ascii tokenizer.
*//*
** Create an "ascii" tokenizer.
*//*
** Delete a "ascii" tokenizer.
*//* 0x70..0x7F *//* 0x60..0x6F *//* 0x50..0x5F *//* 0x40..0x4F *//* 0x30..0x3F *//* 0x20..0x2F *//* 0x10..0x1F *//* 0x00..0x0F *//*
** For tokenizers with no "unicode" modifier, the set of token characters
** is the same as the set of ASCII range alphanumeric characters.
*//**************************************************************************
** Start of ascii tokenizer implementation.
*//*
** 2014 May 31
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
*//*
** Flush any data currently held in-memory to disk.
*//* nTotalRow being zero does not necessarily indicate a corrupt
    ** database - it might be that the FTS5 table really does contain zero
    ** rows. However this function is only called from the xRowCount() API,
    ** and there is no way for that API to be invoked if the table contains
    ** no rows. Hence the FTS5_CORRUPT return.  *//* Statement to query %_docsize *//* Number of user columns in table *//*
** Argument aCol points to an array of integers containing one entry for
** each table column. This function reads the %_docsize record for the
** specified rowid and populates aCol[] with the results.
**
** An SQLite error code is returned if an error occurs, or SQLITE_OK
** otherwise.
*//* Record to read varints from *//* Array to populate *//*
** Release an SQLite statement handle obtained via an earlier call to
** sqlite3Fts5StorageStmt(). The eStmt parameter passed to this function
** must match that passed to the sqlite3Fts5StorageStmt() call.
*//*
** Obtain an SQLite statement handle that may be used to read data from the
** %_content table.
*//* Pass the expected checksum down to the FTS index module. It will
  ** verify, amongst other things, that it matches the checksum generated by
  ** inspecting the index itself.  *//* Check that the %_docsize and %_content tables contain the expected
    ** number of rows.  *//* Test that the "totals" (sometimes called "averages") record looks Ok *//* If this is not a columnsize=0 database, check that the number
            ** of tokens in the value matches the aColSize[] value read from
            ** the %_docsize table.  *//* Generate the expected index checksum based on the contents of the
    ** %_content table. This block stores the checksum in ctx.cksum. *//* Array of size pConfig->nCol *//*
** Check that the contents of the FTS index match that of the %_content
** table. Return SQLITE_OK if they do, or SQLITE_CORRUPT if not. Return
** some other SQLite error code if an error occurs while attempting to
** determine this.
*//* End offset of token *//* Start offset of token *//* Buffer containing token *//* Pointer to Fts5IntegrityCtx object *//*
** Tokenization callback used by integrity check.
*//*
** Context object used by sqlite3Fts5StorageIntegrity().
*//* Write the %_docsize record *//* Pointer to buffer containing text value *//* Size of pText in bytes *//* Buffer used to build up %_docsize blob *//* Tokenization callback context object *//*
** Insert new entries into the FTS index and %_docsize table.
*//* This is an UPDATE statement, and user-defined column (i-2) was not
          ** modified.  Retrieve the value from Fts5Storage.pSavedRow.  *//* Loop through values for user-defined columns. i=2 is the leftmost
    ** user-defined column. As is column 1 of pSavedRow.  *//* Bind the rowid value *//* Counter variable *//* Statement to write %_content table *//* Insert the new row into the %_content table. *//* True to use REPLACE instead of INSERT *//*
** Insert a new row into the FTS content table.
*//*
** Allocate a new rowid. This is used for "external content" tables when
** a NULL value is inserted into the rowid column. The new rowid is allocated
** by inserting a dummy row into the %_docsize table. The dummy will be
** overwritten later.
**
** If the %_docsize table does not exist, SQLITE_MISMATCH is returned. In
** this case the user is required to provide a rowid explicitly.
*//* Write the averages record *//* Size of pLoc in bytes *//* Reinitialize the %_data table. This call creates the initial structure
  ** and averages records.  *//* Delete the contents of the %_data and %_docsize tables. *//*
** Delete all entries in the FTS5 index.
*//* Delete the %_content record *//* Delete the %_docsize record *//* Delete the index records *//* If true, set pSavedRow for deleted row *//* Optional - values to remove from index *//* Rowid to delete from table *//* Storage object *//*
** Remove a row from the FTS table.
*//*
** Store the current contents of the p->nTotalRow and p->aTotalSize[]
** variables in the "averages" record on disk.
**
** Return SQLITE_OK if successful, or an SQLite error code if an error
** occurs.
*//*
** Load the contents of the "averages" record from disk into the
** p->nTotalRow and p->aTotalSize[] variables. If successful, and if
** argument bCache is true, set the p->bTotalsValid flag to indicate
** that the contents of aTotalSize[] and nTotalRow are valid until
** further notice.
**
** Return SQLITE_OK if successful, or an SQLite error code if an error
** occurs.
*//* sz value *//* id value *//* Storage module to write to *//*
** Insert a record into the %_docsize table. Specifically, do:
**
**   INSERT OR REPLACE INTO %_docsize(id, sz) VALUES(iRowid, pBuf);
**
** If there is no %_docsize table (as happens if the columnsize=0 option
** is specified when the FTS5 table is created), this function is a no-op.
*//* Look up the origin of the document in the %_docsize table. Store
  ** this in stack variable iOrigin.  *//*
** This function is called to process a DELETE on a contentless_delete=1
** table. It adds the tombstone required to delete the entry with rowid
** iDel. If successful, SQLITE_OK is returned. Or, if an error occurs,
** an SQLite error code.
*//*
** Reset any saved statement pSavedRow. Zero pSavedRow as well. This
** should be called by the xUpdate() method of the fts5 table before
** returning from any operation that may have set Fts5Storage.pSavedRow.
*//* sqlite3_reset() return code *//* SELECT to read row iDel from %_data *//* True to set pSavedRow *//*
** If a row with rowid iDel is present in the %_content table, add the
** delete-markers to the FTS index necessary to delete it. Do not actually
** remove the %_content row at this time though.
**
** If parameter bSaveRow is true, then Fts5Storage.pSavedRow is left
** pointing to a statement (FTS5_STMT_LOOKUP2) that may be used to access
** the original values of the row being deleted. This is used by UPDATE
** statements.
*//*
** This function is used as part of an UPDATE statement that modifies the
** rowid of a row. In that case, this function is called first to set
** Fts5Storage.pSavedRow to point to a statement that may be used to
** access the original values of the row being deleted - iDel.
**
** SQLITE_OK is returned if successful, or an SQLite error code otherwise.
** It is not considered an error if row iDel does not exist. In this case
** pSavedRow is not set and SQLITE_OK returned.
*//* Pointer to Fts5InsertCtx object *//*
** Tokenization callback used when inserting tokens into the FTS index.
*//* Size of column value in tokens *//* Finalize all SQL statements *//*
** Close a handle opened by an earlier call to sqlite3Fts5StorageOpen().
*//* Fts5Storage.aTotalSize[] *//* Fts5Storage object *//* New object *//*
** Open a new Fts5Index handle. If the bCreate argument is true, create
** and initialize the underlying tables
**
** If successful, set *pp to point to the new object and return SQLITE_OK.
** Otherwise, set *pp to NULL and return an SQLite error code.
*//* True for without rowid *//* Columns etc. for shadow table *//* Shadow table to create (e.g. "content") *//* FTS5 configuration *//*
** Create the shadow table named zPost, with definition zDefn. Return
** SQLITE_OK if successful, or an SQLite error code otherwise.
*//* New name of FTS5 table *//* Tail of table name e.g. "data", "config" *//* Current FTS5 configuration *//*
** Drop all shadow tables. Return SQLITE_OK if successful or an SQLite error
** code otherwise.
*//* ... printf arguments *//* One of the internal tables - not the %_content table - is missing.
        ** This counts as a corrupted table.  *//* Add bindings for any "l*" columns. Only non-UNINDEXED columns
        ** require these.  *//* Add bindings for the "c*" columns - those that store the actual
        ** table content. If eContent==NORMAL, then there is one binding
        ** for each column. Or, if eContent==UNINDEXED, then there are only
        ** bindings for the UNINDEXED columns. *//* SCAN *//* REPLACE_CONFIG *//* LOOKUP_DOCSIZE  *//* DELETE_DOCSIZE  *//* REPLACE_DOCSIZE  *//* DELETE_CONTENT  *//* REPLACE_CONTENT *//* INSERT_CONTENT  *//* LOOKUP2  *//* LOOKUP  *//* If there is no %_docsize table, there should be no requests for
  ** statements to operate on it.  *//* OUT: Prepared statement handle *//* FTS5_STMT_XXX constant *//* Storage handle *//*
** Prepare the two insert statements - Fts5Storage.pInsertContent and
** Fts5Storage.pInsertDocsize - if they have not already been prepared.
** Return SQLITE_OK if successful, or an SQLite error code if an error
** occurs.
*//* Total sizes of each column *//* Total number of rows in FTS table *//* True if nTotalRow/aTotalSize[] are valid *//*
** pSavedRow:
**   SQL statement FTS5_STMT_LOOKUP2 is a copy of FTS5_STMT_LOOKUP, it
**   does a by-rowid lookup to retrieve a single row from the %_content
**   table or equivalent external-content table/view.
**
**   However, FTS5_STMT_LOOKUP2 is only used when retrieving the original
**   values for a row being UPDATEd. In that case, the SQL statement is
**   not reset and pSavedRow is set to point at it. This is so that the
**   insert operation that follows the delete may access the original
**   row values for any new values for which sqlite3_value_nochange() returns
**   true. i.e. if the user executes:
**
**        CREATE VIRTUAL TABLE ft USING fts5(a, b, c, locale=1);
**        ...
**        UPDATE fts SET a=?, b=? WHERE rowid=?;
**
**   then the value passed to the xUpdate() method of this table as the
**   new.c value is an sqlite3_value_nochange() value. So in this case it
**   must be read from the saved row stored in Fts5Storage.pSavedRow.
**
**   This is necessary - using sqlite3_value_nochange() instead of just having
**   SQLite pass the original value back via xUpdate() - so as not to discard
**   any locale information associated with such values.
**
*//*
** 2014 May 31
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
*//*
** The following functions are used to register the module with SQLite. If
** this module is being built as part of the SQLite core (SQLITE_CORE is
** defined), then sqlite3_open() will call sqlite3Fts5Init() directly.
**
** Or, if this module is being built as a loadable extension,
** sqlite3Fts5Init() is omitted and the two standard entry points
** sqlite3_fts_init() and sqlite3_fts5_init() defined instead.
*//* If SQLITE_FTS5_ENABLE_TEST_MI is defined, assume that the file
  ** fts5_test_mi.c is compiled and linked into the executable. And call
  ** its entry point to enable the matchinfo() demo.  *//* Initialize pGlobal->aLocaleHdr[] to a 128-bit pseudo-random vector.
    ** The constants below were generated randomly.  *//* Write error message here *//* True if this is a quick-check *//* Name of the table itself *//* Name of schema in which this table lives *//* the FTS5 virtual table to check *//*
** Run an integrity check on the FTS5 data structures.  Return a string
** if anything is found amiss.  Return a NULL pointer if everything is
** OK.
*//*
** Return true if zName is the extension on one of the shadow tables used
** by this module.
*//* Function arguments *//* Number of args *//* Function call context *//*
** Implementation of fts5_insttoken() function.
*//*
** Implementation of fts5_locale(LOCALE, TEXT) function.
**
** If parameter LOCALE is NULL, or a zero-length string, then a copy of
** TEXT is returned. Otherwise, both LOCALE and TEXT are interpreted as
** text, and the value returned is a blob consisting of:
**
**     * The 4 bytes 0x00, 0xE0, 0xB2, 0xEb (FTS5_LOCALE_HEADER).
**     * The LOCALE, as utf-8 text, followed by
**     * 0x00, followed by
**     * The TEXT, as utf-8 text.
**
** There is no final nul-terminator following the TEXT value.
*//*
** Implementation of fts5_source_id() function.
*//*
** Implementation of the fts5() function used by clients to obtain the
** API pointer.
*//*
** xDestroy callback passed to sqlite3_create_module(). This is invoked
** when the db handle is being closed. Free memory associated with
** tokenizers and aux functions registered with this db handle.
*//*
** Attempt to instantiate the tokenizer.
*//* Name of new function *//* Global context (one per db handle) *//*
** Find a tokenizer. This is the implementation of the
** fts5_api.xFindTokenizer() method.
*//* Name of tokenizer *//*
** Find a tokenizer. This is the implementation of the
** fts5_api.xFindTokenizer_v2() method.
*//* Name of tokenizer module to find *//* Global (one per db handle) object *//*
** Search the global context passed as the first argument for a tokenizer
** module named zName. If found, return a pointer to the Fts5TokenizerModule
** object. Otherwise, return NULL.
*//* Destructor for pUserData *//* Tokenizer implementation *//* User data for aux. function *//*
** The fts5_api.xCreateTokenizer() method.
*//*
** Register a new tokenizer. This is the implementation of the
** fts5_api.xCreateTokenizer_v2() method.
*//*
** xTokenizer method for a wrapper tokenizer that offers the v2 interface
** (with locale support).
*//*
** xTokenizer method for a wrapper tokenizer that offers the v1 interface
** (no support for locales).
*//*
** Delete an Fts5VtoVTokenizer wrapper tokenizer.
*//*
** Create a wrapper tokenizer. The context argument pCtx points to the
** Fts5TokenizerModule object.
*//* V2 tokenizer functions *//* Tokenizer functions *//* True if v2 native tokenizer *//*
** An instance of this type is used as the Fts5Tokenizer object for
** wrapper tokenizers - those that provide access to a v1 tokenizer via
** the fts5_tokenizer_v2 API, and those that provide access to a v2 tokenizer
** via the fts5_tokenizer API.
*//* Size of zName and its \0 terminator *//*
** This function is used by xCreateTokenizer_v2() and xCreateTokenizer().
** It allocates and partially populates a new Fts5TokenizerModule object.
** The new object is already linked into the Fts5Global context before
** returning.
**
** If successful, SQLITE_OK is returned and a pointer to the new
** Fts5TokenizerModule object returned via output parameter (*ppNew). All
** that is required is for the caller to fill in the methods in
** Fts5TokenizerModule.x1 and x2, and to set Fts5TokenizerModule.bV2Native
** as appropriate.
**
** If an error occurs, an SQLite error code is returned and the final value
** of (*ppNew) undefined.
*//* Size of zName in bytes, including \0 *//* Aux. function implementation *//*
** Register a new auxiliary function with global context pGlobal.
*//*
** The xRollbackTo() method.
**
** Discard the contents of the pending terms table.
*//*
** The xRelease() method.
**
** This is a no-op.
*//*
** The xSavepoint() method.
**
** Flush the contents of the pending-terms table to disk.
*//* New name of table *//*
** Implementation of FTS5 xRename method. Rename an fts5 table.
*//* No function of the specified name was found. Return 0. *//*
** This routine implements the xFindFunction method for the FTS3
** virtual table.
*//* The value of the "rank" column. *//* User is requesting the value of the special column with the same name
    ** as the table. Return the cursor integer id number. This value is only
    ** useful in that it may be passed as the first argument to an FTS5
    ** auxiliary function.  *//*
** This is the xColumn method, called by SQLite to request a value from
** the row that the supplied cursor currently points to.
*//* Append the position lists *//* Append the varints *//*
** Return a "position-list blob" corresponding to the current position of
** cursor pCsr via sqlite3_result_blob(). A position-list blob contains
** the current position-list for each phrase in the query associated with
** cursor pCsr.
**
** A position-list blob begins with (nPhrase-1) varints, where nPhrase is
** the number of phrases in the query. Following the varints are the
** concatenated position lists for each phrase, in order.
**
** The first varint (if it exists) contains the size of the position list
** for phrase 0. The second (same disclaimer) contains the size of position
** list 1. And so on. There is no size field for the final position list,
** as it can be derived from the total size of the blob.
*//* Id of cursor to find *//* FTS5 global context for db handle *//*
** Given cursor id iId, return a pointer to the corresponding Fts5Table
** object. Or NULL If the cursor id does not exist.
*//*
** Parameter zFmt is a printf() style formatting string. This function
** formats it using the trailing arguments and returns the result as
** an error message to the context passed as the first argument.
*//*
** Implementation of API function xQueryPhrase().
*//*
** The xColumnLocale() API.
*//*
** xInstToken() API implemenetation.
*//*
** xQueryToken() API implemenetation.
*//* Avoid returning a (*piCol) value that is too large for the table,
      ** even if the position-list is corrupt. The caller might not be
      ** expecting it.  *//* Search through the cursors list of Fts5Auxdata objects for one that
  ** corresponds to the currently executing auxiliary function.  *//* Destructor for pPtr (or NULL) *//* Pointer to save as auxdata *//* Fts5 context *//*
** Implementation of the xSetAuxdata() method.
*//* Pointer to int *//* Initialize all iterators *//* Number instances seen so far *//* Number of iterators/phrases *//* One iterator for each phrase *//*
** Ensure that the Fts5Cursor.nInstCount and aInst[] variables are populated
** correctly for the current view. Return SQLITE_OK if successful, or an
** SQLite error code otherwise.
*//* OUT: Size of (*pa) in bytes *//* OUT: Pointer to position list buffer *//* Phrase to find position list for *//* Fts5 cursor object *//*
** This is called by various API functions - xInst, xPhraseFirst,
** xPhraseFirstColumn etc. - to obtain the position list for phrase iPhrase
** of the current row. This function works for both detail=full tables (in
** which case the position-list was read from the fts index) or for other
** detail= modes if the row content is available.
*//*
** Argument pStmt is an SQL statement of the type used by Fts5Cursor. This
** function extracts the text value of column iCol of the current row.
** Additionally, if there is an associated locale, it invokes
** sqlite3Fts5SetLocale() to configure the tokenizer. In all cases the caller
** should invoke sqlite3Fts5ClearLocale() to clear the locale at some point
** after this function returns.
**
** If successful, (*ppText) is set to point to a buffer containing the text
** value as utf-8 and SQLITE_OK returned. (*pnText) is set to the size of that
** buffer in bytes. It is not guaranteed to be nul-terminated. If an error
** occurs, an SQLite error code is returned. The final values of the two
** output parameters are undefined in this case.
*//*
** Implementation of xTokenize() API. This is just xTokenize_v2() with NULL/0
** passed as the locale.
*//*
** Implementation of xTokenize_v2() API.
*//*
** Implementation of xRollback(). Discard the contents of the pending-terms
** hash-table. Any changes made to the database are reverted by SQLite.
*//* Call below is a no-op for NDEBUG builds *//*
** Implementation of xCommit() method. This is a no-op. The contents of
** the pending-terms hash-table have already been flushed into the database
** by fts5SyncMethod().
*//*
** Implementation of xBegin() method.
*//*
** Implementation of xSync() method.
*//* This occurs when an UPDATE on a contentless table affects *only*
          ** UNINDEXED columns. This is a no-op for contentless_unindexed=0
          ** tables, or a write to the %_content table only for =1 tables.  *//* If this is a contentless table (including contentless_unindexed=1
        ** tables), check if the UPDATE may proceed.  *//* Content only update *//* New rowid *//* Old rowid *//* UPDATE *//* Rowid to delete *//* An INSERT statement. If the conflict-mode is REPLACE, first remove
        ** the current entry (if any). *//* It is an error to write an fts5_locale() value to a table without
      ** the locale=1 option. *//* INSERT or UPDATE *//* It is only possible to DELETE from a contentless table if the
      ** contentless_delete=1 flag is set. *//* DELETE *//* A regular INSERT, UPDATE or DELETE statement. The trick here is that
    ** any conflict on the rowid value must be detected before any
    ** modifications are made to the database file. There are 4 cases:
    **
    **   1) DELETE
    **   2) UPDATE (rowid not modified)
    **   3) UPDATE (rowid modified)
    **   4) INSERT
    **
    ** Cases 3 and 4 may violate the rowid constraint.
    *//* A "special" INSERT op. These are handled separately. *//* Put any active cursors into REQUIRE_SEEK state. *//* A transaction must be open when this is called. *//* value_type() of apVal[0] *//* OUT: The affected (or effected) rowid *//* Array of arguments *//* Size of argument array *//*
** This function is the implementation of the xUpdate callback used by
** FTS3 virtual tables. It is invoked by SQLite each time a row is to be
** inserted, updated or deleted.
**
** A delete specifies a single argument - the rowid of the row to remove.
**
** Update and insert operations pass:
**
**   1. The "old" rowid, or NULL.
**   2. The "new" rowid.
**   3. Values for each of the nCol matchable columns.
**   4. Values for the two hidden columns (<tablename> and "rank").
*//* Have seen unmodified indexed column *//* Have seen modified indexed column *//*
**
** This function is called when the user attempts an UPDATE on a contentless
** table. Parameter bRowidModified is true if the UPDATE statement modifies
** the rowid value. Parameter apVal[] contains the new values for each user
** defined column of the fts5 table. pConfig is the configuration object of the
** table being updated (guaranteed to be contentless). The contentless_delete=1
** and contentless_unindexed=1 options may or may not be set.
**
** This function returns SQLITE_OK if the UPDATE can go ahead, or an SQLite
** error code if it cannot. In this case an error message is also loaded into
** pConfig. Output parameter (*pbContent) is set to true if the caller should
** update the %_content table only - not the FTS index or any other shadow
** table. This occurs when an UPDATE modifies only UNINDEXED columns of the
** table.
**
** An UPDATE may proceed if:
**
**   * The only columns modified are UNINDEXED columns, or
**
**   * The contentless_delete=1 option was specified and all of the indexed
**     columns (not a subset) have been modified.
*//* Value inserted into rank column *//* Text inserted into table-name column *//* Fts5 table object *//*
** This function is called to handle an FTS INSERT command. In other words,
** an INSERT statement of the form:
**
**     INSERT INTO fts(fts) VALUES($pCmd)
**     INSERT INTO fts(fts, rank) VALUES($pCmd, $pVal)
**
** Argument pVal is the value assigned to column "fts" by the INSERT
** statement. This function returns SQLITE_OK if successful, or an SQLite
** error code if an error occurs.
**
** The commands implemented by this function are documented in the "Special
** INSERT Directives" section of the documentation. It should be updated if
** more commands are added to this function.
*//* If the cursor does not yet have a statement handle, obtain one now. *//*
** If the cursor requires seeking (bSeekRequired flag is set), seek it.
** Return SQLITE_OK if no error occurs, or an SQLite error code otherwise.
**
** If argument bErrormsg is true and an error occurs, an error message may
** be left in sqlite3_vtab.zErrMsg.
*//*
** This is the xRowid method. The SQLite core calls this routine to
** retrieve the rowid for the current row of the result set. fts5
** exposes %_content.rowid as the rowid for the virtual table. The
** rowid should be written to *pRowid.
*//*
** Return the rowid that the cursor currently points to.
*//* This is either a full-table scan (ePlan==FTS5_PLAN_SCAN) or a lookup
    ** by rowid (ePlan==FTS5_PLAN_ROWID).  *//* If pSortCsr is non-NULL, then this call is being made as part of
    ** processing for a "... MATCH <expr> ORDER BY rank" query (ePlan is
    ** set to FTS5_PLAN_SORTED_MATCH). pSortCsr is the cursor that will
    ** return results to the user for this query. The current cursor
    ** (pCursor) is used to execute the query issued by function
    ** fts5CursorFirstSorted() above.  *//* Set the cursor upper and lower rowid limits. Only some strategies
  ** actually use them. This is ok, as the xBestIndex() method leaves the
  ** sqlite3_index_constraint.omit flag clear for range constraints
  ** on the rowid field.  *//* The user has issued a query of the form "MATCH '*...'". This
          ** indicates that the MATCH expression is not a full text query,
          ** but a request for an internal parameter.  *//* Decode the arguments passed through to this function. *//* Column on LHS of MATCH operator *//* rowid >= ? expression (or NULL) *//* rowid <= ? expression (or NULL) *//* rowid = ? expression (or NULL) *//* rank MATCH ? expression (or NULL) *//* True if ORDER BY rank *//* True if ORDER BY [rank|rowid] DESC *//*
** This is the xFilter interface for the virtual table.  See
** the virtual table xFilter method documentation for additional
** information.
**
** There are three possible query strategies:
**
**   1. Full-text search using a MATCH operator.
**   2. A by-rowid lookup.
**   3. A full-table scan.
*//* OUT: Free (*pzText) and clear locale *//* OUT: nul-terminated buffer of text *//* Value to extract expression text from *//* Fts5 configuration *//*
** Argument pVal is the text of a full-text search expression. It may or
** may not have been wrapped by fts5_locale(). This function extracts
** the text of the expression, and sets output variable (*pzText) to
** point to a nul-terminated buffer containing the expression.
**
** If pVal was an fts5_locale() value, then sqlite3Fts5SetLocale() is called
** to set the tokenizer to use the specified locale.
**
** If output variable (*pbFreeAndReset) is set to true, then the caller
** is required to (a) call sqlite3Fts5ClearLocale() to reset the tokenizer
** locale, and (b) call sqlite3_free() to free (*pzText).
*//*
** Value pVal is guaranteed to be an fts5_locale() value, according to
** sqlite3Fts5IsLocaleValue(). This function extracts the text and locale
** from the value and returns them separately.
**
** If successful, SQLITE_OK is returned and (*ppText) and (*ppLoc) set
** to point to buffers containing the text and locale, as utf-8,
** respectively. In this case output parameters (*pnText) and (*pnLoc) are
** set to the sizes in bytes of these two buffers.
**
** Or, if an error occurs, then an SQLite error code is returned. The final
** value of the four output parameters is undefined in this case.
*//* Call sqlite3_value_bytes() after sqlite3_value_blob() in this case.
    ** If the blob was created using zeroblob(), then sqlite3_value_blob()
    ** may call malloc(). If this malloc() fails, then the values returned
    ** by both value_blob() and value_bytes() will be 0. If value_bytes() were
    ** called first, then the NULL pointer returned by value_blob() might
    ** be dereferenced.  *//*
** Return true if the value passed as the only argument is an
** fts5_locale() value.
*//*
** Clear any locale configured by an earlier call to sqlite3Fts5SetLocale().
*//*
** Arrange for subsequent calls to sqlite3Fts5Tokenize() to use the locale
** specified by pLocale/nLocale. The buffer indicated by pLocale must remain
** valid until after the final call to sqlite3Fts5Tokenize() that will use
** the locale.
*//*
** Set the error message on the virtual table passed as the first argument.
*//*
** Search for an auxiliary function named zName that can be used with table
** pTab. If one is found, return a pointer to the corresponding Fts5Auxiliary
** structure. Otherwise, if no such function exists, return NULL.
*//* An unrecognized directive. Return an error message. *//* Number of bytes in text at z *//* Special query text *//*
** Process a "special" query. A special query is identified as one with a
** MATCH expression that begins with a '*' character. The remainder of
** the text passed to the MATCH operator are used as  the special query
** parameters.
*//* TODO: It would be better to have some system for reusing statement
  ** handles here, rather than preparing a new one for each query. But that
  ** is not possible as SQLite reference counts the virtual table objects.
  ** And since the statement required here reads from this very virtual
  ** table, saving it creates a circular reference.
  **
  ** If SQLite a built-in statement cache, this wouldn't be a problem. *//* If this cursor uses FTS5_PLAN_MATCH and this is a tokendata=1 table,
  ** clear any token mappings accumulated at the fts5_index.c level. In
  ** other cases, specifically FTS5_PLAN_SOURCE and FTS5_PLAN_SORTED_MATCH,
  ** we need to retain the mappings for the entire query.  *//*
** Advance the cursor to the next row in the table that matches the
** search criteria.
**
** Return SQLITE_OK if nothing goes wrong.  SQLITE_OK is returned
** even if we reach end-of-file.  The fts5EofMethod() will be called
** subsequently to determine whether or not an EOF was hit.
*//*
** If the REQUIRE_RESEEK flag is set on the cursor passed as the first
** argument, close and reopen all Fts5IndexIter iterators that the cursor
** is using. Then attempt to move the cursor to a rowid equal to or laster
** (in the cursors sort order - ASC or DESC) than the current rowid.
**
** If the new rowid is not equal to the old, set output parameter *pbSkip
** to 1 before returning. Otherwise, leave it unchanged.
**
** Return SQLITE_OK if successful or if no reseek was required, or an
** error code if an error occurred.
*//*
** Set the FTS5CSR_REQUIRE_RESEEK flag on all FTS5_PLAN_MATCH cursors
** open on table pTab.
*//* nBlob==0 in detail=none mode. *//* Remove the cursor from the Fts5Global.pCsr list *//*
** This function is called after the cursor passed as the only argument
** is moved to point at a different row. It clears all cached data
** specific to the previous row stored by the cursor object.
*//* New cursor object *//* Calculate the estimated cost based on the flags set in idxFlags. *//* Set idxFlags flags for the ORDER BY clause
  **
  ** Note that tokendata=1 tables cannot currently handle "ORDER BY rowid DESC".
  *//* As there exists an unusable MATCH constraint this is an
        ** unusable plan. Return SQLITE_CONSTRAINT. *//* A MATCH operator or equivalent *//* Parameter passed through to xFilter() *//*
** Implementation of the xBestIndex method for FTS5 tables. Within the
** WHERE constraint, it searches for the following:
**
**   1. A MATCH constraint against the table column.
**   2. A MATCH constraint against the "rank" column.
**   3. A MATCH constraint against some other column.
**   4. An == constraint against the rowid column.
**   5. A < or <= constraint against the rowid column.
**   6. A > or >= constraint against the rowid column.
**
** Within the ORDER BY, the following are supported:
**
**   5. ORDER BY rank [ASC|DESC]
**   6. ORDER BY rowid [ASC|DESC]
**
** Information for the xFilter call is passed via both the idxNum and
** idxStr variables. Specifically, idxNum is a bitmask of the following
** flags used to encode the ORDER BY clause:
**
**     FTS5_BI_ORDER_RANK
**     FTS5_BI_ORDER_ROWID
**     FTS5_BI_ORDER_DESC
**
** idxStr is used to encode data from the WHERE clause. For each argument
** passed to the xFilter method, the following is appended to idxStr:
**
**   Match against table column:            "m"
**   Match against rank column:             "r"
**   Match against other column:            "M<column-number>"
**   LIKE  against other column:            "L<column-number>"
**   GLOB  against other column:            "G<column-number>"
**   Equality constraint against the rowid: "="
**   A < or <= against the rowid:           "<"
**   A > or >= against the rowid:           ">"
**
** This function ensures that there is at most one "r" or "=". And that if
** there exists an "=" then there is no "<" or ">".
**
** If an unusable MATCH operator is present in the WHERE clause, then
** SQLITE_CONSTRAINT is returned.
**
** Costs are assigned as follows:
**
**  a) If a MATCH operator is present, the cost depends on the other
**     constraints also present. As follows:
**
**       * No other constraints:         cost=1000.0
**       * One rowid range constraint:   cost=750.0
**       * Both rowid range constraints: cost=500.0
**       * An == rowid constraint:       cost=100.0
**
**  b) Otherwise, if there is no MATCH:
**
**       * No other constraints:         cost=1000000.0
**       * One rowid range constraint:   cost=750000.0
**       * Both rowid range constraints: cost=250000.0
**       * An == rowid constraint:       cost=10.0
**
** Costs are not modified by the ORDER BY clause.
*//*
** Set the SQLITE_INDEX_SCAN_UNIQUE flag in pIdxInfo->flags. Unless this
** extension is currently being used by a version of SQLite too old to
** support index-info flags. In that case this function is a no-op.
*//* (rowid = ?) *//* No usable constraint *//* (<tbl> MATCH ? ORDER BY rank) *//* An internal query *//* A source cursor for SORTED_MATCH *//* (<tbl> MATCH ?) *//*
** The different query plans.
*//*
** The xConnect() and xCreate() methods for the virtual table. All the
** work is done in function fts5InitVtab().
*//* Load the initial configuration *//* Call sqlite3_declare_vtab() *//* Open the storage sub-system *//* Open the index sub-system *//* Allocate the new vtab object and parse the configuration *//* New virtual table object *//* Results of parsing argc/argv *//* Hash table containing tokenizers *//* True for xCreate, false for xConnect *//*
** This function is the implementation of both the xConnect and xCreate
** methods of the FTS3 virtual table.
**
** The argv[] array contains the following:
**
**   argv[0]   -> module name  ("fts5")
**   argv[1]   -> database name
**   argv[2]   -> table name
**   argv[...] -> "column name" and other module argument fields.
*//*
** Delete a virtual table handle allocated by fts5InitVtab().
*//*
** Return true if pTab is a contentless table. If parameter bIncludeUnindexed
** is true, this includes contentless tables that store UNINDEXED columns
** only.
*//* assert( iSavepoint<=p->ts.iSavepoint ); *//* The following assert() can fail if another vtab strikes an error
      ** within an xSavepoint() call then SQLite calls xRollbackTo() - without
      ** having called xSavepoint() on this vtab.  *//* Next object in linked list *//* Destructor *//* Pointer value *//* Extension to which this belongs *//*
** Macros to Set(), Clear() and Test() cursor flags.
*//*
** Values for Fts5Cursor.csrflags
*//* rowid >= ? *//* rowid <= ? *//* rowid == ? *//* rank MATCH ? *//* <tbl> MATCH ? *//*
** Bits that make up the "idxNum" parameter passed indirectly by
** xBestIndex() to xFilter().
*//* 3 integers per phrase instance *//* Number of phrase instances *//* Size of aInst[] array (entries / 3) *//* One for each phrase *//* Cache used by auxiliary API functions xInst() and xInstCount() *//* First in linked list of saved aux-data *//* Currently executing extension function *//* Auxiliary data storage *//* Origin of objects in apRankArg[] *//* Number of trailing arguments for rank() *//* Rank callback (or NULL) *//* Custom rank function args *//* Custom rank function *//* "rank" function. Populated on demand from vtab.xColumn(). *//* Result of special query *//* Mask of cursor flags (see below) *//* Sorter for "ORDER BY rank" queries *//* Expression for MATCH queries *//* Statement used to read %_content *//* Return no rowids later than this *//* Return no rowids earlier than this *//* True for "ORDER BY rowid DESC" queries *//* FTS5_PLAN_XXX value *//* Zero from this point onwards on cursor reset *//* Cursor id *//* Values for xColumnSize() *//* Next cursor in Fts5Cursor.pCsr list *//* Base class used by SQLite core *//*
** Virtual-table cursor object.
**
** iSpecial:
**   If this is a 'special' query (refer to function fts5SpecialMatch()),
**   then this variable contains the result of the query.
**
** iFirstRowid, iLastRowid:
**   These variables are only used for FTS5_PLAN_MATCH cursors. Assuming the
**   cursor iterates in ascending order of rowids, iFirstRowid is the lower
**   limit of rowids to return, and iLastRowid the upper. In other words, the
**   WHERE clause in the user's query might have been:
**
**       <tbl> MATCH <expr> AND rowid BETWEEN $iFirstRowid AND $iLastRowid
**
**   If the cursor iterates in descending order of rowid, iFirstRowid
**   is the upper limit (i.e. the "first" rowid visited) and iLastRowid
**   the lower.
*//* Offsets into aPoslist for current row *//* Number of entries in aIdx[] *//* Position lists for current row *//*
** pStmt:
**   SELECT rowid, <fts> FROM <fts> ORDER BY +rank;
**
** aIdx[]:
**   There is one entry in the aIdx[] array for each phrase in the query,
**   the value of which is the offset within aPoslist[] following the last
**   byte of the position list for the corresponding phrase.
*//* Size of phrase in terms *//* Pointer to current poslist *//* Successful xSavepoint()+1 *//* Sort data from this cursor *//* Global (connection wide) data *//* Document store *//* Public class members from fts5Int.h *//* Next registered tokenizer module *//* Destructor function *//* User pointer passed to xCreate() *//*
** Each tokenizer module registered with the FTS5 module is represented
** by an object of the following type. All such objects are stored as part
** of the Fts5Global.pTok list.
**
** bV2Native:
**  True if the tokenizer was registered using xCreateTokenizer_v2(), false
**  for xCreateTokenizer(). If this variable is true, then x2 is populated
**  with the routines as supplied by the caller and x1 contains synthesized
**  wrapper routines. In this case the user-data pointer passed to
**  x1.xCreate should be a pointer to the Fts5TokenizerModule structure,
**  not a copy of pUserData.
**
**  Of course, if bV2Native is false, then x1 contains the real routines and
**  x2 the synthesized ones. In this case a pointer to the Fts5TokenizerModule
**  object should be passed to x2.xCreate.
**
**  The synthesized wrapper routines are necessary for xFindTokenizer(_v2)
**  calls.
*//* Next registered auxiliary function *//* User-data pointer *//* Function name (nul-terminated) *//* Global context for this function *//*
** Each auxiliary function registered with the FTS5 module is represented
** by an object of the following type. All such objects are stored as part
** of the Fts5Global.pAux list.
*//*
** Size of header on fts5_locale() values. And macro to access a buffer
** containing a copy of the header from an Fts5Config pointer.
*//* First in list of all open cursors *//* Default tokenizer module *//* First in list of all tokenizer modules *//* First in list of all aux. functions *//* Used to allocate unique cursor ids *//* Associated database connection *//* User visible part of object (see fts5.h) *//*
** A single object of this type is allocated when the FTS5 module is
** registered with a database handle. It is used to store pointers to
** all registered FTS5 extensions - tokenizers and auxiliary functions.
*//* Number of open savepoints (0 -> none) *//* 0==closed, 1==open, 2==synced *//*
** NOTES ON TRANSACTIONS:
**
** SQLite invokes the following virtual table methods as transactions are
** opened and closed by the user:
**
**     xBegin():    Start of a new transaction.
**     xSync():     Initial part of two-phase commit.
**     xCommit():   Final part of two-phase commit.
**     xRollback(): Rollback the transaction.
**
** Anything that is required as part of a commit that may fail is performed
** in the xSync() callback. Current versions of SQLite ignore any errors
** returned by xCommit().
**
** And as sub-transactions are opened/closed:
**
**     xSavepoint(int S):  Open savepoint S.
**     xRelease(int S):    Commit and close savepoint S.
**     xRollbackTo(int S): Rollback to start of savepoint S.
**
** During a write-transaction the fts5_index.c module may cache some data
** in-memory. It is flushed to disk whenever xSync(), xRelease() or
** xSavepoint() is called. And discarded whenever xRollback() or xRollbackTo()
** is called.
**
** Additionally, if SQLITE_DEBUG is defined, an instance of the following
** structure is used to record the current transaction state. This information
** is not required, but it is used in the assert() statements executed by
** function fts5CheckTransactionState() (see below).
*//*
** This variable is set to false when running tests for which the on disk
** structures should not be corrupt. Otherwise, true. If it is false, extra
** assert() conditions in the fts5 code are activated - conditions that are
** only true if it is guaranteed that the fts5 database is not corrupt.
*//*
** 2014 Jun 09
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This is an SQLite module implementing full-text search.
*//*
** This is called as part of registering the FTS5 module with database
** connection db. It registers several user-defined scalar functions useful
** with FTS5.
**
** If successful, SQLITE_OK is returned. If an error occurs, some other
** SQLite error code is returned instead.
*//* SQLITE_TEST || SQLITE_FTS5_DEBUG *//*
** Initialize a cursor.
**
**    idxNum==0     means show all subprograms
**    idxNum==1     means show only the main bytecode and omit subprograms.
*//* nentry *//* nentrytombstone *//* npgtombstone *//* origin2 *//* origin1 *//* leaf2 *//* leaf1 *//* segid *//* merge *//* segment *//* level *//*
** Return values of columns for the row at which the bytecodevtab_cursor
** is currently pointing.
*//*
** Advance a bytecodevtab_cursor to its next row of output.
*//*
** Destructor for a bytecodevtab_cursor.
*//*
** Constructor for a new bytecodevtab_cursor object.
*//*
** This method is the destructor for bytecodevtab objects.
*//*
** We must have a single struct=? constraint that will be passed through
** into the xFilter method.  If there is no valid struct=? constraint,
** then return an SQLITE_CONSTRAINT error.
*//*
** Create a new fts5_structure() table-valued function.
*//* Number of args (always 2) *//*
** The implementation of user-defined scalar function fts5_rowid().
*//* Bytes of data *//* True for first term on page *//* Decode any more doclist data that appears on the page before the
    ** first term. *//* Decode the position list tail at the start of the page *//* Previous value read from pgidx *//* Offset of pgidx in a[] *//* Current term read from page *//* Figure out where the doclist for this term ends *//* Read the term data for the next term*//* Decode any entries that occur before the first term. *//* Make a copy of the second argument (a blob) in aBlob[]. The aBlob[]
  ** copy is followed by FTS5_DATA_ZERO_PADDING 0x00 bytes, which prevents
  ** buffer overreads even if the record is corrupt.  *//* Build up text to return here *//* Record to decode *//* Rowid components *//* Rowid for record being decoded *//*
** The implementation of user-defined scalar function fts5_decode().
*//* Data to decode list-of-rowids from *//* Buffer to append text to *//*
** This function is part of the fts5_decode() debugging function. It is
** only ever used with detail=none tables.
**
** Buffer (pData/nData) contains a doclist in the format used by detail=none
** tables. This function appends a human-readable version of that list to
** buffer pBuf.
**
** If *pRc is other than SQLITE_OK when this function is called, it is a
** no-op. If an OOM or other error occurs within this function, *pRc is
** set to an SQLite error code before returning. The final state of buffer
** pBuf is undefined in this case.
*//*
** The start of buffer (a/n) contains the start of a doclist. The doclist
** may or may not finish within the buffer. This function appends a text
** representation of the part of the doclist that is present to buffer
** pBuf.
**
** The return value is the number of bytes read from the input buffer.
*//*
** Buffer (a/n) is assumed to contain a list of serialized varints. Read
** each varint and append its string representation to buffer pBuf. Return
** after either the input buffer is exhausted or a 0 value is read.
**
** The return value is the number of bytes read from the input buffer.
*//* IN/OUT: error code *//*
** This is part of the fts5_decode() debugging aid.
**
** Arguments pBlob/nBlob contain an "averages" record. This function
** appends a human-readable representation of record to the buffer passed
** as the second argument.
*//* Decoded structure object *//*
** This is part of the fts5_decode() debugging aid.
**
** Arguments pBlob/nBlob contain a serialized Fts5Structure object. This
** function appends a human-readable representation of the same object
** to the buffer passed as the second argument.
*//* Iterate through levels, segments *//* Rowid compenents *//* OUT: Page number *//* OUT: Height *//* OUT: Dlidx flag *//* OUT: Segment id *//* OUT: Tombstone hash flag *//* Rowid from %_data table *//*
** Decode a segment-data rowid from the %_data table. This function is
** the opposite of macro FTS5_SEGMENT_ROWID().
*//*************************************************************************
**************************************************************************
** Below this point is the implementation of the fts5_decode() scalar
** function only.
*//* If this is a new term, query for it. Update cksum3 with the results. *//* Offset within poslist *//* Position read from poslist *//* Size of term in bytes *//* The cksum argument passed to this function is a checksum calculated
  ** based on all expected entries in the FTS index (including prefix index
  ** entries). This block checks that a checksum calculated based on the
  ** actual contents of FTS index is identical.
  **
  ** Two versions of the same checksum are calculated. The first (stack
  ** variable cksum2) based on entries extracted from the full-text index
  ** while doing a linear scan of each individual index in turn.
  **
  ** As each term visited by the linear scans, a separate query for the
  ** same term is performed. cksum3 is calculated based on the entries
  ** extracted by these queries.
  *//* Check that the internal nodes of each segment match the leaves *//* Load the FTS index structure *//* Buffer used to hold most recent term *//* Checksum based on contents of indexes *//* Used by extra internal tests only run if NDEBUG is not defined *//* Index structure *//* Used to iterate through entire index *//* Buffer used to hold a poslist *//*
** Run internal checks to ensure that the FTS index (a) is internally
** consistent and (b) contains entries for which the XOR of the checksums
** as calculated by sqlite3Fts5IndexEntryCksum() is cksum.
**
** Return SQLITE_CORRUPT if any of the internal checks fail, or if the
** checksum does not match. Return SQLITE_OK if all checks pass without
** error, or some other SQLite error code if another error (e.g. OOM)
** occurs.
*//* Page iter.iLeaf must now be the rightmost leaf-page in the segment *//* TODO: Check there is no doclist index *//* Check that the leaf page indicated by the iterator really does
        ** contain the rowid suggested by the same. *//* Check any rowid-less pages that occur before the current leaf. *//* For iterating through doclist index *//* If there is a doclist-index, check that it looks right. *//* Now check that the iter.nEmpty leaves following the current leaf
    ** (a) exist and (b) contain no terms. *//* Comparison of term and split-key *//* Size of term on leaf in bytes *//* Offset of first rowid on leaf *//* Offset of first term on leaf *//* special case - the very first page in a segment keeps its %_idx
        ** entry even if all the terms are removed from it by secure-delete
        ** operations. *//* Check that the leaf contains at least one term, and that it is equal
    ** to or larger than the split-key in zIdxTerm.  Also check that if there
    ** is also a rowid pointer within the leaf page header, it points to a
    ** location before the term.  *//* If the leaf in question has already been trimmed from the segment,
    ** ignore this b-tree entry. Otherwise, load it into memory. *//* Data for this leaf *//* Rowid for this leaf *//* Iterate through the b-tree hierarchy.  *//* Segment to check internal consistency *//* FTS5 backend object *//* Now check that the iter.nEmpty leaves following the current leaf
  ** (a) exist and (b) contain no terms. *//*
** Check that:
**
**   1) All leaves of pSeg between iFirst and iLast (inclusive) exist and
**      contain zero terms.
**   2) All leaves of pSeg between iNoRowid and iLast (inclusive) exist and
**      contain zero rowids.
*//* If this is a prefix query, check that the results returned if the
    ** the index is disabled are the same. In both ASC and DESC order.
    **
    ** This check may only be performed if the hash table is empty. This
    ** is because the hash table only supports a single scan query at
    ** a time, and the multi-iter loop from which this function is called
    ** is already performing such a scan.
    **
    ** Also only do this if buffer zTerm contains nTerm bytes of valid
    ** utf-8. Otherwise, the last part of the buffer contents might contain
    ** a non-utf-8 sequence that happens to be a prefix of a valid utf-8
    ** character stored in the main fts index, which will cause the
    ** test to fail.  *//* Check that the results returned for ASC and DESC queries are
    ** the same. If not, call this corruption.  *//* Size of zTerm in bytes *//* term sans prefix-byte *//* Possibly new term to test *//* Previous term *//*
** This function is also purely an internal test. It does not contribute to
** FTS functionality, or even the integrity-check, in any way.
*//*
** Check if buffer z[], size n bytes, contains as series of valid utf-8
** encoded codepoints. If so, return 0. Otherwise, if the buffer does not
** contain valid utf-8, return non-zero.
*//* IN/OUT: Checksum value *//* Flags for Fts5IndexQuery *//* Size of index key in bytes *//* Index key to query for *//* Fts5 index object *//* Load doclist-index for this leaf *//* Segment id to load from *//*
** This function is purely an internal test. It does not contribute to
** FTS functionality, or even the integrity-check, in any way.
**
** Instead, it tests that the same set of pgno/rowid combinations are
** visited regardless of whether the doclist-index identified by parameters
** iSegid/iLeaf is iterated in forwards or reverse order.
*//*
** Return a simple checksum value based on the arguments.
*//*************************************************************************
**************************************************************************
** Below this point is the implementation of the integrity-check
** functionality.
*//* True after pSeg->nEntryTombstone incr. *//*
** Add iRowid to the tombstone list of the segment or segments that contain
** rows from origin iOrigin. Return SQLITE_OK if successful, or an SQLite
** error code otherwise.
*//* If all has succeeded, write the new rowid into one of the new hash
  ** table pages, then write them all out to disk. *//* Rebuild the hash table *//* Have to rebuild the hash table. First figure out the key-size (4 or 8). *//*
** Add a tombstone for rowid iRowid to segment pSeg.
*//* If control flows to here, it was not possible to rebuild the hash
    ** table. Free all buffers and then try again with more pages. *//* Rebuild the hash table. *//* Allocate space for the new hash table *//* Allocate the required array and output pages *//* Case 3. *//* Case 2. *//* Case 1. *//* Figure out how many output pages (nOut) and how many slots per
  ** page (nSlot).  There are three possibilities:
  **
  **   1. The hash table does not yet exist. In this case the new hash
  **      table will consist of a single page with MINSLOT slots.
  **
  **   2. The hash table exists but is currently a single page. In this
  **      case an attempt is made to grow the page to accommodate the new
  **      entry. The page is allowed to grow up to nSlotPerPage (see above)
  **      slots.
  **
  **   3. The hash table already consists of more than one page, or of
  **      a single page already so large that it cannot be grown. In this
  **      case the new hash consists of (nPg*2+1) pages of nSlotPerPage
  **      slots each, where nPg is the current number of pages in the
  **      hash table.
  *//* Number of slots in each output page *//* OUT: Output hash pages *//* OUT: Number of output pages *//* 4 or 8, the keysize *//* Which page of the current hash is pData1 *//* One page of current hash - or NULL *//* Segment to rebuild hash of *//*
** This is called to rebuild the hash table belonging to segment pSeg.
** If parameter pData1 is not NULL, then one page of the existing hash table
** has already been loaded - pData1, which is page iPg1. The key-size for
** the new hash table is szKey (4 or 8).
**
** If successful, the new hash table is not written to disk. Instead,
** output parameter (*pnOut) is set to the number of pages in the new
** hash table, and (*papOut) to point to an array of buffers containing
** the new page data.
**
** If an error occurs, an error code is left in the Fts5Index object and
** both output parameters set to 0 before returning.
*//* If this is page 0 of the old hash, copy the rowid-0-flag from the
      ** old hash to the new.  *//* If iVal is not 0 at this point, insert it into the new hash table *//* Read the value from slot iIn of the input page into iVal. *//* Free this at the end of the loop *//* Page ii of the current hash table *//* Loop through the current pages of the hash table. *//* Initialize the headers of all the output pages *//* Array of output hash pages *//* Number of output pages *//*
** This function attempts to build a new hash containing all the keys
** currently in the tombstone hash table for segment pSeg. The new
** hash will be stored in the nOut buffers passed in array apOut[].
** All pages of the new hash use key-size szKey (4 or 8).
**
** Return 0 if the hash is successfully rebuilt into the nOut pages.
** Or non-zero if it is not (because one page became overfull). In this
** case the caller should retry with a larger nOut parameter.
**
** Parameter pData1 is page iPg1 of the hash table being rebuilt.
*//*
** Buffer pPg contains a page of a tombstone hash table - one of nPg pages
** associated with the same segment. This function adds rowid iRowid to
** the hash table. The caller is required to guarantee that there is at
** least one free slot on the page.
**
** If parameter bForce is false and the hash table is deemed to be full
** (more than half of the slots are occupied), then non-zero is returned
** and iRowid not inserted. Or, if bForce is true or if the hash table page
** is not full, iRowid is inserted and zero returned.
*//*
** Retrieve the origin value that will be used for the segment currently
** being accumulated in the in-memory hash table when it is flushed to
** disk. If successful, SQLITE_OK is returned and (*piOrigin) set to
** the queried value. Or, if an error occurs, an error code is returned
** and the final value of (*piOrigin) is undefined.
*//* Binary representation of iNew *//* Configuration object *//*
** Set the 32-bit cookie value stored at the start of all structure
** records to the value passed as the second argument.
**
** Return SQLITE_OK if successful, or an SQLite error code if an error
** occurs.
*//*
** Return the total number of blocks this module has read from the %_data
** table since it was created.
*//*
** Replace the current "averages" record with the contents of the buffer
** supplied as the second argument.
*//*
** Read and decode the "averages" record from the database.
**
** Parameter anSize must point to an array of size nCol, where nCol is
** the number of user defined columns in the FTS table.
*//*
** Close an iterator opened by an earlier call to sqlite3Fts5IndexQuery().
*//* This is a prefix term iterator. *//*
** Set a token-mapping for the iterator passed as the first argument. This
** is used in detail=column or detail=none mode when a token is requested
** using the xInstToken() API. In this case the caller tokenizers the
** current row and configures the token-mapping via multiple calls to this
** function.
*//*
** Clear any existing entries from the token-map associated with the
** iterator passed as the only argument.
*//*
** This is used by xInstToken() to access the token at offset iOff, column
** iCol of row iRowid. The token is returned via output variables *ppOut
** and *pnOut. The iterator passed as the first argument must be a tokendata=1
** iterator (pIter->pTokenDataIter!=0).
**
** pToken/nToken:
*//* Fill in the token prefix to search for *//* Size of pToken in bytes *//* Token prefix to search for *//*
** pIter is a prefix query. This function populates pIter->pTokenDataIter
** with an Fts5TokenDataIter object containing mappings for all rows
** matched by the query.
*//*
** Return the current term.
*//*
** Move to the next matching rowid that occurs at or after iMatch. The
** definition of "at or after" depends on whether this iterator iterates
** in ascending or descending rowid order.
*//*
** Move to the next matching term/rowid. Used by the fts5vocab module.
*//*
** Move to the next matching rowid.
*//*
** Return true if the iterator passed as the only argument is at EOF.
*//* Scan multiple terms in the main index for a prefix query. *//* Straight index lookup *//* Figure out which index to search and set iIdx accordingly. If this
    ** is a prefix query for which there is no prefix index, set iIdx to
    ** greater than pConfig->nPrefix to indicate that the query will be
    ** satisfied by scanning multiple terms in the main index.
    **
    ** If the QUERY_TEST_NOIDX flag was specified, then this must be a
    ** prefix-query. Instead of using a prefix-index (if one exists),
    ** evaluate the prefix query using the main FTS index. This is used
    ** for internal sanity checking by the integrity-check in debug
    ** mode only.  *//* The NOTOKENDATA flag is set when each token in a tokendata=1 table
    ** should be treated individually, instead of merging all those with
    ** a common prefix into a single entry. This is used, for example, by
    ** queries performed as part of an integrity-check, or by the fts5vocab
    ** module.  *//* +1 prefix index *//* Index to search *//* If the QUERY_SCAN flag is set, all other flags must be clear. *//* OUT: New iterator object *//* Match these columns only *//* Mask of FTS5INDEX_QUERY_X flags *//* Token (or prefix) to query for *//* FTS index to query *//*
** Open a new iterator to iterate though all rowid that match the
** specified token or token prefix.
*//* Append this iterator to the set and continue. *//* If pSmall is still NULL at this point, then the new iterator does
    ** not point to any terms that match the query. So delete it and break
    ** out of the loop - all required iterators have been collected.  *//* Loop through all segments in the new iterator. Find the smallest
    ** term that any segment-iterator points to. Iterator pNew will be
    ** used for this term. Also, set any iterator that points to a term that
    ** does not match pToken/nToken to point to EOF *//* Colset to filter on *//* Size of buffer pToken in bytes *//* Buffer containing query term *//*
** This function sets up an iterator to use for a non-prefix query on a
** tokendata=1 table.
*//*
** If the segment-iterator passed as the first argument is at EOF, then
** set pIter->term to a copy of buffer pTerm.
*//*
** The iterator passed as the only argument must be a tokendata=1 iterator
** (pIter->pTokenDataIter!=0). This function advances the iterator. If
** argument bFrom is false, then the iterator is advanced to the next
** entry. Or, if bFrom is true, it is advanced to the first entry with
** a rowid of iFrom or greater.
*//* If all readers were at EOF, break out of the loop. *//* Find smallest position *//* Ensure the token-mapping is large enough *//* Ensure the output buffer is large enough *//* Populate an iterator for each poslist that will be merged *//* Allocate array of iterators if they are not already allocated. *//*
** The iterator passed as the only argument must be a tokendata=1 iterator
** (pIter->pTokenDataIter!=0). This function sets the iterator output
** variables (pIter->base.*) according to the contents of the current
** row.
*//* Append this iterator *//* Current Fts5TokenDataIter struct *//* Index object (for error code) *//*
** This function appends iterator pAppend to Fts5TokenDataIter pIn and
** returns the result.
*//*
** Ensure the segment-iterator passed as the only argument points to EOF.
*//*
** pToken points to a buffer of size nToken bytes containing a search
** term, including the index number at the start, used on a tokendata=1
** table. This function returns true if the term in buffer pBuf matches
** token pToken/nToken.
*//* Add the entry to the main terms index. *//* Used to iterate through indexes *//* Token to add or remove to or from index *//* Position of token within column *//* Column token appears in (-ve -> delete) *//* Index to write to *//*
** Insert or remove data to or from the index. Each time a document is
** added to or removed from the index, this function is called one or more
** times.
**
** For an insert, it must be called once for each token in the new document.
** If the operation is a delete, it must be called (at least) once for each
** unique token in the document with an iCol value less than zero. The iPos
** argument is ignored for a delete.
*//*
** pIn is a UTF-8 encoded string, nIn bytes in size. Return the number of
** unicode characters in the string.
*//* Input contains fewer than nChar chars *//*
** Argument p points to a buffer containing utf-8 text that is n bytes in
** size. Return the number of bytes in the nChar character prefix of the
** buffer, or 0 if there are less than nChar characters in total.
*//*
** Close a handle opened by an earlier call to sqlite3Fts5IndexOpen().
*//*
** Open a new Fts5Index handle. If the bCreate argument is true, create
** and initialize the underlying %_data table.
**
** If successful, set *pp to point to the new object and return SQLITE_OK.
** Otherwise, set *pp to NULL and return an SQLite error code.
*//*
** The %_data table is completely empty when this function is called. This
** function populates it with the initial structure objects for each index,
** and the initial version of the "averages" record (a zero-byte blob).
*//*
** Discard any data stored in the in-memory hash tables. Do not write it
** to the database. Additionally, assume that the contents of the %_data
** table may have changed on disk. So any in-memory caches of %_data
** records must be invalidated.
*//*
** Commit data to disk.
*//* Flush the hash table to disk if required *//* Allocate the hash table if it has not already been allocated *//*
** Indicate that all subsequent calls to sqlite3Fts5IndexWrite() pertain
** to the document with rowid iRowid.
*//* If iIdx is non-zero, then it is the number of a prefix-index for
    ** prefixes 1 character longer than the prefix being queried for. That
    ** index contains all the doclists required, except for the one
    ** corresponding to the prefix itself. That one is extracted from the
    ** main term index here.  *//* Sufficient to merge (16^8)==(2^32) lists *//* OUT: New iterator *//* Restrict matches to these columns *//* Buffer containing prefix to match *//* Index to scan for data *//* True for "ORDER BY rowid DESC" *//* Index to read from *//*
** fts5VisitEntries() callback used by fts5SetupPrefixIter()
*//*
** Context object passed by fts5SetupPrefixIter() to fts5VisitEntries().
*//*
** fts5VisitEntries() callback used by fts5SetupPrefixIterTokendata(). This
** callback adds an entry to the Fts5TokenDataIter.aMap[] array for each
** position in the current position-list. It doesn't matter that some of
** these may be out of order - they will be sorted later.
*//* Size of current term in bytes *//* Offset of current term in terms.p[] *//* Object being populated with mappings *//*
** fts5VisitEntries() context object used by fts5SetupPrefixIterTokendata()
** to pass data to prefixIterSetupTokendataCb().
*//*
** Delete an Fts5TokenDataIter structure and its contents.
*//*
** Sort the contents of the pT->aMap[] array.
**
** The sorting algorithm requries a malloc(). If this fails, an error code
** is left in Fts5Index.rc before returning.
*//*
** Append a mapping to the token-map belonging to object pT.
*//* Output array *//* Input array 2 *//* Input array 1 *//*
** The two input arrays - a1[] and a2[] - are in sorted order. This function
** merges the two arrays together and writes the result to output array
** aOut[]. aOut[] is guaranteed to be large enough to hold the result.
**
** Duplicate entries are copied into the output. So the size of the output
** array is always (n1+n2) entries.
*//* The following are used for other full-token tokendata queries only. *//* The following are used for prefix-queries only. *//* Array of (rowid+pos -> token) mappings *//* Number of valid entries in aMap[] *//* Allocated size of aMap[] in entries *//*
** An object used to supplement Fts5Iter for tokendata=1 iterators.
**
** This object serves two purposes. The first is as a container for an array
** of Fts5TokenDataMap structures, which are used to find the token required
** when the xInstToken() API is used. This is done by the nMapAlloc, nMap and
** aMap[] variables.
*//* Length of token in bytes (or 0) *//* Iterator token was read from *//* Position of token *//* Row this token is located in *//*
** Usually, a tokendata=1 iterator (struct Fts5TokenDataIter) accumulates an
** array of these for each row it visits (so all iRowid fields are the same).
** Or, for an iterator used by an "ORDER BY rank" query, it accumulates an
** array of these for the entire query (in which case iRowid fields may take
** a variety of values).
**
** Each instance in the array indicates the iterator (and therefore term)
** associated with position iPos of rowid iRowid. This is used by the
** xInstToken() API.
**
** iRowid:
**   Rowid for the current entry.
**
** iPos:
**   Position of current entry within row. In the usual ((iCol<<32)+iOff)
**   format (e.g. see macros FTS5_POS2COLUMN() and FTS5_POS2OFFSET()).
**
** iIter:
**   If the Fts5TokenDataIter iterator that the entry is part of is
**   actually an iterator (i.e. with nIter>0, not just a container for
**   Fts5TokenDataMap structures), then this variable is an index into
**   the apIter[] array. The corresponding term is that which the iterator
**   at apIter[iIter] currently points to.
**
**   Or, if the Fts5TokenDataIter iterator is just a container object
**   (nIter==0), then iIter is an index into the term.p[] buffer where
**   the term is stored.
**
** nByte:
**   In the case where iIter is an index into term.p[], this variable
**   is the size of the term in bytes. If iIter is an index into apIter[],
**   this variable is unused.
*//* Iterator used to gather data from index *//* Passed as second argument to xVisit() *//* True for a prefix scan *//* Columns filter to apply, or NULL *//*
** Iterate through a range of entries in the FTS index, invoking the xVisit
** callback for each of them.
**
** Parameter pToken points to an nToken buffer containing an FTS index term
** (i.e. a document term with the preceding 1 byte index identifier -
** FTS5_MAIN_PREFIX or similar). If bPrefix is true, then the call visits
** all entries for terms that have pToken/nToken as a prefix. If bPrefix
** is false, then only entries with pToken/nToken as the entire key are
** visited.
**
** If the current table is a tokendata=1 table, then if bPrefix is true then
** each index term is treated separately. However, if bPrefix is false, then
** all index terms corresponding to pToken/nToken are collapsed into a single
** term before the callback is invoked.
**
** The callback invoked for each entry visited is specified by paramter xVisit.
** Each time it is invoked, it is passed a pointer to the Fts5Index object,
** a copy of the 7th paramter to this function (pCtx) and a pointer to the
** iterator that indicates the current entry. If the current entry is the
** first with a new term (i.e. different from that of the previous entry,
** including the very first term), then the final two parameters are passed
** a pointer to the term and its size in bytes, respectively. If the current
** entry is not the first associated with its term, these two parameters
** are passed 0.
**
** If parameter pColset is not NULL, then it is used to filter entries before
** the callback is invoked.
*//* Copy poslist from pHead to output *//* WRITEPOSLISTSIZE *//* See the earlier comment in this function for an explanation of why
      ** corrupt input position lists might cause the output to consume
      ** at most nMerge*10 bytes of unexpected space. *//* Merge data from two or more poslists *//* The maximum size of the output is equal to the sum of the
  ** input sizes + 1 varint (9 bytes). The extra varint is because if the
  ** first rowid in one input is a large negative number, and the first in
  ** the other a non-negative number, the delta for the non-negative
  ** number will be larger on disk than the literal integer value
  ** was.
  **
  ** Or, if the input position-lists are corrupt, then the output might
  ** include up to (nBuf+1) extra 10-byte positions created by interpreting -1
  ** (the value PoslistNext64() uses for EOF) as a position and appending
  ** it to the output. This can happen at most once for each input
  ** position-list, hence (nBuf+1) 10 byte paddings.  *//* Initialize a doclist-iterator for each input buffer. Arrange them in
  ** a linked-list starting at pHead in ascending order of rowid. Avoid
  ** linking any iterators already at EOF into the linked list at all. *//* Other lists to merge in *//* Number of buffers in array aBuf[] *//* First list to merge *//*
** Array aBuf[] contains nBuf doclists. These are all merged in with the
** doclist in buffer p1.
*//* Next in docid/poslist order *//* For iterating through a position list *//* Doclist iterator *//* Array of other lists to merge into p1 *//* Number of entries in apBuf[] *//*
** This is the equivalent of fts5MergePrefixLists() for detail=none mode.
** In this case the buffers consist of a delta-encoded list of rowids only.
*//*
** Swap the contents of buffer *p1 with that of *p2.
*//* Rowid to append *//* IN/OUT: Previous rowid written (if any) *//* Buffer to write to *//*
** Append a doclist to buffer pBuf.
**
** This function assumes that space within the buffer has already been
** allocated.
*//* Read position list size *//*
** This is called to implement the special "VALUES('merge', $nMerge)"
** INSERT command.
*//* Iterate through all segments, from oldest to newest. Add them to
      ** the new Fts5Level object so that pLvl->aSeg[0] is the oldest
      ** segment in the data structure.  *//* Figure out if this structure requires optimization. A structure does
  ** not require optimization if either:
  **
  **  1. it consists of fewer than two segments, or
  **  2. all segments are on the same level, or
  **  3. all segments except one are currently inputs to a merge operation.
  **
  ** In the first case, if there are no tombstone hash pages, return NULL. In
  ** the second, increment the ref-count on *pStruct and return a copy of the
  ** pointer to it.
  *//* Unless it is empty, flush the hash table to disk *//*
** Flush any data stored in the in-memory hash tables to the database.
*//* Update the Fts5Structure. It is written back to the database by the
        ** fts5StructureRelease() call below.  *//* pBuf->p[pBuf->n++] = '\0'; *//* TODO2: Doclist terminator written here. *//* The entire poslist will not fit on this leaf. So it needs
                ** to be broken into sections. The only qualification being
                ** that each varint must be stored contiguously.  *//* The entire poslist will fit on the current leaf. So copy
                ** it in one go. *//* first rowid on page *//* If in secure delete mode, and if this entry in the poslist is
            ** in fact a delete, then edit the existing segments directly
            ** using fts5FlushSecureDelete().  *//* The entire doclist will not fit on this leaf. The following
          ** loop iterates through the poslists that make up the current
          ** doclist.  *//* The entire doclist will fit on the current leaf. *//* Get the term and doclist for this entry. *//* Size of doclist in bytes *//* Pointer to doclist for this term *//* Buffer containing term *//* Begin scanning through hash table entries. This loop runs once for each
      ** term/doclist currently stored within the hash table. *//* fts5WriteInit() should have initialized the buffers to (most likely)
      ** the maximum space required. *//* Buffer in which to assemble pgidx *//* Buffer in which to assemble leaf page *//* New segment within pStruct *//* Obtain a reference to the index structure and allocate a new segment-id
  ** for the new level-0 segment.  *//* Last leaf page number in segment *//*
** Flush the contents of in-memory hash table iHash to a new level-0
** segment on disk. Also update the corresponding structure record.
**
** If an error occurs, set the Fts5Index.rc error code. If an error has
** already occurred, this function is a no-op.
*//* If the version number has not been set to SECUREDELETE, do so now. *//* Used to find term instance *//*
** This is called as part of flushing a delete to disk in 'secure-delete'
** mode. It edits the segments within the database described by argument
** pStruct to remove the entries for term zTerm, rowid iRowid.
**
** Return SQLITE_OK if successful, or an SQLite error code if an error
** has occurred. Any error code is also stored in the Fts5Index handle.
*//* Distance to move them *//* Number of bytes to move *//* Assuming no error has occurred, this block does final edits to the
  ** leaf page before writing it back to disk. Input variables are:
  **
  **   nPg: Total initial size of leaf page.
  **   iPgIdx: Initial offset of page footer.
  **
  **   iOff: Offset to move data to
  **   iNextOff: Offset to move data from
  *//* The entry being removed may be the only position list in
    ** its doclist. *//* This is the only position-list associated with the term, and there
      ** is another term following it on this page. So the subsequent term
      ** needs to be moved to replace the term associated with the entry
      ** being removed. *//* Set iDelKeyOff to the value of the footer entry to remove from
    ** the page. *//* Set iKeyOff to the offset of the term that will be removed - the
    ** last offset in the footer that is not greater than iStart. *//* The entry being removed was the only position list in its
    ** doclist. Therefore the term needs to be removed as well. *//* If this is (a) the first rowid on a page and (b) is not followed by
    ** another position list on the same page, set the "first-rowid" field
    ** of the header to 0.  *//* Loop through the page-footer. If iNextOff (offset of the
      ** entry following the one we are removing) is equal to the
      ** offset of a key on this page, then the entry is the last
      ** in its doclist. *//* If the position-list for the entry being removed flows over past
  ** the end of this page, delete the portion of the position-list on the
  ** next page and beyond.
  **
  ** Set variable bLastInDoclist to true if this entry happens
  ** to be the last rowid in the doclist for its term.  *//* Start-Of-Position-list *//* At this point segment iterator pSeg points to the entry
  ** this function should remove from the b-tree segment.
  **
  ** In detail=full or detail=column mode, pSeg->iLeafOffset is the
  ** offset of the first byte in the position-list for the entry to
  ** remove. Immediately before this comes two varints that will also
  ** need to be removed:
  **
  **     + the rowid or delta rowid value for the entry, and
  **     + the size of the position list in bytes.
  **
  ** Or, in detail=none mode, there is a single varint prior to
  ** pSeg->iLeafOffset - the rowid or delta rowid value.
  **
  ** This block sets the following variables:
  **
  **   iStart:
  **     The offset of the first byte of the rowid or delta-rowid
  **     value for the doclist entry being removed.
  **
  **   iDelta:
  **     The value of the rowid or delta-rowid value for the doclist
  **     entry being removed.
  **
  **   iNextOff:
  **     The offset of the next entry following the position list
  **     for the one being removed. If the position list for this
  **     entry overflows onto the next leaf page, this value will be
  **     greater than pLeaf->szLeaf.
  *//* Offset of deleted key, if any *//*
** Completely remove the entry that pSeg currently points to from
** the database.
*//* Write the new page to disk and exit the loop *//* Modify the contents of buffer aPg[]. Set nPg to the new size
      ** in bytes. The new page is always smaller than the old.  *//* Unless the current page footer is 0 bytes in size (in which case
      ** the new page footer will be as well), allocate and populate a
      ** buffer containing the new page footer. Set stack variables aIdx
      ** and nIdx accordingly.  *//* The page contains no terms or rowids. Replace it with an empty
      ** page and move on to the right-hand peer.  *//*
** This is called when a secure-delete operation removes a position-list
** that overflows onto segment page iPgno of segment pSeg. This function
** rewrites node iPgno, and possibly one or more of its right-hand peers,
** to remove this portion of the position list.
**
** Output variable (*pbLastInDoclist) is set to true if the position-list
** removed is followed by a new term or the end-of-segment, or false if
** it is followed by another rowid/position list.
*//* Page number within segment *//* Id of segment to delete entry for *//*
** Execute the SQL statement:
**
**    DELETE FROM %_idx WHERE (segid, (pgno/2)) = ($iSegid, $iPgno);
**
** This is used when a secure-delete operation removes the last term
** from a segment leaf page. In that case the %_idx entry is removed
** too. This is done to ensure that if all instances of a token are
** removed from an fts5 database in secure-delete mode, no trace of
** the token itself remains in the database.
*//*
** Buffer aBuf[] contains a list of varints, all small enough to fit
** in a 32-bit integer. Return the size of the largest prefix of this
** list nMax bytes or less in size.
*//*
** Close the read-only blob handle, if it is open.
*//* IN/OUT: Current structure of index *//* Update the write-counter. While doing so, set nWork. *//* Number of leaf pages left to write *//* Number of work-quanta to perform *//* Initial value of write-counter *//* Number of output leaves just written *//*
** A total of nLeaf leaf pages of data has just been flushed to a level-0
** segment. This function updates the write-counter accordingly and, if
** necessary, performs incremental merge work.
**
** If an error occurs, set the Fts5Index.rc error code. If an error has
** already occurred, this function is a no-op.
*//* Set iBestLvl to the level to read input segments from. Or to -1 if
    ** there is no level suitable to merge segments from.  *//* Number of input segments on best level *//* Level offering the most input segments *//* To iterate through levels *//* Minimum number of segments to merge *//* Pages of work to do *//*
** Do up to nPg pages of automerge work on the index.
**
** Return true if any changes were actually made, or false otherwise.
*//* If pLvl is already the input level to an ongoing merge, look no
      ** further for a merge candidate. The caller should be allowed to
      ** continue merging from pLvl first.  *//*
** If this is not a contentless_delete=1 table, or if the 'deletemerge'
** configuration option is set to 0, then this function always returns -1.
** Otherwise, it searches the structure object passed as the second argument
** for a level suitable for merging due to having a large number of
** tombstones in the tombstone hash. If one is found, its index is returned.
** Otherwise, if there is no suitable level, -1.
*//* Remove the redundant segments from the input level *//* Remove the redundant segments from the %_data table *//* Flush the last leaf page to disk. Set the output segment b-tree height
  ** and last leaf page number at the same time.  *//* Append the position-list data to the output *//* Append the rowid to the output *//* This is a new term. Append a term to the output segment. *//* Check for key annihilation. *//* position-list size field value *//* Set the range of origins that will go into the output segment. *//* Read input from all segments in the input level *//* Add the new segment to the output level *//* Extend the Fts5Structure object as required to ensure the output
    ** segment exists. *//* True if current term already output *//* True if the output segment is the oldest *//* Output segment *//* Writer object *//* Number of input segments *//* Output leaf pages left to write *//* Iterator to read input data *//* Write up to this many output leaves *//* Level to read input from *//* IN/OUT: Stucture of index *//*
**
*//* Set up the new page-index array *//* Set the szLeaf field *//* This can occur if the pages that the segments occupy overlap - if
          ** a single page has been assigned to more than one segment. In
          ** this case a prior iteration of this loop may have corrupted the
          ** segment currently being trimmed.  *//* Offset on new first leaf page *//* All keys from this input segment have been transfered to the output.
      ** Set both the first and last page-numbers to 0 to indicate that the
      ** segment is now empty. *//*
** Iterator pIter was used to iterate through the input segments of on an
** incremental merge operation. This function is called if the incremental
** merge step has finished but the input has not been completely exhausted.
*//* Bind the current output segment id to the index-writer. This is an
    ** optimization over binding the same value over and over as rows are
    ** inserted into %_idx by the current writer.  *//* Initialize the 4-byte leaf-page header to 0x00. *//* Grow the two buffers to pgsz + padding bytes in size. *//* OUT: Number of leaf pages in b-tree *//*
** Flush any data cached by the writer object to the database. Free any
** allocations associated with the writer.
*//* Write the rowid. *//* If this is to be the first rowid written to the page, set the
    ** rowid-pointer in the page-header. Also append a value to the dlidx
    ** buffer, in case a doclist-index is required.  *//*
** Append a rowid and position-list size field to the writers output.
*//* Update the Fts5PageWriter.term field. *//* Append the number of bytes of new data, then the term data itself
  ** to the page. *//* This is the first term on a leaf that is not the leftmost leaf in
      ** the segment b-tree. In this case it is necessary to add a term to
      ** the b-tree hierarchy that is (a) larger than the largest term
      ** already written to the segment and (b) smaller than or equal to
      ** this term. In other words, a prefix of (pTerm/nTerm) that is one
      ** byte longer than the longest prefix (pTerm/nTerm) shares with the
      ** previous term.
      **
      ** Usually, the previous term is available in pPage->term. The exception
      ** is if this is the first term written in an incremental-merge step.
      ** In this case the previous term is not available, so just write a
      ** copy of (pTerm/nTerm) into the parent node. This is slightly
      ** inefficient, but still correct.  *//* TODO1: Updating pgidx here. *//* If the current leaf page is full, flush it to disk. *//* Bytes of prefix compression for term *//*
** Append term pTerm/nTerm to the segment being written by the writer passed
** as the second argument.
**
** If an error occurs, set the Fts5Index.rc error code. If an error has
** already occurred, this function is a no-op.
*//* The new leaf holds no terms or rowids *//* Increase the leaves written counter *//* Initialize the next page. *//* Write the page out to disk *//* Append the pgidx to the page buffer. Set the szLeaf header field. *//* No term was written to this page. *//* Set the szLeaf header field. *//* This was the root node. Push its first rowid up to the new root. *//* Not the root node *//* The current doclist-index page is full. Write it to disk and push
      ** a copy of iRowid (which will become the first rowid on the next
      ** doclist-index leaf page) up into the next level of the b-tree
      ** hierarchy. If the node being flushed is currently the root node,
      ** also push its first rowid upwards. *//*
** Rowid iRowid has just been appended to the current leaf page. It is the
** first on the page. This function appends an appropriate entry to the current
** doclist-index.
*//* Increment the "number of sequential leaves without a term" counter. *//* If there were no rowids on the leaf page either and the doclist-index
  ** has already been started, append an 0x00 byte to it.  *//*
** This function is called when flushing a leaf page that contains no
** terms at all to disk.
*//* First term on new page *//*
** This is called once for each leaf page except the first that contains
** at least one term. Argument (nTerm/pTerm) is the split-key - a term that
** is larger than all terms written to earlier leaves, and equal to or
** smaller than the first term on the new leaf.
**
** If an error occurs, an error code is left in Fts5Index.rc. If an error
** has already occurred when this function is called, it is a no-op.
*//* sqlite3_bind_int(p->pIdxWriter, 1, pWriter->iSegid); *//* The following was already done in fts5WriteInit(): *//*
** This function is called whenever processing of the doclist for the
** last term on leaf page (pWriter->iBtPage) is completed.
**
** The doclist-index for that term is currently stored in-memory within the
** Fts5SegWriter.aDlidx[] array. If it is large enough, this function
** writes it out to disk. Or, if it is too small to bother with, discards
** it.
**
** Fts5SegWriter.btterm currently contains the first term on page iBtPage.
*//* If there were FTS5_MIN_DLIDX_SIZE or more empty leaf pages written
  ** to the database, also write the doclist-index to disk.  *//*
** If the current doclist-index accumulating in pWriter->aDlidx[] is large
** enough, flush it to disk and return 1. Otherwise discard it and return
** zero.
*//*
** Grow the pWriter->aDlidx[] array to at least nLvl elements in size.
** Any new array elements are zeroed before returning.
*//* If true, write dlidx to disk *//*
** Return the size of the prefix, in bytes, that buffer
** (pNew/<length-unknown>) shares with buffer (pOld/nOld).
**
** Buffer (pNew/<length-unknown>) is guaranteed to be greater
** than buffer (pOld/nOld).
*//*
** Discard all data currently cached in the hash-tables.
*//* FTS5_MAX_SEGMENT is currently defined as 2000. So the following
      ** array is 63 elements, or 252 bytes, in size.  *//*
** Allocate a new segment-id for the structure pStruct. The new segment
** id must be between 1 and 65335 inclusive, and must not be used by
** any currently existing segment. If a free segment id cannot be found,
** SQLITE_FULL is returned.
**
** If an error has already occurred, this function is a no-op. 0 is
** returned in this case.
*//*
** Return a pointer to a buffer containing the term associated with the
** entry that the iterator currently points to.
*//*
** Move the iterator to the next entry at or following iMatch.
*//*
** Return the rowid of the entry that the iterator currently points
** to. If the iterator points to EOF when this function is called the
** results are undefined.
*//*
** Return true if the iterator is at EOF or if an error has occurred.
** False otherwise.
*//* True for descending rowid order *//* Doclist to iterate through *//* FTS5 backend to iterate within *//*
** Create an Fts5Iter that iterates through the doclist provided
** as the second argument.
*//* If the above was successful, each component iterator now points
  ** to the first entry in its segment. In this case initialize the
  ** aFirst[] array. Or, if an error has occurred, free the iterator
  ** object and set the output variable to NULL.  *//* Add a segment iterator for the current contents of the hash table. *//* Initialize each of the component segment iterators. *//* Allocate space for the new multi-seg-iterator. *//* Used to iterate through segments *//* *//* Number of segment-iters in use *//* Number of segments to merge (iLevel>=0) *//* Level to iterate (-1 for all) *//* Term to seek to (or NULL/0) *//* Colset to filter on (or NULL) *//* FTS5INDEX_QUERY_XXX flags *//* Structure of specific index *//*
** Allocate a new Fts5Iter object.
**
** The new object will be used to iterate through data in structure pStruct.
** If iLevel is -ve, then all data in all segments is merged. Or, if iLevel
** is zero or greater, data from the first nSegment segments on level iLevel
** is merged.
**
** The iterator initially points to the first term/rowid entry in the
** iterated data.
*//*
** All the component segment-iterators of pIter have been set up. This
** functions finishes setup for iterator pIter itself.
*//* The data is distributed over two or more pages. Copy it into the
    ** Fts5Iter.poslist buffer and then set the output pointer to point
    ** to this buffer.  *//* All data is stored on the current page. Populate the output
    ** variables to point into the body of the page object. *//*
** xSetOutputs callback used by detail=full when there is a column filter.
*//*
** xSetOutputs callback used when:
**
**   * detail=col,
**   * there is a column filter, and
**   * the table contains 100 or fewer columns.
**
** The last point is to ensure all column numbers are stored as
** single-byte varints.
*//*
** xSetOutputs callback used by detail=col when there is a column filter
** and there are 100 or more columns. Also called as a fallback from
** fts5IterSetOutputs_Col100 if the column-list spans more than one page.
*//*
** xSetOutputs callback used when the Fts5Colset object has nCol==0 (match
** against no columns at all).
*//*
** xSetOutputs callback used by detail=full and detail=col tables when no
** column filters are specified.
*//*
** xSetOutputs callback used by detail=none tables.
*//* Advance pointer p until it points to pEnd or an 0x01 byte that is
      ** not part of a varint *//* One byte past end of position list *//*
** Parameter pPos points to a buffer containing a position list, size nPos.
** This function filters it according to pColset (which must be non-NULL)
** and sets pIter->base.pData/nData to point to the new position list.
** If memory is required for the new position list, use buffer pIter->poslist.
** Or, if the new position list is a contiguous subset of the input, set
** pIter->base.pData/nData to point directly to it.
**
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. If an OOM error is encountered, *pRc is set to SQLITE_NOMEM
** before returning.
*//*
** Iterator pIter currently points to a valid entry (not EOF). This
** function appends the position list data for the current entry to
** buffer pBuf. It does not make a copy of the position-list size
** field.
*//* This function does not work with detail=none databases. *//* Number of bytes still to come *//* Context pointer for xChunk callback *//* Poslist of this iterator *//* Index object *//* Search through to find the first varint with value 1. This is the
    ** start of the next columns hits. *//*
** TODO: Make this more efficient!
*//* Restrict matches to this column *//* Append to this buffer *//* pNew->aFirst[] *//* pNew->aSeg[] *//* pNew *//* Power of two >= nSeg *//* OUT: True if *might* be new term *//* Advance at least as far as this *//* True if argument iFrom is valid *//*
** Move the iterator to the next entry.
**
** If an error occurs, an error code is left in Fts5Index.rc. It is not
** considered an error if the iterator reaches EOF, or if it is already at
** EOF when this function is called.
*//* If tombstone hash page iPg has not yet been loaded from the
    ** database, load it now. *//* Figure out which page the rowid might be present on. *//*
** Return true if the iterator passed as the only argument points
** to an segment entry for which there is a tombstone. Return false
** if there is no tombstone or if the iterator is already at EOF.
*//* Rowid to query hash for *//* Number of pages attached to segment *//* Hash table page to query *//*
** Query a single tombstone hash table for rowid iRowid. Return true if
** it is found or false otherwise. The tombstone hash table is one of
** nHashTable tables.
*//*
** The argument to this macro must be an Fts5Data structure containing a
** tombstone hash page. This macro returns the key-size of the hash-page.
*//*
** Set the pIter->bEof variable based on the state of the sub-iterators.
*//* Index of sub-iterator just advanced *//* Iterator to update aFirst[] array for *//*
** Sub-iterator iChanged of iterator pIter has just been advanced. It still
** points to the same term though - just a different rowid. This function
** attempts to update the contents of the pIter->aFirst[] accordingly.
** If it does so successfully, 0 is returned. Otherwise 1.
**
** If non-zero is returned, the caller should call fts5MultiIterAdvanced()
** on the iterator instead. That function does the same as this one, except
** that it deals with more complicated cases as well.
*//* Minimum entry in aFirst[] to set *//*
** Free the iterator object passed as the second argument.
*//* Advance iterator at least this far *//* Iterator to advance *//*
** Advance the iterator passed as the second argument until it is at or
** past rowid iFrom. Regardless of the value of iFrom, the iterator is
** always advanced at least once.
*//*
** Move the seg-iter so that it points to the first rowid on page iLeafPgno.
** It is an error if leaf iLeafPgno does not exist. Unless the db is
** a 'secure-delete' db, if it contains no rowids then this is also an error.
*//* If p2 is at EOF *//* If p1 is at EOF *//* Right-hand Fts5SegIter *//* Left-hand Fts5SegIter *//* Index of right-hand Fts5SegIter *//* Index of left-hand Fts5SegIter *//*
** Do the comparison necessary to populate pIter->aFirst[iOut].
**
** If the returned value is non-zero, then it is the index of an entry
** in the pIter->aSeg[] array that is (a) not at EOF, and (b) pointing
** to a key that is a duplicate of another, higher priority,
** segment-iterator in the pSeg->aSeg[] array.
*//* Check that pIter->iSwitchRowid is set correctly. *//*
** This function is a no-op unless SQLITE_DEBUG is defined when this module
** is compiled. In that case, this function is essentially an assert()
** statement used to verify that the contents of the pIter->aFirst[] array
** are correct.
*//*
** This function is used as part of the big assert() procedure implemented by
** fts5AssertMultiIterSetup(). It ensures that the result currently stored
** in *pRes is the correct result of comparing the current positions of the
** two iterators.
*//*
** Zero the iterator passed as the only argument.
*//*
** Decrement the ref-count of the object passed as the only argument. If it
** reaches 0, free it and its contents.
*//*
** Array ap[] contains n elements. Release each of these elements using
** fts5DataRelease(). Then free the array itself using sqlite3_free().
*//* The call to sqlite3Fts5HashScanInit() causes the hash table to
    ** fill the size field of all existing position lists. This means they
    ** can no longer be appended to. Since the only scenario in which they
    ** can be appended to is if the previous operation on this table was
    ** a DELETE, by clearing the Fts5Index.bDelete flag we can avoid this
    ** possibility altogether.  *//* Mask of FTS5INDEX_XXX flags *//* Term to seek to *//* FTS5 backend *//*
** Initialize the object pIter to point to term pTerm/nTerm within the
** in-memory hash table. If there is no such term in the hash-table, the
** iterator is set to EOF.
**
** If an error occurs, Fts5Index.rc is set to an appropriate error code. If
** an error has already occurred when this function is called, it is a no-op.
*//* SELECT to find iPg *//* Page of segment to open *//* Description of segment *//*
** This is similar to fts5SegIterSeekInit(), except that it initializes
** the segment iterator to point to the first term following the page
** with pToken/nToken on it.
*//*
** SQL used by fts5SegIterNextInit() to find the page to open.
*//* 4 *//* 3 *//* 2 *//* 1 *//* Either:
  **
  **   1) an error has occurred, or
  **   2) the iterator points to EOF, or
  **   3) the iterator points to an entry with term (pTerm/nTerm), or
  **   4) the FTS5INDEX_QUERY_SCAN flag was set and the iterator points
  **      to an entry with a term greater than or equal to (pTerm/nTerm).
  *//* This block sets stack variable iPg to the leaf page number that may
  ** contain term (pTerm/nTerm), if it is present in the segment. *//* True if there is a doclist-index *//*
** Initialize the object pIter to point to term pTerm/nTerm within segment
** pSeg. If there is no such term in the index, the iterator is set to EOF.
**
** If an error occurs, Fts5Index.rc is set to an appropriate error code. If
** an error has already occurred when this function is called, it is a no-op.
*//* Read the nKeep field of the next term. *//* Figure out how many new bytes are in this term *//* Current offset in pgidx *//* Term to search for *//* Iterator to seek *//* True for a >= search *//* Leave any error code here *//*
** The iterator object passed as the second argument currently contains
** no valid values except for the Fts5SegIter.pLeaf member variable. This
** function searches the leaf page for a term matching (pTerm/nTerm).
**
** If the specified term is found on the page, then the iterator is left
** pointing to it. If argument bGe is zero and the term is not found,
** the iterator is left pointing at EOF.
**
** If bGe is non-zero and the specified term is not found, then the
** iterator is left pointing to the smallest term in the segment that
** is larger than the specified term, even if this term is not on the
** current page.
*//* Check if the current doclist ends on this page. If it does, return
  ** early without loading the doclist-index (as it belongs to a different
  ** term. *//* Current leaf data *//*
** Iterator pIter currently points to the first rowid of a doclist.
** There is a doclist-index associated with the final term on the current
** page. If the current term is the last term on the page, load the
** doclist-index from disk and initialize an iterator at (pIter->pDlidx).
*//* If pLast is NULL at this point, then the last rowid for this doclist
  ** lies on the page currently indicated by the iterator. In this case
  ** pIter->iLeafOffset is already set to point to the position-list size
  ** field associated with the first relevant rowid on the page.
  **
  ** Or, if pLast is non-NULL, then it is the page that contains the last
  ** rowid. In this case configure the iterator so that it points to the
  ** first rowid on this page.
  *//* The last rowid in the doclist may not be on the current page. Search
      ** forward to find the page containing the last rowid.  *//* If this condition is true then the largest rowid for the current
    ** term may not be stored on the current page. So search forward to
    ** see where said rowid really is.  *//* Currently, Fts5SegIter.iLeafOffset points to the first byte of
    ** position-list content for the current rowid. Back it up so that it
    ** points to the start of the position-list size field. *//*
** Iterator pIter currently points to the first rowid in a doclist. This
** function sets the iterator up so that iterates in reverse order through
** the doclist.
*//* The following could be done by calling fts5SegIterLoadNPos(). But
      ** this block is particularly performance critical, so equivalent
      ** code is inlined.  *//* Check if the iterator is now at EOF. If so, return early. *//* Next entry is not on the current page *//* The next entry is on the current page. *//* Search for the end of the position list within the current page. *//* OUT: Set for new term *//*
** Advance iterator pIter to the next entry.
**
** If an error occurs, Fts5Index.rc is set to an appropriate error code. It
** is not considered an error if the iterator reaches EOF. If an error has
** already occurred when this function is called, it is a no-op.
*//* Next entry is on the current page *//* Next entry is on the next page *//*
** Advance iterator pIter to the next entry.
**
** This version of fts5SegIterNext() is only used if detail=none and the
** iterator is not a reverse direction iterator.
*//*
** Advance iterator pIter to the next entry.
**
** This version of fts5SegIterNext() is only used by reverse iterators.
*//*
** Return true if the iterator passed as the second argument currently
** points to a delete marker. A delete marker is an entry with a 0 byte
** position-list.
*//* iTermLeafOffset may be equal to szLeaf if the term is the last
      ** thing on the page - i.e. the first rowid is on the following page.
      ** In this case leave pIter->pLeaf==0, this iterator is at EOF. *//* If necessary, grow the pIter->aRowidOffset[] array. *//* todo *//*
** This function is only ever called on iterators created by calls to
** Fts5IndexQuery() with the FTS5INDEX_QUERY_DESC flag set.
**
** The iterator is in an unusual state when this function is called: the
** Fts5SegIter.iLeafOffset variable is set to the offset of the start of
** the position-list size field for the first relevant rowid on the page.
** Fts5SegIter.rowid is set, but nPos and bDel are not.
**
** This function advances the iterator so that it points to the last
** relevant rowid on the page and, if necessary, initializes the
** aRowidOffset[] and iRowidOffset variables. At this point the iterator
** is in its regular state - Fts5SegIter.iLeafOffset points to the first
** byte of the position list content associated with said rowid.
*//* This happens if the segment is being used as an input to an incremental
    ** merge and all data has already been "trimmed". See function
    ** fts5TrimSegments() for details. In this case leave the iterator empty.
    ** The caller will see the (pIter->pLeaf==0) and assume the iterator is
    ** at EOF already. *//* FTS index object *//*
** Initialize the iterator object pIter to iterate through the entries in
** segment pSeg. The iterator is left pointing to the first entry when
** this function returns.
**
** If an error occurs, Fts5Index.rc is set to an appropriate error code. If
** an error has already occurred when this function is called, it is a no-op.
*//*
** Allocate a tombstone hash page array object (pIter->pTombArray) for
** the iterator passed as the second argument. If an OOM error occurs,
** leave an error in the Fts5Index object.
*//* Bytes of new data *//* Offset to read at *//* Buffer to read data from *//*
** Fts5SegIter.iLeafOffset currently points to the first byte of the
** "nSuffix" field of a term. Function parameter nKeep contains the value
** of the "nPrefix" field (if there was one - it is passed 0 if this is
** the first term in the segment).
**
** This function populates:
**
**   Fts5SegIter.term
**   Fts5SegIter.rowid
**
** accordingly and leaves (Fts5SegIter.iLeafOffset) set to the content of
** the first position list. The position list belonging to document
** (Fts5SegIter.iRowid).
*//*
** Fts5SegIter.iLeafOffset currently points to the first byte of a
** position-list size field. Read the value of the field and store it
** in the following variables:
**
**   Fts5SegIter.nPos
**   Fts5SegIter.bDel
**
** Leave Fts5SegIter.iLeafOffset pointing to the first byte of the
** position list content (if any).
*//*
** Argument p points to a buffer containing a varint to be interpreted as a
** position list size field. Read the varint and return the number of bytes
** read. Before returning, set *pnSz to the number of bytes in the position
** list, and *pbDel to true if the delete flag is set, or false otherwise.
*//* Iterator to advance to next page *//*
** Load the next leaf page into the segment iterator.
*//* Leaf page number to load dlidx for *//* Segment id *//* True for ORDER BY ASC *//* Fts5 Backend to iterate within *//*
** Free a doclist-index iterator object allocated by fts5DlidxIterInit().
*//*
** Move the iterator passed as the only argument to the previous entry.
*//* Advance each level to the last entry on the last page *//*
** The iterator passed as the first argument has the following fields set
** as follows. This function sets up the rest of the iterator so that it
** points to the first rowid in the doclist-index.
**
**   pData:
**     pointer to doclist-index record,
**
** When this function is called pIter->iLeafPgno is the page number the
** doclist is associated with (the one featuring the term).
*//*
** Advance the iterator passed as the only argument.
*//*
** Advance the iterator passed as the only argument. If the end of the
** doclist-index page is reached, return non-zero.
*//* If condition (a) is not met, assume (b) is true. StructurePromoteTo()
    ** is a no-op if it is not.  *//* Condition (a) is true. Promote the newest segment on level
        ** iLvl to level iTst.  *//* Check for condition (a) *//* Size of segment just written *//* Segment just written *//* Promote anything this size or smaller *//* Index level just updated *//*
** A new segment has just been written to level iLvl of index structure
** pStruct. This function determines if any segments should be promoted
** as a result. Segments are promoted in two scenarios:
**
**   a) If the segment just written is smaller than one or more segments
**      within the previous populated level, it is promoted to the previous
**      populated level.
**
**   b) If the segment just written is larger than the newest segment on
**      the next populated level, then that segment, and any other adjacent
**      segments that are also smaller than the one just written, are
**      promoted.
**
** If one or more segments are promoted, the structure object is updated
** to reflect this.
*//*
** Return a copy of index structure pStruct. Except, promote as many
** segments as possible to level iPromote. If an OOM occurs, NULL is
** returned.
*//* Append the current configuration cookie *//* Cookie value to store *//* Used to iterate through levels *//* Buffer to serialize record into *//*
** Serialize and store the "structure" record.
**
** If an error occurs, leave an error code in the Fts5Index object. If an
** error has already occurred, this function is a no-op.
*//* Total number of segments *//*
** Return the total number of segments in index structure pStruct. This
** function is only ever used as part of assert() conditions.
*//*
** Read, deserialize and return the structure record.
**
** The Fts5Structure.aLevel[] and each Fts5StructureLevel.aSeg[] array
** are over-allocated as described for function fts5StructureDecode()
** above.
**
** If an error occurs, NULL is returned and an error code left in the
** Fts5Index handle. If an error has already occurred when this function
** is called, it is a no-op.
*//* TODO: Do we need this if the leaf-index is appended? Probably... *//* Configuration cookie *//*
** Extend level iLvl so that there is room for at least nExtra more
** segments.
*//* aLevel[] array *//* Main structure *//*
** Add a level to the Fts5Structure.aLevel[] array of structure object
** (*ppStruct).
*//* Read the total number of levels and segments from the start of the
  ** structure record.  *//* Check if this is a V2 structure record. Set bStructureV2 if it is. *//* Grab the cookie value *//* Largest origin value seen so far *//* True for FTS5_STRUCTURE_V2 *//* Structure object to return *//* Bytes of space to allocate at pRet *//* OUT: Deserialized object *//* Configuration cookie value *//* Size of buffer pData in bytes *//* Buffer containing serialized structure *//*
** Deserialize and return the structure record currently stored in serialized
** form within buffer pData/nData.
**
** The Fts5Structure.aLevel[] and each Fts5StructureLevel.aSeg[] array
** are over-allocated by one slot. This allows the structure contents
** to be more easily edited.
**
** If an error occurs, *ppOut is set to NULL and an SQLite error code
** returned. Otherwise, *ppOut is set to point to the new object and
** SQLITE_OK returned.
*//*
** Ensure that structure object (*pp) is writable.
**
** This function is a no-op if (*pRc) is not SQLITE_OK when it is called. If
** an error occurs, (*pRc) is set to an SQLite error code before returning.
*//*
** Release a reference to an Fts5Structure object returned by an earlier
** call to fts5StructureRead() or fts5StructureDecode().
*//*
** Remove all records associated with segment iSegid.
*//*
** Execute the following SQL:
**
**     DELETE FROM %_data WHERE id BETWEEN $iFirst AND $iLast
*//*
** INSERT OR REPLACE a record into the %_data table.
*//* If this prepare() call fails with SQLITE_ERROR, then one of the
      ** %_idx or %_data tables has been removed or modified. Call this
      ** corruption.  *//*
** Release a reference to data record returned by an earlier call to
** fts5DataRead().
*//* TODO1: Fix this *//* Read blob data into this buffer *//* If either of the sqlite3_blob_open() or sqlite3_blob_reopen() calls
    ** above returned SQLITE_ERROR, return SQLITE_CORRUPT_VTAB instead.
    ** All the reasons those functions might return SQLITE_ERROR - missing
    ** table, missing row, non-blob/text in block column - indicate
    ** backing store corruption.  *//* If the blob handle is not open at this point, open it and seek
    ** to the requested entry.  *//* This call may return SQLITE_ABORT if there has been a savepoint
      ** rollback since it was last used. In this case a new blob handle
      ** is required.  *//*
** Retrieve a record from the %_data table.
**
** If an error occurs, NULL is returned and an error left in the
** Fts5Index object.
*//*
** Compare the contents of the two buffers using memcmp(). If one buffer
** is a prefix of the other, it is considered the lesser.
**
** Return -ve if pLeft is smaller than pRight, 0 if they are equal or
** +ve if pRight is smaller than pLeft. In other words:
**
**     res = *pLeft - *pRight
*//* Right hand side of comparison *//* Left hand side of comparison *//*
** Compare the contents of the pLeft buffer with the pRight/nRight blob.
**
** Return -ve if pLeft is smaller than pRight, 0 if they are equal or
** +ve if pRight is smaller than pLeft. In other words:
**
**     res = *pLeft - *pRight
*//*
** Allocate and return a buffer at least nByte bytes in size.
**
** If an OOM error is encountered, return NULL and set the error code in
** the Fts5Index handle passed as the first argument.
*//*
** Write iVal, formated as a 32-bit big-endian unsigned integer, to the
** buffer indicated by the first argument.
*//*
** Write iVal, formated as a 64-bit big-endian unsigned integer, to the
** buffer indicated by the first argument.
*//*
** The only argument points to a buffer at least 4 bytes in size. This
** function interprets the first 4 bytes of the buffer as a 32-bit big-endian
** unsigned integer and returns the result.
*//*
** The only argument points to a buffer at least 8 bytes in size. This
** function interprets the first 8 bytes of the buffer as a 64-bit big-endian
** unsigned integer and returns the result.
*//* First rowid on leaf iLeafPgno *//* Page number of current leaf page *//* Output variables *//* Used by reverse iterators *//* At EOF already *//* Current offset into pData *//* Data for current page of this level *//*
** An instance of the following type is used to iterate through the contents
** of a doclist-index record.
**
** pData:
**   Record containing the doclist-index data.
**
** bEof:
**   Set to true once iterator has reached EOF.
**
** iOff:
**   Set to the current offset within record pData.
*//* Array of segment iterators *//* Current merge state (see above) *//* Firstest rowid of other than aFirst[1] *//* True to skip deleted entries *//* True to iterate in reverse order *//* Size of aSeg[] array *//* Invoked to set output variables. *//* Buffer containing current poslist *//* Index that owns this iterator *//* Base class containing output vars *//*
** Object for iterating through the merged results of one or more segments,
** visiting each term/rowid pair in the merged data.
**
** nSeg is always a power of two greater than or equal to the number of
** segments that this object is merging data from. Both the aSeg[] and
** aFirst[] arrays are sized at nSeg entries. The aSeg[] array is padded
** with zeroed objects - these are handled as if they were iterators opened
** on empty segments.
**
** The results of comparing segments aSeg[N] and aSeg[N+1], where N is an
** even number, is stored in aFirst[(nSeg+N)/2]. The "result" of the
** comparison in this context is the index of the iterator that currently
** points to the smaller term/rowid combination. Iterators at EOF are
** considered to be greater than all other iterators.
**
** aFirst[1] contains the index in aSeg[] of the iterator that points to
** the smallest key overall. aFirst[0] is unused.
**
** poslist:
**   Used by sqlite3Fts5IterPoslist() when the poslist needs to be buffered.
**   There is no way to tell if this is populated or not.
**
** pColset:
**   If not NULL, points to an object containing a set of column indices.
**   Only matches that occur in one of these columns will be returned.
**   The Fts5Iter does not own the Fts5Colset object, and so it is not
**   freed when the iterator is closed - it is owned by the upper layer.
*//*
** Argument is a pointer to an Fts5Data structure that contains a leaf
** page. This macro evaluates to true if the leaf contains no terms, or
** false if it contains at least one term.
*//*
** Argument is a pointer to an Fts5Data structure that contains a
** leaf page.
*//* Array of tombstone pages *//* Number of pointers to this object *//*
** Array of tombstone pages. Reference counted.
*//* True if the delete flag is set *//* Number of bytes in current position list *//* Current term *//* Variables populated based on current entry. *//* If there is a doclist-index *//* Array of offset to rowid fields *//* Allocated size of aRowidOffset[] array *//* Current entry in aRowidOffset[] *//* The following are only used if the FTS5_SEGITER_REVERSE flag is set. *//* Next offset in pgidx *//* The page and offset from which the current term was read. The offset
  ** is the offset of the first rowid in the current doclist.  *//* Next method *//* Byte offset within current leaf *//* Leaf page (iLeafPgno+1) *//* Current leaf page number *//* Mask of configuration flags *//* Segment to iterate through *//*
** Object for iterating through a single segment, visiting each term/rowid
** pair in the segment.
**
** pSeg:
**   The segment to iterate through.
**
** iLeafPgno:
**   Current leaf page number within segment.
**
** iLeafOffset:
**   Byte offset within the current leaf that is the first byte of the
**   position list data (one byte passed the position-list size field).
**
** pLeaf:
**   Buffer containing current leaf page data. Set to NULL at EOF.
**
** iTermLeafPgno, iTermLeafOffset:
**   Leaf page number containing the last term read from the segment. And
**   the offset immediately following the term data.
**
** flags:
**   Mask of FTS5_SEGITER_XXX values. Interpreted as follows:
**
**   FTS5_SEGITER_ONETERM:
**     If set, set the iterator to point to EOF after the current doclist
**     has been exhausted. Do not proceed to the next term in the segment.
**
**   FTS5_SEGITER_REVERSE:
**     This flag is only ever set if FTS5_SEGITER_ONETERM is also set. If
**     it is set, iterate through rowid in descending order instead of the
**     default ascending order.
**
** iRowidOffset/nRowidOffset/aRowidOffset:
**     These are used if the FTS5_SEGITER_REVERSE flag is set.
**
**     For each rowid on the page corresponding to the current term, the
**     corresponding aRowidOffset[] entry is set to the byte offset of the
**     start of the "position-list-size" field within the page.
**
** iTermIdx:
**     Index of current term on iTermLeafPgno.
**
** apTombstone/nTombstone:
**     These are used for contentless_delete=1 tables only. When the cursor
**     is first allocated, the apTombstone[] array is allocated so that it
**     is large enough for all tombstones hash pages associated with the
**     segment. The pages themselves are loaded lazily from the database as
**     they are required.
*//* True if the terms are equal *//* aSeg[] index of firstest iterator *//* Page number corresponding to btterm *//* Next term to insert into %_idx table *//* Values to insert into the %_idx table *//* Array of Fts5DlidxWriter objects *//* Allocated size of aDlidx[] array *//* Number of contiguous term-less nodes *//* Number of leaf pages written *//* True if next term will be first in leaf *//* TODO1: Can use (writer.pgidx.n==0) instead of bFirstTermInPage *//* True if next rowid is first in page *//* True if next rowid is first in doclist *//* Previous rowid written to current leaf *//* PageWriter object *//* Segid to write to *//* Buffer containing page data *//* Previous rowid value written to page *//* True if iPrev is valid *//* Page number for this page *//* Buffer containing previous term on page *//* Buffer containing page-index *//* Buffer containing leaf data *//* Previous value written into pgidx *//*
** An object of type Fts5SegWriter is used to write to segments.
*//* Array of nLevel level objects *//* Number of levels in this index *//* Total segments in this structure *//* Origin value for next top-level segment *//* Total leaves written to level 0 *//* Object reference count *//* Array of segments. aSeg[0] is oldest. *//* Total number of segments on level *//* Number of segments in incr-merge *//* Number of rows in this segment *//* Number of tombstone entries that "count" *//* Number of tombstone hash table pages *//* contentlessdelete=1 tables only: *//* First leaf page number in segment *//*
** The contents of the "structure" record for each index are represented
** using an Fts5Structure record in memory. Which uses instances of the
** other Fts5StructureXXX types as components.
**
** nOriginCntr:
**   This value is set to non-zero for structure records created for
**   contentlessdelete=1 tables only. In that case it represents the
**   origin value to apply to the next top-level segment created.
*//* Output variables. aPoslist==0 at EOF *//* Pointer to 1 byte past end of doclist *//* Current db structure (or NULL) *//* data_version when pStruct read *//* Total number of blocks read *//* "DELETE FROM %_idx WHERE segid=?" *//* "INSERT ... %_idx VALUES(?,?,?,?)" *//* "DELETE FROM %_data ... id>=? AND id<=?" *//* "INSERT ... %_data VALUES(?,?)" *//* RO incr-blob open on %_data table *//* State used by the fts5DataXXX() functions. *//* Current error code *//* Error state. *//* Number of INSERT in hash table *//* Number of contentless delete ops *//* Current write is a delete *//* Rowid for current doc being written *//* Current bytes of pending data *//* Hash table for in-memory data *//*
  ** Variables related to the accumulation of tokens and doclists within the
  ** in-memory hash tables before they are flushed to disk.
  *//* Leaf pages in a "unit" of work *//* Name of %_data table *//* Virtual table configuration *//*
** One object per %_data table.
**
** nContentlessDelete:
**   The number of contentless delete operations since the most recent
**   call to fts5IndexFlush() or fts5IndexDiscardData(). This is tracked
**   so that extra auto-merge work can be done by fts5IndexFlush() to
**   account for the delete operations.
*//* Size of leaf without page-index *//* Size of record in bytes *//* Pointer to buffer containing record *//*
** Each time a blob is read from the %_data table, it is padded with this
** many zero bytes. This makes it easier to decode the various record formats
** without overreading if the records are corrupt.
*//* Max page number of 2147483648 *//* Max dlidx tree height of 32 *//* Doclist-index flag (1 bit) *//* Max seg id number 65535 *//*
** Macros determining the rowids used by segment leaves and dlidx leaves
** and nodes. All nodes and leaves are stored in the %_data table with large
** positive rowids.
**
** Each segment has a unique non-zero 16-bit id.
**
** The rowid for each segment leaf is found by passing the segment id and
** the leaf page number to the FTS5_SEGMENT_ROWID macro. Leaves are numbered
** sequentially starting from 1.
*//* The structure record *//* Rowid used for the averages record *//*
** Rowids for the averages and structure records in the %_data table.
*//*
** Details:
**
** The %_data table managed by this module,
**
**     CREATE TABLE %_data(id INTEGER PRIMARY KEY, block BLOB);
**
** , contains the following 6 types of records. See the comments surrounding
** the FTS5_*_ROWID macros below for a description of how %_data rowids are
** assigned to each fo them.
**
** 1. Structure Records:
**
**   The set of segments that make up an index - the index structure - are
**   recorded in a single record within the %_data table. The record consists
**   of a single 32-bit configuration cookie value followed by a list of
**   SQLite varints.
**
**   If the structure record is a V2 record, the configuration cookie is
**   followed by the following 4 bytes: [0xFF 0x00 0x00 0x01].
**
**   Next, the record continues with three varints:
**
**     + number of levels,
**     + total number of segments on all levels,
**     + value of write counter.
**
**   Then, for each level from 0 to nMax:
**
**     + number of input segments in ongoing merge.
**     + total number of segments in level.
**     + for each segment from oldest to newest:
**         + segment id (always > 0)
**         + first leaf page number (often 1, always greater than 0)
**         + final leaf page number
**
**      Then, for V2 structures only:
**
**         + lower origin counter value,
**         + upper origin counter value,
**         + the number of tombstone hash pages.
**
** 2. The Averages Record:
**
**   A single record within the %_data table. The data is a list of varints.
**   The first value is the number of rows in the index. Then, for each column
**   from left to right, the total number of tokens in the column for all
**   rows of the table.
**
** 3. Segment leaves:
**
**   TERM/DOCLIST FORMAT:
**
**     Most of each segment leaf is taken up by term/doclist data. The
**     general format of term/doclist, starting with the first term
**     on the leaf page, is:
**
**         varint : size of first term
**         blob:    first term data
**         doclist: first doclist
**         zero-or-more {
**           varint:  number of bytes in common with previous term
**           varint:  number of bytes of new term data (nNew)
**           blob:    nNew bytes of new term data
**           doclist: next doclist
**         }
**
**     doclist format:
**
**         varint:  first rowid
**         poslist: first poslist
**         zero-or-more {
**           varint:  rowid delta (always > 0)
**           poslist: next poslist
**         }
**
**     poslist format:
**
**         varint: size of poslist in bytes multiplied by 2, not including
**                 this field. Plus 1 if this entry carries the "delete" flag.
**         collist: collist for column 0
**         zero-or-more {
**           0x01 byte
**           varint: column number (I)
**           collist: collist for column I
**         }
**
**     collist format:
**
**         varint: first offset + 2
**         zero-or-more {
**           varint: offset delta + 2
**         }
**
**   PAGE FORMAT
**
**     Each leaf page begins with a 4-byte header containing 2 16-bit
**     unsigned integer fields in big-endian format. They are:
**
**       * The byte offset of the first rowid on the page, if it exists
**         and occurs before the first term (otherwise 0).
**
**       * The byte offset of the start of the page footer. If the page
**         footer is 0 bytes in size, then this field is the same as the
**         size of the leaf page in bytes.
**
**     The page footer consists of a single varint for each term located
**     on the page. Each varint is the byte offset of the current term
**     within the page, delta-compressed against the previous value. In
**     other words, the first varint in the footer is the byte offset of
**     the first term, the second is the byte offset of the second less that
**     of the first, and so on.
**
**     The term/doclist format described above is accurate if the entire
**     term/doclist data fits on a single leaf page. If this is not the case,
**     the format is changed in two ways:
**
**       + if the first rowid on a page occurs before the first term, it
**         is stored as a literal value:
**
**             varint:  first rowid
**
**       + the first term on each page is stored in the same way as the
**         very first term of the segment:
**
**             varint : size of first term
**             blob:    first term data
**
** 5. Segment doclist indexes:
**
**   Doclist indexes are themselves b-trees, however they usually consist of
**   a single leaf record only. The format of each doclist index leaf page
**   is:
**
**     * Flags byte. Bits are:
**         0x01: Clear if leaf is also the root page, otherwise set.
**
**     * Page number of fts index leaf page. As a varint.
**
**     * First rowid on page indicated by previous field. As a varint.
**
**     * A list of varints, one for each subsequent termless page. A
**       positive delta if the termless page contains at least one rowid,
**       or an 0x00 byte otherwise.
**
**   Internal doclist index nodes are:
**
**     * Flags byte. Bits are:
**         0x01: Clear for root page, otherwise set.
**
**     * Page number of first child page. As a varint.
**
**     * Copy of first rowid on page indicated by previous field. As a varint.
**
**     * A list of delta-encoded varints - the first rowid on each subsequent
**       child page.
**
** 6. Tombstone Hash Page
**
**   These records are only ever present in contentless_delete=1 tables.
**   There are zero or more of these associated with each segment. They
**   are used to store the tombstone rowids for rows contained in the
**   associated segments.
**
**   The set of nHashPg tombstone hash pages associated with a single
**   segment together form a single hash table containing tombstone rowids.
**   To find the page of the hash on which a key might be stored:
**
**       iPg = (rowid % nHashPg)
**
**   Then, within page iPg, which has nSlot slots:
**
**       iSlot = (rowid / nHashPg) % nSlot
**
**   Each tombstone hash page begins with an 8 byte header:
**
**     1-byte:  Key-size (the size in bytes of each slot). Either 4 or 8.
**     1-byte:  rowid-0-tombstone flag. This flag is only valid on the
**              first tombstone hash page for each segment (iPg=0). If set,
**              the hash table contains rowid 0. If clear, it does not.
**              Rowid 0 is handled specially.
**     2-bytes: unused.
**     4-bytes: Big-endian integer containing number of entries on page.
**
**   Following this are nSlot 4 or 8 byte slots (depending on the key-size
**   in the first byte of the page header). The number of slots may be
**   determined based on the size of the page record and the key-size:
**
**     nSlot = (nByte - 8) / key-size
*//*
** There are two versions of the format used for the structure record:
**
**   1. the legacy format, that may be read by all fts5 versions, and
**
**   2. the V2 format, which is used by contentless_delete=1 databases.
**
** Both begin with a 4-byte "configuration cookie" value. Then, a legacy
** format structure record contains a varint - the number of levels in
** the structure. Whereas a V2 structure record contains the constant
** 4 bytes [0xff 0x00 0x00 0x01]. This is unambiguous as the value of a
** varint has to be at least 16256 to begin with "0xFF". And the default
** maximum number of levels is 64.
**
** See below for more on structure record formats.
*//* Add dlidx if this many empty pages *//* Number of leaf pages in unit of work *//* Number of leaf pages per optimize step *//*
** Overview:
**
** The %_data table contains all the FTS indexes for an FTS5 virtual table.
** As well as the main term index, there may be up to 31 prefix indexes.
** The format is similar to FTS3/4, except that:
**
**   * all segment b-tree leaf data is stored in fixed size page records
**     (e.g. 1000 bytes). A single doclist may span multiple pages. Care is
**     taken to ensure it is possible to iterate in either direction through
**     the entries in a doclist, or to seek to a specific entry within a
**     doclist, without loading it into memory.
**
**   * large doclists that span many pages have associated "doclist index"
**     records that contain a copy of the first rowid on each page spanned by
**     the doclist. This is used to speed up seek operations, and merges of
**     large doclists with very small doclists.
**
**   * extra fields in the "structure record" record the state of ongoing
**     incremental merge operations.
**
*//*
** 2014 May 31
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** Low level access to the FTS index stored in the database file. The
** routines in this file file implement all read and write access to the
** %_data table. Other parts of the system access this functionality via
** the interface defined in fts5Int.h.
*//* OUT: size of doclist in bytes *//* OUT: pointer to doclist *//* OUT: Size of term in bytes *//* OUT: term (nul-terminated) *//*
** Return true if the hash table is empty, false otherwise.
*//* Query prefix *//* Hash table to query *//* OUT: Size of doclist in bytes *//* Query term *//*
** Query the hash table for a doclist associated with term pTerm/nTerm.
*//* Query prefix, if any *//*
** Link all tokens from hash table iHash into a list in sorted order. The
** tokens are not removed from the hash table.
*//* p1 is smaller *//* p2 is smaller *//*
** Arguments pLeft and pRight point to linked-lists of hash-entry objects,
** each sorted in key order. This function merges the two lists into a
** single list and returns a pointer to its first element.
*//* This is a delete. Set the delete flag. *//* Append the new position offset, if necessary *//* Append a new column value, if necessary *//* If this is a new rowid, append the 4-byte size field for the previous
  ** entry, and the new rowid for this entry.  *//* Appending to an existing hash-entry. Check that there is enough
    ** space to append the largest possible new entry. Worst case scenario
    ** is:
    **
    **     + 9 bytes for a new rowid,
    **     + 4 byte reserved for the "poslist size" varint.
    **     + 1 byte for a "new column" byte,
    **     + 3 bytes for a new column number (16-bit max) as a varint,
    **     + 5 bytes for the new position offset (32-bit max).
    *//* Add the first rowid field to the hash-entry *//* Allocate new Fts5HashEntry and add it to the hash table. *//* Grow the Fts5Hash.aSlot[] array if necessary. *//* Figure out how much space to allocate *//* If an existing hash entry cannot be found, create a new one. *//* Attempt to locate an existing hash entry *//* If non-delete entry should be written *//* Amount to increment (*pHash->pnByte) by *//* First byte of token *//* Rowid for this entry *//*
** Add an entry to the in-memory hash table. The key is the concatenation
** of bByte and (pToken/nToken). The value is (iRowid/iCol/iPos).
**
**     (bByte || pToken) -> (iRowid,iCol,iPos)
**
** Or, if iCol is negative, then the value is a delete marker.
*//* Value of nPos field *//* Size in bytes *//*
** Resize the hash table by doubling the number of slots.
*//*
** Empty (but do not delete) a hash table.
*//*
** Free a hash table object.
*//*
** Allocate a new hash table.
*//*
** Eqivalent to:
**
**   char *fts5EntryKey(Fts5HashEntry *pEntry){ return zKey; }
*//* Rowid of last value written *//* Position of last value written *//* Column of last value written *//* Set content-flag (detail=none mode) *//* Set delete-flag @ iSzPoslist *//* Length of key in bytes *//* Total bytes of data (incl. structure) *//* Offset of space for 4-byte poslist size *//* Total size of allocation *//* Next entry in sorted order *//* Next hash entry with same hash-key *//*
** Each entry in the hash table is represented by an object of the
** following type. Each object, its key, and its current data are stored
** in a single memory allocation. The key immediately follows the object
** in memory. The position list data immediately follows the key data
** in memory.
**
** The key is Fts5HashEntry.nKey bytes in size. It consists of a single
** byte identifying the index (either the main term index or a prefix-index),
** followed by the term data. For example: "0token". There is no
** nul-terminator - in this case nKey=6.
**
** The data that follows the key is in a similar, but not identical format
** to the doclist data stored in the database. It is:
**
**   * Rowid, as a varint
**   * Position list, without 0x00 terminator.
**   * Size of previous position list and rowid, as a 4 byte
**     big-endian integer.
**
** iRowidOff:
**   Offset of last rowid written to data area. Relative to first byte of
**   structure.
**
** nData:
**   Bytes of data written since iRowidOff.
*//* Array of hash slots *//* Current ordered scan item *//* Size of aSlot[] array *//* Number of entries currently in hash *//* Pointer to bytes counter *//* Copy of Fts5Config.eDetail *//*
** This file contains the implementation of an in-memory hash table used
** to accumuluate "term -> doclist" content before it is flused to a level-0
** segment.
*//*
** 2014 August 11
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
*//*
** Clear the token mappings for all Fts5IndexIter objects mannaged by
** the expression passed as the only argument.
*//*
** Does the work of the fts5_api.xInstToken() API method.
*//*
** Does the work of the fts5_api.xQueryToken() API method.
*//*
** This function is only called for detail=columns tables.
*//*
** pToken is a buffer nToken bytes in size that may or may not contain
** an embedded 0x00 byte. If it does, return the number of bytes in
** the buffer before the 0x00. If it does not, return nToken.
*//*
** Clear the position lists associated with all phrases in the expression
** passed as the first argument. Argument bLive is true if the expression
** might be pointing to a real entry, otherwise it has just been reset.
**
** At present this function is only used for detail=col and detail=none
** fts5 tables. This implies that all phrases must be at most 1 token
** in size, as phrase matches are not supported without detail=full.
*//* True if ok to populate *//*
** This function is used to access the current position list for phrase
** iPhrase.
*//*
** Return the number of terms in the iPhrase'th phrase in pExpr.
*//*
** Return the number of phrases in expression pExpr.
*//* Avoid warnings indicating that sqlite3Fts5ParserTrace() and
  ** sqlite3Fts5ParserFallback() are unused *//*
** This is called during initialization to register the fts5_expr() scalar
** UDF with the SQLite handle passed as the only argument.
*//* if SQLITE_TEST || SQLITE_FTS5_DEBUG *//*
** The implementation of an SQLite user-defined-function that accepts a
** single integer as an argument. If the integer is an alpha-numeric
** unicode code point, 1 is returned. Otherwise 0.
*//* Size of azConfig[] *//* Array of arguments for Fts5Config *//*
** The implementation of user-defined scalar functions fts5_expr() (bTcl==0)
** and fts5_expr_tcl() (bTcl!=0).
*//*
** Compose a tcl-readable representation of expression pExpr. Return a
** pointer to a buffer containing that representation. It is the
** responsibility of the caller to at some point free the buffer using
** sqlite3_free().
*//* Determine the maximum amount of space required. *//* Right hand child expression *//* Left hand child expression *//* Parse context *//* Bytes of space to allocate for this node *//* Number of children of returned node *//* For STRING expressions, the near cluster *//* FTS5_STRING, AND, OR or NOT *//*
** Allocate and return a new expression object. If anything goes wrong (i.e.
** OOM error), leave an error code in pParse and return NULL.
*//*
** This function is used when parsing LIKE or GLOB patterns against
** trigram indexes that specify either detail=column or detail=none.
** It converts a phrase:
**
**     abc + def + ghi
**
** into an AND tree:
**
**     abc AND def AND ghi
*//*
** Add pSub as a child of p.
*//*
** Apply colset pColset to expression node pExpr and all of its descendents.
*//*
** Recursively apply colset pColset to expression node pNode and all of
** its decendents. If (*ppFree) is not NULL, it contains a spare copy
** of pColset. This function may use the spare copy and set (*ppFree) to
** zero, or it may create copies of pColset using fts5CloneColset().
*//* Next output slot in pColset *//* Next input in pMerge *//* Next input in pColset *//*
** Remove from colset pColset any columns that are not also in colset pMerge.
*//*
** If argument pOrig is NULL, or if (*pRc) is set to anything other than
** SQLITE_OK when this function is called, NULL is returned.
**
** Otherwise, a copy of (*pOrig) is made into memory obtained from
** sqlite3Fts5MallocZero() and a pointer to it returned. If the allocation
** fails, (*pRc) is set to SQLITE_NOMEM and NULL is returned.
*//* Dequoted copy of token p *//* Existing colset object *//* Store SQLITE_NOMEM here if required *//*
** Allocate and return an Fts5Colset object specifying the inverse of
** the colset passed as the second argument. Free the colset passed
** as the second argument before returning.
*//* Check that the array is in order and contains no duplicate entries. *//* New colset object to return *//* Num. columns already in colset object *//* New column to add to colset object *//*
** The second argument passed to this function may be NULL, or it may be
** an existing Fts5Colset object. This function returns a pointer to
** a new colset object containing the contents of (p) with new value column
** number iCol appended.
**
** If an OOM error occurs, store an error code in pParse and return NULL.
** The old colset object (if any) is not freed in this case.
*//*
** Token pTok has appeared in a MATCH expression where the NEAR operator
** is expected. If token pTok does not contain "NEAR", store an error
** in the pParse object.
*//* All the allocations succeeded. Put the expression object together. *//* This happens when parsing a token or quoted phrase that contains
      ** no token characters at all. (e.g ... MATCH '""'). *//* Used to iterate through phrase terms *//* Context object for fts5ParseTokenize *//* Expression to return via *ppNew *//* The phrase extracted from pExpr *//*
** Create a new FTS5 expression by cloning phrase iPhrase of the
** expression passed as the second argument.
*//* Tokenize return code *//* Context object passed to callback *//* True if there is a trailing "*" *//* String to tokenize *//* Phrase to append to *//*
** This function is called by the parser to process a string token. The
** string may or may not be quoted. In any case it is tokenized and a
** phrase object consisting of all tokens returned.
*//*
** Free the phrase object passed as the second argument.
*//*
** Free the phrase object passed as the only argument.
*//* If an error has already occurred, this is a no-op *//*
** Callback for tokenizing terms used by ParseTerm().
*//* Recently parsed phrase *//* Existing nearset, or NULL *//*
** If argument pNear is NULL, then a new Fts5ExprNearset object is allocated
** and populated with pPhrase. Or, if pNear is not NULL, phrase pPhrase is
** appended to it and the results returned.
**
** If an OOM error occurs, both the pNear and pPhrase objects are freed and
** NULL returned.
*//*
** Set the "bFirst" flag on the first token of the phrase passed as the
** only argument.
*//*
** Move to the next document
**
** Return SQLITE_OK if successful, or an SQLite error code otherwise. It
** is not considered an error if the query does not match any documents.
*//* If the iterator is not at a real match, skip forward until it is. *//* If not at EOF but the current rowid occurs earlier than iFirst in
  ** the iteration order, move to document iFirst or later. *//*
** Begin iterating through the set of documents in index pIdx matched by
** the MATCH expression passed as the first argument. If the "bDesc"
** parameter is passed a non-zero value, iteration is in descending rowid
** order. Or, if it is zero, in ascending order.
**
** If iterating in ascending rowid order (bDesc==0), the first document
** visited is that with the smallest rowid that is larger than or equal
** to parameter iFirst. Or, if iterating in ascending order (bDesc==1),
** then the first document visited must have a rowid smaller than or
** equal to iFirst.
**
** Return SQLITE_OK if successful, or an SQLite error code otherwise. It
** is not considered an error if the query does not match any documents.
*//* Initialize all term iterators in the NEAR object. *//*
** Set node pNode, which is part of expression pExpr, to point to the first
** match. If there are no matches, set the Node.bEof flag to indicate EOF.
**
** Return an SQLite error code if an error occurs, or SQLITE_OK otherwise.
** It is not an error if there are no matches.
*//* Expression node to test *//* Expression of which pNode is a part *//*
** If pNode currently points to a match, this function returns SQLITE_OK
** without modifying it. Otherwise, pNode is advanced until it does point
** to a match or EOF is reached.
*//* FTS5_NOT node to advance *//* Expression pPhrase belongs to *//* If the child node is now at EOF, so is the parent AND node. Otherwise,
      ** the child node is guaranteed to have advanced at least as far as
      ** rowid iLast. So if it is not at exactly iLast, pChild->iRowid is the
      ** new lastest rowid seen so far.  *//* Advance pChild until it points to iLast or laster *//* FTS5_AND node to advance *//*
** Argument pNode is an FTS5_AND node.
*//*
** xNext() method for a node of type FTS5_TERM.
*//* As this "NEAR" object is actually a single phrase that consists
  ** of a single term only, grab pointers into the poslist managed by the
  ** fts5_index.c iterator object. This is much faster than synthesizing
  ** a new poslist the way we have to for more complicated phrase or NEAR
  ** expressions.  *//* The "NEAR" node (FTS5_TERM) *//* Expression that pNear is a part of *//* Set the EOF flag if either all synonym iterators are at EOF or an
    ** error has occurred.  *//* Advance each iterator that currently points to iRowid. Or, if iFrom
    ** is valid - each iterator that points to a rowid before iFrom.  *//* Find the firstest rowid any synonym points to. *//* FTS5_STRING or FTS5_TERM node *//*
** Advance the first term iterator in the first phrase of pNear. Set output
** variable *pbEof to true if it reaches EOF or if an error occurs.
**
** Return SQLITE_OK if successful, or an SQLite error code if an error
** occurs.
*//* Initialize iLast, the "lastest" rowid any iterator points to. If the
  ** iterator skips through rowids in the default ascending order, this means
  ** the maximum rowid. Or, if the iterator is "ORDER BY rowid DESC", then it
  ** means the minimum rowid.  *//* Check that this node should not be FTS5_TERM *//* True if all terms are at the same rowid *//* Phrase and token index, respectively *//* Lastest rowid any iterator points to *//*
** All individual term iterators in pNear are guaranteed to be valid when
** this function is called. This function checks if all term iterators
** point to the same rowid, and if not, advances them until they do.
** If an EOF is reached before this happens, *pbEof is set to true before
** returning.
**
** SQLITE_OK is returned if an error occurs, or an SQLite error code
** otherwise. It is not considered an error code if an iterator reaches
** EOF.
*//*
** Compare the values currently indicated by the two nodes as follows:
**
**    res = (*p1) - (*p2)
**
** Nodes that point to values that come later in the iteration order are
** considered to be larger. Nodes at EOF are the largest of all.
**
** This means that if the iteration order is ASC, then numerically larger
** rowids are considered larger. Or if it is the default DESC, numerically
** smaller rowids are larger.
*//*
** If pExpr is an ASC iterator, this function returns a value with the
** same sign as:
**
**   (iLhs - iRhs)
**
** Otherwise, if this is a DESC iterator, the opposite is returned:
**
**   (iRhs - iLhs)
*//*
** Initialize all term iterators in the pNear object. If any term is found
** to match no documents at all, return immediately without initializing any
** further iterators.
**
** If an error occurs, return an SQLite error code. Otherwise, return
** SQLITE_OK. It is not considered an error if some term matches zero
** documents.
*//* Check that each phrase in the nearset matches the current row.
    ** Populate the pPhrase->poslist buffers at the same time. If any
    ** phrase is not a match, break out of the loop early.  *//* The "NEAR" node (FTS5_STRING) *//* IN/OUT: Lastest rowid seen so far *//* True if iterator is "rowid DESC" *//* Term iterator to advance *//* OUT: Set to true if EOF *//*
** Advance iterator pIter until it points to a value equal to or laster
** than the initial value of *piLast. If this means the iterator points
** to a value laster than *piLast, update *piLast to the new lastest value.
**
** If the iterator reaches EOF, set *pbEof to true before returning. If
** an error occurs, set *pRc to an error code. If either *pbEof or *pRc
** are set, return a non-zero value. Otherwise, return zero.
*//* Add an entry to each output position list *//* This block advances the phrase iterators until they point to a set of
    ** entries that together comprise a match.  *//* Initialize a lookahead iterator for each phrase. After passing the
  ** buffer and buffer size to the lookaside-reader init function, zero
  ** the phrase poslist buffer. The new poslist for the phrase (containing
  ** the same entries as the original with some entries removed on account
  ** of the NEAR constraint) is written over the original even as it is
  ** being read. This is safe as the entries for the new poslist are a
  ** subset of the old, so it is not possible for data yet to be read to
  ** be overwritten.  *//* If the aStatic[] array is not large enough, allocate a large array
  ** using sqlite3_malloc(). This approach could be improved upon. *//*
** The near-set object passed as the first argument contains more than
** one phrase. All phrases currently point to the same row. The
** Fts5ExprPhrase.poslist buffers are populated accordingly. This function
** tests if the current row contains instances of each phrase sufficiently
** close together to meet the NEAR constraint. Non-zero is returned if it
** does, or zero otherwise.
**
** If in/out parameter (*pRc) is set to other than SQLITE_OK when this
** function is called, it is a no-op. Or, if an error (e.g. SQLITE_NOMEM)
** occurs within this function (*pRc) is set accordingly before returning.
** The return value is undefined in both these cases.
**
** If no error occurs and non-zero (a match) is returned, the position-list
** of each phrase object is edited to contain only those entries that
** meet the constraint before returning.
*//* Output poslist *//* Writer context *//* Input iterator *//* Iterator object to initialize *//* Buffer to read position list from *//* Next position *//* Current position *//* Current offset in position list *//* Size of buffer a[] in bytes *//* Buffer containing position list *//* Append position iPos to the output *//* Initialize a term iterator for each term in the phrase *//* OUT: Set to true if really a match *//* Phrase object to initialize *//* Node pPhrase belongs to *//*
** All individual term iterators in pPhrase are guaranteed to be valid and
** pointing to the same rowid when this function is called. This function
** checks if the current rowid really is a match, and if so populates
** the pPhrase->poslist buffer accordingly. Output parameter *pbMatch
** is set to true if this is really a match, or false otherwise.
**
** SQLITE_OK is returned if an error occurs, or an SQLite error code
** otherwise. It is not considered an error code if the current rowid is
** not a match.
*//* Use this buffer for space if required *//*
** Argument pTerm must be a synonym iterator.
*//*
** Argument pTerm must be a synonym iterator. Return the current rowid
** that it points to.
*//*
** Free the expression object passed as the only argument.
*//*
** Free the expression node object passed as the only argument.
*//*
** This function is only called when using the special 'trigram' tokenizer.
** Argument zText contains the text of a LIKE or GLOB pattern matched
** against column iCol. This function creates and compiles an FTS5 MATCH
** expression that will match a superset of the rows matched by the LIKE or
** GLOB. If successful, SQLITE_OK is returned. Otherwise, an SQLite error
** code.
*//*
** Assuming that buffer z is at least nByte bytes in size and contains a
** valid utf-8 string, return the number of characters in the string.
*//* If the LHS of the MATCH expression was a user column, apply the
  ** implicit column-filter.  *//* Next token type *//* Expression text *//* FTS5 Configuration *//* Skip past any whitespace *//* IN/OUT: Pointer into buffer *//*
** Read the first token from the nul-terminated string at *pz.
*//*
** Check that the Fts5ExprNode.iHeight variables are set correctly in
** the expression tree passed as the only argument.
*//* Convert "a+b" to "a AND b" *//* Result of a successful parse *//* Array of all phrases *//* Size of apPhrase array *//*
** Parse context.
*//* Array of phrase pointers *//* Number of entries in aPhrase[] array *//* Columns to search (NULL -> all columns) *//* NEAR parameter *//*
** One or more phrases that must appear within a certain token distance of
** each other within each matching document.
*//* Terms that make up this phrase *//* Number of entries in aTerm[] *//* Current position list *//* FTS5_STRING node this phrase is part of *//*
** A phrase. One or more terms that must appear in a contiguous sequence
** within a document for it to match.
*//* Pointer to first in list of synonyms *//* Iterator for this term *//* Size of term in bytes incl. tokendata *//* Effective size of term in bytes *//* Term data *//* True if token must be first in column *//* True for a prefix term *//*
** An instance of the following structure represents a single search term
** or term prefix.
*//*
** Invoke the xNext method of an Fts5ExprNode object. This macro should be
** used as if it has the same signature as the xNext() methods themselves.
*//* Array of child nodes *//* Number of child nodes *//* Child nodes. For a NOT node, this array always contains 2 entries. For
  ** AND or OR nodes, it contains 2 or more entries.  *//* For FTS5_STRING - cluster of phrases *//* Next method for this node. *//* Distance to tree leaf nodes *//* True if entry is not a match *//* True at EOF *//* Node type *//*
** eType:
**   Expression node type. Usually one of:
**
**       FTS5_AND                 (nChild, apChild valid)
**       FTS5_OR                  (nChild, apChild valid)
**       FTS5_NOT                 (nChild, apChild valid)
**       FTS5_STRING              (pNear valid)
**       FTS5_TERM                (pNear valid)
**
**   An expression node with eType==0 may also exist. It always matches zero
**   rows. This is created when a phrase containing no tokens is parsed.
**   e.g. "".
**
** iHeight:
**   Distance from this node to furthest leaf. This is always 0 for nodes
**   of type FTS5_STRING and FTS5_TERM. For all other nodes it is one
**   greater than the largest child value.
*//* Pointers to phrase objects *//* Number of phrases in expression *//* Iterate in descending rowid order *//* #include <stdio.h> *//*
** Functions generated by lemon from fts5parse.y.
*//*
** All token types in the generated fts5parse.h file are greater than 0.
*//* #include "fts5parse.h" *//*
** Set (*pConfig->pzErrmsg) to point to an sqlite3_malloc()ed buffer
** containing the error message created using printf() style formatting
** string zFmt and its trailing arguments.
*//* Set default values *//*
** Load the contents of the %_config table into memory.
*//* OUT: Rank function arguments *//* OUT: Rank function name *//* Input string *//*
** Parameter zIn contains a rank() function specification. The format of
** this is:
**
**   + Bareword (function name)
**   + Open parenthesis - "("
**   + Zero or more SQL literals in a comma separated list
**   + Close parenthesis - ")"
*//*
** Argument pIn points to the first character in what is expected to be
** a comma-separated list of SQL literals followed by a ')' character.
** If it actually is this, return a pointer to the ')'. Otherwise, return
** NULL to indicate a parse error.
*//* FTS5_TOKENIZE_* flags *//* FTS5 Configuration object *//*
** Tokenize the text passed via the second and third arguments.
**
** The callback is invoked once for each token in the input text. The
** arguments passed to it are, in order:
**
**     void *pCtx          // Copy of 4th argument to sqlite3Fts5Tokenize()
**     const char *pToken  // Pointer to buffer containing token
**     int nToken          // Size of token in bytes
**     int iStart          // Byte offset of start of token within input text
**     int iEnd            // Byte offset of end of token within input text
**     int iPos            // Position of token in input (first token is 0)
**
** If the callback returns a non-zero value the tokenization is abandoned
** and no further callbacks are issued.
**
** This function returns SQLITE_OK if successful or an SQLite error code
** if an error occurs. If the tokenization was abandoned early because
** the callback returned SQLITE_DONE, this is not an error and this function
** still returns SQLITE_OK. Or, if the tokenization was abandoned early
** because the callback returned another non-zero value, it is assumed
** to be an SQLite error code and returned to the caller.
*//*
** Call sqlite3_declare_vtab() based on the contents of the configuration
** object passed as the only argument. Return SQLITE_OK if successful, or
** an SQLite error code if an error occurs.
*//*
** Free the configuration object passed as the only argument.
*//* Formulate the zContentExprlist text *//* If no zContent option was specified, fill in the default values. *//* We only allow contentless_unindexed=1 if the table is actually a
  ** contentless one.
  *//* We only allow contentless_delete=1 if columnsize=0 is not present.
  **
  ** This restriction may be removed at some point.
  *//* We only allow contentless_delete=1 if the table is indeed contentless. *//* True if there are one or more UNINDEXED *//* New object to return *//* OUT: Results of parse *//* Array of nArg CREATE VIRTUAL TABLE args *//*
** Arguments nArg/azArg contain the string arguments passed to the xCreate
** or xConnect method of the virtual table. This function attempts to
** allocate an instance of Fts5Config containing the results of parsing
** those arguments.
**
** If successful, SQLITE_OK is returned and *ppOut is set to point to the
** new Fts5Config object. If an error occurs, an SQLite error code is
** returned, *ppOut is set to NULL and an error message may be left in
** *pzErr. It is the responsibility of the caller to eventually free any
** such error message using sqlite3_free().
*//*
** Populate the Fts5Config.zContentExprlist string.
*//* OUT: Set to true if dequoting required *//* OUT: malloc'd buffer containing str/bw *//* Buffer to gobble string/bareword from *//*
** Gobble up the first bareword or quoted word from the input buffer zIn.
** Return a pointer to the character immediately following the last in
** the gobbled word if successful, or a NULL pointer otherwise (failed
** to find close-quote character).
**
** Before returning, set pzOut to point to a new buffer containing a
** nul-terminated, dequoted copy of the gobbled word. If the word was
** quoted, *pbQuoted is also set to 1 before returning.
**
** If *pRc is other than SQLITE_OK when this function is called, it is
** a no-op (NULL is returned). Otherwise, if an OOM occurs within this
** function, *pRc is set to SQLITE_NOMEM before returning. *pRc is *not*
** set if a parse error (failed to find close quote) occurs.
*//* Argument to parse *//* Special command to parse *//* Configuration object to update *//*
** Parse a "special" CREATE VIRTUAL TABLE directive and update
** configuration object pConfig as appropriate.
**
** If successful, object pConfig is updated and SQLITE_OK returned. If
** an error occurs, an SQLite error code is returned and an error message
** may be left in *pzErr. It is the responsibility of the caller to
** eventually free any such error message using sqlite3_free().
*//* Quote character (if any ) *//*
** Convert an SQL-style quoted string into a normal string by removing
** the quote characters.  The conversion is done in-place.  If the
** input does not begin with a quote character, then this routine
** is a no-op.
**
** Examples:
**
**     "abc"   becomes   abc
**     'xyz'   becomes   xyz
**     [pqr]   becomes   pqr
**     `mno`   becomes   mno
*//* Character iIn and iIn+1 form an escaped quote character. Skip
        ** the input cursor past both and copy a single quote character
        ** to the output buffer. *//* Character iIn was the close quote. *//* Set stack variable q to the close-quote character *//*
** The first character of the string pointed to by argument z is guaranteed
** to be an open-quote character (see function fts5_isopenquote()).
**
** This function searches for the corresponding close-quote character within
** the string and, if found, dequotes the string in place and adds a new
** nul-terminator byte.
**
** If the close-quote is found, the value returned is the byte offset of
** the character immediately following it. Or, if the close-quote is not
** found, -1 is returned. If -1 is returned, the buffer is left in an
** undefined state.
*//* At this point, if the literal was an integer, the parse is
      ** finished. Or, if it is a floating point value, it may continue
      ** with either a decimal point or an 'E' character. *//* maybe a number *//*
** Argument pIn points to a character that is part of a nul-terminated
** string. Return a pointer to the first character following *pIn in
** the string that is not a "bareword" character.
*//*
** Argument pIn points to a character that is part of a nul-terminated
** string. Return a pointer to the first character following *pIn in
** the string that is not a white-space character.
*//* Maximum allowed page size *//* default 10% *//* Calculate a hash value for this term. This is the same hash checksum
    ** used by the fts5_hash.c module. This is not important for correct
    ** operation of the module, but is necessary to ensure that some tests
    ** designed to produce hash table collisions really do work.  *//* Index (main or aPrefix[] entry) *//*************************************************************************
*//* 0x70 .. 0x7F *//* 0x60 .. 0x6F *//* 0x50 .. 0x5F *//* 0x40 .. 0x4F *//* 0x30 .. 0x3F *//* 0x20 .. 0x2F *//* 0x10 .. 0x1F *//* 0x00 .. 0x0F *//*
** Return true if character 't' may be part of an FTS5 bareword, or false
** otherwise. Characters that may be part of barewords:
**
**   * All non-ASCII characters,
**   * The 52 upper and lower case ASCII characters, and
**   * The 10 integer ASCII characters.
**   * The underscore character "_" (0x5F).
**   * The unicode "subsitute" character (0x1A).
*//*
** Return a nul-terminated copy of the string indicated by pIn. If nIn
** is non-negative, then it is the length of the string in bytes. Otherwise,
** the length of the string is determined using strlen().
**
** It is the responsibility of the caller to eventually free the returned
** buffer using sqlite3_free(). If an OOM error occurs, NULL is returned.
*//* Initialized only to suppress erroneous warning from Clang *//*
** Append position iPos to the position list being accumulated in buffer
** pBuf, which must be already be large enough to hold the new data.
** The previous position written to this list is *piPrev. *piPrev is set
** to iPos before returning.
*//* Poslist buffer to iterate through *//*
** Advance the iterator object passed as the only argument. Return true
** if the iterator reaches EOF, or false otherwise.
*//* This is a corrupt record. So stop parsing it here. *//* IN/OUT: Current offset *//* IN/OUT: Offset within a[] *//* Buffer containing poslist *//*
** Set the buffer to contain nData/pData. If an OOM error occurs, leave an
** the error code in p. If an error has already occurred when this function
** is called, it is a no-op.
*//*
** Zero the contents of the buffer object. But do not free the associated
** memory allocation.
*//*
** Free any buffer allocated by pBuf. Zero the structure before returning.
*//*
** Argument zFmt is a printf() style format string. This function performs
** the printf() style processing, then appends the results to buffer pBuf.
**
** Like sqlite3Fts5BufferAppendString(), this function ensures that the byte
** following the buffer data is set to 0x00, even though this byte is not
** included in the pBuf->n count.
*//*
** Append the nul-terminated string zStr to the buffer pBuf. This function
** ensures that the byte following the buffer data is set to 0x00, even
** though this byte is not included in the pBuf->n count.
*//*
** Append buffer nData/pData to buffer pBuf. If an OOM error occurs, set
** the error code in p. If an error has already occurred when this function
** is called, it is a no-op.
*//*
** Encode value iVal as an SQLite varint and append it to the buffer object
** pBuf. If an OOM error occurs, set the error code in p.
*//* xColumnLocale() must be available *//*
** Implementation of fts5_get_locale() function.
*//* Determine and return the BM25 score for the current row. Or, if an
  ** error has occurred, throw an exception. *//* Figure out the total size of the current row in tokens. *//* Calculate the phrase frequency (symbol "f(qi,D)" in the documentation)
  ** for each phrase in the query for the current row. *//* Array of phrase freq. for current row *//* Total number of tokens in row *//* Value returned by xInstCount() *//* Iterator variable *//* Values allocated/calculated once only *//* SQL function return value *//* Constant "b" from BM25 formula *//* Constant "k1" from BM25 formula *//*
** Implementation of bm25() function.
*//* Calculate the IDF (Inverse Document Frequency) for phrase i.
        ** This is done using the standard BM25 formula as found on wikipedia:
        **
        **   IDF = log( (N - nHit + 0.5) / (nHit + 0.5) )
        **
        ** where "N" is the total number of documents in the set and nHit
        ** is the number that contain at least one instance of the phrase
        ** under consideration.
        **
        ** The problem with this is that if (N < 2*nHit), the IDF is
        ** negative. Which is undesirable. So the mimimum allowable IDF is
        ** (1e-6) - roughly the same as a term that appears in just over
        ** half of set of 5,000,000 documents.  *//* Calculate an IDF for each phrase in the query *//* Calculate the average document length for this FTS5 table *//* Allocate the Fts5Bm25Data object *//* Number of tokens in table *//* Number of rows in table *//* Number of phrases in query *//* Object to return *//* OUT: bm25-data object for this query *//*
** Set *ppData to point to the Fts5Bm25Data object for the current query.
** If the object has not already been allocated, allocate and populate it
** now.
*//* Pointer to sqlite3_int64 variable *//*
** Callback used by fts5Bm25GetData() to count the number of rows in the
** table matched by each individual phrase within the query.
*//* Array used to calculate phrase freq. *//* IDF for each phrase *//* Average number of tokens in each row *//*
** The first time the bm25() function is called for a query, an instance
** of the following structure is allocated and populated.
*//************************************************************************//* Advance iterator ctx.iter so that it points to the first coalesced
    ** phrase instance at or following position iBestStart. *//* Bytes in pLoc *//* Locale of column iBestCol *//* Locale of column iCol *//* Used to find the beginnings of sentences *//* Total size of iBestCol in tokens *//* Score of best snippet *//* First token of best snippet *//* Column containing best snippet *//* Array of "seen instance" flags *//* Used to iterate through instances *//* Number of instance matches this row *//* 5th argument to snippet() *//* 4th argument to snippet() *//* 1st argument to snippet() *//*
** Implementation of snippet() function.
*//*
** Return the value in pVal interpreted as utf-8 text. Except, if pVal
** contains a NULL value, return a pointer to a static string zero
** bytes in length instead of a NULL pointer.
*//* OUT: Adjusted offset *//* OUT: Score *//* Max tokens per snippet *//* Starting offset to score *//* Column to score *//* Array with one element per query phrase *//* Size of column in tokens *//* Pointer to HighlightContext object *//*
** This function is an xTokenize() callback used by the auxiliary snippet()
** function. Its job is to identify tokens that are the first in a sentence.
** For each such token, an entry is added to the SFinder.aFirst[] array.
*//*
** Add an entry to the Fts5SFinder.aFirst[] array. Grow the array if
** necessary. Return SQLITE_OK if successful, or SQLITE_NOMEM if an
** error occurs.
*//* Document being tokenized *//* Array of first token in each sentence *//* Number of entries in aFirst[] *//* Allocated size of aFirst[] *//* Current token position *//*
** Context object passed to the fts5SentenceFinderCb() function.
*//*
** End of highlight() implementation.
**************************************************************************//*
** Implementation of highlight() function.
*//* If this is the start of a new phrase, and the highlight is not open:
  **
  **   * copy text from the input up to the start of the phrase, and
  **   * open the highlight.
  *//* If the parenthesis is open, and this token is not part of the current
  ** phrase, and the starting byte offset of this token is past the point
  ** that has currently been copied into the output buffer, close the
  ** parenthesis. *//* End byte offset of token *//* Start byte offset of token *//*
** Tokenizer callback used by implementation of highlight() function.
*//*
** Append text to the HighlightContext output string - p->zOut. Argument
** z points to a buffer containing n bytes of text to append. If n is
** negative, everything up until the first '\0' is appended to the output.
**
** If *pRc is set to any value other than SQLITE_OK when this function is
** called, it is a no-op. If an error (i.e. an OOM condition) is encountered,
** *pRc is set to an error code before returning.
*//* Output value *//* True if highlight is open *//* Have copied up to this offset in zIn[] *//* Current token offset in zIn[] *//* Coalesced Instance Iterator *//* Variables modified by fts5HighlightCb() *//* Size of input text in bytes *//* Input text *//* Closing highlight *//* Opening highlight *//* If non-zero, last token to include *//* First token to include *//* Constant parameters to fts5HighlightCb() *//*************************************************************************
** Start of highlight() implementation.
*//*
** Initialize the iterator object indicated by the final parameter to
** iterate through coalesced phrase instances in column iCol.
*//*
** Advance the iterator to the next coalesced phrase instance. Return
** an SQLite error code if an error occurs, or SQLITE_OK otherwise.
*//* Last token in coalesced phrase instance *//* First token in coalesced phrase instance *//* Total number of phrase instances *//* Next phrase instance index *//* Column to search *//*
** Object used to iterate through all "coalesced phrase instances" in
** a single column of the current row. If the phrase instances in the
** column being considered do not overlap, this object simply iterates
** through them. Or, if they do overlap (share one or more tokens in
** common), each set of overlapping instances is treated as a single
** match. See documentation for the highlight() auxiliary function for
** details.
**
** Usage is:
**
**   for(rc = fts5CInstIterNext(pApi, pFts, iCol, &iter);
**      (rc==SQLITE_OK && 0==fts5CInstIterEof(&iter);
**      rc = fts5CInstIterNext(&iter)
**   ){
**     printf("instance starts at %d, ends at %d\n", iter.iStart, iter.iEnd);
**   }
**
*//* amalgamator: keep *//*
** Return the fallback token corresponding to canonical token iToken, or
** 0 if iToken has no fallback.
*//* This is what we do if the grammar does not define ERROR:
      **
      **  * Report an error message, and throw away the input token.
      **
      **  * If the input token is $, then fail the parse.
      **
      ** As before, subsequent error messages are suppressed until
      ** three input tokens have been successfully shifted.
      *//* fts5YYERRORSYMBOL is not defined *//* If the fts5YYNOERRORRECOVERY macro is defined, then do not attempt to
      ** do any kind of error recovery.  Instead, simply invoke the syntax
      ** error routine and continue going as if nothing had happened.
      **
      ** Applications can set this macro (for example inside %include) if
      ** they intend to abandon the parse upon the first syntax error seen.
      *//* A syntax error has occurred.
      ** The response to an error depends upon whether or not the
      ** grammar defines an error token "ERROR".
      **
      ** This is what we do if the grammar does define ERROR:
      **
      **  * Call the %syntax_error function.
      **
      **  * Begin popping the stack until we enter a state where
      **    it is legal to shift the error symbol, then shift
      **    the error symbol.
      **
      **  * Set the error count to three.
      **
      **  * Begin accepting and shifting new tokens.  No new error
      **    processing will occur until three tokens have been
      **    shifted successfully.
      **
      *//* Check that the stack is large enough to grow by a single entry
      ** if the RHS of the rule is empty.  This ensures that there is room
      ** enough on the stack to push the LHS value *//* NDEBUG *//* Reduce by this rule *//* Exit by "break" *//* The parser *//* True if fts5yymajor has invoked an error *//* True if we are at the end of input *//* The parser action. *//* Optional %extra_argument parameter *//* The value for the token *//* The major token code number *//* The main parser program.
** The first argument is a pointer to a structure obtained from
** "sqlite3Fts5ParserAlloc" which describes the current state of the parser.
** The second argument is the major token number.  The third is
** the minor token.  The fourth optional argument is whatever the
** user wants (and specified in the grammar) and is available for
** use by the action routines.
**
** Inputs:
** <ul>
** <li> A pointer to the parser (an opaque structure.)
** <li> The major token number.
** <li> The minor token number.
** <li> An option argument of a grammar-specified type.
** </ul>
**
** Outputs:
** None.
*//* Suppress warning about unused %extra_argument variable *//*********** End %parse_accept code *******************************************//*********** Begin %parse_accept code *****************************************//* Here code is inserted which will be executed whenever the
  ** parser accepts *//*
** The following is executed when the parser accepts
*//************ End %syntax_error code ******************************************//* Silence a compiler warning *//************ Begin %syntax_error code ****************************************//* The minor type of the error token *//* The major type of the error token *//*
** The following code executes when a syntax error first occurs.
*//* fts5YYNOERRORRECOVERY *//************ End %parse_failure code *****************************************//************ Begin %parse_failure code ***************************************//* Here code is inserted which will be executed whenever the
  ** parser fails *//*
** The following code executes when the parse fails
*//* It is not possible for a REDUCE to be followed by an error *//* There are no SHIFTREDUCE actions on nonterminals because the table
  ** generator has simplified them to pure REDUCE actions. *//********** End reduce actions ************************************************//* star_opt ::= *//* star_opt ::= STAR *//* phrase ::= STRING star_opt *//* phrase ::= phrase PLUS STRING star_opt *//* neardist_opt ::= COMMA STRING *//* neardist_opt ::= *//* nearphrases ::= nearphrases phrase *//* nearphrases ::= phrase *//* nearset ::= STRING LP nearphrases neardist_opt RP *//* nearset ::= CARET phrase *//* nearset ::= phrase *//* cnearset ::= colset COLON nearset *//* cnearset ::= nearset *//* exprlist ::= exprlist cnearset *//* exprlist ::= cnearset *//* expr ::= exprlist *//* expr ::= LP expr RP *//* expr ::= colset COLON LP expr RP *//* expr ::= expr NOT expr *//* expr ::= expr OR expr *//* expr ::= expr AND expr *//* colsetlist ::= STRING *//* colsetlist ::= colsetlist STRING *//* colset ::= MINUS STRING *//* colset ::= STRING *//* colset ::= LCP colsetlist RCP *//* colset ::= MINUS LCP colsetlist RCP *//* input ::= expr *//********** Begin reduce actions **********************************************//* Beginning here are the reduction cases.  A typical example
  ** follows:
  **   case 0:
  **  #line <lineno> <grammarfile>
  **     { ... }           // User supplied code
  **  #line <lineno> <thisfile>
  **     break;
  *//* Amount to pop the stack *//* The top of the parser's stack *//* The next action *//* The next state *//* %extra_context *//* Value of the lookahead token *//* Lookahead token, or fts5YYNOCODE if none *//* Number of the rule by which to reduce *//*
** Perform a reduce action and the shift that must immediately
** follow the reduce.
**
** The fts5yyLookahead and fts5yyLookaheadToken parameters provide reduce actions
** access to the lookahead token (if any).  The fts5yyLookahead will be fts5YYNOCODE
** if the lookahead token has already been consumed.  As this procedure is
** only called from one place, optimizing compilers will in-line it, which
** means that the extra parameters have no performance impact.
*//* Forward Declaration *//* (27) star_opt ::= *//* (26) star_opt ::= STAR *//* (25) phrase ::= STRING star_opt *//* (24) phrase ::= phrase PLUS STRING star_opt *//* (23) neardist_opt ::= COMMA STRING *//* (22) neardist_opt ::= *//* (21) nearphrases ::= nearphrases phrase *//* (20) nearphrases ::= phrase *//* (19) nearset ::= STRING LP nearphrases neardist_opt RP *//* (18) nearset ::= CARET phrase *//* (17) nearset ::= phrase *//* (16) cnearset ::= colset COLON nearset *//* (15) cnearset ::= nearset *//* (14) exprlist ::= exprlist cnearset *//* (13) exprlist ::= cnearset *//* (12) expr ::= exprlist *//* (11) expr ::= LP expr RP *//* (10) expr ::= colset COLON LP expr RP *//* (9) expr ::= expr NOT expr *//* (8) expr ::= expr OR expr *//* (7) expr ::= expr AND expr *//* (6) colsetlist ::= STRING *//* (5) colsetlist ::= colsetlist STRING *//* (4) colset ::= MINUS STRING *//* (3) colset ::= STRING *//* (2) colset ::= LCP colsetlist RCP *//* (1) colset ::= MINUS LCP colsetlist RCP *//* (0) input ::= expr *//* For rule J, fts5yyRuleInfoNRhs[J] contains the negative of the number
** of symbols on the right-hand side of that rule. *//* For rule J, fts5yyRuleInfoLhs[J] contains the symbol on the left-hand side
** of that rule *//* The minor token to shift in *//* The major token to shift in *//* The new state to shift in *//* The parser to be shifted *//*
** Perform a shift action.
*//*
** Print tracing information for a SHIFT action
*//* Suppress warning about unused %extra_argument var *//******** End %stack_overflow code ********************************************//******** Begin %stack_overflow code ******************************************//* Here code is inserted which will execute if the parser
   ** stack every overflows *//*
** The following routine is called if the stack overflows.
*//* The look-ahead token *//* Current state number *//*
** Find the appropriate action for a parser given the non-terminal
** look-ahead token iLookAhead.
*//* fts5YYWILDCARD *//* Fallback loop must terminate *//* Fallback token *//*
** Find the appropriate action for a parser given the terminal
** look-ahead token iLookAhead.
*//*
** Write into out a description of every state/lookahead combination that
**
**   (1)  has not been used by the parser, and
**   (2)  is not a syntax error.
**
** Return the number of missed state/lookahead combinations.
*//* This array of booleans keeps track of the parser statement
** coverage.  The element fts5yycoverage[X][Y] is set when the parser
** is in state X and has a lookahead token Y.  In a well-tested
** systems, every element of this matrix should end up being set.
*//*
** Return the peak depth of the stack for a parser.
*//* sqlite3Fts5Parser_ENGINEALWAYSONSTACK *//* Function used to reclaim memory *//* The parser to be deleted *//*
** Deallocate and destroy a parser.  Destructors are called for
** all stack elements before shutting the parser down.
**
** If the fts5YYPARSEFREENEVERNULL macro exists (for example because it
** is defined in a %include section of the input grammar) then it is
** assumed that the input pointer is never NULL.
*//* In-lined version of calling fts5yy_pop_parser_stack() for each
  ** element left in the stack *//*
** Clear all secondary memory allocations from the parser
*//*
** Pop the parser's stack once.
**
** If there is a destructor routine associated with the token which
** is popped from the stack, then call it.
*//* If no destructor action specified: do nothing *//********* End destructor definitions *****************************************//* phrase *//* nearphrases *//* nearset *//* colsetlist *//* colset *//* exprlist *//* cnearset *//* expr *//* input *//********* Begin destructor definitions ***************************************//* Here is inserted the actions which take place when a
    ** terminal or non-terminal is destroyed.  This can happen
    ** when the symbol is popped from the stack during a
    ** reduce or during error processing or when a parser is
    ** being destroyed before it is finished parsing.
    **
    ** Note: during a reduce, the only symbols destroyed are those
    ** which appear on the RHS of the rule, but which are *not* used
    ** inside the C code.
    *//* The object to be destroyed *//* Type code for object to destroy *//* The following function deletes the "minor type" or semantic value
** associated with a symbol.  The symbol can be either a terminal
** or nonterminal. "fts5yymajor" is the symbol code, and "fts5yypminor" is
** a pointer to the value to be deleted.  The code used to do the
** deletions is derived from the %destructor and/or %token_destructor
** directives of the input grammar.
*//*
** This function allocates a new parser.
** The only argument is a pointer to a function which works like
** malloc.
**
** Inputs:
** A pointer to the function used to allocate memory.
**
** Outputs:
** A pointer to a parser.  This pointer is used in subsequent calls
** to sqlite3Fts5Parser and sqlite3Fts5ParserFree.
*//* Initialize a new parser that has already been allocated.
*//* Datatype of the argument to the memory allocated passed as the
** second argument to sqlite3Fts5ParserAlloc() below.  This can be changed by
** putting an appropriate #define in the %include section of the input
** grammar.
*//* For builds that do no have a growable stack, fts5yyGrowStack always
** returns an error.
*//* fts5YYGROWABLESTACK *//*
** Try to increase the size of the parser stack.  Return the number
** of errors.  Return 0 on success.
*//*  27 *//*  26 *//*  25 *//*  24 *//*  23 *//*  22 *//*  21 *//*  20 *//*  19 *//*  18 *//*  17 *//*  16 *//*  15 *//*  14 *//*  13 *//*  12 *//*  11 *//*  10 *//*   9 *//*   8 *//*   7 *//*   6 *//*   5 *//*   4 *//*   3 *//*   2 *//*   1 *//*   0 *//* For tracing reduce actions, the names of all rules are required.
*//* defined(fts5YYCOVERAGE) || !defined(NDEBUG) *//*   26 *//*   25 *//*   24 *//*   23 *//*   22 *//*   21 *//*   20 *//*   19 *//*   18 *//*   17 *//*   16 *//*   15 *//*   14 *//*   13 *//*   12 *//*   11 *//*   10 *//*    9 *//*    8 *//*    7 *//*    6 *//*    5 *//*    4 *//*    3 *//*    2 *//*    1 *//*    0 *//* For tracing shifts, the names of all terminals and nonterminals
** are required.  The following table supplies these names *//*
** Turn parser tracing on by giving a stream to which to write the trace
** and a prompt to preface each trace message.  Tracing is turned off
** by making either argument NULL
**
** Inputs:
** <ul>
** <li> A FILE* to which trace output should be written.
**      If NULL, then tracing is turned off.
** <li> A prefix string written at the beginning of every
**      line of trace output.  If NULL, then tracing is
**      turned off.
** </ul>
**
** Outputs:
** None.
*//* Initial stack space *//* The parser stack *//* Last entry in the stack *//* A place to hold %extra_context *//* A place to hold %extra_argument *//* Shifts left before out of the error *//* High-water mark of the stack *//* Pointer to top element of the stack *//* The state of the parser is completely contained in an instance of
** the following structure *//* The user-supplied minor token value.  This
                         ** is the value of the token  *//* The major token value.  This is the code
                         ** number for the token at this stack level *//* The state-number, or reduce action in SHIFTREDUCE *//* The following structure represents a single element of the
** parser's stack.  Information stored includes:
**
**   +  The state number for the parser at this level of the stack.
**
**   +  The value of the token stored at this level of the stack.
**      (In other words, the "major" token.)
**
**   +  The semantic value stored at this level of the stack.  This is
**      the information used by the action routines in the grammar.
**      It is sometimes called the "minor" token.
**
** After the "shift" half of a SHIFTREDUCE action, the stateno field
** actually contains the reduce action for the second half of the
** SHIFTREDUCE.
*//* fts5YYFALLBACK *//* The next table maps tokens (terminal symbols) into fallback tokens.
** If a construct like the following:
**
**      %fallback ID X Y Z.
**
** appears in the grammar, then ID becomes a fallback token for X, Y,
** and Z.  Whenever one of the tokens X, Y, or Z is input to the parser
** but it does not parse, the type of the token is changed to ID and
** the parse is retried before an error is thrown.
**
** This feature can be used, for example, to cause some keywords in a language
** to revert to identifiers if they keyword does not apply in the context where
** it appears.
*//********** End of lemon-generated parsing tables *****************************//*    30 *//*    20 *//*    10 *//*     0 *//*   120 *//*   110 *//*   100 *//*    90 *//*    80 *//*    70 *//*    60 *//*    50 *//*    40 *//* Next are the tables used to determine what action to take based on the
** current state and lookahead token.  These tables are used to implement
** functions that take a state number and lookahead value and return an
** action integer.
**
** Suppose the action integer is N.  Then the action is determined as
** follows
**
**   0 <= N <= fts5YY_MAX_SHIFT             Shift N.  That is, push the lookahead
**                                      token onto the stack and goto state N.
**
**   N between fts5YY_MIN_SHIFTREDUCE       Shift to an arbitrary state then
**     and fts5YY_MAX_SHIFTREDUCE           reduce by rule N-fts5YY_MIN_SHIFTREDUCE.
**
**   N == fts5YY_ERROR_ACTION               A syntax error has occurred.
**
**   N == fts5YY_ACCEPT_ACTION              The parser accepts its input.
**
**   N == fts5YY_NO_ACTION                  No such action.  Denotes unused
**                                      slots in the fts5yy_action[] table.
**
**   N between fts5YY_MIN_REDUCE            Reduce by rule N-fts5YY_MIN_REDUCE
**     and fts5YY_MAX_REDUCE
**
** The action table is constructed as a single large table named fts5yy_action[].
** Given state S and lookahead X, the action is computed as either:
**
**    (A)   N = fts5yy_action[ fts5yy_shift_ofst[S] + X ]
**    (B)   N = fts5yy_default[S]
**
** The (A) formula is preferred.  The B formula is used instead if
** fts5yy_lookahead[fts5yy_shift_ofst[S]+X] is not equal to X.
**
** The formulas above are for computing the action when the lookahead is
** a terminal symbol.  If the lookahead is a non-terminal (as occurs after
** a reduce action) then the fts5yy_reduce_ofst[] array is used in place of
** the fts5yy_shift_ofst[] array.
**
** The following are the tables generated in this section:
**
**  fts5yy_action[]        A single table containing all actions.
**  fts5yy_lookahead[]     A table containing the lookahead for each entry in
**                     fts5yy_action.  Used to detect hash collisions.
**  fts5yy_shift_ofst[]    For each state, the offset into fts5yy_action for
**                     shifting terminals.
**  fts5yy_reduce_ofst[]   For each state, the offset into fts5yy_action for
**                     shifting non-terminals after a reduce.
**  fts5yy_default[]       Default action for each state.
**
*********** Begin parsing tables **********************************************//* Need a minimum stack size *//* Guarantee a minimum number of initial stack slots.
*//* Macro to determine if stack space has the ability to grow using
** heap memory.
*//* Define the fts5yytestcase() macro to be a no-op if is not already defined
** otherwise.
**
** Applications can choose to define fts5yytestcase() in the %include section
** to a macro that can assist in verifying code coverage.  For production
** code the fts5yytestcase() macro should be turned off.  But it is useful
** for testing.
*//************* End control #defines *******************************************//************* Begin control #defines *****************************************//* The next sections is a series of control #defines.
** various aspects of the generated parser.
**    fts5YYCODETYPE         is the data type used to store the integer codes
**                       that represent terminal and non-terminal symbols.
**                       "unsigned char" is used if there are fewer than
**                       256 symbols.  Larger types otherwise.
**    fts5YYNOCODE           is a number of type fts5YYCODETYPE that is not used for
**                       any terminal or nonterminal symbol.
**    fts5YYFALLBACK         If defined, this indicates that one or more tokens
**                       (also known as: "terminal symbols") have fall-back
**                       values which should be used if the original symbol
**                       would not parse.  This permits keywords to sometimes
**                       be used as identifiers, for example.
**    fts5YYACTIONTYPE       is the data type used for "action codes" - numbers
**                       that indicate what to do in response to the next
**                       token.
**    sqlite3Fts5ParserFTS5TOKENTYPE     is the data type used for minor type for terminal
**                       symbols.  Background: A "minor type" is a semantic
**                       value associated with a terminal or non-terminal
**                       symbols.  For example, for an "ID" terminal symbol,
**                       the minor type might be the name of the identifier.
**                       Each non-terminal can have a different minor type.
**                       Terminal symbols all have the same minor type, though.
**                       This macros defines the minor type for terminal
**                       symbols.
**    fts5YYMINORTYPE        is the data type used for all minor types.
**                       This is typically a union of many types, one of
**                       which is sqlite3Fts5ParserFTS5TOKENTYPE.  The entry in the union
**                       for terminal symbols is called "fts5yy0".
**    fts5YYSTACKDEPTH       is the maximum depth of the parser's stack.  If
**                       zero the stack is dynamically sized using realloc()
**    sqlite3Fts5ParserARG_SDECL     A static variable declaration for the %extra_argument
**    sqlite3Fts5ParserARG_PDECL     A parameter declaration for the %extra_argument
**    sqlite3Fts5ParserARG_PARAM     Code to pass %extra_argument as a subroutine parameter
**    sqlite3Fts5ParserARG_STORE     Code to store %extra_argument into fts5yypParser
**    sqlite3Fts5ParserARG_FETCH     Code to extract %extra_argument from fts5yypParser
**    sqlite3Fts5ParserCTX_*         As sqlite3Fts5ParserARG_ except for %extra_context
**    fts5YYREALLOC          Name of the realloc() function to use
**    fts5YYFREE             Name of the free() function to use
**    fts5YYDYNSTACK         True if stack space should be extended on heap
**    fts5YYERRORSYMBOL      is the code number of the error symbol.  If not
**                       defined, then do no error processing.
**    fts5YYNSTATE           the combined number of states.
**    fts5YYNRULE            the number of rules in the grammar
**    fts5YYNFTS5TOKEN           Number of terminal symbols
**    fts5YY_MAX_SHIFT       Maximum value for shift actions
**    fts5YY_MIN_SHIFTREDUCE Minimum value for shift-reduce actions
**    fts5YY_MAX_SHIFTREDUCE Maximum value for shift-reduce actions
**    fts5YY_ERROR_ACTION    The fts5yy_action[] code for syntax error
**    fts5YY_ACCEPT_ACTION   The fts5yy_action[] code for accept
**    fts5YY_NO_ACTION       The fts5yy_action[] code for no-op
**    fts5YY_MIN_REDUCE      Minimum value for reduce actions
**    fts5YY_MAX_REDUCE      Maximum value for reduce actions
**    fts5YY_MIN_DSTRCTR     Minimum symbol value that has a destructor
**    fts5YY_MAX_DSTRCTR     Maximum symbol value that has a destructor
*//**************** End token definitions ***************************************//* These constants specify the various numeric values for terminal symbols.
***************** Begin token definitions *************************************//**************** End of %include directives **********************************//*
** Alternative datatype for the argument to the malloc() routine passed
** into sqlite3ParserAlloc().  The default is size_t.
*//*
** Indicate that sqlite3ParserFree() will never be called with a null
** pointer.
*//*
** Make fts5yytestcase() the same as testcase()
*//*
** Disable all error recovery processing in the parser push-down
** automaton.
*//************ Begin %include sections from the grammar ************************//*
** 2000-05-29
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** Driver template for the LEMON parser generator.
**
** The "lemon" program processes an LALR(1) input grammar file, then uses
** this template to construct a parser.  The "lemon" program inserts text
** at each "%%" line.  Also, any "P-a-r-s-e" identifer prefix (without the
** interstitial "-" characters) contained in this template is changed into
** the value of the %name directive from the grammar.  Otherwise, the content
** of this template is copied straight through into the generate parser
** source file.
**
** The following is the concatenation of all %include directives from the
** input grammar file:
*//* This file is automatically generated by Lemon from input grammar
** source file "fts5parse.y".
*//*
** End of interface to code in fts5_unicode2.c.
**************************************************************************//**************************************************************************
** Interface to automatically generated code in fts5_unicode2.c.
*//*
** End of interface to code in fts5_vocab.c.
**************************************************************************//**************************************************************************
** Interface to code in fts5_vocab.c.
*//*
** End of interface to code in fts5_tokenizer.c.
**************************************************************************//**************************************************************************
** Interface to code in fts5_tokenizer.c.
*//*
** End of interface to code in fts5_aux.c.
**************************************************************************//**************************************************************************
** Interface to code in fts5_aux.c.
*//*
** End of interface to code in fts5_expr.c.
**************************************************************************//*******************************************
** The fts5_expr.c API above this point is used by the other hand-written
** C code in this module. The interfaces below this point are called by
** the parser code in fts5parse.y.  *//* Called during startup to register a UDF with SQLite *//*
** for(rc = sqlite3Fts5ExprFirst(pExpr, pIdx, bDesc);
**     rc==SQLITE_OK && 0==sqlite3Fts5ExprEof(pExpr);
**     rc = sqlite3Fts5ExprNext(pExpr)
** ){
**   // The document with rowid iRowid matches the expression!
**   i64 iRowid = sqlite3Fts5ExprRowid(pExpr);
** }
*//* Parse a MATCH expression. *//* Size of buffer p in bytes *//* Token text (not NULL terminated) *//**************************************************************************
** Interface to code in fts5_expr.c.
*//*
** End of interface to code in fts5_storage.c.
**************************************************************************//* SELECT rowid, * FROM ... WHERE rowid=? *//* SELECT rowid, * FROM ... ORDER BY 1 DESC *//* SELECT rowid, * FROM ... ORDER BY 1 ASC *//**************************************************************************
** Interface to code in fts5_storage.c. fts5_storage.c contains contains
** code to access the data stored in the %_content and %_docsize tables.
*//*
** End of interface to code in fts5_hash.c.
**************************************************************************//* OUT: Pointer to doclist for pTerm *//*
** Return true if the hash is empty, false otherwise.
*//*
** Create a hash table, free a hash table.
*//**************************************************************************
** Interface to code in fts5_hash.c.
*//*
** End of interface to code in fts5.c.
**************************************************************************//* Full-text index *//*
** Virtual-table object.
*//**************************************************************************
** Interface to code in fts5_main.c.
*//*
** End of interface to code in fts5_varint.c.
**************************************************************************//**************************************************************************
** Interface to code in fts5_varint.c.
*//*
** End of interface to code in fts5_index.c.
**************************************************************************//* Used to populate hash tables for xInstToken in detail=none/column mode. *//*
** Return the total number of entries read from the %_data table by
** this connection since it was created.
*//*
** Called during virtual module initialization to register UDF
** fts5_decode() with SQLite
*//*
** Functions called by the storage module as part of integrity-check.
*//*
** Get or set the "averages" values.
*//*
** Flush any data stored in the in-memory hash tables to the database.
** Also close any open blob handles.
*//* Docid to add or remove data from *//* True if current operation is a delete *//*
** Indicate that subsequent calls to sqlite3Fts5IndexWrite() pertain to
** document iDocid.
*//*
** Used by xInstToken():
*//*
** This interface is used by the fts5vocab module.
*//*
** Close the reader blob handle, if it is open.
*//*
** Close an iterator opened by sqlite3Fts5IndexQuery().
*//*
** The various operations on open token or token prefix iterators opened
** using sqlite3Fts5IndexQuery().
*//*
** Open a new iterator to iterate though all rowids that match the
** specified token or token prefix.
*//*
** Create/destroy an Fts5Index object.
*//* The following are used internally by the fts5_index.c module. They are
** defined here only to make it easier to avoid clashes with the flags
** above. *//* Scan query (fts5vocab) *//* Do not use prefix index *//* Docs in descending rowid order *//* Prefix query *//*
** Values used as part of the flags argument passed to IndexQuery().
*//**************************************************************************
** Interface to code in fts5_index.c. fts5_index.c contains contains code
** to access the data stored in the %_data table.
*//*
** End of interface to code in fts5_buffer.c.
**************************************************************************//* Bucket of terms object used by the integrity-check in offsets=0 mode. *//* Character set tests (like isspace(), isalpha() etc.) *//* Malloc utility *//* (iCol<<32) + iPos *//* Set to true at EOF *//* For client use (any custom purpose) *//* Current offset in a[] *//* Size of buffer at a[] in bytes *//* Position list to iterate through *//* Variables used only by sqlite3Fts5PoslistIterXXX() functions. *//* Write and decode big-endian 32-bit integer values *//*
** Buffer object for the incremental building of string data.
*//**************************************************************************
** Interface to code in fts5_buffer.c.
*//*
** End of interface to code in fts5_config.c.
**************************************************************************//* Set the value of a single config attribute *//* Load the contents of the %_config table *//* matches SQLITE_INDEX_CONSTRAINT_GLOB *//* matches SQLITE_INDEX_CONSTRAINT_LIKE *//* Current expected value of %_config table 'version' field. And
** the expected version if the 'secure-delete' option has ever been
** set on the table.  *//* True to use prefix-indexes *//* If non-NULL, points to sqlite3_vtab.base.zErrmsg. Often NULL. *//* 'prefix-insttoken' *//* 'deletemerge' *//* 'secure-delete' *//* Arguments to rank function *//* Name of rank function *//* Bytes of memory for in-memory hash *//* 'usermerge' setting *//* Maximum allowed segments per level *//* 'automerge' setting *//* Approximate page size used in %_data *//* Incremented when %_config is modified *//* fts5 file format 'version' *//* Values loaded from the %_config table *//* True when table is preparing statement *//* FTS5_DETAIL_XXX value *//* "locale=" option value (dflt==0) *//* "tokendata=" option value (dflt==0) *//* "columnsize=" option value (dflt==1) *//* "content_rowid=" option value *//* content table *//* "contentless_unindexed=" option (dflt=0) *//* "contentless_delete=" option (dflt==0) *//* An FTS5_CONTENT value *//* Sizes in bytes of nPrefix prefix indexes *//* Number of prefix indexes *//* True for unindexed columns *//* Number of columns *//* Name of FTS index *//* Database holding FTS index (e.g. "main") *//* Global fts5 object for handle db *//*
** An instance of the following structure encodes all information that can
** be gleaned from the CREATE VIRTUAL TABLE statement.
**
** And all information loaded from the %_config table.
**
** nAutomerge:
**   The minimum number of segments that an auto-merge operation should
**   attempt to merge together. A value of 1 sets the object to use the
**   compile time default. Zero disables auto-merge altogether.
**
** bContentlessDelete:
**   True if the contentless_delete option was present in the CREATE
**   VIRTUAL TABLE statement.
**
** zContent:
**
** zContentRowid:
**   The value of the content_rowid= option, if one was specified. Or
**   the string "rowid" otherwise. This text is not quoted - if it is
**   used as part of an SQL statement it needs to be quoted appropriately.
**
** zContentExprlist:
**
** pzErrmsg:
**   This exists in order to allow the fts5_index.c module to return a
**   decent error message if it encounters a file-format version it does
**   not understand.
**
** bColumnsize:
**   True if the %_docsize table is created.
**
** bPrefixIndex:
**   This is only used for debugging. If set to false, any prefix indexes
**   are ignored. This value is configured using:
**
**       INSERT INTO tbl(tbl, rank) VALUES('prefix-index', $bPrefixIndex);
**
** bLocale:
**   Set to true if locale=1 was specified when the table was created.
*//* Size of pLocale in bytes *//* Current locale to use *//* FTS_PATTERN_XXX constant *//**************************************************************************
** Interface to code in fts5_config.c. fts5_config.c contains contains code
** to parse the arguments passed to the CREATE VIRTUAL TABLE statement.
*//* If a NEAR() clump or phrase may only match a specific set of columns,
** then an object of the following type is used to record the set of columns.
** Each entry in the aiCol[] array is a column that may be matched.
**
** This object is used by fts5_expr.c and fts5_index.c.
*//*
** A version of memcmp() that does not cause asan errors if one of the pointer
** parameters is NULL and the number of bytes to compare is zero.
*//*
** The assert_nc() macro is similar to the assert() macro, except that it
** is used for assert() conditions that are true only if it can be
** guranteed that the database is not corrupt.
*//* Name of rank and rowid columns *//*
** Maximum segments permitted in a single index
*//*
** Maximum number of prefix indexes on single FTS5 table. This must be
** less than 32. If it is set to anything large than that, an #error
** directive in fts5_index.c will cause the build to fail.
*//* Truncate very long tokens to this many bytes. Hard limit is
** (65536-1-1-4-9)==65521 bytes. The limiting factor is the 16-bit offset
** field that occurs at the start of each leaf page (see fts5_index.c). *//* The uptr type is an unsigned integer large enough to hold a pointer
*//*
** Constants for the largest and smallest possible 64-bit signed integers.
*//* #include "fts5.h" *//* #include <inttypes.h> *//* #include <stdint.h> *//*
** This, the "fts5.c" source file, is a composite file that is itself
** assembled from the following files:
**
**    fts5.h
**    fts5Int.h
**    fts5parse.h          <--- Generated from fts5parse.y by Lemon
**    fts5parse.c          <--- Generated from fts5parse.y by Lemon
**    fts5_aux.c
**    fts5_buffer.c
**    fts5_config.c
**    fts5_expr.c
**    fts5_hash.c
**    fts5_index.c
**    fts5_main.c
**    fts5_storage.c
**    fts5_tokenize.c
**    fts5_unicode2.c
**    fts5_varint.c
**    fts5_vocab.c
*//************** Begin file fts5.c ********************************************//************** End of sqlite3session.c **************************************//* SQLITE_ENABLE_SESSION && SQLITE_ENABLE_PREUPDATE_HOOK *//*
** Global configuration
*//*
** Destroy a rebaser object
*//* Iterator to skip through input *//*
** Rebase a changeset according to current rebaser configuration
*//* Iterator opened on pData/nData *//*
** Call this one or more times to configure a rebaser.
*//*
** Create a new rebaser object.
*//* Append a table header to the output for this new table *//* A patchset may not be rebased *//* OUT: Inverse of pChangeset *//* Context for xOutput callback *//* Input data *//* Rebaser hash table *//*
** pIter is configured to iterate through a changeset. This function rebases
** that changeset according to the current configuration of the rebaser
** object passed as the first argument. If no error occurs and argument xOutput
** is not NULL, then the changeset is returned to the caller by invoking
** xOutput zero or more times and SQLITE_OK returned. Or, if xOutput is NULL,
** then (*ppOut) is set to point to a buffer containing the rebased changeset
** before this function returns. In this case (*pnOut) is set to the size of
** the buffer in bytes.  It is the responsibility of the caller to eventually
** free the (*ppOut) buffer using sqlite3_free().
**
** If an error occurs, an SQLite error code is returned. If ppOut and
** pnOut are not NULL, then the two output parameters are set to 0 before
** returning.
*//* IN/OUT: Return Code *//* Record to rebase against *//* Local change *//* Iterator pointed at local change *//* Append record here *//*
** This function is called when rebasing a local UPDATE change against one
** or more remote UPDATE changes. The aRec/nRec buffer contains the current
** old.* and new.* records for the change. The rebase buffer (a single
** record) is in aChange/nChange. The rebased change is appended to buffer
** pBuf.
**
** Rebasing the UPDATE involves:
**
**   * Removing any changes to fields for which the corresponding field
**     in the rebase buffer is set to "replaced" (type 0xFF). If this
**     means the UPDATE change updates no fields, nothing is appended
**     to the output buffer.
**
**   * For each field modified by the local change for which the
**     corresponding field in the rebase buffer is not "undefined" (0x00)
**     or "replaced" (0xFF), the old.* value is replaced by the value
**     in the rebase buffer.
*//* Record 2 *//* Record 1 *//* Number of columns in each record *//* Buffer to append to *//*
** Buffers a1 and a2 must both contain a sessions module record nCol
** fields in size. This function appends an nCol sessions module
** record to buffer pBuf that is a copy of a1, except that for
** each field that is undefined in a1[], swap in the field from a2[].
*//* Hash table *//*
** Changeset rebaser handle.
*//*
** Streaming version of sqlite3changeset_concat().
*//* OUT: changeset (left <concat> right) *//* Rhs input changeset *//* Number of bytes in rhs input *//* Lhs input changeset *//* Number of bytes in lhs input *//*
** Combine two changesets together.
*//*
** Delete a changegroup object.
*//*
** Streaming versions of changegroup_output().
*//*
** Streaming versions of changegroup_add().
*//*
** Obtain a buffer containing a changeset representing the concatenation
** of all changesets added to the group so far.
*//* Iterator does not point to any valid entry or is an INVERT iterator. *//*
** Add a single change to a changeset-group.
*//*
** Add the changeset currently stored in buffer pData, size nData bytes,
** to changeset-group p.
*//* Cannot add a schema after one or more calls to sqlite3changegroup_add(),
    ** or after sqlite3changegroup_schema() has already been called. *//*
** Provide a database schema to the changegroup object.
*//*
** Allocate a new, empty, sqlite3_changegroup.
*//* Create the serialized output changeset based on the contents of the
  ** hash tables attached to the SessionTable objects in list p->pList.
  *//*
** Serialize a changeset (or patchset) based on all changesets (or patchsets)
** added to the changegroup object passed as the first argument.
**
** If xOutput is not NULL, then the changeset/patchset is returned to the
** user via one or more calls to xOutput, as with the other streaming
** interfaces.
**
** Or, if xOutput is NULL, then (*ppOut) is populated with a pointer to a
** buffer containing the output changeset before this function returns. In
** this case (*pnOut) is set to the size of the output buffer in bytes. It
** is the responsibility of the caller to free the output buffer using
** sqlite3_free() when it is no longer required.
**
** If successful, SQLITE_OK is returned. Or, if an error occurs, an SQLite
** error code. If an error occurs and xOutput is NULL, (*ppOut) and (*pnOut)
** are both set to 0 before returning.
*//* True if hash table is for rebasing *//* Changegroup object to add changeset to *//* Iterator to read from *//*
** Add all changes in the changeset traversed by the iterator passed as
** the first argument to the changegroup hash tables.
*//* Search for existing entry. If found, remove it from the hash table.
    ** Code below may link it back in.  *//* Ensure that only changesets, or only patchsets, but not a mixture
  ** of both, are being combined. It is an error to try to combine a
  ** changeset and a patchset.  *//*
** Add the change currently indicated by iterator pIter to the hash table
** belonging to changegroup pGrp.
*//* Check that the table is compatible. *//* The new object must be linked on to the end of the list, not
    ** simply added to the start of it. This is to ensure that the
    ** tables within the output of sqlite3changegroup_output() are in
    ** the right order.  *//* If one was not found above, create a new table now *//* Search the list for an existing table *//*
** Locate or create a SessionTable object that may be used to add the
** change currently pointed to by iterator pIter to changegroup pGrp.
** If successful, set output variable (*ppTab) to point to the table
** object and return SQLITE_OK. Otherwise, if some error occurs, return
** an SQLite error code and leave (*ppTab) set to NULL.
*//* Append missing "undefined" entries to the old.* record. And, if this
    ** is an UPDATE, to the new.* record as well.  *//* Append the missing default column values to the record. *//*
** Check if a changeset entry with nCol columns and the PK array passed
** as the final argument to this function is compatible with SessionTable
** pTab. If so, return 1. Otherwise, if they are incompatible in some way,
** return 0.
*//* UPDATE + DELETE *//* UPDATE + UPDATE *//* DELETE + INSERT *//* INSERT + UPDATE *//* Allocate a new SessionChange object. Ensure that the aRecord[]
      ** buffer of the new object is large enough to hold any record that
      ** may be generated by combining the input records.  *//*
    **   op1=INSERT, op2=INSERT      ->      Unsupported. Discard op2.
    **   op1=INSERT, op2=UPDATE      ->      INSERT.
    **   op1=INSERT, op2=DELETE      ->      (none)
    **
    **   op1=UPDATE, op2=INSERT      ->      Unsupported. Discard op2.
    **   op1=UPDATE, op2=UPDATE      ->      UPDATE.
    **   op1=UPDATE, op2=DELETE      ->      DELETE.
    **
    **   op1=DELETE, op2=INSERT      ->      UPDATE.
    **   op1=DELETE, op2=UPDATE      ->      Unsupported. Discard op2.
    **   op1=DELETE, op2=DELETE      ->      Unsupported. Discard op2.
    *//* OUT: Merged change *//* Number of bytes in aRec *//* Second change record *//* True if second change is indirect *//* Second change operation *//* Existing change *//* True for patchsets *//* True for a rebase hash-table *//* Table structure *//*
** This function is called to merge two changes to the same row together as
** part of an sqlite3changeset_concat() operation. A new change object is
** allocated and a pointer to it stored in *ppNew.
*//* Configured by changegroup_schema() *//* List of tables in current patch *//* True to accumulate patchsets *//*
** sqlite3_changegroup handle.
*//* Iterator to skip through changeset *//*
** Apply the changeset passed via xInput/pIn to the main database
** attached to handle "db". Invoke the supplied conflict handler callback
** to resolve any conflicts encountered while applying the change.
*//* Copy of fifth arg to _apply() *//*
** Apply the changeset passed via pChangeset/nChangeset to the main database
** attached to handle "db". Invoke the supplied conflict handler callback
** to resolve any conflicts encountered while applying the change.
*//*
** Apply the changeset passed via pChangeset/nChangeset to the main
** database attached to handle "db".
*//* cast works around VC++ bug *//* If there is a schema mismatch on the current table, proceed to the
    ** next change. A log message has already been issued. *//* If an xFilter() callback was specified, invoke it now. If the
      ** xFilter callback returns zero, skip this table. If it returns
      ** non-zero, proceed. *//* changeset_apply() context object *//* Result of sqlite3Strlen30(zTab) *//* Name of current table *//* SESSION_APPLY_XXX flags *//* OUT: Rebase information *//* Changeset to apply *//*
** Argument pIter is a changeset iterator that has been initialized, but
** not yet passed to sqlite3changeset_next(). This function applies the
** changeset to the main database attached to handle "db". The supplied
** conflict handler callback is invoked to resolve any conflicts encountered
** while applying the change.
*//* No progress was made on the last round. *//*
** Retry the changes accumulated in the pApply->constraints buffer.
*//* If the bReplace flag is set, the change is an INSERT that has not
    ** been performed because the database already contains a row with the
    ** specified primary key and the conflict handler returned
    ** SQLITE_CHANGESET_REPLACE. In this case remove the conflicting row
    ** before reattempting the INSERT.  *//* If the bRetry flag is set, the change has not been applied due to an
    ** SQLITE_CHANGESET_DATA problem (i.e. this is an UPDATE or DELETE and
    ** a row with the correct PK is present in the db, but one or more other
    ** fields do not contain the expected values) and the conflict handler
    ** returned SQLITE_CHANGESET_REPLACE. In this case retry the operation,
    ** but pass NULL as the final argument so that sessionApplyOneOp() ignores
    ** the SQLITE_CHANGESET_DATA problem.  *//* Apply context *//* Changeset iterator to read change from *//*
** Attempt to apply the change that the iterator passed as the first argument
** currently points to to the database. If a conflict is encountered, invoke
** the conflict handler callback.
**
** The difference between this function and sessionApplyOne() is that this
** function handles the case where the conflict-handler is invoked and
** returns SQLITE_CHANGESET_REPLACE - indicating that the change should be
** retried in some manner.
*//* Check if there is a conflicting row. For sqlite_stat1, this needs
      ** to be done using a SELECT, as there is no PRIMARY KEY in the
      ** database schema to throw an exception if a duplicate is inserted.  *//* This is always a CONSTRAINT conflict. *//* A NOTFOUND or DATA error. Search the table to see if it contains
      ** a row with a matching primary key. If so, this is a DATA conflict.
      ** Otherwise, if there is no primary key match, it is a NOTFOUND. *//* Attempt the UPDATE. In the case of a NOTFOUND or DATA conflict,
    ** the result will be SQLITE_OK with 0 rows modified. *//* Bind values to the UPDATE statement. *//* Bind values to the DELETE statement. If conflict handling is required,
    ** bind values for all columns and set bound variable (nCol+1) to true.
    ** Or, if conflict handling is not required, bind just the PK column
    ** values and, if it exists, set (nCol+1) to false. Conflict handling
    ** is not required if:
    **
    **   * this is a patchset, or
    **   * (pbRetry==0), or
    **   * all columns of the table are PK columns (in this case there is
    **     no (nCol+1) variable to bind to).
    *//* OUT: True to retry. *//* OUT: True to remove PK row and retry *//* First argument for the conflict handler *//* changeset_apply() context *//*
** Attempt to apply the change that the iterator passed as the first argument
** currently points to to the database. If a conflict is encountered, invoke
** the conflict handler callback.
**
** If argument pbRetry is NULL, then ignore any CHANGESET_DATA conflict. If
** one is encountered, update or delete the row with the matching primary key
** instead. Or, if pbRetry is not NULL and a CHANGESET_DATA conflict occurs,
** invoke the conflict handler. If it returns CHANGESET_REPLACE, set *pbRetry
** to true before returning. In this case the caller will invoke this function
** again, this time with pbRetry set to NULL.
**
** If argument pbReplace is NULL and a CHANGESET_CONFLICT conflict is
** encountered invoke the conflict handler with CHANGESET_CONSTRAINT instead.
** Or, if pbReplace is not NULL, invoke it with CHANGESET_CONFLICT. If such
** an invocation returns SQLITE_CHANGESET_REPLACE, set *pbReplace to true
** before retrying. In this case the caller attempts to remove the conflicting
** row before invoking this function again, this time with pbReplace set
** to NULL.
**
** If any conflict handler returns SQLITE_CHANGESET_ABORT, this function
** returns SQLITE_ABORT. Otherwise, if no error occurs, SQLITE_OK is
** returned.
*//* No other row with the new.* primary key. *//* Instead of invoking the conflict handler, append the change blob
      ** to the SessionApplyCtx.constraints buffer. *//* There exists another row with the new.* primary key. *//* Bind the new.* PRIMARY KEY values to the SELECT statement. *//* Value returned by conflict handler *//* OUT: Set to true if PK row is found *//* First argument for conflict handler *//* Either CHANGESET_DATA or CONFLICT *//*
** Invoke the conflict handler for the change that the changeset iterator
** currently points to.
**
** Argument eType must be either CHANGESET_DATA or CHANGESET_CONFLICT.
** If argument pbReplace is NULL, then the type of conflict handler invoked
** depends solely on eType, as follows:
**
**    eType value                 Value passed to xConflict
**    -------------------------------------------------
**    CHANGESET_DATA              CHANGESET_NOTFOUND
**    CHANGESET_CONFLICT          CHANGESET_CONSTRAINT
**
** Or, if pbReplace is not NULL, then an attempt is made to find an existing
** record with the same primary key as the record about to be deleted, updated
** or inserted. If such a record can be found, it is available to the conflict
** handler as the "conflicting" record. In this case the type of conflict
** handler invoked is as follows:
**
**    eType value         PK Record found?   Value passed to xConflict
**    ----------------------------------------------------------------
**    CHANGESET_DATA      Yes                CHANGESET_DATA
**    CHANGESET_DATA      No                 CHANGESET_NOTFOUND
**    CHANGESET_CONFLICT  Yes                CHANGESET_CONFLICT
**    CHANGESET_CONFLICT  No                 CHANGESET_CONSTRAINT
**
** If pbReplace is not NULL, and a record with a matching PK is found, and
** the conflict handler function returns SQLITE_CHANGESET_REPLACE, *pbReplace
** is set to non-zero before returning SQLITE_OK.
**
** If the conflict handler returns SQLITE_CHANGESET_ABORT, SQLITE_ABORT is
** returned. Or, if the conflict handler returns an invalid value,
** SQLITE_MISUSE. If the conflict handler returns SQLITE_CHANGESET_OMIT,
** this function returns SQLITE_OK.
*//* Append a table-header to the rebase buffer *//* Iterator pointing at current change *//* Conflict resolution (OMIT or REPLACE) *//*
** This function is called from within sqlite3changeset_apply_v2() when
** a conflict is encountered and resolved using conflict resolution
** mode eType (either SQLITE_CHANGESET_OMIT or SQLITE_CHANGESET_REPLACE)..
** It adds a conflict resolution record to the buffer in
** SessionApplyCtx.rebase, which will eventually be returned to the caller
** of apply_v2() as the "rebase" buffer.
**
** Return SQLITE_OK if successful, or an SQLite error code otherwise.
*//* Changset operation (SQLITE_UPDATE etc.) *//*
** SQL statement pSelect is as generated by the sessionSelectRow() function.
** This function binds the primary key values from the change that changeset
** iterator pIter points to to the SELECT and attempts to seek to the table
** entry. If a row is found, the SELECT statement left pointing at the row
** and SQLITE_ROW is returned. Otherwise, if no row is found and no error
** has occured, the statement is reset and SQLITE_OK is returned. If an
** error occurs, the statement is reset and an SQLite error code is returned.
**
** If this function returns SQLITE_ROW, the caller must eventually reset()
** statement pSelect. If any other value is returned, the statement does
** not require a reset().
**
** If the iterator currently points to an INSERT record, bind values from the
** new.* record to the SELECT statement. Or, if it points to a DELETE or
** UPDATE, bind values from the old.* record.
*//* The value in the changeset was "undefined". This indicates a
        ** corrupt changeset blob.  *//* Neither sqlite3changeset_old or sqlite3changeset_new can fail if the
  ** argument iterator points to a suitable entry. Make sure that xValue
  ** is one of these to guarantee that it is safe to ignore the return
  ** in the code below. *//* Bind values to this statement *//* If not NULL, bind only if true *//* Iterator to read values from *//*
** Iterator pIter must point to an SQLITE_INSERT entry. This function
** transfers new.* values from the current iterator entry to statement
** pStmt. The table being inserted into has nCol columns.
**
** New.* value $i from the iterator is bound to variable ($i+1) of
** statement pStmt. If parameter abPK is NULL, all values from 0 to (nCol-1)
** are transfered to the statement. Otherwise, if abPK is not NULL, it points
** to an array nCol elements in size. In this case only those values for
** which abPK[$i] is true are read from the iterator and bound to the
** statement.
**
** An SQLite error code is returned if an error occurs. Otherwise, SQLITE_OK.
*//* This condition occurs when an earlier OOM in a call to
    ** sqlite3_value_text() or sqlite3_value_blob() (perhaps from within
    ** a conflict-handler) has zeroed the pVal->z pointer. Return NOMEM. *//* COVERAGE: The (pVal->z==0) branch is never true using current versions
  ** of SQLite. If a malloc fails in an sqlite3_value_xxx() function, either
  ** the (pVal->z) variable remains as it was or the type of the value is
  ** set to SQLITE_NULL.  *//* Value to bind *//* Parameter number to bind to *//* Statement to bind value to *//*
** A wrapper around sqlite3_bind_value() that detects an extra problem.
** See comments in the body of this function for details.
*//*
** Prepare statements for applying changes to the sqlite_stat1 table.
** These are similar to those created by sessionSelectRow(),
** sessionInsertRow(), sessionUpdateRow() and sessionDeleteRow() for
** other tables.
*//* Session changeset-apply context *//*
** Formulate and prepare an INSERT statement to add a record to table zTab.
** For example:
**
**     INSERT INTO main."zTab" VALUES(?1, ?2, ?3 ...);
**
** If successful, SQLITE_OK is returned and SessionApplyCtx.pInsert is left
** pointing to the prepared version of the SQL statement.
*//* TODO *//*
** Formulate and prepare an SQL statement to query table zTab by primary
** key. Assuming the following table structure:
**
**     CREATE TABLE x(a, b, c, d, PRIMARY KEY(a, c));
**
** The SELECT statement looks like this:
**
**     SELECT * FROM x WHERE a = ?1 AND c = ?3
**
** If successful, SQLITE_OK is returned and SessionApplyCtx.pSelect is left
** pointing to the prepared version of the SQL statement.
*//*
** Formulate a statement to DELETE a row from database db. Assuming a table
** structure like this:
**
**     CREATE TABLE x(a, b, c, d, PRIMARY KEY(a, c));
**
** The DELETE statement looks like this:
**
**     DELETE FROM x WHERE a = :1 AND c = :3 AND (:5 OR b IS :2 AND d IS :4)
**
** Variable :5 (nCol+1) is a boolean. It should be set to 0 if we require
** matching b and d values, or 1 otherwise. The second case comes up if the
** conflict handler is invoked with NOTFOUND and returns CHANGESET_REPLACE.
**
** If successful, SQLITE_OK is returned and SessionApplyCtx.pDelete is left
** pointing to the prepared version of the SQL statement.
*//*
** Free all cached UPDATE statements.
*//* Create the WHERE clause part of the UPDATE *//* Create the assignments part of the UPDATE *//*
** Find a prepared UPDATE statement suitable for the UPDATE step currently
** being visited by the iterator. The UPDATE is of the form:
**
**   UPDATE tbl SET col = ?, col2 = ? WHERE pk1 IS ? AND pk2 IS ?
*//* Number of prepared UPDATE statements to cache. *//* True to ignore no-op conflicts *//* True to collect rebase information *//* If table header is already in rebase *//* Rebase information (if any) here *//* Deferred constraints are stored here *//* Invert when iterating constraints buffer *//* True to defer constraints *//* True if table is sqlite_stat1 *//* Used by sessionUpdateFind *//* Boolean array - true if column is in PK *//* Array of column names *//* Size of azCol[] and abPK[] arrays *//* SELECT statement *//* INSERT statement *//* DELETE statement *//* Set up the input stream *//*
** Streaming version of sqlite3changeset_invert().
*//* Number of bytes in input *//*
** Invert a changeset object.
*//* Write the new new.* record. Consists of a copy of all values
        ** from the original old.* record, except for the PK columns, which
        ** are set to "undefined". *//* Write the new old.* record. Consists of the PK columns from the
        ** original old.* record, and the other values from the original
        ** new.* record. *//* Read the old.* and new.* records for the update change. *//* Write the header for the new UPDATE change. Same as the original. *//* A 'table' record consists of:
        **
        **   * A constant 'T' character,
        **   * Number of columns in said table (a varint),
        **   * An array of nCol bytes (sPK),
        **   * A nul-terminated table name.
        *//* Test for EOF. *//* Zero the output variables in case an error occurs. *//* Initialize the output buffer *//* PK array for current table *//* Space for values for UPDATE inversion *//* Number of cols in current table *//* Return value *//* Used to iterate through p->apValue[] *//*
** Finalize an iterator allocated with sqlite3changeset_start().
**
** This function may not be called on iterators passed to a conflict handler
** callback by changeset_apply().
*//*
** This function may only be called with an iterator passed to an
** SQLITE_CHANGESET_FOREIGN_KEY conflict handler callback. In this case
** it sets the output variable to the total number of known foreign key
** violations in the destination database and returns SQLITE_OK.
**
** In all other cases this function returns SQLITE_MISUSE.
*//* Index of conflict record value to fetch *//*
** This function may only be called with a changeset iterator that has been
** passed to an SQLITE_CHANGESET_DATA or SQLITE_CHANGESET_CONFLICT
** conflict-handler function. Otherwise, SQLITE_MISUSE is returned.
**
** If successful, *ppValue is set to point to an sqlite3_value structure
** containing the iVal'th value of the conflicting record.
**
** If value iVal is out-of-range or some other error occurs, an SQLite error
** code is returned. Otherwise, SQLITE_OK.
*//*
** The following two macros are used internally. They are similar to the
** sqlite3changeset_new() and sqlite3changeset_old() functions, except that
** they omit all error checking and return a pointer to the requested value.
*//* Index of new.* value to retrieve *//*
** This function may only be called while the iterator is pointing to an
** SQLITE_UPDATE or SQLITE_INSERT change (see sqlite3changeset_op()).
** Otherwise, SQLITE_MISUSE is returned.
**
** It sets *ppValue to point to an sqlite3_value structure containing the
** iVal'th value in the new.* record. Or, if that particular value is not
** included in the record (because the change is an UPDATE and the field
** was not modified), set *ppValue to NULL.
**
** If value iVal is out-of-range, SQLITE_RANGE is returned and *ppValue is
** not modified. Otherwise, SQLITE_OK.
*//* Index of old.* value to retrieve *//*
** This function may only be called while the iterator is pointing to an
** SQLITE_UPDATE or SQLITE_DELETE change (see sqlite3changeset_op()).
** Otherwise, SQLITE_MISUSE is returned.
**
** It sets *ppValue to point to an sqlite3_value structure containing the
** iVal'th value in the old.* record. Or, if that particular value is not
** included in the record (because the change is an UPDATE and the field
** was not modified and is not a PK column), set *ppValue to NULL.
**
** If value iVal is out-of-range, SQLITE_RANGE is returned and *ppValue is
** not modified. Otherwise, SQLITE_OK.
*//*
** Return information regarding the PRIMARY KEY and number of columns in
** the database table affected by the change that pIter currently points
** to. This function may only be called after changeset_next() returns
** SQLITE_ROW.
*//* OUT: True if change is indirect *//* Iterator handle *//*
** The following function extracts information on the current change
** from a changeset iterator. It may only be called after changeset_next()
** has returned SQLITE_ROW.
*//*
** Advance an iterator created by sqlite3changeset_start() to the next
** change in the changeset. This function may return SQLITE_ROW, SQLITE_DONE
** or SQLITE_CORRUPT.
**
** This function may not be called on iterators passed to a conflict handler
** callback by changeset_apply().
*//* If non-NULL, true if new table *//* If non-NULL, store size of record here *//* If non-NULL, store record pointer here *//*
** Advance the changeset iterator to the next change.
**
** If both paRec and pnRec are NULL, then this function works like the public
** API sqlite3changeset_next(). If SQLITE_ROW is returned, then the
** sqlite3changeset_new() and old() APIs may be used to query for values.
**
** Otherwise, if paRec and pnRec are not NULL, then a pointer to the change
** record is written to *paRec before returning and the number of bytes in
** the record to *pnRec.
**
** Either way, this function returns SQLITE_ROW if the iterator is
** successfully advanced to the next change in the changeset, an SQLite
** error code if an error occurs, or SQLITE_DONE if there are no further
** changes in the changeset.
*//* If this is an UPDATE that is part of a changeset, then check that
    ** there are no fields in the old.* record that are not (a) PK fields,
    ** or (b) also present in the new.* record.
    **
    ** Such records are technically corrupt, but the rebaser was at one
    ** point generating them. Under most circumstances this is benign, but
    ** can cause spurious SQLITE_RANGE errors when applying the changeset. *//* If this is an UPDATE that is part of a patchset, then all PK and
      ** modified fields are present in the new.* record. The old.* record
      ** is currently completely empty. This block shifts the PK fields from
      ** new.* to old.*, to accommodate the code that reads these arrays.  *//* If this is an INSERT or UPDATE, read the new.* record. *//* If this is an UPDATE or DELETE, read the old.* record. *//* Number of values to buffer *//* The first record in the changeset is not a table header. Must be a
    ** corrupt changeset. *//* If the iterator is already at the end of the changeset, return DONE. *//* Make sure the buffer contains at least 10 bytes of input data, or all
  ** remaining data if there are less than 10 bytes available. This is
  ** sufficient either for the 'T' or 'P' byte and the varint that follows
  ** it, or for the two single byte values otherwise. *//* Free the current contents of p->apValue[], if any. *//* If the iterator is in the error-state, return immediately. *//*
** Advance the changeset iterator to the next change. The differences between
** this function and sessionChangesetNext() are that
**
**   * If pbEmpty is not NULL and the change is a no-op UPDATE (an UPDATE
**     that modifies no columns), this function sets (*pbEmpty) to 1.
**
**   * If the iterator is configured to skip no-op UPDATEs,
**     sessionChangesetNext() does that. This function does not.
*//*
** The input pointer currently points to the second byte of a table-header.
** Specifically, to the following:
**
**   + number of columns in table (varint)
**   + array of PK flags (1 byte per column),
**   + table name (nul terminated).
**
** This function decodes the table-header and populates the p->nCol,
** p->zTab and p->abPK[] variables accordingly. The p->apValue[] array is
** also allocated or resized according to the new value of p->nCol. The
** input pointer is left pointing to the byte following the table header.
**
** If successful, SQLITE_OK is returned. Otherwise, an SQLite error code
** is returned and the final values of the various fields enumerated above
** are undefined.
*//* OUT: Size of record in bytes *//* Number of columns in record *//*
** The input pointer currently points to the first byte of the first field
** of a record consisting of nCol columns. This function ensures the entire
** record is buffered. It does not move the input pointer.
**
** If successful, SQLITE_OK is returned and *pnByte is set to the size of
** the record in bytes. Otherwise, an SQLite error code is returned. The
** final value of *pnByte is undefined in this case.
*//* The hard upper limit for the number of columns in an SQLite
    ** database table is, according to sqliteLimit.h, 32676. So
    ** consider any table-header that purports to have more than 65536
    ** columns to be corrupt. This is convenient because otherwise,
    ** if the (nCol>65536) condition below were omitted, a sufficiently
    ** large value for nCol may cause nRead to wrap around and become
    ** negative. Leading to a crash. *//*
** The input pointer currently points to the second byte of a table-header.
** Specifically, to the following:
**
**   + number of columns in table (varint)
**   + array of PK flags (1 byte per column),
**   + table name (nul terminated).
**
** This function ensures that all of the above is present in the input
** buffer (i.e. that it can be accessed without any calls to xInput()).
** If successful, SQLITE_OK is returned. Otherwise, an SQLite error code.
** The input pointer is not moved.
*//* Type of value (SQLITE_NULL, TEXT etc.) *//* Used to iterate through columns *//* Write values to this array *//* Array of primary key flags, or NULL *//* Number of values in record *//*
** Deserialize a single record from a buffer in memory. See "RECORD FORMAT"
** for details.
**
** When this function is called, *paChange points to the start of the record
** to deserialize. Assuming no error occurs, *paChange is set to point to
** one byte after the end of the same record before this function returns.
** If the argument abPK is NULL, then the record contains nCol values. Or,
** if abPK is other than NULL, then the record contains only the PK fields
** (in other words, it is a patchset DELETE record).
**
** If successful, each element of the apOut[] array (allocated by the caller)
** is set to point to an sqlite3_value object containing the value read
** from the corresponding position in the record. If that value is not
** included in the record (i.e. because the record is part of an UPDATE change
** and the field was not modified), the corresponding element of apOut[] is
** set to NULL.
**
** It is the responsibility of the caller to free all sqlite_value structures
** using sqlite3_free().
**
** If an error occurs, an SQLite error code (e.g. SQLITE_NOMEM) is returned.
** The apOut[] array may have been partially populated in this case.
*//* In theory this code could just pass SQLITE_TRANSIENT as the final
  ** argument to sqlite3ValueSetStr() and have the copy created
  ** automatically. But doing so makes it difficult to detect any OOM
  ** error. Hence the code to create the copy externally. *//* String encoding (0 for blobs) *//* Size of buffer aData[] in bytes *//* Buffer containing string or blob data *//* Set the value of this object *//*
** This function sets the value of the sqlite3_value object passed as the
** first argument to a copy of the string or blob held in the aData[]
** buffer. SQLITE_OK is returned if successful, or SQLITE_NOMEM if an OOM
** error occurs.
*//* IN/OUT: Record pointer *//*
** When this function is called, *ppRec points to the start of a record
** that contains nCol values. This function advances the pointer *ppRec
** until it points to the byte immediately following that record.
*//*
** Ensure that there are at least nByte bytes available in the buffer. Or,
** if there are not nByte bytes remaining in the input, that all available
** data is in the buffer.
**
** Return an SQLite error code if an error occurs, or SQLITE_OK otherwise.
*//*
** If the SessionInput object passed as the only argument is a streaming
** object and the buffer is full, discard some data to free up space.
*//* OUT: Changeset iterator handle *//*
** Streaming version of sqlite3changeset_start().
*//* Pointer to buffer containing changeset *//* Size of buffer pChangeset in bytes *//*
** Create an iterator used to iterate through the contents of a changeset.
*//* Populate the output variable and return success. *//* Allocate and initialize the iterator structure. *//* Zero the output variable in case an error occurs. *//* Number of bytes to allocate for iterator *//* Iterator to return *//* True to skip empty UPDATE changes *//* True to invert changeset *//*
** Do the work for either sqlite3changeset_start() or start_strm().
*//*
** Return the maximum size of sqlite3session_changeset() output.
*//*
** Configure the session object passed as the first argument.
*//*
** Return the amount of heap memory in use.
*//*
** Return true if there have been no changes to monitored tables recorded
** by the session object passed as the only argument.
*//*
** Enable or disable the session object passed as the first argument.
*//*
** Obtain a patchset object containing all changes recorded by the
** session object passed as the first argument.
**
** It is the responsibility of the caller to eventually free the buffer
** using sqlite3_free().
*//*
** Streaming version of sqlite3session_patchset().
*//*
** Streaming version of sqlite3session_changeset().
*//*
** Obtain a changeset object containing all changes recorded by the
** session object passed as the first argument.
**
** It is the responsibility of the caller to eventually free the buffer
** using sqlite3_free().
*//* If the buffer is now larger than sessions_strm_chunk_size, pass
          ** its contents to the xOutput() callback. *//* Used to iterate through changes *//* Build and compile a statement to execute: *//* Write a table header *//* Check the table schema is still Ok. *//* Size of buffer after writing tbl header *//* Initial size of write buffer *//* SELECT statement to query table pTab *//* Used to iterate through hash buckets *//* Zero the output variables in case an error occurs. If this session
  ** object is already in the error state (sqlite3_session.rc != SQLITE_OK),
  ** this call will be a no-op.  *//* Buffer in which to accumlate changeset *//* Used to iterate through attached tables *//* First argument for xOutput *//* True for patchset, false for changeset *//*
** Generate either a changeset (if argument bPatchset is zero) or a patchset
** (if it is non-zero) based on the current contents of the session object
** passed as the first argument.
**
** If no error occurs, SQLITE_OK is returned and the new changeset/patchset
** stored in output variables *pnChangeset and *ppChangeset. Or, if an error
** occurs, an SQLite error code is returned and both output variables set
** to 0.
*//* Table object to append header for *//* Use the patchset format if true *//* Append header to this buffer *//*
** This function is a no-op if *pRc is set to other than SQLITE_OK when it
** is called. Otherwise, append a serialized table header (part of the binary
** changeset format) to buffer *pBuf. If an error occurs, set *pRc to an
** SQLite error code before returning.
*//* Change structure *//* PRIMARY KEY array *//* SELECT from sessionSelectStmt() *//*
** Bind the PRIMARY KEY values from the change passed in argument pChange
** to the SELECT statement passed as the first argument. The SELECT statement
** is as prepared by function sessionSelectStmt().
**
** Return SQLITE_OK if all PK values are successfully bound, or an SQLite
** error code (e.g. SQLITE_NOMEM) otherwise.
*//* OUT: Prepared SELECT statement *//* PRIMARY KEY  array *//* Names of table columns *//*
** Formulate and prepare a SELECT statement to retrieve a row from table
** zTab in database zDb based on its primary key. i.e.
**
**   SELECT *, <noop-test> FROM zDb.zTab WHERE (pk1, pk2,...) IS (?1, ?2,...)
**
** where <noop-test> is:
**
**   1 AND (?A OR ?1 IS <column>) AND ...
**
** for each non-pk <column>.
*//* Boolean array - true for PK columns *//* Object containing old values *//* True for "patchset", 0 for "changeset" *//*
** Append a DELETE change to the buffer passed as the first argument. Use
** the changeset format if argument bPatchset is zero, or the patchset
** format otherwise.
*//* Add a field to the new.* record. Or the only record if currently
    ** generating a patchset.  *//* Add a field to the old.* record. This is omitted if this module is
    ** currently generating a patchset. *//* If at least one field has been modified, this is not a no-op. *//* Used to iterate through old.* values *//* Set to zero if any values are modified *//* Buffer to accumulate new.* record in *//* Statement handle pointing at new row *//*
**
** This function appends an update change to the buffer (see the comments
** under "CHANGESET FORMAT" at the top of the file). An update change
** consists of:
**
**   1 byte:  SQLITE_UPDATE (0x17)
**   n bytes: old.* record (see RECORD FORMAT)
**   m bytes: new.* record (see RECORD FORMAT)
**
** The SessionChange object passed as the third argument contains the
** values that were stored in the row when the session began (the old.*
** values). The statement handle passed as the second argument points
** at the current version of the row (the new.* values).
**
** If all of the old.* values are equal to their corresponding new.* value
** (i.e. nothing has changed), then no data at all is appended to the buffer.
**
** Otherwise, the old.* record contains all primary key values and the
** original values of any fields that have been modified. The new.* record
** contains the new values of only those fields that have been modified.
*//* Column to read value from *//* Handle pointing to row containing value *//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. Otherwse, it appends the serialized version of the value stored
** in column iCol of the row that SQL statement pStmt currently points
** to to the buffer.
*//* String to quote, escape and append *//* Buffer to a append to *//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. Otherwise, append the string zStr enclosed in quotes (") and
** with any embedded quote characters escaped to the buffer. No
** nul-terminator byte is written.
**
** If an OOM condition is encountered, set *pRc to SQLITE_NOMEM before
** returning.
*//* Value to write the string rep. of *//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. Otherwise, append the string representation of integer iVal
** to the buffer. No nul-terminator is written.
**
** If an OOM condition is encountered, set *pRc to SQLITE_NOMEM before
** returning.
*//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. Otherwise, append a blob of data to the buffer.
**
** If an OOM condition is encountered, set *pRc to SQLITE_NOMEM before
** returning.
*//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. Otherwise, append a single varint to the buffer.
**
** If an OOM condition is encountered, set *pRc to SQLITE_NOMEM before
** returning.
*//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. Otherwise, append a single byte to the buffer.
**
** If an OOM condition is encountered, set *pRc to SQLITE_NOMEM before
** returning.
*//*
** Append the value passed as the second argument to the buffer passed
** as the first.
**
** This function is a no-op if *pRc is non-zero when it is called.
** Otherwise, if an error occurs, *pRc is set to an SQLite error code
** before returning.
*//* Populate the new SessionTable object and link it into the list.
        ** The new object must be linked onto the end of the list, not
        ** simply added to the start of it in order to ensure that tables
        ** appear in the correct order when a changeset or patchset is
        ** eventually generated. *//* Allocate new SessionTable object. *//* First search for an existing entry. If one is found, this call is
    ** a no-op. Return early. *//* Number of bytes in string zName *//* New table object (if required) *//*
** Attach a table to a session. All subsequent changes made to the table
** while the session object is enabled will be recorded.
**
** Only tables that have a PRIMARY KEY defined may be attached. It does
** not matter if the PRIMARY KEY is an "INTEGER PRIMARY KEY" (rowid alias)
** or not.
*//*
** Set a table filter on a Session Object.
*//* Free the session object. *//* Delete all attached table objects. And the contents of their
  ** associated hash-tables. *//* Unlink the session from the linked list of sessions attached to the
  ** database handle. Hold the db mutex while doing so.  *//*
** Delete a session object previously allocated using sqlite3session_create().
*//*
** Free the list of table objects passed as the first argument. The contents
** of the changed-rows hash tables are also deleted.
*//* Add the new session object to the linked list of session objects
  ** attached to database handle $db. Do this under the cover of the db
  ** handle mutex.  *//* Allocate and populate the new session object. *//* Zero the output value in case an error occurs. *//* Length of zDb in bytes *//* Session object already attached to db *//* Newly allocated session object *//*
** Create a session object. This session object will record changes to
** database zDb attached to connection db.
*//* Find modified rows *//* Find old rows *//* Find new rows *//* Ignore tables with no primary keys *//* Columns in zFrom.zTbl *//* Check the table schemas match *//* Locate and if necessary initialize the target table object *//* Table zTbl *//*
** Return a comma-separated list of the fully-qualified (with both database
** and table name) column names from table pTab. e.g.
**
**    "main"."t1"."a", "main"."t1"."b", "main"."t1"."c"
*//* But not in this one *//* Pick rows in this db only *//*
** Install the diff hooks on the session object passed as the only
** argument.
*//*
** The diff hook implementations.
*//*
** Install the pre-update hooks on the session object passed as the only
** argument.
*//*
** The pre-update hook implementations.
*//* If this session is attached to a different database ("main", "temp"
    ** etc.), or if it is not currently enabled, there is nothing to do. Skip
    ** to the next session object attached to this database. *//*
** The 'pre-update' hook registered by this module with SQLite databases.
*//* If there is a table-filter configured, invoke it. If it returns 0,
    ** do not automatically add the new table. *//* Search for an existing table *//* If an error has occurred, mark the session object as failed. *//* If the existing change is considered "indirect", but this current
      ** change is "direct", mark the change object as direct. *//* Add the change to the hash-table *//* Populate the change object. None of the preupdate_old(),
      ** preupdate_new() or SerializeValue() calls below may fail as all
      ** required values and encodings have already been cached in memory.
      ** It is not possible for an OOM to occur in this block. *//* Allocate the change object *//* Size of rowid field - an integer *//* This may fail if SQLite value p contains a utf-16 string that must
          ** be converted to utf-8 and an OOM error occurs while doing so. *//* This may fail if the column has a non-NULL default and was added
          ** using ALTER TABLE ADD COLUMN after this record was created. *//* Figure out how large an allocation is required *//* Number of bytes to allocate *//* Create a new change object containing all the old values (if
      ** this is an SQLITE_UPDATE or SQLITE_DELETE), or just the PK
      ** values (if this is an INSERT). *//* Search the hash table for an existing record for this row. *//* Calculate the hash-key for this change. If the primary key of the row
  ** includes a NULL value, exit early. Such changes are ignored by the
  ** session module. *//* Grow the hash table if required *//* Check the number of columns in this xPreUpdate call matches the
  ** number of columns in the table.  *//* Load table details if required *//* Table that change applies to *//* Session object pTab is attached to *//* One of SQLITE_UPDATE, INSERT, DELETE *//*
** This function is only called from with a pre-update-hook reporting a
** change on table pTab (attached to session pSession). The type of change
** (UPDATE, INSERT, DELETE) is specified by the first argument.
**
** Unless one is already present or an error occurs, an entry is added
** to the changed-rows hash table associated with table pTab.
*//* Update pC->nMaxSize *//*
** Versions of the four methods in object SessionHook for use with the
** sqlite_stat1 table. The purpose of this is to substitute a zero-length
** blob each time a NULL value is read from the "idx" column of the
** sqlite_stat1 table.
*//*
** Table pTab has one or more existing change-records with old.* records
** with fewer than pTab->nCol columns. This function updates all such
** change-records with the default values for the missing columns.
*//* Table to prepare statement for *//*
** Prepare a statement against database handle db that SELECTs a single
** row containing the default values for each column in table pTab. For
** example, if pTab is declared as:
**
**   CREATE TABLE pTab(a PRIMARY KEY, b DEFAULT 123, c DEFAULT 'abcd');
**
** Then this function prepares and returns the SQL statement:
**
**   SELECT NULL, 123, 'abcd';
*//*
** Format a string using printf() style formatting and then append it to the
** buffer using sessionAppendString().
*//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is
** called. Otherwise, append a string to the buffer. All bytes in the string
** up to (but not including) the nul-terminator are written to the buffer.
**
** If an OOM condition is encountered, set *pRc to SQLITE_NOMEM before
** returning.
*//* The value of SESSION_MAX_BUFFER_SZ is copied from the implementation
    ** of sqlite3_realloc64(). Allocations greater than this size in bytes
    ** always fail. It is used here to ensure that this routine can always
    ** allocate up to this limit - instead of up to the largest power of
    ** two smaller than the limit.  *//*
** Ensure that there is room in the buffer to append nByte bytes of data.
** If not, use sqlite3_realloc() to grow the buffer so that there is.
**
** If successful, return zero. Otherwise, if an OOM condition is encountered,
** set *pRc to SQLITE_NOMEM and return non-zero.
*//* SELECT <default-values...> *//* Number of columns now in table *//* IN/OUT: Change object to update *//* For memory accounting *//*
** Session-change object (*pp) contains an old.* record with fewer than
** nCol fields. This function updates it with the default values for
** the missing fields.
*//*
** Re-initialize table object pTab.
*//* Name of db - "main", "temp" etc. *//* Database handle to read schema from *//* Table object to initialize *//* Optional session handle *//*
** This function is called to initialize the SessionTable.nCol, azCol[]
** abPK[] and azDflt[] members of SessionTable object pTab. If these
** fields are already initilialized, this function is a no-op.
**
** If an error occurs, an error code is stored in sqlite3_session.rc and
** non-zero returned. Or, if no error occurs but the table has no primary
** key, sqlite3_session.rc is left set to SQLITE_OK and non-zero returned to
** indicate that updates on this table should be ignored. SessionTable.abPK
** is set to NULL in this case.
*//* If successful, populate the output variables. Otherwise, zero them and
  ** free any allocation made. An error code will be returned in this case.
  *//* !hidden *//* pk *//* dflt_value *//* For sqlite_stat1, pretend that (tbl,idx) is the PRIMARY KEY. *//* Set to true to use rowid as PK *//* OUT: True if only PK is a rowid *//* OUT: Array of booleans - true for PK col *//* OUT: Array of xNew/xOld indexes *//* OUT: Array of default value expressions *//* OUT: Array of column names for table *//* OUT: Copy of zThis *//* OUT: number of hidden columns *//* OUT: number of columns *//* Name of attached database (e.g. "main") *//* For memory accounting. May be NULL *//*
** This function queries the database for the names of the columns of table
** zThis, in schema zDb.
**
** Otherwise, if they are not NULL, variable *pnCol is set to the number
** of columns in the database table and variable *pzTab is set to point to a
** nul-terminated copy of the table name. *pazCol (if not NULL) is set to
** point to an array of pointers to column names. And *pabPK (again, if not
** NULL) is set to point to an array of booleans - true if the corresponding
** column is part of the primary key.
**
** For example, if the table is declared as:
**
**     CREATE TABLE tbl1(w, x DEFAULT 'abc', y, z, PRIMARY KEY(w, z));
**
** Then the five output variables are populated as follows:
**
**     *pnCol  = 4
**     *pzTab  = "tbl1"
**     *pazCol = {"w", "x", "y", "z"}
**     *pazDflt = {NULL, 'abc', NULL, NULL}
**     *pabPK  = {1, 0, 0, 1}
**
** All returned buffers are part of the same single allocation, which must
** be freed using sqlite3_free() by the caller
*//*
** If required, grow the hash table used to store changes on table pTab
** (part of the session pSession). If a fatal OOM error occurs, set the
** session object to failed and return SQLITE_ERROR. Otherwise, return
** SQLITE_OK.
**
** It is possible that a non-fatal OOM error occurs in this function. In
** that case the hash-table does not grow, but SQLITE_OK is returned anyway.
** Growing the hash table in this case is a performance optimization only,
** it is not required for correct operation.
*//* A SessionChange object never has a NULL value in a PK column *//* Suppress warning about unused variable *//* assert( db->pPreUpdate->pUnpacked ); *//* assert( db->pPreUpdate->pNewUnpacked || db->pPreUpdate->aNew ); *//* The following calls to preupdate_new() and preupdate_old() can not
      ** fail. This is because they cache their return values, and by the
      ** time control flows to here they have already been called once from
      ** within sessionPreupdateHash(). The first two asserts below verify
      ** this (that the method has already been called). *//* Type of value from change record *//* Error code from preupdate_new/old *//* Value returned by preupdate_new/old *//* Cursor used to scan change record *//* Current pre-update operation *//* Change to compare to *//* Table associated with change *//* Rowid value if pTab->bRowid *//* Session object that owns SessionTable *//*
** This function is only called from within a pre-update-hook callback.
** It determines if the current pre-update-hook change affects the same row
** as the change stored in argument pChange. If so, it returns true. Otherwise
** if the pre-update-hook does not affect the same row as pChange, it returns
** false.
*//* Write the new.* vector *//* Write the old.* vector first. *//* new.* record for second change *//* new.* record for first change *//* old.* record for second change *//* old.* record for first change *//* True if records are patchset records *//* Table change pertains to *//* IN/OUT: Pointer to output buffer *//*
** This function is used by changeset_concat() to merge two UPDATE changes
** on the same row.
*//* OUT: Bytes in returned value *//* IN/OUT: Right-hand buffer pointer *//* IN/OUT: Left-hand buffer pointer *//*
** This is a helper function used by sessionMergeUpdate().
**
** When this function is called, both *paOne and *paTwo point to a value
** within a change record. Before it returns, both have been advanced so
** as to point to the next value in the record.
**
** If, when this function is called, *paTwo points to a valid value (i.e.
** *paTwo[0] is not 0x00 - the "no value" placeholder), a copy of the *paTwo
** pointer is returned and *pnVal is set to the number of bytes in the
** serialized value. Otherwise, a copy of *paOne is returned and *pnVal
** set to the number of bytes in the value at *paOne. If *paOne points
** to the "no value" placeholder, *pnVal is set to 1. In other words:
**
**   if( *paTwo is valid ) return *paTwo;
**   return *paOne;
**
*//* Used to iterate from 0 to nCol *//* Output cursor *//* Cursor used to iterate through aRight *//* Cursor used to iterate through aLeft *//*
** Arguments aLeft and aRight both point to buffers containing change
** records with nCol columns. This function "merges" the two records into
** a single records which is written to the buffer at *paOut. *paOut is
** then set to point to one byte after the last byte written before
** returning.
**
** The merging of records is done as follows: For each column, if the
** aRight record contains a value for the column, copy the value from
** their. Otherwise, if aLeft contains a value, copy it. If neither
** record contains a value for a given column, then neither does the
** output record.
*//* Used to iterate through table columns *//* Cursor to iterate through aRight *//* Cursor to iterate through aLeft *//* Change record *//* True if aRight[] contains PK fields only *//* True if aLeft[] contains PK fields only *//* Table used for PK definition *//*
** Arguments aLeft and aRight are pointers to change records for table pTab.
** This function returns true if the two records apply to the same row (i.e.
** have the same values stored in the primary key columns), or false
** otherwise.
*//* It is not possible for eType to be SQLITE_NULL here. The session
    ** module does not record changes for rows with NULL values stored in
    ** primary key columns. *//* Used to iterate through change record *//* Value to return *//* Assume this many buckets in hash table *//* Record consists of PK fields only *//* Table handle *//*
** Based on the primary key values stored in change aRecord, calculate a
** hash key. Assume the has table has nBucket buckets. The hash keys
** calculated by this function are compatible with those calculated by
** sessionPreupdateHash().
**
** The bPkOnly argument is non-zero if the record at aRecord[] is from
** a patchset DELETE. In this case the non-PK fields are omitted entirely.
*//*
** The buffer that the argument points to contains a serialized SQL value.
** Return the number of bytes of space occupied by the value (including
** the type byte).
*//* Hash value to return *//* OUT: True if there are NULL values in PK *//* OUT: Hash value *//* True to hash the new.* PK *//* Session table handle *//* Session object that owns pTab *//*
** This function may only be called from within a pre-update callback.
** It calculates a hash based on the primary key values of the old.* or
** new.* row currently available and, assuming no error occurs, writes it to
** *piHash before returning. If the primary key contains one or more NULL
** values, *pbNullPK is set to true before returning.
**
** If an error occurs, an SQLite error code is returned and the final values
** of *piHash asn *pbNullPK are undefined. Otherwise, SQLITE_OK is returned
** and the output variables are set as described above.
*//*
** Append the hash of the data type passed as the second argument to the
** hash-key value passed as the first. Return the new hash-key value.
*//*
** Append the hash of the blob passed via the second and third arguments to
** the hash-key value passed as the first. Return the new hash-key value.
*//*
** Append the hash of the 64-bit integer passed as the second argument to the
** hash-key value passed as the first. Return the new hash-key value.
*//*
** This macro is used to calculate hash key values for data structures. In
** order to use this macro, the entire data structure must be represented
** as a series of unsigned integers. In order to calculate a hash-key value
** for a data structure represented as three such integers, the macro may
** then be used as follows:
**
**    int hash_key_value;
**    hash_key_value = HASH_APPEND(0, <value 1>);
**    hash_key_value = HASH_APPEND(hash_key_value, <value 2>);
**    hash_key_value = HASH_APPEND(hash_key_value, <value 3>);
**
** In practice, the data structures this macro is used for are the primary
** key values of modified rows.
*//*
** Free buffer pFree, which must have been allocated by an earlier
** call to sessionMalloc64(). If pSession is not NULL, decrease the
** sqlite3_session.nMalloc counter by the number of bytes freed.
*//*
** Allocate and return a pointer to a buffer nByte bytes in size. If
** pSession is not NULL, increase the sqlite3_session.nMalloc variable
** by the number of bytes allocated.
*//* TODO: SQLite does something special to deal with mixed-endian
          ** floating point values (e.g. ARM7). This code probably should
          ** too.  *//* Value type (SQLITE_NULL, TEXT etc.) *//* Size of serialized value in bytes *//* IN/OUT: Increment by bytes written *//* Value to serialize *//* If non-NULL, write serialized value here *//*
** This function is used to serialize the contents of value pValue (see
** comment titled "RECORD FORMAT" above).
**
** If it is non-NULL, the serialized form of the value is written to
** buffer aBuf. *pnWrite is set to the number of bytes written before
** returning. Or, if aBuf is NULL, the only thing this function does is
** set *pnWrite.
**
** If no error occurs, SQLITE_OK is returned. Or, if an OOM error occurs
** within a call to sqlite3_value_text() (may fail if the db is utf-16))
** SQLITE_NOMEM is returned.
*//*
** Write a 64-bit big-endian integer value to the buffer aBuf[].
*//*
** Read a 64-bit big-endian integer value from buffer aRec[]. Return
** the value read.
*//* Load an unaligned and unsigned 32-bit integer *//*
** Read a varint value from aBuf[] into *piVal. Return the number of
** bytes read.
*//*
** Return the number of bytes required to store value iVal as a varint.
*//*
** Write a varint with value iVal into the buffer at aBuf. Return the
** number of bytes written.
*//* For hash-table collisions *//* Buffer containing old.* record *//* Number of bytes in buffer aRecord[] *//* Max size of eventual changeset record *//* Number of fields in aRecord[] *//* True if this change is "indirect" *//* One of UPDATE, DELETE, INSERT *//*
** For each row modified during a session, there exists a single instance of
** this structure stored in a SessionTable.aChange[] hash table.
*//*
** RECORD FORMAT:
**
** The following record format is similar to (but not compatible with) that
** used in SQLite database files. This format is used as part of the
** change-set binary format, and so must be architecture independent.
**
** Unlike the SQLite database record format, each field is self-contained -
** there is no separation of header and data. Each field begins with a
** single byte describing its type, as follows:
**
**       0x00: Undefined value.
**       0x01: Integer value.
**       0x02: Real value.
**       0x03: Text value.
**       0x04: Blob value.
**       0x05: SQL NULL value.
**
** Note that the above match the definitions of SQLITE_INTEGER, SQLITE_TEXT
** and so on in sqlite3.h. For undefined and NULL values, the field consists
** only of the single type byte. For other types of values, the type byte
** is followed by:
**
**   Text values:
**     A varint containing the number of bytes in the value (encoded using
**     UTF-8). Followed by a buffer containing the UTF-8 representation
**     of the text value. There is no nul terminator.
**
**   Blob values:
**     A varint containing the number of bytes in the value, followed by
**     a buffer containing the value itself.
**
**   Integer values:
**     An 8-byte big-endian integer value.
**
**   Real values:
**     An 8-byte big-endian IEEE 754-2008 real value.
**
** Varint values are encoded in the same way as varints in the SQLite
** record format.
**
** CHANGESET FORMAT:
**
** A changeset is a collection of DELETE, UPDATE and INSERT operations on
** one or more tables. Operations on a single table are grouped together,
** but may occur in any order (i.e. deletes, updates and inserts are all
** mixed together).
**
** Each group of changes begins with a table header:
**
**   1 byte: Constant 0x54 (capital 'T')
**   Varint: Number of columns in the table.
**   nCol bytes: 0x01 for PK columns, 0x00 otherwise.
**   N bytes: Unqualified table name (encoded using UTF-8). Nul-terminated.
**
** Followed by one or more changes to the table.
**
**   1 byte: Either SQLITE_INSERT (0x12), UPDATE (0x17) or DELETE (0x09).
**   1 byte: The "indirect-change" flag.
**   old.* record: (delete and update only)
**   new.* record: (insert and update only)
**
** The "old.*" and "new.*" records, if present, are N field records in the
** format described above under "RECORD FORMAT", where N is the number of
** columns in the table. The i'th field of each record is associated with
** the i'th column of the table, counting from left to right in the order
** in which columns were declared in the CREATE TABLE statement.
**
** The new.* record that is part of each INSERT change contains the values
** that make up the new row. Similarly, the old.* record that is part of each
** DELETE change contains the values that made up the row that was deleted
** from the database. In the changeset format, the records that are part
** of INSERT or DELETE changes never contain any undefined (type byte 0x00)
** fields.
**
** Within the old.* record associated with an UPDATE change, all fields
** associated with table columns that are not PRIMARY KEY columns and are
** not modified by the UPDATE change are set to "undefined". Other fields
** are set to the values that made up the row before the UPDATE that the
** change records took place. Within the new.* record, fields associated
** with table columns modified by the UPDATE change contain the new
** values. Fields associated with table columns that are not modified
** are set to "undefined".
**
** PATCHSET FORMAT:
**
** A patchset is also a collection of changes. It is similar to a changeset,
** but leaves undefined those fields that are not useful if no conflict
** resolution is required when applying the changeset.
**
** Each group of changes begins with a table header:
**
**   1 byte: Constant 0x50 (capital 'P')
**   Varint: Number of columns in the table.
**   nCol bytes: 0x01 for PK columns, 0x00 otherwise.
**   N bytes: Unqualified table name (encoded using UTF-8). Nul-terminated.
**
** Followed by one or more changes to the table.
**
**   1 byte: Either SQLITE_INSERT (0x12), UPDATE (0x17) or DELETE (0x09).
**   1 byte: The "indirect-change" flag.
**   single record: (PK fields for DELETE, PK and modified fields for UPDATE,
**                   full record for INSERT).
**
** As in the changeset format, each field of the single record that is part
** of a patchset change is associated with the correspondingly positioned
** table column, counting from left to right within the CREATE TABLE
** statement.
**
** For a DELETE change, all fields within the record except those associated
** with PRIMARY KEY columns are omitted. The PRIMARY KEY fields contain the
** values identifying the row to delete.
**
** For an UPDATE change, all fields except those associated with PRIMARY KEY
** columns and columns that are modified by the UPDATE are set to "undefined".
** PRIMARY KEY fields contain the values identifying the table row to update,
** and fields associated with modified columns contain the new column values.
**
** The records associated with INSERT changes are in the same format as for
** changesets. It is not possible for a record associated with an INSERT
** change to contain a field set to "undefined".
**
** REBASE BLOB FORMAT:
**
** A rebase blob may be output by sqlite3changeset_apply_v2() and its
** streaming equivalent for use with the sqlite3_rebaser APIs to rebase
** existing changesets. A rebase blob contains one entry for each conflict
** resolved using either the OMIT or REPLACE strategies within the apply_v2()
** call.
**
** The format used for a rebase blob is very similar to that used for
** changesets. All entries related to a single table are grouped together.
**
** Each group of entries begins with a table header in changeset format:
**
**   1 byte: Constant 0x54 (capital 'T')
**   Varint: Number of columns in the table.
**   nCol bytes: 0x01 for PK columns, 0x00 otherwise.
**   N bytes: Unqualified table name (encoded using UTF-8). Nul-terminated.
**
** Followed by one or more entries associated with the table.
**
**   1 byte: Either SQLITE_INSERT (0x12), DELETE (0x09).
**   1 byte: Flag. 0x01 for REPLACE, 0x00 for OMIT.
**   record: (in the record format defined above).
**
** In a rebase blob, the first field is set to SQLITE_INSERT if the change
** that caused the conflict was an INSERT or UPDATE, or to SQLITE_DELETE if
** it was a DELETE. The second field is set to 0x01 if the conflict
** resolution strategy was REPLACE, or 0x00 if it was OMIT.
**
** If the change that caused the conflict was a DELETE, then the single
** record is a copy of the old.* record from the original changeset. If it
** was an INSERT, then the single record is a copy of the new.* record. If
** the conflicting change was an UPDATE, then the single record is a copy
** of the new.* record with the PK fields filled in based on the original
** old.* record.
*//* Hash table buckets *//* Size of apChange[] array *//* Total number of entries in hash table *//* Array of primary key flags *//* Index to pass to xNew/xOld *//* Default value expressions *//* True if this table uses rowid for PK *//* True if this is sqlite_stat1 *//* Number of columns including hidden *//* Number of non-hidden columns *//* Local name of table *//*
** Each session object maintains a set of the following structures, one
** for each table the session object is monitoring. The structures are
** stored in a linked list starting at sqlite3_session.pTable.
**
** The keys of the SessionTable.aChange[] hash table are all rows that have
** been modified in any way since the session object was attached to the
** table.
**
** The data associated with each hash-table entry is a structure containing
** a subset of the initial values that the modified row contained at the
** start of the session. Or no initial values if the row was inserted.
**
** pDfltStmt:
**   This is only used by the sqlite3changegroup_xxx() APIs, not by
**   regular sqlite3_session objects. It is a SELECT statement that
**   selects the default value for each table column. For example,
**   if the table is
**
**      CREATE TABLE xx(a DEFAULT 1, b, c DEFAULT 'abc')
**
**   then this variable is the compiled version of:
**
**      SELECT 1, NULL, 'abc'
*//* old.* and new.* values *//* Primary key array *//* True if current change was indirect *//* Current operation *//* Number of columns in zTab *//* Current table *//* Points to conflicting row, if any *//* Iterator error code *//* Skip noop UPDATE changes *//* True if this is a patchset *//* Buffer to hold apValue/zTab/abPK/ *//* Input buffer or stream *//*
** Structure for changeset iterators.
*//* Set to true after xInput finished *//* First argument to xInput *//* Input stream call (or NULL) *//* Current read buffer *//* Number of bytes in aData *//* Offset in aData[] of next change *//* Offset in aData[] of current change *//* If true, do not discard in InputBuffer() *//*
** An object of this type is used internally as an abstraction for
** input data. Input data may be supplied either as a single large buffer
** (e.g. sqlite3changeset_start()) or using a stream function (e.g.
**  sqlite3changeset_start_strm()).
**
** bNoDiscard:
**   If true, then the only time data is discarded is as a result of explicit
**   sessionDiscardData() calls. Not within every sessionInputBuffer() call.
*//* Size of allocation containing aBuf *//* Size of buffer aBuf *//* Pointer to changeset buffer *//*
** Instances of this structure are used to build strings or binary records.
*//* APIs to grab new and old data with *//* List of attached tables *//* Next session object on same db. *//* Value containing X'' *//* Number of bytes of data allocated *//* First argument to pass to xTableFilter *//* Non-zero if an error has occurred *//* True to handle tables with implicit PK *//* True to auto-attach tables *//* True if all changes are indirect *//* True if currently recording *//* True if changeset_size() enabled *//* Name of database session is attached to *//* Database handle session is attached to *//*
** Session handle structure.
*//*
** Minimum chunk size used by streaming versions of functions.
*//* # include "vdbeInt.h" *//* # include "sqliteInt.h" *//* #include "sqlite3session.h" *//************** Begin file sqlite3session.c **********************************//************** End of dbpage.c **********************************************//* SQLITE_ENABLE_DBSTAT_VTAB *//*
** Invoke this routine to register the "dbpage" virtual table module
*//* Cancel any pending truncate.
*//* Invoke sqlite3PagerTruncate() as necessary, just prior to COMMIT
*//* "INSERT INTO dbpage($PGNO,NULL)" causes page number $PGNO and
      ** all subsequent pages to be deleted. *//*
** Open write transactions. Since we do not know in advance which database
** files will be written by the sqlite_dbpage virtual table, start a write
** transaction on them all.
**
** Return SQLITE_OK if successful, or an SQLite error code otherwise.
*//* schema *//* The pending byte page. Assume it is zeroed out. Attempting to
        ** request this page from the page is an SQLITE_CORRUPT error. *//* Default setting is no rows of result *//*
** idxNum:
**
**     0     schema=main, full table scan
**     1     schema=main, pgno=?1
**     2     schema=?1, full table scan
**     3     schema=?1, pgno=?2
**
** idxStr is not used
*//*
** Move a dbpagevfs cursor to the next entry in the file.
*//*
** Close a dbpagevfs cursor.
*//*
** Open a new dbpagevfs cursor.
*//* Check for constraints against pgno *//* If we reach this point, it means that either there is no schema=
  ** constraint (in which case we use the "main" schema) or else the
  ** schema constraint was accepted.  Lower the estimated cost accordingly
  *//* No solution. *//* If there is a schema= constraint, it must be honored.  Report a
  ** ridiculously large estimated cost if the schema= constraint is
  ** unavailable
  *//*
** idxNum:
**
**     0     schema=main, full table scan
**     1     schema=main, pgno=?1
**     2     schema=?1, full table scan
**     3     schema=?1, pgno=?2
*//*
** Disconnect from or destroy a dbpagevfs virtual table.
*//*
** Connect to or create a dbpagevfs virtual table.
*//* Columns *//* Size to truncate to *//* Database to truncate *//* Size of each page in bytes *//* Index of database to analyze *//* Page 1 of the database *//* Pager being read/written *//* Last page to visit on this scan *//* #include "sqliteInt.h"   ** Requires access to internal data structures ** *//*
** 2017-10-11
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file contains an implementation of the "sqlite_dbpage" virtual table.
**
** The sqlite_dbpage virtual table is used to read or write whole raw
** pages of the database file.  The pager interface is used so that
** uncommitted changes and changes recorded in the WAL file are correctly
** retrieved.
**
** Usage example:
**
**    SELECT data FROM sqlite_dbpage('aux1') WHERE pgno=123;
**
** This is an eponymous virtual table so it does not need to be created before
** use.  The optional argument to the sqlite_dbpage() table name is the
** schema for the database file that is to be read.  The default schema is
** "main".
**
** The data field of sqlite_dbpage table can be updated.  The new
** value must be a BLOB which is the correct page size, otherwise the
** update fails.  INSERT operations also work, and operate as if they
** where REPLACE.  The size of the database can be extended by INSERT-ing
** new pages on the end.
**
** Rows may not be deleted.  However, doing an INSERT to page number N
** with NULL page data causes the N-th page and all subsequent pages to be
** deleted and the database to be truncated.
*//************** Begin file dbpage.c ******************************************//************** End of dbstat.c **********************************************//*
** Invoke this routine to register the "dbstat" virtual table module
*//* aggregate *//* pgsize *//* pgoffset *//* mx_payload *//* unused *//* payload *//* ncell *//* pagetype *//* pageno *//* path *//* aggregate=? constraint is present *//* name=? constraint is present *//* schema=? constraint is present.  Get its value *//* Only provide analysis of this table *//* Result of this operation *//* Count of argv[] parameters used so far *//* String value of pSql *//* Query of btrees to analyze *//* Initialize a cursor according to the query plan idxNum using the
** arguments in argv[0].  See statBestIndex() for a description of the
** meaning of the bits in idxNum.
*//* If computing aggregate space usage by btree, continue with the
      ** next page.  The loop will exit via the return at label-statNext-done
      *//* index leaf *//* table leaf *//* index internal *//* table internal *//* Populate the StatCursor fields with the values to be returned
  ** by the xColumn() and xRowid() methods.
  *//* Tail recursion *//* label-statNext-done:  When computing aggregate space usage over
        ** an entire btree, this is the exit point from this function *//* Continue analyzing the btree previously started *//* Start measuring space on the next btree *//*
** Move a DBSTAT cursor to the next entry.  Normally, the next
** entry will be the next page, but in aggregated mode (pCsr->isAgg!=0),
** the next entry is the next btree.
*//* Load page into this object *//* Page number to load *//* Load page from this b-tree *//*
** Load a copy of the page data for page iPg into the buffer belonging
** to page object pPg. Allocate the buffer if necessary. Return SQLITE_OK
** if successful, or an SQLite error code otherwise.
*//* Not ZIPVFS: The default page size and offset *//* If connected to a ZIPVFS backend, find the page size and
  ** offset from ZIPVFS.
  *//*
** Populate the pCsr->iOffset and pCsr->szPage member variables. Based on
** the current value of pCsr->iPageno.
*//* Bytes of payload stored locally *//* Bytes of payload total (local+overflow) *//* A table interior node. nPayload==0. *//* Usable bytes per page *//* Used to iterate through cells *//* Populate the StatPage object with information about the all
** cells found on the page currently under analysis.
*//* Index interior and leaf nodes *//* Table leaf node *//* Total record (payload) size *//* Page flags *//*
** For a single cell on a btree page, compute the number of bytes of
** content (payload) stored on that page.  That is to say, compute the
** number of bytes of content not found on overflow pages.
*//*
** Close a DBSTAT cursor.
*//* Resize the space-used counters inside of the cursor *//* In some circumstances, specifically if an OOM has occurred, the call
  ** to sqlite3_reset() may cause the pager to be reset (emptied). It is
  ** important that statClearPage() is called to free any page refs before
  ** this happens. dbsqlfuzz 9ed3e4e3816219d3509d711636c38542bf3f40b1. *//*
** Open a new DBSTAT cursor.
*//* Records are always returned in ascending order of (name, path).
  ** If this will satisfy the client, set the orderByConsumed flag so that
  ** SQLite does not do an external sort.
  *//* Force DBSTAT table should always be the right-most table in a join *//* Look for a valid schema=? constraint.  If found, change the idxNum to
  ** 1 and request the value of that constraint be sent to xFilter.  And
  ** lower the cost estimate to encourage the constrained version to be
  ** used.
  *//*
** Compute the best query strategy and return the result in idxNum.
**
**   idxNum-Bit        Meaning
**   ----------        ----------------------------------------------
**      0x01           There is a schema=? term in the WHERE clause
**      0x02           There is a name=? term in the WHERE clause
**      0x04           There is an aggregate=? term in the WHERE clause
**      0x08           Output should be ordered by name and path
*//*
** Disconnect from or destroy the DBSTAT virtual table.
*//*
** Connect to or create a new DBSTAT virtual table.
*//* Database connection that owns this vtab *//* base class.  MUST BE FIRST! *//* An instance of the DBSTAT virtual table *//* Value of 'pgSize' column *//* Value of 'pgOffset' column *//* Value of 'payload' column *//* Value of 'unused' column *//* Value of 'mx_payload' column *//* Value of 'ncell' column *//* Number of pages in current btree *//* Value of 'pagetype' column *//* Value of 'path' column *//* Value of 'name' column *//* Value of 'pageno' column *//* Values to return. *//* Current entry in aPage[] *//* Pages in path to current page *//* Schema used for this query *//* Aggregate results for each table *//* After pStmt has returned SQLITE_DONE *//* Iterates through set of root pages *//* The cursor for scanning the dbstat virtual table *//* Largest payload of any cell on the page *//* Right-child page number (or 0) *//* Array of parsed cells *//* Number of unused bytes on page *//* Copy of flags byte *//* Variables populated by statDecodePage(): *//* Path to this page *//* Current cell *//* Page buffer from sqlite3_malloc() *//* Page number *//* Size information for a single btree page *//* Iterates through aOvfl[] *//* Bytes of payload on final overflow page *//* Array of overflow page numbers *//* Entries in aOvfl[] *//* Child node (or 0 if this is a leaf) *//* Bytes of local payload *//* Size information for a single cell within a btree page *//* Forward reference to data structured used in this module *//* 11 aggregate info for each table *//* 10 Database schema being analyzed *//*  9 Size of the page (sum for aggregate) *//*  8 Offset of page in file (NULL for agg) *//*  7 Largest payload size of all cells *//*  6 Bytes of unused space on this page *//*  5 Bytes of payload on this page *//*  4 Cells on page (0 for overflow) *//*  3 'internal', 'leaf', 'overflow', or NULL *//*  2 Page number (page count for aggregates) *//*  1 Path to page from root (NULL for agg) *//*  0 Name of table or index *//*
** Page paths:
**
**   The value of the 'path' column describes the path taken from the
**   root-node of the b-tree structure to each page. The value of the
**   root-node path is '/'.
**
**   The value of the path for the left-most child page of the root of
**   a b-tree is '/000/'. (Btrees store content ordered from left to right
**   so the pages to the left have smaller keys than the pages to the right.)
**   The next to left-most child of the root page is
**   '/001', and so on, each sibling page identified by a 3-digit hex
**   value. The children of the 451st left-most sibling have paths such
**   as '/1c2/000/, '/1c2/001/' etc.
**
**   Overflow pages are specified by appending a '+' character and a
**   six-digit hexadecimal value to the path to the cell they are linked
**   from. For example, the three overflow pages in a chain linked from
**   the left-most cell of the 450th child of the root page are identified
**   by the paths:
**
**      '/1c2/000+000000'         // First page in overflow chain
**      '/1c2/000+000001'         // Second page in overflow chain
**      '/1c2/000+000002'         // Third page in overflow chain
**
**   If the paths are sorted using the BINARY collation sequence, then
**   the overflow pages associated with a cell will appear earlier in the
**   sort-order than its child page:
**
**      '/1c2/000/'               // Left-most child of 451st child of root
*//*
** The pager and btree modules arrange objects in memory so that there are
** always approximately 200 bytes of addressable memory following each page
** buffer. This way small buffer overreads caused by corrupt database pages
** do not cause undefined behaviour. This module pads each page buffer
** by the following number of bytes for the same purpose.
*//*
** 2010 July 12
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file contains an implementation of the "dbstat" virtual table.
**
** The dbstat virtual table is used to extract low-level storage
** information from an SQLite database in order to implement the
** "sqlite3_analyzer" utility.  See the ../tool/spaceanal.tcl script
** for an example implementation.
**
** Additional information is available on the "dbstat.html" page of the
** official SQLite documentation.
*//************** Begin file dbstat.c ******************************************//************** End of sqlite3rbu.c ******************************************//* !defined(SQLITE_CORE) || defined(SQLITE_ENABLE_RBU) *//**************************************************************************//*
** Configure the aggregate temp file size limit for this RBU handle.
*//* Allocate the mutex and register the new VFS (not as the default) *//* Parent VFS *//* Newly allocated VFS *//* Unimplemented version 3 methods *//* xCurrentTimeInt64 (version 2) *//* pAppData *//* szOsFile *//* Template for VFS *//*
** Create an RBU VFS named zName that accesses the underlying file-system
** via existing VFS zParent. The new object is registered as a non-default
** VFS with SQLite before returning.
*//*
** Deregister and destroy an RBU vfs created by an earlier call to
** sqlite3rbu_create_vfs().
*//*
** No-op.
*//*
** Sleep for nMicro microseconds. Return the number of microseconds
** actually slept.
*//*
** Populate the buffer pointed to by zBufOut with nByte bytes of
** random data.
*//* SQLITE_OMIT_LOAD_EXTENSION *//*
** Populate the buffer zErrMsg (size nByte bytes) with a human readable
** utf-8 string describing the most recent error encountered associated
** with dynamic libraries.
*//* If this call is to check if a *-wal file associated with an RBU target
  ** database connection exists, and the RBU update is in RBU_STAGE_OAL,
  ** the following special handling is activated:
  **
  **   a) if the *-wal file does exist, return SQLITE_CANTOPEN. This
  **      ensures that the RBU extension never tries to update a database
  **      in wal mode, even if the first page of the database file has
  **      been damaged.
  **
  **   b) if the *-wal file does not exist, claim that it does anyway,
  **      causing SQLite to call xOpen() to open it. This call will also
  **      be intercepted (see the rbuVfsOpen() function) and the *-oal
  **      file opened instead.
  *//*
** Delete the file located at zPath.
*//* The xOpen() operation has succeeded. Set the sqlite3_file.pMethods
    ** pointer and, if the file is a main database file, link it into the
    ** mutex protected linked list of all such files.  *//* This call is to open a *-wal file. Intead, open the *-oal. *//* A main database has just been opened. The following block sets
      ** (pFd->zWal) to point to a buffer owned by SQLite that contains
      ** the name of the *-wal file this db connection will use. SQLite
      ** happens to pass a pointer to this buffer when using xAccess()
      ** or xOpen() to operate on the *-wal file.  *//* xFetch, xUnfetch *//*
** Open an rbu file handle.
*//* Release the checkpointer and writer locks *//*
** The xShmUnmap method.
*//*
** Memory barrier.
*//* This is an RBU connection that uses its own heap memory for the
    ** pages of the *-shm file. Since no other process can have run
    ** recovery, the connection must request *-shm pages in order
    ** from start to finish.  *//* If not in RBU_STAGE_OAL, allow this call to pass through. Or, if this
  ** rbu is in the RBU_STAGE_OAL state, use heap memory for *-shm space
  ** instead of a file on disk.  *//*
** Obtain a pointer to a mapping of a single 32KiB page of the *-shm file.
*//* Prevent SQLite from taking a shm-lock on the target file when it
    ** is supplying heap memory to the upper layer in place of *-shm
    ** segments. *//*
** Take or release a shared-memory lock.
*//*
** Return the device characteristic flags supported by an rbuVfs-file.
*//*
** Return the sector-size in bytes for an rbuVfs-file.
*//* Now search for a zipvfs instance lower down in the VFS stack. If
      ** one is found, this is an error.  *//* First try to find another RBU vfs lower down in the vfs stack. If
    ** one is found, this vfs will operate in pass-through mode. The lower
    ** level vfs will do the special RBU handling.  *//*
** File control method. For custom operations on an rbuVfs-file.
*//*
** Check if another file-handle holds a RESERVED lock on an rbuVfs-file.
*//*
** Unlock an rbuVfs-file.
*//* Do not allow EXCLUSIVE locks. Preventing SQLite from taking this
    ** prevents it from checkpointing the database from sqlite3_close(). *//*
** Lock an rbuVfs-file.
*//* If this is an RBU vacuum operation and this is the target database,
  ** pretend that it has at least one page. Otherwise, SQLite will not
  ** check for the existance of a *-wal file. rbuVfsRead() contains
  ** similar logic.  *//*
** Return the current file-size of an rbuVfs-file.
*//*
** Sync an rbuVfs-file.
*//*
** Truncate an rbuVfs-file.
*//* These look like magic numbers. But they are stable, as they are part
      ** of the definition of the SQLite file format, which may not change. *//*
** Write data to an rbuVfs-file.
*//* These look like magic numbers. But they are stable, as they are part
       ** of the definition of the SQLite file format, which may not change. *//* Change counter *//* size of db file in pages *//* first page on free list trunk *//* number of free pages *//* largest root page number *//* If this is being called to read the first page of the target
      ** database as part of an rbu vacuum operation, synthesize the
      ** contents of the first page if it does not yet exist. Otherwise,
      ** SQLite will not check for a *-wal file.  *//*
** Read data from an rbuVfs-file.
*//*
** Write an unsigned 32-bit value in big-endian format to the supplied
** buffer.
*//*
** Read and return an unsigned 32-bit big-endian integer from the buffer
** passed as the only argument.
*//* Close the underlying file handle *//* Free the contents of the apShm[] array. And the array itself. *//*
** Close an rbu file.
*//*
** Given that zWal points to a buffer containing a wal file name passed to
** either the xOpen() or xAccess() VFS method, search the main-db list for
** a file-handle opened by the same database connection on the corresponding
** database file.
**
** If parameter bRbu is true, only search for file-descriptors with
** rbu_file.pDb!=0.
*//*
** Remove an item from the main-db lists.
*//*
** Add an item to the main-db lists, if it is not already present.
**
** There are two main-db lists. One for all file descriptors, and one
** for all file descriptors with rbu_file.pDb!=0. If the argument has
** rbu_file.pDb!=0, then it is assumed to already be present on the
** main list and is only added to the pDb!=0 list.
*//*
*//**************************************************************************
** Beginning of RBU VFS shim methods. The VFS shim modifies the behaviour
** of a standard VFS in the following ways:
**
** 1. Whenever the first page of a main database file is read or
**    written, the value of the change-counter cookie is stored in
**    rbu_file.iCookie. Similarly, the value of the "write-version"
**    database header field is stored in rbu_file.iWriteVer. This ensures
**    that the values are always trustworthy within an open transaction.
**
** 2. Whenever an SQLITE_OPEN_WAL file is opened, the (rbu_file.pWalFd)
**    member variable of the associated database file descriptor is set
**    to point to the new file. A mutex protected linked list of all main
**    db fds opened using a particular RBU VFS is maintained at
**    rbu_vfs.pMain to facilitate this.
**
** 3. Using a new file-control "SQLITE_FCNTL_RBU", a main db rbu_file
**    object can be marked as the target database of an RBU update. This
**    turns on the following extra special behaviour:
**
** 3a. If xAccess() is called to check if there exists a *-wal file
**     associated with an RBU target database currently in RBU_STAGE_OAL
**     stage (preparing the *-oal file), the following special handling
**     applies:
**
**      * if the *-wal file does exist, return SQLITE_CANTOPEN. An RBU
**        target database may not be in wal mode already.
**
**      * if the *-wal file does not exist, set the output parameter to
**        non-zero (to tell SQLite that it does exist) anyway.
**
**     Then, when xOpen() is called to open the *-wal file associated with
**     the RBU target in RBU_STAGE_OAL stage, instead of opening the *-wal
**     file, the rbu vfs opens the corresponding *-oal file instead.
**
** 3b. The *-shm pages returned by xShmMap() for a target db file in
**     RBU_STAGE_OAL mode are actually stored in heap memory. This is to
**     avoid creating a *-shm file on disk. Additionally, xShmLock() calls
**     are no-ops on target database files in RBU_STAGE_OAL mode. This is
**     because assert() statements in some VFS implementations fail if
**     xShmLock() is called before xShmMap().
**
** 3c. If an EXCLUSIVE lock is attempted on a target database file in any
**     mode except RBU_STAGE_DONE (all work completed and checkpointed), it
**     fails with an SQLITE_BUSY error. This is to stop RBU connections
**     from automatically checkpointing a *-wal (or *-oal) file from within
**     sqlite3_close().
**
** 3d. In RBU_STAGE_CAPTURE mode, all xRead() calls on the wal file, and
**     all xWrite() calls on the target database file perform no IO.
**     Instead the frame and page numbers that would be read and written
**     are recorded. Additionally, successful attempts to obtain exclusive
**     xShmLock() WRITER, CHECKPOINTER and READ0 locks on the target
**     database file are recorded. xShmLock() calls to unlock the same
**     locks are no-ops (so that once obtained, these locks are never
**     relinquished). Finally, calls to xSync() on the target database
**     file fail with SQLITE_NOTICE errors.
*//*
** Default xRename callback for RBU.
*//* Sync the db file *//*
** Return the current state of the RBU vacuum or update operation.
*//*
** Return permyriadage progress indications for the two main stages of
** an RBU update.
*//*
** Return the total number of key-value operations (inserts, deletes or
** updates) that have been performed on the target database since the
** current RBU update was started.
*//* Close the open database handle and VFS object. *//* If this is an RBU vacuum handle and the vacuum has either finished
    ** successfully or encountered an error, delete the contents of the
    ** state table. This causes the next call to sqlite3rbu_vacuum()
    ** specifying the current target and state databases to start a new
    ** vacuum from scratch.  *//* Close any open statement handles. *//* Sync the db file if currently doing an incremental checkpoint *//* Commit the transaction to the *-oal file. *//*
** Close the RBU handle.
*//*
** If the error code currently stored in the RBU handle is SQLITE_CONSTRAINT,
** then edit any error message string so as to remove all occurrences of
** the pattern "rbu_imp_[0-9]*".
*//*
** Return the database handle used by pRbu.
*//* TODO: Check that both arguments are non-NULL *//*
** Open a handle to begin or resume an RBU VACUUM operation.
*//*
** Open and return a new RBU handle.
*//*
** Allocate and return an RBU handle with all fields zeroed except for the
** error code, which is set to SQLITE_MISUSE.
*//* If the rbu_exclusive_checkpoint=1 URI parameter was specified
          ** and an incremental checkpoint is being resumed, attempt an
          ** exclusive lock on the db file. If this fails, so be it.  *//* Check if the main database is a zipvfs db. If it is, set the upper
          ** level pager to use "journal_mode=off". This prevents it from
          ** generating a large journal using a temp file.  *//* Open transactions both databases. The *-oal file is opened or
          ** created at this point. *//* If the RBU database contains no data_xxx tables, declare the RBU
        ** update finished.  *//* Point the object iterator at the first object *//* At this point (pTargetFd->iCookie) contains the value of the
        ** change-counter cookie (the thing that gets incremented when a
        ** transaction is committed in rollback mode) currently stored on
        ** page 1 of the database file. *//* If the first attempt to open the database file fails and the bRetry
      ** flag it set, this means that the db was not opened because it seemed
      ** to be a wal-mode db. But, this may have happened due to an earlier
      ** RBU vacuum operation leaving an old wal file in the directory.
      ** If this is the case, it will have been checkpointed and deleted
      ** when the handle was closed and a second attempt to open the
      ** database may succeed.  *//* Open the target, RBU and state databases *//* Create the custom VFS. *//* Check for the rbu_count table. If it does not exist, or if an error
    ** occurs, nPhaseOneStep will be left set to -1. *//* True if rbu_count exists *//*
** If the RBU database contains the rbu_count table, use it to initialize
** the sqlite3rbu.nPhaseOneStep variable. The schema of the rbu_count table
** is assumed to contain the same columns as:
**
**   CREATE TABLE rbu_count(tbl TEXT PRIMARY KEY, cnt INTEGER) WITHOUT ROWID;
**
** There should be one row in the table for each data_xxx table in the
** database. The 'tbl' column should contain the name of a data_xxx table,
** and the cnt column the number of rows it contains.
**
** sqlite3rbu.nPhaseOneStep is initialized to the sum of (1 + nIndex) * cnt
** for all rows in the rbu_count table, where nIndex is the number of
** indexes on the corresponding target database table.
*//*
** This user-defined SQL function is invoked with a single argument - the
** name of a table expected to appear in the target database. It returns
** the number of auxilliary indexes on the table.
*//*
** Destroy the private VFS created for the rbu handle passed as the only
** argument by an earlier call to rbuCreateVfs().
*//*
** Allocate a private rbu VFS for the rbu handle passed as the only
** argument. This VFS will be used unless the call to sqlite3rbu_open()
** specified a URI with a vfs=? option in place of a target database
** file name.
*//*
** If there is a "*-oal" file in the file-system corresponding to the
** target database in the file-system, delete it. If an error occurs,
** leave an error code and error message in the rbu handle.
*//*
** This function is called as part of sqlite3rbu_open() when initializing
** an rbu handle in OAL stage. If the rbu update has not started (i.e.
** the rbu_state table was empty) it is a no-op. Otherwise, it arranges
** things so that the next call to sqlite3rbu_step() continues on from
** where the previous rbu handle left off.
**
** If an error occurs, an error code and error message are left in the
** rbu handle passed as the first argument.
*//*
** Compare strings z1 and z2, returning 0 if they are identical, or non-zero
** otherwise. Either or both argument may be NULL. Two NULL values are
** considered equal, and NULL is considered distinct from all other values.
*//* At one point the following block copied a single frame from the
            ** wal file to the database file. So that one call to sqlite3rbu_step()
            ** checkpointed a single frame.
            **
            ** However, if the sector-size is larger than the page-size, and the
            ** application calls sqlite3rbu_savestate() or close() immediately
            ** after this step, then rbu_step() again, then a power failure occurs,
            ** then the database page written here may be damaged. Work around
            ** this by checkpointing frames until the next page in the aFrame[]
            ** lies on a different disk sector to the current one. *//* Update nBackfill *//* Advance to the next row to process. *//* Clean up the rbu_tmp_xxx table for the previous table. It
            ** cannot be dropped as there are currently active SQL statements.
            ** But the contents can be deleted.  *//* If this is an RBU vacuum operation and the state table was empty
        ** when this handle was opened, create the target database schema. *//*
** Step the RBU object.
*//*
** The RBU handle passed as the only argument has just been opened and
** the state database is empty. If this RBU handle was opened for an
** RBU vacuum operation, create the schema in the target db.
*//*
** The second argument passed to this function is the name of a PRAGMA
** setting - "page_size", "auto_vacuum", "user_version" or "application_id".
** This function executes the following on sqlite3rbu.dbRbu:
**
**   "PRAGMA main.$zPragma"
**
** where $zPragma is the string passed as the second argument, then
** on sqlite3rbu.dbMain:
**
**   "PRAGMA main.$zPragma = $val"
**
** where $val is the value returned by the first PRAGMA invocation.
**
** In short, it copies the value  of the specified PRAGMA setting from
** dbRbu to dbMain.
*//*
** Update the contents of the rbu_state table within the rbu database. The
** value stored in the RBU_STATE_STAGE column is eStage. All other values
** are determined by inspecting the rbu handle passed as the first argument.
*//* Coverage: it may be that this sqlite3_step() cannot fail. There
      ** is already a transaction open, so the prepared statement cannot
      ** throw an SQLITE_SCHEMA exception. The only database page the
      ** statement reads is page 1, which is guaranteed to be in the cache.
      ** And no memory allocations are required.  *//*
** Increment the schema cookie of the main database opened by p->dbMain.
**
** Or, if this is an RBU vacuum, set the schema cookie of the main db
** opened by p->dbMain to one more than the schema cookie of the main
** db opened by p->dbRbu.
*//* Bind the rbu_rowid value to column _rowid_ *//*
** This function does the work for an sqlite3rbu_step() call.
**
** The object-iterator (p->objiter) currently points to a valid object,
** and the input cursor (p->objiter.pSelect) currently points to a valid
** input row. Perform whatever processing is required and return.
**
** If no  error occurs, SQLITE_OK is returned. Otherwise, an error code
** and message is left in the RBU handle and a copy of the error code
** returned.
*//* For a virtual table, or a table with no primary key, the
      ** SELECT statement is:
      **
      **   SELECT <cols>, rbu_control, rbu_rowid FROM ....
      **
      ** Hence column_value(pIter->nCol+1).
      *//* If this is an INSERT into a table b-tree and the table has an
    ** explicit INTEGER PRIMARY KEY, check that this is not an attempt
    ** to write a NULL into the IPK column. That is not permitted.  *//* If this is a delete, decrement nPhaseOneStep by nIndex. If the DELETE
  ** statement below does actually delete a row, nPhaseOneStep will be
  ** incremented by the same amount when SQL function rbu_tmp_insert()
  ** is invoked by the trigger.  *//*
** Argument eType must be one of RBU_INSERT, RBU_DELETE, RBU_IDX_INSERT or
** RBU_IDX_DELETE. This function performs the work of a single
** sqlite3rbu_step() call for the type of operation specified by eType.
*//*
** Assert that column iCol of statement pStmt is named zName.
*//* Index of rbu_control column *//*
** The SELECT statement iterating through the keys for the current object
** (p->objiter.pSelect) currently points to a valid row. This function
** determines the type of operation requested by this row and returns
** one of the following values to indicate the result:
**
**     * RBU_INSERT
**     * RBU_DELETE
**     * RBU_IDX_DELETE
**     * RBU_UPDATE
**
** If RBU_UPDATE is returned, then output variable *pzMask is set to
** point to the text value indicating the columns to update.
**
** If the rbu_control field contains an invalid value, an error code and
** message are left in the RBU handle and zero returned.
*//* Re-open the databases. *//* Move the *-oal file to *-wal. At this point connection p->db is
    ** holding a SHARED lock on the target database file (because it is
    ** in WAL mode). So no other connection may be writing the db.
    **
    ** In order to ensure that there are no database readers, an EXCLUSIVE
    ** lock is obtained here before the *-oal is moved to *-wal.
    *//*
** The RBU handle is currently in RBU_STAGE_OAL state, with a SHARED lock
** on the database file. This proc moves the *-oal file to the *-wal path,
** then reopens the database file (this time in vanilla, non-oal, WAL mode).
** If an error occurs, leave an error code and error message in the rbu
** handle.
*//*
** Return true if the database handle passed as the only argument
** was opened with the rbu_exclusive_checkpoint=1 URI parameter
** specified. Or false otherwise.
*//*
** Take an EXCLUSIVE lock on the database file. Return SQLITE_OK if
** successful, or an SQLite error code otherwise.
*//*
** This value is copied from the definition of ZIPVFS_CTRL_FILE_POINTER
** in zipvfs.h.
*//*
** This is called as part of an incremental checkpoint operation. Copy
** a single frame of data from the wal file into the database file, as
** indicated by the RbuFrame object.
*//*
** Called when a page of data is written to offset iOff of the database
** file while the rbu handle is in capture mode. Record the page number
** of the page being written in the aFrame[] array.
*//*
** Called when iAmt bytes are read from offset iOff of the wal file while
** the rbu object is in capture mode. Record the frame number of the frame
** being read in the aFrame[] array.
*//* Call xSync() on the wal file. This causes SQLite to sync the
      ** directory in which the target database and the wal file reside, in
      ** case it has not been synced since the rename() call in
      ** rbuMoveOalFile(). *//* Assuming no error has occurred, run a "restart" checkpoint with the
  ** sqlite3rbu.eStage variable set to CAPTURE. This turns on the following
  ** special behaviour in the rbu VFS:
  **
  **   * If the exclusive shm WRITER or READ0 lock cannot be obtained,
  **     the checkpoint fails with SQLITE_BUSY (normally SQLite would
  **     proceed with running a passive checkpoint instead of failing).
  **
  **   * Attempts to read from the *-wal file or write to the database file
  **     do not perform any IO. Instead, the frame/page combinations that
  **     would be read/written are recorded in the sqlite3rbu.aFrame[]
  **     array.
  **
  **   * Calls to xShmLock(UNLOCK) to release the exclusive shm WRITER,
  **     READ0 and CHECKPOINT locks taken as part of the checkpoint are
  **     no-ops. These locks will not be released until the connection
  **     is closed.
  **
  **   * Attempting to xSync() the database file causes an SQLITE_NOTICE
  **     error.
  **
  ** As a result, unless an error (i.e. OOM or SQLITE_BUSY) occurs, the
  ** checkpoint below fails with SQLITE_NOTICE, and leaves the aFrame[]
  ** array populated with a set of (frame -> page) mappings. Because the
  ** WRITER, CHECKPOINT and READ0 locks are still held, it is safe to copy
  ** data from the wal file into the database file according to the
  ** contents of aFrame[].
  *//* If pState is NULL, then the wal file may not have been opened and
  ** recovered. Running a read-statement here to ensure that doing so
  ** does not interfere with the "capture" process below.  *//*
** This function is called as part of initializing or reinitializing an
** incremental checkpoint.
**
** It populates the sqlite3rbu.aFrame[] array with the set of
** (wal frame -> db page) copy operations required to checkpoint the
** current wal file, and obtains the set of shm locks required to safely
** perform the copy operations directly on the file-system.
**
** If argument pState is not NULL, then the incremental checkpoint is
** being resumed. In this case, if the checksum of the wal-index-header
** following recovery is not the same as the checksum saved in the RbuState
** object, then the rbu handle is set to DONE state. This occurs if some
** other client appends a transaction to the wal file in the middle of
** an incremental checkpoint.
*//*
** Return the current wal-index header checksum for the target database
** as a 64-bit integer.
**
** The checksum is store in the first page of xShmMap memory as an 8-byte
** blob starting at byte offset 40.
*//*
** This routine is a copy of the sqlite3FileSuffix3() routine from the core.
** It is a no-op unless SQLITE_ENABLE_8_3_NAMES is defined.
**
** If SQLITE_ENABLE_8_3_NAMES is set at compile-time and if the database
** filename in zBaseFilename is a URI with the "8_3_names=1" parameter and
** if filename in z[] has a suffix (a.k.a. "extension") that is longer than
** three characters, then shorten the suffix on z[] to be the last three
** characters of the original suffix.
**
** If SQLITE_ENABLE_8_3_NAMES is set to 2 at compile-time, then always
** do the suffix shortening regardless of URI parameter.
**
** Examples:
**
**     test.db-journal    =>   test.nal
**     test.db-wal        =>   test.wal
**     test.db-shm        =>   test.shm
**     test.db-mj7f3319fa =>   test.9fa
*//* Mark the database file just opened as an RBU target database. If
  ** this call returns SQLITE_NOTFOUND, then the RBU vfs is not in use.
  ** This is an error.  *//* If it has not already been created, create the rbu_state table *//* If using separate RBU and state databases, attach the state database to
  ** the RBU db handle now.  *//* Open the RBU database *//*
** Open the database handle and attach the RBU database as "rbu". If an
** error occurs, leave an error code and message in the RBU handle.
**
** If argument dbMain is not NULL, then it is a database handle already
** open on the target database. Use this handle instead of opening a new
** one.
*//*
** Allocate an RbuState object and load the contents of the rbu_state
** table into it. Return a pointer to the new object. It is the
** responsibility of the caller to eventually free the object using
** sqlite3_free().
**
** If an error occurs, leave an error code and message in the rbu handle
** and return NULL.
*//*
** Free an RbuState object allocated by rbuLoadState().
*//* Search for an existing statement. If one is found, shift it to the front
  ** of the LRU queue and return immediately. Otherwise, leave nUp pointing
  ** to the number of statements currently in the cache and pUp to the
  ** last object in the list.  *//* In case an error occurs *//* OUT: UPDATE statement handle *//* rbu_control value ('x.x.') *//* Object iterator *//* RBU handle *//*
** Set output variable *ppStmt to point to an UPDATE statement that may
** be used to update the imposter table for the main table b-tree of the
** table object that pIter currently points to, assuming that the
** rbu_control column of the data_xyz table contains zMask.
**
** If the zMask string does not specify any columns to update, then this
** is not an error. Output variable *ppStmt is set to NULL in this case.
*//* Create the SELECT statement to read keys from data_xxx *//* Create the rbu_tmp_xxx table and the triggers to populate it. *//* Create the DELETE statement to write to the target PK b-tree.
      ** Because it only performs INSERT operations, this is not required for
      ** an rbu vacuum handle.  *//* Create the INSERT statement to write to the target PK b-tree *//* Create the imposter table or tables (if required). *//* Imposter table name *//* Table this step applies to *//* Create the SELECT statement to read keys in sorted order *//* And to delete index entries *//* Create the statement to insert index entries *//* Create the imposter table used to write to this index. *//* WHERE clause on PK columns *//* Primary key declaration for imposter *//* Columns for imposter table *//* List of indexed columns *//* Add "LIMIT -1 OFFSET $nOffset" to SELECT *//*
** Ensure that the SQLite statement handles required to update the
** target database object currently indicated by the iterator passed
** as the second argument are available.
*//* If necessary, grow the pIter->aIdxCol[] array *//* Number of open parenthesis *//*
** Prepare a statement used to insert rows into the "rbu_tmp_xxx" table.
** Specifically a statement of the form:
**
**     INSERT INTO rbu_tmp_xxx VALUES(?, ?, ? ...);
**
** The number of bound variables is equal to the number of columns in
** the target table, plus one (for the rbu_control column), plus one more
** (for the rbu_rowid column) if the target table is an implicit IPK or
** virtual table.
*//* If the target table column is an "INTEGER PRIMARY KEY", add
        ** "PRIMARY KEY" to the imposter table column declaration. *//*
** If an error has already occurred when this function is called, it
** immediately returns zero (without doing any work). Or, if an error
** occurs during the execution of this function, it sets the error code
** in the sqlite3rbu object indicated by the first argument and returns
** zero.
**
** The iterator passed as the second argument is guaranteed to point to
** a table (not an index) when this function is called. This function
** attempts to create any imposter table required to write to the main
** table b-tree of the table before returning. Non-zero is returned if
** an imposter table are created, or zero otherwise.
**
** An imposter table is required in all cases except RBU_PK_VTAB. Only
** virtual tables are written to directly. The imposter table has the
** same schema as the actual target table (less any UNIQUE constraints).
** More precisely, the "same schema" means the same columns, types,
** collation sequences. For tables that do not have an external PRIMARY
** KEY, it also means the same PRIMARY KEY declaration.
*//* Figure out the name of the primary key index for the current table.
    ** This is needed for the argument to "PRAGMA index_xinfo". Set
    ** zIdx to point to a nul-terminated string containing this name. *//* Used to build up table PK declaration *//* Used to build up list of table cols *//* PRAGMA main.index_xinfo = $zIdx *//* Name of PK index *//* SELECT name ... WHERE rootpage = $tnum *//* Root page of PK index *//*
** This function creates the second imposter table used when writing to
** a table b-tree where the table has an external primary key. If the
** iterator passed as the second argument does not currently point to
** a table (not index) with an external primary key, this function is a
** no-op.
**
** Assuming the iterator does point to a table with an external PK, this
** function creates a WITHOUT ROWID imposter table named "rbu_imposter2"
** used to access that PK index. For example, if the target table is
** declared as follows:
**
**   CREATE TABLE t1(a, b TEXT, c REAL, PRIMARY KEY(b, c));
**
** then the imposter table schema is:
**
**   CREATE TABLE rbu_imposter2(c1 TEXT, c2 REAL, id INTEGER) WITHOUT ROWID;
**
*//* int iCid = sqlite3_column_int(pXInfo, 0); *//* PRAGMA index_xinfo = <pk-index> *//* PRAGMA index_list = (pIter->zTbl) *//*
** The iterator currently points to a table (not index) of type
** RBU_PK_WITHOUT_ROWID. This function creates the PRIMARY KEY
** declaration for the corresponding imposter table. For example,
** if the iterator points to a table created as:
**
**   CREATE TABLE t1(a, b, c, PRIMARY KEY(b, a DESC)) WITHOUT ROWID
**
** this function returns:
**
**   PRIMARY KEY("b", "a" DESC)
*//*
** Return a nul-terminated string consisting of nByte comma separated
** "?" expressions. For example, if nByte is 3, return a pointer to
** a buffer containing the string "?,?,?".
**
** The memory for the returned string is obtained from sqlite3_malloc().
** It is the responsibility of the caller to eventually free it using
** sqlite3_free().
**
** If an OOM error is encountered when allocating space for the new
** string, an error code is left in the rbu handle passed as the first
** argument and NULL is returned. Or, if an error has already occurred
** when this function is called, NULL is returned immediately, without
** attempting the allocation or modifying the stored error code.
*//*
** Return a nul-terminated string containing the comma separated list of
** assignments that should be included following the "SET" keyword of
** an UPDATE statement used to update the table object that the iterator
** passed as the second argument currently points to if the rbu_control
** column of the data_xxx table entry is set to zMask.
**
** The memory for the returned string is obtained from sqlite3_malloc().
** It is the responsibility of the caller to eventually free it using
** sqlite3_free().
**
** If an OOM error is encountered when allocating space for the new
** string, an error code is left in the rbu handle passed as the first
** argument and NULL is returned. Or, if an error has already occurred
** when this function is called, NULL is returned immediately, without
** attempting the allocation or modifying the stored error code.
*//*
** The SELECT statement iterating through the keys for the current object
** (p->objiter.pSelect) currently points to a valid row. However, there
** is something wrong with the rbu_control value in the rbu_control value
** stored in the (p->nCol+1)'th column. Set the error code and error message
** of the RBU handle to something reflecting this.
*//*
** Return an expression that can be used in a WHERE clause to match the
** primary key of the current table. For example, if the table is:
**
**   CREATE TABLE t1(a, b, c, PRIMARY KEY(b, c));
**
** Return the string:
**
**   "b = ?1 AND c = ?2"
*//* For a table with implicit rowids, append "old._rowid_" to the list. *//*
** Assuming the current table columns are "a", "b" and "c", and the zObj
** paramter is passed "old", return a string of the form:
**
**     "old.a, old.b, old.b"
**
** With the column names escaped.
**
** For tables with implicit rowids - RBU_PK_EXTERNAL and RBU_PK_NONE, append
** the text ", old._rowid_" to the returned value.
*//* An integer primary key. If the table has an explicit IPK, use
        ** its name. Otherwise, use "rbu_rowid".  *//* PRAGMA index_xinfo = ? *//* Set to " AND " later on *//* Set to ", " later on *//* Value to return via *pnBind *//* String to return via *pzWhere *//* String to return via *pzImposterPK *//* String to return via *pzImposterCols *//* String to return *//* sqlite3_finalize() return code *//* OUT: Trbul number of columns *//* OUT: WHERE clause *//* OUT: Imposter PK clause *//* OUT: Columns for imposter table *//* Object iterator for column names *//* RBU object *//*
** This function is used to create a SELECT list (the list of SQL
** expressions that follows a SELECT keyword) for a SELECT statement
** used to read from an data_xxx or rbu_tmp_xxx table while updating the
** index object currently indicated by the iterator object passed as the
** second argument. A "PRAGMA index_xinfo = <idxname>" statement is used
** to obtain the required information.
**
** If the index is of the following form:
**
**   CREATE INDEX i1 ON t1(c, b COLLATE nocase);
**
** and "t1" is a table with an explicit INTEGER PRIMARY KEY column
** "ipk", the returned string is:
**
**   "`c` COLLATE 'BINARY', `b` COLLATE 'NOCASE', `ipk` COLLATE 'BINARY'"
**
** As well as the returned string, three other malloc'd strings are
** returned via output parameters. As follows:
**
**   pzImposterCols: ...
**   pzImposterPk: ...
**   pzWhere: ...
*//* RBU iterator object *//*
** This function is called as part of restating an RBU vacuum when the
** current operation is writing content to an index. If possible, it
** queries the target index b-tree for the largest key already written to
** it, then composes and returns an expression that can be used in a WHERE
** clause to select the remaining required rows from the source table.
** It is only possible to return such an expression if:
**
**   * The index contains no DESC columns, and
**   * The last key written to the index before the operation was
**     suspended does not contain any NULL values.
**
** The expression is of the form:
**
**   (index-field1, index-field2, ...) > (?, ?, ...)
**
** except that the "?" placeholders are replaced with literal values.
**
** If the expression cannot be created, NULL is returned. In this case,
** the caller has to use an OFFSET clause to extract only the required
** rows from the sourct table, just as it does for an RBU update operation.
*//* Target table name prefix *//* True for a rowid table *//*
** This function is called as part of restarting an RBU vacuum within
** stage 1 of the process (while the *-oal file is being built) while
** updating a table (not an index). The table may be a rowid table or
** a WITHOUT ROWID table. It queries the target database to find the
** largest key that has already been written to the target table and
** constructs a WHERE clause that can be used to extract the remaining
** rows from the source table. For a rowid table, the WHERE clause
** is of the form:
**
**     "WHERE _rowid_ > ?"
**
** and for WITHOUT ROWID tables:
**
**     "WHERE (key1, key2) > (?, ?)"
**
** Instead of "?" placeholders, the actual WHERE clauses created by
** this function contain literal SQL values.
*//* After each quoted column name *//* Separator to use between columns *//* Before each quoted column name *//*
** Return a comma separated list of the quoted PRIMARY KEY column names,
** in order, for the current table. Before each column name, add the text
** zPre. After each column name, add the zPost text. Use zSeparator as
** the separator text (usually ", ").
*//*
** This function constructs and returns a pointer to a nul-terminated
** string containing some SQL clause or list based on one or more of the
** column names currently stored in the pIter->azTblCol[] array.
*//* An OOM - finalize() below returns S_NOMEM *//* Check that all non-HIDDEN columns in the destination table are also
    ** present in the input table. Populate the abTblPk[], azTblType[] and
    ** aiTblOrder[] arrays at the same time.  *//* Populate the azTblCol[] and nTblCol variables based on the columns
    ** of the input table. Ignore any input table columns that begin with
    ** "rbu_".  *//* Figure out the type of table this step will deal with. *//* If input table has column "rbu_rowid" *//* for() loop iterator variable *//*
** If they are not already populated, populate the pIter->azTblCol[],
** pIter->abTblPk[], pIter->nTblCol and pIter->bRowid variables according to
** the table (not index) that the iterator currently points to.
**
** Return SQLITE_OK if successful, or an SQLite error code otherwise. If
** an error does occur, an error code and error message are also left in
** the RBU handle.
*//* "PRAGMA index_list" includes the main PK b-tree *//*
** This is a helper function for rbuObjIterCacheTableInfo(). It populates
** the pIter->abIndexed[] array.
*//* explicit IPK column *//* virtual table *//* Either an error, or no such table. *//*
  ** 0) SELECT count(*) FROM sqlite_schema where name=%Q AND IsVirtual(%Q)
  ** 1) PRAGMA index_list = ?
  ** 2) SELECT count(*) FROM sqlite_schema where name=%Q
  ** 3) PRAGMA table_info = ?
  *//* Determine the type of a table.
**
**   peType is of type (int*), a pointer to an output parameter of type
**   (int). This call sets the output parameter as follows, depending
**   on the type of the table specified by parameters dbName and zTbl.
**
**     RBU_PK_NOTABLE:       No such table.
**     RBU_PK_NONE:          Table has an implicit rowid.
**     RBU_PK_IPK:           Table has an explicit IPK column.
**     RBU_PK_EXTERNAL:      Table has an external PK index.
**     RBU_PK_WITHOUT_ROWID: Table is WITHOUT ROWID.
**     RBU_PK_VTAB:          Table is a virtual table.
**
**   Argument *piPk is also of type (int*), and also points to an output
**   parameter. Unless the table has an external primary key index
**   (i.e. unless *peType is set to 3), then *piPk is set to zero. Or,
**   if the table does have an external primary key index, then *piPk
**   is set to the root page number of the primary key index before
**   returning.
**
** ALGORITHM:
**
**   if( no entry exists in sqlite_schema ){
**     return RBU_PK_NOTABLE
**   }else if( sql for the entry starts with "CREATE VIRTUAL" ){
**     return RBU_PK_VTAB
**   }else if( "PRAGMA index_list()" for the table contains a "pk" index ){
**     if( the index that is the pk exists in sqlite_schema ){
**       *piPK = rootpage of that index.
**       return RBU_PK_EXTERNAL
**     }else{
**       return RBU_PK_WITHOUT_ROWID
**     }
**   }else if( "PRAGMA table_info()" lists one or more "pk" columns ){
**     return RBU_PK_IPK
**   }else{
**     return RBU_PK_NONE
**   }
*//*
** Finalize the statement passed as the second argument.
**
** If the sqlite3_finalize() call indicates that an error occurs, and the
** rbu handle error code is not already set, set the error code and error
** message accordingly.
*//*
** The first argument must be a nul-terminated string. This function
** returns a copy of the string in memory obtained from sqlite3_malloc().
** It is the responsibility of the caller to eventually free this memory
** using sqlite3_free().
**
** If an OOM condition is encountered when attempting to allocate memory,
** output variable (*pRc) is set to SQLITE_NOMEM before returning. Otherwise,
** if the allocation succeeds, (*pRc) is left unchanged.
*//*
** Allocate and zero the pIter->azTblCol[] and abTblPk[] arrays so that
** there is room for at least nCol elements. If an OOM occurs, store an
** error code in the RBU handle passed as the first argument.
*//*
** Attempt to allocate and return a pointer to a zeroed block of nByte
** bytes.
**
** If an error (i.e. an OOM condition) occurs, return NULL and leave an
** error code in the rbu handle passed as the first argument. Or, if an
** error has already occurred when this function is called, return NULL
** immediately without attempting the allocation or modifying the stored
** error code.
*//*
** Argument zFmt is a sqlite3_mprintf() style format string. The trailing
** arguments are the usual subsitution values. This function performs
** the printf() style substitutions and executes the result as an SQL
** statement on the RBU handles database.
**
** If an error occurs, an error code and error message is stored in the
** RBU handle. If an error has already occurred when this function is
** called, it is a no-op.
*//*
** This is a wrapper around "sqlite3_mprintf(zFmt, ...)". If an OOM occurs,
** an error code is stored in the RBU handle passed as the first argument.
**
** If an error has already occurred (p->rc is already set to something other
** than SQLITE_OK), then this function returns NULL without modifying the
** stored error code. In this case it still calls sqlite3_free() on any
** printf() parameters associated with %z conversions.
*//*
** Initialize the iterator structure passed as the second argument.
**
** If no error occurs, SQLITE_OK is returned and the iterator is left
** pointing to the first entry. Otherwise, an error code and message is
** left in the RBU handle passed as the first argument. A copy of the
** error code is returned.
*//*
** The implementation of the rbu_target_name() SQL function. This function
** accepts one or two arguments. The first argument is the name of a table -
** the name of a table in the RBU database.  The second, if it is present, is 1
** for a view or 0 for a table.
**
** For a non-vacuum RBU handle, if the table name matches the pattern:
**
**     data[0-9]_<name>
**
** where <name> is any sequence of 1 or more characters, <name> is returned.
** Otherwise, if the only argument does not match the above pattern, an SQL
** NULL is returned.
**
**     "data_t1"     -> "t1"
**     "data0123_t2" -> "t2"
**     "dataAB_t3"   -> NULL
**
** For an rbu vacuum handle, a copy of the first argument is returned if
** the second argument is either missing or 0 (not a view).
*//* Free any SQLite statements used while processing the previous object *//*
** Advance the iterator to the next position.
**
** If no error occurs, SQLITE_OK is returned and the iterator is left
** pointing to the next entry. Otherwise, an error code and message is
** left in the RBU handle passed as the first argument. A copy of the
** error code is returned.
*//*
** Clean up any resources allocated as part of the iterator object passed
** as the only argument.
*//*
** Finalize all statements and free all allocations that are specific to
** the current object (table/index pair).
*//* Invalid value *//*
** Free the RbuObjIter.azTblCol[] and RbuObjIter.abTblPk[] arrays allocated
** by an earlier call to rbuObjIterCacheTableInfo().
*//*
** Unless it is NULL, argument zSql points to a buffer allocated using
** sqlite3_malloc containing an SQL statement. This function prepares the SQL
** statement against database db and frees the buffer. If statement
** compilation is successful, *ppStmt is set to point to the new statement
** handle and SQLITE_OK is returned.
**
** Otherwise, if an error occurs, *ppStmt is set to NULL and an error code
** returned. In this case, *pzErrmsg may also be set to point to an error
** message. It is the responsibility of the caller to free this error message
** buffer using sqlite3_free().
**
** If argument zSql is NULL, this function assumes that an OOM has occurred.
** In this case SQLITE_NOMEM is returned and *ppStmt set to NULL.
*//*
** Reset the SQL statement passed as the first argument. Return a copy
** of the value returned by sqlite3_reset().
**
** If an error has occurred, then set *pzErrmsg to point to a buffer
** containing an error message. It is the responsibility of the caller
** to eventually free this buffer using sqlite3_free().
*//*
** Prepare the SQL statement in buffer zSql against database handle db.
** If successful, set *ppStmt to point to the new statement and return
** SQLITE_OK.
**
** Otherwise, if an error does occur, set *ppStmt to NULL and return
** an SQLite error code. Additionally, set output variable *pzErrmsg to
** point to a buffer containing an error message. It is the responsibility
** of the caller to (eventually) free this buffer using sqlite3_free().
*//* Figure out the size of the output *//*
** Implementation of SQL scalar function rbu_fossil_delta().
**
** This function applies a fossil delta patch to a blob. Exactly two
** arguments must be passed to this function. The first is the blob to
** patch and the second the patch to apply. If no error occurs, this
** function returns the patched blob.
*//*
** End of code taken from fossil.
*************************************************************************//* ERROR: size integer not terminated by "\n" *//* ERROR: unterminated delta *//* ERROR: unknown delta operator *//* ERROR: generated size does not match predicted size *//* ERROR:  bad checksum *//* ERROR: insert count exceeds size of delta *//* ERROR:  insert command gives an output larger than predicted *//* ERROR: copy extends past end of input *//* ERROR: copy exceeds output file size *//* ERROR: copy command not terminated by ',' *//* Write the output into this preallocated buffer *//* Length of the delta *//* Delta to apply to the pattern *//* Length of the source file *//* The source or pattern file *//*
** Apply a delta.
**
** The output buffer should be big enough to hold the whole output
** file and a NUL terminator at the end.  The delta_output_size()
** routine will determine this size for you.
**
** The delta string should be null-terminated.  But the delta string
** may contain embedded NUL characters (if the input and output are
** binary files) so we also have to pass in the length of the delta in
** the lenDelta parameter.
**
** This function returns the size of the output file in bytes (excluding
** the final NUL terminator character).  Except, if the delta string is
** malformed or intended for use with a source file other than zSrc,
** then this routine returns -1.
**
** Refer to the delta_create() documentation above for a description
** of the delta file format.
*//*
** Compute a 32-bit checksum on the N-byte buffer.  Return the result.
*//*
** Read bytes from *pz and convert them into a positive integer.  When
** finished, leave *pz pointing to the first character past the end of
** the integer.  The *pLen parameter holds the length of the string
** in *pz and is decremented once for each character in the integer.
*//*************************************************************************
** The following three functions, found below:
**
**   rbuDeltaGetInt()
**   rbuDeltaChecksum()
**   rbuDeltaApply()
**
** are lifted from the fossil source code (http://fossil-scm.org). They
** are used to implement the scalar SQL function rbu_fossil_delta().
*//*
** True for an RBU vacuum handle, or false otherwise.
*//* Next MAIN_DB file with pRbu!=0 *//* Next MAIN_DB file *//* Wal file descriptor for this main db *//* Wal filename for this main db file *//* Delete this when closing file *//* Array of mmap'd *-shm regions *//* Number of entries in apShm[] array *//* True to fail EXCLUSIVE locks *//* "write-version" value for main db files *//* Cookie value for main db files *//* Flags this file was opened with *//* Size of file in bytes (temp only) *//* Pointer to rbu object (rbu target only) *//* Pointer to the rbu_vfs object *//* Underlying file handle *//* sqlite3_file methods *//*
** Each file opened by an rbu VFS is represented by an instance of
** the following structure.
**
** If this is a temporary file (pRbu!=0 && flags&DELETE_ON_CLOSE), variable
** "sz" is set to the current size of the database file.
*//* List of main db files with pRbu!=0 *//* List of main db files *//* Owner RBU object *//* Mutex to protect pMain *//* Underlying VFS *//* rbu VFS shim methods *//*
** An rbu VFS is implemented using an instance of this structure.
**
** Variable pRbu is only non-NULL for automatically created RBU VFS objects.
** It is NULL for RBU VFS objects created explicitly using
** sqlite3rbu_create_vfs(). It is used to track the total amount of temp
** space used by the RBU handle.
*//* Fd for main db of dbRbu *//* Number of RBU VFS in the stack *//* Used in RBU vacuum mode only *//* Total size limit for temp files *//* Current size of all temp files in use *//* Allocated size of aFrame[] array *//* Entries in aFrame[] array *//* Largest iWalFrame value in aFrame[] *//* The following state variables are used as part of the incremental
  ** checkpoint stage (eStage==RBU_STAGE_CKPT). See comments surrounding
  ** function rbuSetupCheckpoint() for details.  *//* Pages per sector for pTargetFd *//* File handle open on target db *//* Name of automatically created rbu vfs *//* Iterator for skipping through tbl/idx *//* Rows processed for all objects *//* Rows processed for current object *//* Error message if rc!=SQLITE_OK *//* Value returned by last rbu_step() call *//* Db name for state ("stat" or "main") *//* Path to state db (or NULL if zRbu) *//* Path to rbu db *//* Path to target db *//* rbu database handle *//* target database handle *//* Value of RBU_STATE_STAGE field *//*
** RBU handle.
**
** nPhaseOneStep:
**   If the RBU database contains an rbu_count table, this value is set to
**   a running estimate of the number of b-tree operations required to
**   finish populating the *-oal file. This allows the sqlite3_bp_progress()
**   API to calculate the permyriadage progress of populating the *-oal file
**   using the formula:
**
**     permyriadage = (10000 * nProgress) / nPhaseOneStep
**
**   nPhaseOneStep is initialized to the sum of:
**
**     nRow * (nIndex + 1)
**
**   for all source tables in the RBU database, where nRow is the number
**   of rows in the source table and nIndex the number of indexes on the
**   corresponding target database table.
**
**   This estimate is accurate if the RBU update consists entirely of
**   INSERT operations. However, it is inaccurate if:
**
**     * the RBU update contains any UPDATE operations. If the PK specified
**       for an UPDATE operation does not exist in the target table, then
**       no b-tree operations are required on index b-trees. Or if the
**       specified PK does exist, then (nIndex*2) such operations are
**       required (one delete and one insert on each index b-tree).
**
**     * the RBU update contains any DELETE operations for which the specified
**       PK does not exist. In this case no operations are required on index
**       b-trees.
**
**     * the RBU update contains REPLACE operations. These are similar to
**       UPDATE operations.
**
**   nPhaseOneStep is updated to account for the conditions above during the
**   first pass of each source table. The updated nPhaseOneStep value is
**   stored in the rbu_state table if the RBU update is suspended.
*//*
** The following macros are used to suppress compiler warnings and to
** make it clear to human readers when a function parameter is deliberately
** left unused within the body of a function. This usually happens when
** a function is called via a function pointer. For example the
** implementation of an SQL aggregate step callback may not use the
** parameter indicating the number of arguments passed to the aggregate,
** if it knows that this is enforced elsewhere.
**
** When a function parameter is not used at all within the body of a function,
** it is generally named "NotUsed" or "NotUsed2" to make things even clearer.
** However, these macros may also be used to suppress warnings related to
** parameters that may or may not be used depending on compilation options.
** For example those parameters only used in assert() statements. In these
** cases the parameters are named as per the usual conventions.
*//*
** A single step of an incremental checkpoint - frame iWalFrame of the wal
** file should be copied to page iDbPage of the database file.
*//* Update a row in a main table b-tree *//* Insert on an aux. index b-tree *//* Delete a row from an aux. index b-tree *//* Delete and then insert a row *//* Delete a row from a main table b-tree *//* Insert on a main table b-tree *//*
** Within the RBU_STAGE_OAL stage, each call to sqlite3rbu_step() performs
** one of the following operations.
*//*
** Values for RbuObjIter.eType
**
**     0: Table does not exist (error)
**     1: Table has an implicit rowid.
**     2: Table has an explicit IPK column.
**     3: Table has an external PK index.
**     4: Table is WITHOUT ROWID.
**     5: Table is a virtual table.
*//* Last UPDATE used (for PK b-tree updates only), or NULL. *//* Insert into rbu_tmp_$zDataTbl *//* Statement for DELETE ops *//* Statement for INSERT operations *//* Source data *//* Number of columns in current object *//* Statements created by rbuObjIterPrepareAll() *//* Number of aux. indexes on table zTbl *//* Current index is unique *//* If eType==EXTERNAL, root of PK index *//* Root page of current object *//* Name of target db index (or null) *//* Name of rbu db table (or null) *//* Name of target db table *//* True in "cleanup" state *//* Output variables. zTbl==0 implies EOF. *//* Table type - an RBU_PK_XXX value *//* Array of flags, set on indexed & PK cols *//* Array of flags, set on NOT NULL columns *//* Array of flags, set on target PK columns *//* src table col -> target table col *//* Array of target column types *//* Array of unquoted target column names *//* Size of azTblCol[] array *//* Index iterator *//* Iterate through tables *//*
** An iterator of this type is used to iterate through all objects in
** the target database that require updating. For each such table, the
** iterator visits, in order:
**
**     * the table itself,
**     * each index of the table (zero or more points to visit), and
**     * a special "cleanup table" state.
**
** abIndexed:
**   If the table has no indexes on it, abIndexed is set to NULL. Otherwise,
**   it points to an array of flags nTblCol elements in size. The flag is
**   set for each column that is either a part of the PK or a part of an
**   index. Or clear otherwise.
**
**   If there are one or more partial indexes on the table, all fields of
**   this array set set to 1. This is because in that case, the module has
**   no way to tell which fields will be required to add and remove entries
**   from the partial indexes.
**
*//* Last update statement (or NULL) *//* Copy of update mask used with pUpdate *//*
** A structure to store values read from the rbu_state table in memory.
*//*
** These values must match the values defined in wal.c for the equivalent
** locks. These are not magic numbers as they are part of the SQLite file
** format.
*//*
** The rbu_state table is used to save the state of a partially applied
** update so that it can be resumed later. The table consists of integer
** keys mapped to values as follows:
**
** RBU_STATE_STAGE:
**   May be set to integer values 1, 2, 4 or 5. As follows:
**       1: the *-rbu file is currently under construction.
**       2: the *-rbu file has been constructed, but not yet moved
**          to the *-wal path.
**       4: the checkpoint is underway.
**       5: the rbu update has been checkpointed.
**
** RBU_STATE_TBL:
**   Only valid if STAGE==1. The target database name of the table
**   currently being written.
**
** RBU_STATE_IDX:
**   Only valid if STAGE==1. The target database name of the index
**   currently being written, or NULL if the main table is currently being
**   updated.
**
** RBU_STATE_ROW:
**   Only valid if STAGE==1. Number of rows already processed for the current
**   table/index.
**
** RBU_STATE_PROGRESS:
**   Trbul number of sqlite3rbu_step() calls made so far as part of this
**   rbu update.
**
** RBU_STATE_CKPT:
**   Valid if STAGE==4. The 64-bit checksum associated with the wal-index
**   header created by recovering the *-wal file. This is used to detect
**   cases when another client appends frames to the *-wal file in the
**   middle of an incremental checkpoint (an incremental checkpoint cannot
**   be continued if this happens).
**
** RBU_STATE_COOKIE:
**   Valid if STAGE==1. The current change-counter cookie value in the
**   target db file.
**
** RBU_STATE_OALSZ:
**   Valid if STAGE==1. The size in bytes of the *-oal file.
**
** RBU_STATE_DATATBL:
**   Only valid if STAGE==1. The RBU database name of the table
**   currently being read.
*//*
** Name of the URI option that causes RBU to take an exclusive lock as
** part of the incremental checkpoint operation.
*//*
** Swap two objects of type TYPE.
*//* Delta checksums disabled by default.  Compile with -DRBU_ENABLE_DELTA_CKSUM
** to enable checksum verification.
*//* Maximum number of prepared UPDATE statements held by this module *//* #include "windows.h" *//************** Continuing where we left off in sqlite3rbu.c *****************//************** End of sqlite3rbu.h ******************************************//* _SQLITE3RBU_H *//*
** Deregister and destroy an RBU vfs created by an earlier call to
** sqlite3rbu_create_vfs().
**
** VFS objects are not reference counted. If a VFS object is destroyed
** before all database handles that use it have been closed, the results
** are undefined.
*//*
** Create an RBU VFS named zName that accesses the underlying file-system
** via existing VFS zParent. Or, if the zParent parameter is passed NULL,
** then the new RBU VFS uses the default system VFS to access the file-system.
** The new object is registered as a non-default VFS with SQLite before
** returning.
**
** Part of the RBU implementation uses a custom VFS object. Usually, this
** object is created and deleted automatically by RBU.
**
** The exception is for applications that also use zipvfs. In this case,
** the custom VFS must be explicitly created by the user before the RBU
** handle is opened. The RBU VFS should be installed so that the zipvfs
** VFS uses the RBU VFS, which in turn uses any other VFS layers in use
** (for example multiplexor) to access the file-system. For example,
** to assemble an RBU enabled VFS stack that uses both zipvfs and
** multiplexor (error checking omitted):
**
**     // Create a VFS named "multiplex" (not the default).
**     sqlite3_multiplex_initialize(0, 0);
**
**     // Create an rbu VFS named "rbu" that uses multiplexor. If the
**     // second argument were replaced with NULL, the "rbu" VFS would
**     // access the file-system via the system default VFS, bypassing the
**     // multiplexor.
**     sqlite3rbu_create_vfs("rbu", "multiplex");
**
**     // Create a zipvfs VFS named "zipvfs" that uses rbu.
**     zipvfs_create_vfs_v3("zipvfs", "rbu", 0, xCompressorAlgorithmDetector);
**
**     // Make zipvfs the default VFS.
**     sqlite3_vfs_register(sqlite3_vfs_find("zipvfs"), 1);
**
** Because the default VFS created above includes a RBU functionality, it
** may be used by RBU clients. Attempting to use RBU with a zipvfs VFS stack
** that does not include the RBU layer results in an error.
**
** The overhead of adding the "rbu" VFS to the system is negligible for
** non-RBU users. There is no harm in an application accessing the
** file-system via "rbu" all the time, even if it only uses RBU functionality
** occasionally.
*//*
** As part of applying an RBU update or performing an RBU vacuum operation,
** the system must at one point move the *-oal file to the equivalent *-wal
** path. Normally, it does this by invoking POSIX function rename(2) directly.
** Except on WINCE platforms, where it uses win32 API MoveFileW(). This
** function may be used to register a callback that the RBU module will invoke
** instead of one of these APIs.
**
** If a callback is registered with an RBU handle, it invokes it instead
** of rename(2) when it needs to move a file within the file-system. The
** first argument passed to the xRename() callback is a copy of the second
** argument (pArg) passed to this function. The second is the full path
** to the file to move and the third the full path to which it should be
** moved. The callback function should return SQLITE_OK to indicate
** success. If an error occurs, it should return an SQLite error code.
** In this case the RBU operation will be abandoned and the error returned
** to the RBU user.
**
** Passing a NULL pointer in place of the xRename argument to this function
** restores the default behaviour.
*//*
** Obtain an indication as to the current stage of an RBU update or vacuum.
** This function always returns one of the SQLITE_RBU_STATE_XXX constants
** defined in this file. Return values should be interpreted as follows:
**
** SQLITE_RBU_STATE_OAL:
**   RBU is currently building a *-oal file. The next call to sqlite3rbu_step()
**   may either add further data to the *-oal file, or compute data that will
**   be added by a subsequent call.
**
** SQLITE_RBU_STATE_MOVE:
**   RBU has finished building the *-oal file. The next call to sqlite3rbu_step()
**   will move the *-oal file to the equivalent *-wal path. If the current
**   operation is an RBU update, then the updated version of the database
**   file will become visible to ordinary SQLite clients following the next
**   call to sqlite3rbu_step().
**
** SQLITE_RBU_STATE_CHECKPOINT:
**   RBU is currently performing an incremental checkpoint. The next call to
**   sqlite3rbu_step() will copy a page of data from the *-wal file into
**   the target database file.
**
** SQLITE_RBU_STATE_DONE:
**   The RBU operation has finished. Any subsequent calls to sqlite3rbu_step()
**   will immediately return SQLITE_DONE.
**
** SQLITE_RBU_STATE_ERROR:
**   An error has occurred. Any subsequent calls to sqlite3rbu_step() will
**   immediately return the SQLite error code associated with the error.
*//*
** Obtain permyriadage (permyriadage is to 10000 as percentage is to 100)
** progress indications for the two stages of an RBU update. This API may
** be useful for driving GUI progress indicators and similar.
**
** An RBU update is divided into two stages:
**
**   * Stage 1, in which changes are accumulated in an oal/wal file, and
**   * Stage 2, in which the contents of the wal file are copied into the
**     main database.
**
** The update is visible to non-RBU clients during stage 2. During stage 1
** non-RBU reader clients may see the original database.
**
** If this API is called during stage 2 of the update, output variable
** (*pnOne) is set to 10000 to indicate that stage 1 has finished and (*pnTwo)
** to a value between 0 and 10000 to indicate the permyriadage progress of
** stage 2. A value of 5000 indicates that stage 2 is half finished,
** 9000 indicates that it is 90% finished, and so on.
**
** If this API is called during stage 1 of the update, output variable
** (*pnTwo) is set to 0 to indicate that stage 2 has not yet started. The
** value to which (*pnOne) is set depends on whether or not the RBU
** database contains an "rbu_count" table. The rbu_count table, if it
** exists, must contain the same columns as the following:
**
**   CREATE TABLE rbu_count(tbl TEXT PRIMARY KEY, cnt INTEGER) WITHOUT ROWID;
**
** There must be one row in the table for each source (data_xxx) table within
** the RBU database. The 'tbl' column should contain the name of the source
** table. The 'cnt' column should contain the number of rows within the
** source table.
**
** If the rbu_count table is present and populated correctly and this
** API is called during stage 1, the *pnOne output variable is set to the
** permyriadage progress of the same stage. If the rbu_count table does
** not exist, then (*pnOne) is set to -1 during stage 1. If the rbu_count
** table exists but is not correctly populated, the value of the *pnOne
** output variable during stage 1 is undefined.
*//*
** Close an RBU handle.
**
** If the RBU update has been completely applied, mark the RBU database
** as fully applied. Otherwise, assuming no error has occurred, save the
** current state of the RBU update appliation to the RBU database.
**
** If an error has already occurred as part of an sqlite3rbu_step()
** or sqlite3rbu_open() call, or if one occurs within this function, an
** SQLite error code is returned. Additionally, if pzErrmsg is not NULL,
** *pzErrmsg may be set to point to a buffer containing a utf-8 formatted
** English language error message. It is the responsibility of the caller to
** eventually free any such buffer using sqlite3_free().
**
** Otherwise, if no error occurs, this function returns SQLITE_OK if the
** update has been partially applied, or SQLITE_DONE if it has been
** completely applied.
*//*
** Force RBU to save its state to disk.
**
** If a power failure or application crash occurs during an update, following
** system recovery RBU may resume the update from the point at which the state
** was last saved. In other words, from the most recent successful call to
** sqlite3rbu_close() or this function.
**
** SQLITE_OK is returned if successful, or an SQLite error code otherwise.
*//*
** Do some work towards applying the RBU update to the target db.
**
** Return SQLITE_DONE if the update has been completely applied, or
** SQLITE_OK if no error occurs but there remains work to do to apply
** the RBU update. If an error does occur, some other error code is
** returned.
**
** Once a call to sqlite3rbu_step() has returned a value other than
** SQLITE_OK, all subsequent calls on the same RBU handle are no-ops
** that immediately return the same value.
*//*
** Internally, each RBU connection uses a separate SQLite database
** connection to access the target and rbu update databases. This
** API allows the application direct access to these database handles.
**
** The first argument passed to this function must be a valid, open, RBU
** handle. The second argument should be passed zero to access the target
** database handle, or non-zero to access the rbu update database handle.
** Accessing the underlying database handles may be useful in the
** following scenarios:
**
**   * If any target tables are virtual tables, it may be necessary to
**     call sqlite3_create_module() on the target database handle to
**     register the required virtual table implementations.
**
**   * If the data_xxx tables in the RBU source database are virtual
**     tables, the application may need to call sqlite3_create_module() on
**     the rbu update db handle to any required virtual table
**     implementations.
**
**   * If the application uses the "rbu_delta()" feature described above,
**     it must use sqlite3_create_function() or similar to register the
**     rbu_delta() implementation with the target database handle.
**
** If an error has occurred, either while opening or stepping the RBU object,
** this function may return NULL. The error code and message may be collected
** when sqlite3rbu_close() is called.
**
** Database handles returned by this function remain valid until the next
** call to any sqlite3rbu_xxx() function other than sqlite3rbu_db().
*//*
** Return the current amount of temp file space, in bytes, currently used by
** the RBU handle passed as the only argument.
*//*
** Configure a limit for the amount of temp space that may be used by
** the RBU handle passed as the first argument. The new limit is specified
** in bytes by the second parameter. If it is positive, the limit is updated.
** If the second parameter to this function is passed zero, then the limit
** is removed entirely. If the second parameter is negative, the limit is
** not modified (this is useful for querying the current limit).
**
** In all cases the returned value is the current limit in bytes (zero
** indicates unlimited).
**
** If the temp space limit is exceeded during operation, an SQLITE_FULL
** error is returned.
*//*
** Open an RBU handle to perform an RBU vacuum on database file zTarget.
** An RBU vacuum is similar to SQLite's built-in VACUUM command, except
** that it can be suspended and resumed like an RBU update.
**
** The second argument to this function identifies a database in which
** to store the state of the RBU vacuum operation if it is suspended. The
** first time sqlite3rbu_vacuum() is called, to start an RBU vacuum
** operation, the state database should either not exist or be empty
** (contain no tables). If an RBU vacuum is suspended by calling
** sqlite3rbu_close() on the RBU handle before sqlite3rbu_step() has
** returned SQLITE_DONE, the vacuum state is stored in the state database.
** The vacuum can be resumed by calling this function to open a new RBU
** handle specifying the same target and state databases.
**
** If the second argument passed to this function is NULL, then the
** name of the state database is "<database>-vacuum", where <database>
** is the name of the target database file. In this case, on UNIX, if the
** state database is not already present in the file-system, it is created
** with the same permissions as the target db is made.
**
** With an RBU vacuum, it is an SQLITE_MISUSE error if the name of the
** state database ends with "-vactmp". This name is reserved for internal
** use.
**
** This function does not delete the state database after an RBU vacuum
** is completed, even if it created it. However, if the call to
** sqlite3rbu_close() returns any value other than SQLITE_OK, the contents
** of the state tables within the state database are zeroed. This way,
** the next call to sqlite3rbu_vacuum() opens a handle that starts a
** new RBU vacuum operation.
**
** As with sqlite3rbu_open(), Zipvfs users should rever to the comment
** describing the sqlite3rbu_create_vfs() API function below for
** a description of the complications associated with using RBU with
** zipvfs databases.
*//*
** Open an RBU handle.
**
** Argument zTarget is the path to the target database. Argument zRbu is
** the path to the RBU database. Each call to this function must be matched
** by a call to sqlite3rbu_close(). When opening the databases, RBU passes
** the SQLITE_CONFIG_URI flag to sqlite3_open_v2(). So if either zTarget
** or zRbu begin with "file:", it will be interpreted as an SQLite
** database URI, not a regular file name.
**
** If the zState argument is passed a NULL value, the RBU extension stores
** the current state of the update (how many rows have been updated, which
** indexes are yet to be updated etc.) within the RBU database itself. This
** can be convenient, as it means that the RBU application does not need to
** organize removing a separate state file after the update is concluded.
** Or, if zState is non-NULL, it must be a path to a database file in which
** the RBU extension can store the state of the update.
**
** When resuming an RBU update, the zState argument must be passed the same
** value as when the RBU update was started.
**
** Once the RBU update is finished, the RBU extension does not
** automatically remove any zState database file, even if it created it.
**
** By default, RBU uses the default VFS to access the files on disk. To
** use a VFS other than the default, an SQLite "file:" URI containing a
** "vfs=..." option may be passed as the zTarget option.
**
** IMPORTANT NOTE FOR ZIPVFS USERS: The RBU extension works with all of
** SQLite's built-in VFSs, including the multiplexor VFS. However it does
** not work out of the box with zipvfs. Refer to the comment describing
** the zipvfs_create_vfs() API below for details on using RBU with zipvfs.
*//* #include "sqlite3.h"              ** Required for error code definitions ** *//*
** SUMMARY
**
** Writing a transaction containing a large number of operations on
** b-tree indexes that are collectively larger than the available cache
** memory can be very inefficient.
**
** The problem is that in order to update a b-tree, the leaf page (at least)
** containing the entry being inserted or deleted must be modified. If the
** working set of leaves is larger than the available cache memory, then a
** single leaf that is modified more than once as part of the transaction
** may be loaded from or written to the persistent media multiple times.
** Additionally, because the index updates are likely to be applied in
** random order, access to pages within the database is also likely to be in
** random order, which is itself quite inefficient.
**
** One way to improve the situation is to sort the operations on each index
** by index key before applying them to the b-tree. This leads to an IO
** pattern that resembles a single linear scan through the index b-tree,
** and all but guarantees each modified leaf page is loaded and stored
** exactly once. SQLite uses this trick to improve the performance of
** CREATE INDEX commands. This extension allows it to be used to improve
** the performance of large transactions on existing databases.
**
** Additionally, this extension allows the work involved in writing the
** large transaction to be broken down into sub-transactions performed
** sequentially by separate processes. This is useful if the system cannot
** guarantee that a single update process will run for long enough to apply
** the entire update, for example because the update is being applied on a
** mobile device that is frequently rebooted. Even after the writer process
** has committed one or more sub-transactions, other database clients continue
** to read from the original database snapshot. In other words, partially
** applied transactions are not visible to other clients.
**
** "RBU" stands for "Resumable Bulk Update". As in a large database update
** transmitted via a wireless network to a mobile device. A transaction
** applied using this extension is hence refered to as an "RBU update".
**
**
** LIMITATIONS
**
** An "RBU update" transaction is subject to the following limitations:
**
**   * The transaction must consist of INSERT, UPDATE and DELETE operations
**     only.
**
**   * INSERT statements may not use any default values.
**
**   * UPDATE and DELETE statements must identify their target rows by
**     non-NULL PRIMARY KEY values. Rows with NULL values stored in PRIMARY
**     KEY fields may not be updated or deleted. If the table being written
**     has no PRIMARY KEY, affected rows must be identified by rowid.
**
**   * UPDATE statements may not modify PRIMARY KEY columns.
**
**   * No triggers will be fired.
**
**   * No foreign key violations are detected or reported.
**
**   * CHECK constraints are not enforced.
**
**   * No constraint handling mode except for "OR ROLLBACK" is supported.
**
**
** PREPARATION
**
** An "RBU update" is stored as a separate SQLite database. A database
** containing an RBU update is an "RBU database". For each table in the
** target database to be updated, the RBU database should contain a table
** named "data_<target name>" containing the same set of columns as the
** target table, and one more - "rbu_control". The data_% table should
** have no PRIMARY KEY or UNIQUE constraints, but each column should have
** the same type as the corresponding column in the target database.
** The "rbu_control" column should have no type at all. For example, if
** the target database contains:
**
**   CREATE TABLE t1(a INTEGER PRIMARY KEY, b TEXT, c UNIQUE);
**
** Then the RBU database should contain:
**
**   CREATE TABLE data_t1(a INTEGER, b TEXT, c, rbu_control);
**
** The order of the columns in the data_% table does not matter.
**
** Instead of a regular table, the RBU database may also contain virtual
** tables or views named using the data_<target> naming scheme.
**
** Instead of the plain data_<target> naming scheme, RBU database tables
** may also be named data<integer>_<target>, where <integer> is any sequence
** of zero or more numeric characters (0-9). This can be significant because
** tables within the RBU database are always processed in order sorted by
** name. By judicious selection of the <integer> portion of the names
** of the RBU tables the user can therefore control the order in which they
** are processed. This can be useful, for example, to ensure that "external
** content" FTS4 tables are updated before their underlying content tables.
**
** If the target database table is a virtual table or a table that has no
** PRIMARY KEY declaration, the data_% table must also contain a column
** named "rbu_rowid". This column is mapped to the table's implicit primary
** key column - "rowid". Virtual tables for which the "rowid" column does
** not function like a primary key value cannot be updated using RBU. For
** example, if the target db contains either of the following:
**
**   CREATE VIRTUAL TABLE x1 USING fts3(a, b);
**   CREATE TABLE x1(a, b)
**
** then the RBU database should contain:
**
**   CREATE TABLE data_x1(a, b, rbu_rowid, rbu_control);
**
** All non-hidden columns (i.e. all columns matched by "SELECT *") of the
** target table must be present in the input table. For virtual tables,
** hidden columns are optional - they are updated by RBU if present in
** the input table, or not otherwise. For example, to write to an fts4
** table with a hidden languageid column such as:
**
**   CREATE VIRTUAL TABLE ft1 USING fts4(a, b, languageid='langid');
**
** Either of the following input table schemas may be used:
**
**   CREATE TABLE data_ft1(a, b, langid, rbu_rowid, rbu_control);
**   CREATE TABLE data_ft1(a, b, rbu_rowid, rbu_control);
**
** For each row to INSERT into the target database as part of the RBU
** update, the corresponding data_% table should contain a single record
** with the "rbu_control" column set to contain integer value 0. The
** other columns should be set to the values that make up the new record
** to insert.
**
** If the target database table has an INTEGER PRIMARY KEY, it is not
** possible to insert a NULL value into the IPK column. Attempting to
** do so results in an SQLITE_MISMATCH error.
**
** For each row to DELETE from the target database as part of the RBU
** update, the corresponding data_% table should contain a single record
** with the "rbu_control" column set to contain integer value 1. The
** real primary key values of the row to delete should be stored in the
** corresponding columns of the data_% table. The values stored in the
** other columns are not used.
**
** For each row to UPDATE from the target database as part of the RBU
** update, the corresponding data_% table should contain a single record
** with the "rbu_control" column set to contain a value of type text.
** The real primary key values identifying the row to update should be
** stored in the corresponding columns of the data_% table row, as should
** the new values of all columns being update. The text value in the
** "rbu_control" column must contain the same number of characters as
** there are columns in the target database table, and must consist entirely
** of 'x' and '.' characters (or in some special cases 'd' - see below). For
** each column that is being updated, the corresponding character is set to
** 'x'. For those that remain as they are, the corresponding character of the
** rbu_control value should be set to '.'. For example, given the tables
** above, the update statement:
**
**   UPDATE t1 SET c = 'usa' WHERE a = 4;
**
** is represented by the data_t1 row created by:
**
**   INSERT INTO data_t1(a, b, c, rbu_control) VALUES(4, NULL, 'usa', '..x');
**
** Instead of an 'x' character, characters of the rbu_control value specified
** for UPDATEs may also be set to 'd'. In this case, instead of updating the
** target table with the value stored in the corresponding data_% column, the
** user-defined SQL function "rbu_delta()" is invoked and the result stored in
** the target table column. rbu_delta() is invoked with two arguments - the
** original value currently stored in the target table column and the
** value specified in the data_xxx table.
**
** For example, this row:
**
**   INSERT INTO data_t1(a, b, c, rbu_control) VALUES(4, NULL, 'usa', '..d');
**
** is similar to an UPDATE statement such as:
**
**   UPDATE t1 SET c = rbu_delta(c, 'usa') WHERE a = 4;
**
** Finally, if an 'f' character appears in place of a 'd' or 's' in an
** ota_control string, the contents of the data_xxx table column is assumed
** to be a "fossil delta" - a patch to be applied to a blob value in the
** format used by the fossil source-code management system. In this case
** the existing value within the target database table must be of type BLOB.
** It is replaced by the result of applying the specified fossil delta to
** itself.
**
** If the target database table is a virtual table or a table with no PRIMARY
** KEY, the rbu_control value should not include a character corresponding
** to the rbu_rowid value. For example, this:
**
**   INSERT INTO data_ft1(a, b, rbu_rowid, rbu_control)
**       VALUES(NULL, 'usa', 12, '.x');
**
** causes a result similar to:
**
**   UPDATE ft1 SET b = 'usa' WHERE rowid = 12;
**
** The data_xxx tables themselves should have no PRIMARY KEY declarations.
** However, RBU is more efficient if reading the rows in from each data_xxx
** table in "rowid" order is roughly the same as reading them sorted by
** the PRIMARY KEY of the corresponding target database table. In other
** words, rows should be sorted using the destination table PRIMARY KEY
** fields before they are inserted into the data_xxx tables.
**
** USAGE
**
** The API declared below allows an application to apply an RBU update
** stored on disk to an existing target database. Essentially, the
** application:
**
**     1) Opens an RBU handle using the sqlite3rbu_open() function.
**
**     2) Registers any required virtual table modules with the database
**        handle returned by sqlite3rbu_db(). Also, if required, register
**        the rbu_delta() implementation.
**
**     3) Calls the sqlite3rbu_step() function one or more times on
**        the new handle. Each call to sqlite3rbu_step() performs a single
**        b-tree operation, so thousands of calls may be required to apply
**        a complete update.
**
**     4) Calls sqlite3rbu_close() to close the RBU update handle. If
**        sqlite3rbu_step() has been called enough times to completely
**        apply the update to the target database, then the RBU database
**        is marked as fully applied. Otherwise, the state of the RBU
**        update application is saved in the RBU database for later
**        resumption.
**
** See comments below for more detail on APIs.
**
** If an update is only partially applied to the target database by the
** time sqlite3rbu_close() is called, various state information is saved
** within the RBU database. This allows subsequent processes to automatically
** resume the RBU update from where it left off.
**
** To remove all RBU extension state information, returning an RBU database
** to its original contents, it is sufficient to drop all tables that begin
** with the prefix "rbu_"
**
** DATABASE LOCKING
**
** An RBU update may not be applied to a database in WAL mode. Attempting
** to do so is an error (SQLITE_ERROR).
**
** While an RBU handle is open, a SHARED lock may be held on the target
** database file. This means it is possible for other clients to read the
** database, but not to write it.
**
** If an RBU update is started and then suspended before it is completed,
** then an external client writes to the database, then attempting to resume
** the suspended RBU update is also an error (SQLITE_BUSY).
*//*
** 2014 August 30
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file contains the public interface for the RBU extension.
*//************** Begin file sqlite3rbu.h **************************************//************** Include sqlite3rbu.h in the middle of sqlite3rbu.c ***********//*
** 2014 August 30
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
**
** OVERVIEW
**
**  The RBU extension requires that the RBU update be packaged as an
**  SQLite database. The tables it expects to find are described in
**  sqlite3rbu.h.  Essentially, for each table xyz in the target database
**  that the user wishes to write to, a corresponding data_xyz table is
**  created in the RBU database and populated with one row for each row to
**  update, insert or delete from the target table.
**
**  The update proceeds in three stages:
**
**  1) The database is updated. The modified database pages are written
**     to a *-oal file. A *-oal file is just like a *-wal file, except
**     that it is named "<database>-oal" instead of "<database>-wal".
**     Because regular SQLite clients do not look for file named
**     "<database>-oal", they go on using the original database in
**     rollback mode while the *-oal file is being generated.
**
**     During this stage RBU does not update the database by writing
**     directly to the target tables. Instead it creates "imposter"
**     tables using the SQLITE_TESTCTRL_IMPOSTER interface that it uses
**     to update each b-tree individually. All updates required by each
**     b-tree are completed before moving on to the next, and all
**     updates are done in sorted key order.
**
**  2) The "<database>-oal" file is moved to the equivalent "<database>-wal"
**     location using a call to rename(2). Before doing this the RBU
**     module takes an EXCLUSIVE lock on the database file, ensuring
**     that there are no other active readers.
**
**     Once the EXCLUSIVE lock is released, any other database readers
**     detect the new *-wal file and read the database in wal mode. At
**     this point they see the new version of the database - including
**     the updates made as part of the RBU update.
**
**  3) The new *-wal file is checkpointed. This proceeds in the same way
**     as a regular database checkpoint, except that a single frame is
**     checkpointed each time sqlite3rbu_step() is called. If the RBU
**     handle is closed before the entire *-wal file is checkpointed,
**     the checkpoint progress is saved in the RBU database and the
**     checkpoint can be resumed by another RBU client at some point in
**     the future.
**
** POTENTIAL PROBLEMS
**
**  The rename() call might not be portable. And RBU is not currently
**  syncing the directory after renaming the file.
**
**  When state is saved, any commit to the *-oal file and the commit to
**  the RBU update database are not atomic. So if the power fails at the
**  wrong moment they might get out of sync. As the main database will be
**  committed before the RBU update database this will likely either just
**  pass unnoticed, or result in SQLITE_CONSTRAINT errors (due to UNIQUE
**  constraint violations).
**
**  If some client does modify the target database mid RBU update, or some
**  other error occurs, the RBU extension will keep throwing errors. It's
**  not really clear how to get out of this state. The system could just
**  by delete the RBU update database and *-oal file and have the device
**  download the update again and start over.
**
**  At present, for an UPDATE, both the new.* and old.* records are
**  collected in the rbu_xyz table. And for both UPDATEs and DELETEs all
**  fields are collected.  This means we're probably writing a lot more
**  data to disk when saving the state of an ongoing update to the RBU
**  update database than is strictly necessary.
**
*//************** Begin file sqlite3rbu.c **************************************//************** End of fts3_icu.c ********************************************//* !defined(SQLITE_CORE) || defined(SQLITE_ENABLE_FTS3) *//* defined(SQLITE_ENABLE_ICU) *//*
** Set *ppModule to point at the implementation of the ICU tokenizer.
*//* xLanguageid *//* xNext       *//* xClose      *//* xOpen       *//* xCreate     *//* iVersion    *//*
** The set of routines that implement the simple tokenizer
*//* Output success/failure *//* Input vars *//* Output vars *//* OUT: Position integer of token *//* OUT: Ending offset of token *//* OUT: Starting offset of token *//* OUT: Number of bytes in token *//* OUT: *ppToken is the token text *//* Cursor returned by simpleOpen *//*
** Extract the next token from a tokenization cursor.
*//*
** Close a tokenization cursor previously opened by a call to icuOpen().
*//* IcuCursor.aOffset[] *//* IcuCursor.aChar[] *//* IcuCursor *//* OUT: Tokenization cursor *//* Length of zInput in bytes *//* The tokenizer *//*
** Prepare to begin tokenizing a particular string.  The input
** string to be tokenized is pInput[0..nBytes-1].  A cursor
** used to incrementally tokenize this string is returned in
** *ppCursor.
*//*
** Destroy a tokenizer
*//* OUT: Created tokenizer *//* Tokenizer creation arguments *//* Number of entries in argv[] *//*
** Create a new tokenizer instance.
*//* Offsets of each character in utf-8 input *//* Copy of input using utf-16 encoding *//* Number of UChar elements in pInput *//* ICU break-iterator object *//* #include <unicode/ustring.h> *//* #include <unicode/ucol.h> *//* #include "fts3_tokenizer.h" *//* #include "fts3Int.h" *//*
** 2007 June 22
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file implements a tokenizer for fts3 based on the ICU library.
*//************** Begin file fts3_icu.c ****************************************//************** End of icu.c *************************************************//* !defined(SQLITE_CORE) || defined(SQLITE_ENABLE_ICU) *//* sqlite3_user_data() context *//* Optimal text encoding *//*
** Register the ICU extension functions with database db.
*//* Return code from sqlite3_create_collation_x() *//* ICU library collation object *//* SQL Collation sequence name (eg. "japanese") *//* Locale identifier - (eg. "jp_JP") *//*
** Implementation of the scalar function icu_load_collation().
**
** This scalar function is used to add ICU collation based collation
** types to an SQLite database connection. It is intended to be called
** as follows:
**
**     SELECT icu_load_collation(<locale>, <collation-name>);
**
** Where <locale> is a string containing an ICU locale identifier (i.e.
** "en_AU", "tr_TR" etc.) and <collation-name> is the name of the
** collation sequence to create.
*//*
** Collation sequence comparison function. The pCtx argument points to
** a UCollator structure previously allocated using ucol_open().
*//*
** Collation sequence destructor function. The pCtx argument points to
** a UCollator structure previously allocated using ucol_open().
*//* Unreachable *//* True for toupper(), false for tolower() *//* Size of output buffer in bytes *//* Size of utf-16 input string in bytes *//* Pointer to output buffer *//* Pointer to input string *//*
** Implementations of scalar functions for case mapping - upper() and
** lower(). Function upper() converts its input to upper-case (ABC).
** Function lower() converts to lower-case (abc).
**
** ICU provides two types of case mapping, "general" case mapping and
** "language specific". Refer to ICU documentation for the differences
** between the two.
**
** To utilise "general" case mapping, the upper() or lower() scalar
** functions are invoked with one argument:
**
**     upper('ABC') -> 'abc'
**     lower('abc') -> 'ABC'
**
** To access ICU "language specific" case mapping, upper() or lower()
** should be invoked with two arguments. The second argument is the name
** of the locale to use. Passing an empty string ("") or SQL NULL value
** as the second argument is the same as invoking the 1 argument version
** of upper() or lower().
**
**     lower('I', 'en_us') -> 'i'
**     lower('I', 'tr_tr') -> '\u131' (small dotless i)
**
** http://www.icu-project.org/userguide/posix.html#case_mappings
*//* Return 1 or 0. *//* Set the text that the regular expression operates on to a NULL
  ** pointer. This is not really necessary, but it is tidier than
  ** leaving the regular expression object configured with an invalid
  ** pointer after this function returns.
  *//* Attempt the match *//* Configure the text that the regular expression operates on. *//* If the left hand side of the regexp operator is NULL,
  ** then the result is also NULL.
  *//*
** Implementation of SQLite REGEXP operator. This scalar function takes
** two arguments. The first is a regular expression pattern to compile
** the second is a string to match against that pattern. If either
** argument is an SQL NULL, then NULL Is returned. Otherwise, the result
** is 1 if the string matches the pattern, or 0 otherwise.
**
** SQLite maps the regexp() function to the regexp() operator such
** that the following two are equivalent:
**
**     zString REGEXP zPattern
**     regexp(zPattern, zString)
**
** Uses the following ICU regexp APIs:
**
**     uregex_open()
**     uregex_matches()
**     uregex_close()
*//*
** Function to delete compiled regexp objects. Registered as
** a destructor function with sqlite3_set_auxdata().
*//* The escape character string must consist of a single UTF-8 character.
    ** Otherwise, return an error.
    *//* Limit the length of the LIKE or GLOB pattern to avoid problems
  ** of deep recursion and N*N behavior in patternCompare().
  *//*
** Implementation of the like() SQL function.  This function implements
** the build-in LIKE operator.  The first argument to the function is the
** pattern and the second argument is the string.  So, the SQL statements:
**
**       A LIKE B
**
** is implemented as like(B, A). If there is an escape character E,
**
**       A LIKE B ESCAPE E
**
** is mapped to like(B, A, E).
*//* Case 4. *//* Skip any MATCH_ALL or MATCH_ONE characters that follow a
      ** MATCH_ALL. For each MATCH_ONE, skip one character in the
      ** test string.
      *//* There are now 4 possibilities:
    **
    **     1. uPattern is an unescaped match-all character "%",
    **     2. uPattern is an unescaped match-one character "_",
    **     3. uPattern is an unescaped escape character, or
    **     4. uPattern is to be handled as an ordinary character
    *//* Read (and consume) the next character from the input pattern. *//* True if the previous character was uEsc *//* The escape character *//* The UTF-8 string to compare against *//* LIKE pattern *//*
** Compare two UTF-8 strings for equality where the first string is
** a "LIKE" expression. Return true (1) if they are the same and
** false (0) if they are different.
*//*
** This lookup table is used to help decode the first byte of
** a multi-byte UTF8 character. It is copied here from SQLite source
** code file utf8.c.
*//*
** Version of sqlite3_free() that is always a function, never a macro.
*//*
** Maximum length (in bytes) of the pattern in a LIKE or GLOB
** operator.
*//* Error code returned by ICU function *//* Name of ICU function that failed *//* SQLite scalar function context *//*
** This function is called when an ICU function called from within
** the implementation of an SQL scalar function returns an error.
**
** The scalar function context passed as the first argument is
** loaded with an error message based on the following two args.
*//*   #include "sqlite3.h" *//*   #include "sqlite3ext.h" *//* Include ICU headers *//*
** 2007 May 6
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** $Id: icu.c,v 1.7 2007/12/13 21:54:11 drh Exp $
**
** This file implements an integration between the ICU library
** ("International Components for Unicode", an open-source library
** for handling unicode data) and SQLite. The integration uses
** ICU to provide the following to SQLite:
**
**   * An implementation of the SQL regexp() function (and hence REGEXP
**     operator) using the ICU uregex_XX() APIs.
**
**   * Implementations of the SQL scalar upper() and lower() functions
**     for case mapping.
**
**   * Integration of ICU and SQLite collation sequences.
**
**   * An implementation of the LIKE operator that uses ICU to
**     provide case-independent matching.
*//************** Begin file icu.c *********************************************//************** End of rtree.c ***********************************************//* Allocate and populate the context object. *//* Context object for new user-function *//* Destructor for the extra data *//* Extra data passed into the callback *//* Name of new SQL function *//* Register SQL function on this connection *//*
** Register a new 2nd-generation geometry function for use with the
** r-tree MATCH operator.
*//* Extra data associated with the callback *//* Name of the new SQL function *//*
** Register a new geometry function for use with the r-tree MATCH operator.
*//*
** Each call to sqlite3_rtree_geometry_callback() or
** sqlite3_rtree_query_callback() creates an ordinary SQLite
** scalar function that is implemented by this routine.
**
** All this function does is construct an RtreeMatchArg object that
** contains the geometry-checking callback routines and a list of
** parameters to this function, then return that RtreeMatchArg object
** as a BLOB.
**
** The R-Tree MATCH operator will read the returned BLOB, deserialize
** the RtreeMatchArg object, and use the RtreeMatchArg object to figure
** out which elements of the R-Tree should be returned by the query.
*//*
** This routine frees the BLOB that is returned by geomCallback().
*//*
** This routine deletes the RtreeGeomCallback object that was attached
** one of the SQL functions create by sqlite3_rtree_geometry_callback()
** or sqlite3_rtree_query_callback().  In other words, this routine is the
** destructor for an RtreeGeomCallback objecct.  This routine is called when
** the corresponding SQL function is deleted.
*//*
** Register the r-tree module with database handle db. This creates the
** virtual table module "rtree" and the debugging/analysis scalar
** function "rtreenode".
*//************** Continuing where we left off in rtree.c **********************//************** End of geopoly.c *********************************************//*
** Report that geopoly_overlap() is an overloaded function suitable
** for use in xBestIndex.
*//* Change the data *//* Insert the new record into the r-tree *//* If the aData[] array contains more than one element, elements
  ** (aData[2]..aData[argc-1]) contain a new record to insert into
  ** the r-tree structure.
  *//* If aData[0] is not an SQL NULL value, it is the rowid of a
  ** record to delete from the r-tree table. The following block does
  ** just that.
  *//* If a rowid value was supplied, check if it is already present in
    ** the table. If so, the constraint has failed. *//* Rowid change *//* UPDATE _shape *//* INSERT *//* not a DELETE *//* Unable to write to the btree while another cursor is reading from it,
    ** since the write might do a rebalance which would disrupt the read
    ** cursor. *//* Change in coordinates *//* True if newRowid is valid *//* The new rowid *//* True if oldRowid is valid *//* The old rowid *//* New cell to insert if nData>1 *//*
** The xUpdate method for GEOPOLY module virtual tables.
**
** For DELETE:
**
**     argv[0] = the rowid to be deleted
**
** For INSERT:
**
**     argv[0] = SQL NULL
**     argv[1] = rowid to insert, or an SQL NULL to select automatically
**     argv[2] = _shape column
**     argv[3] = first application-defined column....
**
** For UPDATE:
**
**     argv[0] = rowid to modify.  Never NULL
**     argv[1] = rowid after the change.  Never NULL
**     argv[2] = new value for _shape
**     argv[3] = new value for first application-defined column....
*//*
** GEOPOLY virtual table module xColumn method.
*//* p->op==SQLITE_INDEX_CONSTRAINT_FUNCTION for geopoly_overlap()
      ** p->op==(SQLITE_INDEX_CONTRAINT_FUNCTION+1) for geopoly_within().
      ** See geopolyFindFunction() *//*
** Rtree virtual table module xBestIndex method. There are three
** table scan strategies to choose from (in order from most to
** least desirable):
**
**   idxNum     idxStr        Strategy
**   ------------------------------------------------
**     1        "rowid"       Direct lookup by rowid.
**     2        "rtree"       R-tree overlap query using geopoly_overlap()
**     3        "rtree"       R-tree within query using geopoly_within()
**     4        "fullscan"    full-table scan.
**   ------------------------------------------------
*//* Within query *//* Overlap query *//* Normal case - r-tree scan. Set up the RtreeCursor.aConstraint array
    ** with the configured constraints.
    *//* Always returns pCsr->sPoint *//* Search point for the leaf *//* Leaf on which the required cell resides *//* Special case - lookup by rowid. *//* Reset the cursor to the same state as rtreeOpen() leaves it in. *//* Parameters to the query plan *//* Query plan *//* The cursor to initialize *//*
** GEOPOLY virtual table module xFilter method.
**
** Query plans:
**
**      1         rowid lookup
**      2         search for objects overlapping the same bounding box
**                that contains polygon argv[0]
**      3         search for objects overlapping the same bounding box
**                that contains polygon argv[0]
**      4         full table scan
*//*
** GEOPOLY virtual table module xConnect method.
*//*
** GEOPOLY virtual table module xCreate method.
*//* Figure out the node size to use. *//* The _shape column is always not-null *//* Add one for _shape *//* Create/Connect to the underlying relational database schema. If
  ** that is successful, call sqlite3_declare_vtab() to configure
  ** the r-tree table schema.
  *//* Allocate the sqlite3_vtab structure *//* Length of string argv[2] *//* Length of string argv[1] *//* OUT: Error message, if any *//* OUT: New virtual table *//* Parameters to CREATE TABLE statement *//* One of the RTREE_COORD_* constants *//*
** This function is the implementation of both the xConnect and xCreate
** methods of the geopoly virtual table.
**
**   argv[0]   -> module name
**   argv[1]   -> database name
**   argv[2]   -> table name
**   argv[...] -> column names...
*//*
** Enable or disable debugging output
*//*
** SQL function:    geopoly_overlap(P1,P2)
**
** Determine whether or not P1 and P2 overlap. Return value:
**
**   0     The two polygons are disjoint
**   1     They overlap
**   2     P1 is completely contained within P2
**   3     P2 is completely contained within P1
**   4     P1 and P2 are the same polygon
**   NULL  Either P1 or P2 or both are not valid polygons
*//* Remove a segment *//* Add a segment *//*
** Determine the overlap between two polygons
*//*
** Sort a list of GeoSegments in order of increasing Y and in the event of
** a tie, increasing C (slope).
*//*
** Merge two lists of sorted segments by Y, and then by C.
*//*
** Sort an array of nEvent event objects into a list.
*//*
** Merge two lists of sorted events by X coordinate
*//* The side of pPoly *//* Take all segments from this polygon *//* Add segments to this Overlap object *//*
** Insert all segments and events for polygon pPoly.
*//* Ignore vertical segments *//*
** Add a single segment and its associated events.
*//* Number of segments *//* Number of events *//* Array of all segments *//* Array of all events *//* Next segment in a list sorted by y *//* Which segment within the side *//* 1 for p1, 2 for p2 *//* Initial y value *//* Current y value *//* y = C*x + B *//* Next event in the sorted list *//* The segment to be added or removed *//* 0 for ADD, 1 for REMOVE *//* X coordinate at which event occurs *//* Objects used by the overlap algorihm. *//*
** SQL function:    geopoly_within(P1,P2)
**
** Return +2 if P1 and P2 are the same polygon
** Return +1 if P2 is contained within P1
** Return 0 if any part of P2 is on the outside of P1
**
*//*
** SQL function:    geopoly_contains_point(P,X,Y)
**
** Return +2 if point X,Y is within polygon P.
** Return +1 if point X,Y is on the polygon boundary.
** Return 0 if point X,Y is outside the polygon
*//* Vertical line segment *//*
** Determine if point (x0,y0) is beneath line segment (x1,y1)->(x2,y2).
** Returns:
**
**    +2  x0,y0 is on the line segement
**
**    +1  x0,y0 is beneath line segment
**
**    0   x0,y0 is not on or beneath the line segment or the line segment
**        is vertical and x0,y0 is not on the line segment
**
** The left-most coordinate min(x1,x2) is not considered to be part of
** the line segment for the purposes of this analysis.
*//*
** Implementation of the geopoly_group_bbox(X) aggregate SQL function.
*//*
** State vector for the geopoly_group_bbox() aggregate function.
*//*
** Implementation of the geopoly_bbox(X) SQL function.
*//* Error code here *//* Results here *//* The polygon *//* For recording the error *//*
** If pPoly is a polygon, compute its bounding box. Then:
**
**    (1) if aCoord!=0 store the bounding box in aCoord, returning NULL
**    (2) otherwise, compute a GeoPoly for the bounding box and return the
**        new GeoPoly
**
** If pPoly is NULL but aCoord is not NULL, then compute a new GeoPoly from
** the bounding box in aCoord and return a pointer to that GeoPoly.
*//*
** Function:   geopoly_regular(X,Y,R,N)
**
** Construct a simple, convex, regular polygon centered at X, Y
** with circumradius R and with N sides.
*//* Fast approximation for sine(X) for X between -0.5*pi and 2*pi
*//*
** Implementation of the geopoly_ccw(X) function.
**
** If the rotation of polygon X is clockwise (incorrect) instead of
** counter-clockwise (the correct winding order according to RFC7946)
** then reverse the order of the vertexes in polygon X.
**
** In other words, this routine returns a CCW polygon regardless of the
** winding order of its input.
**
** Use this routine to sanitize historical inputs that that sometimes
** contain polygons that wind in the wrong direction.
*//*
** Implementation of the geopoly_area(X) function.
**
** If the input is a well-formed Geopoly BLOB then return the area
** enclosed by the polygon.  If the polygon circulates clockwise instead
** of counterclockwise (as it should) then return the negative of the
** enclosed area.  Otherwise return NULL.
*//* (yN + y0) *//* (xN - x0) *//* (y0 + y1) *//* (x0 - x1) *//*
** Compute the area enclosed by the polygon.
**
** This routine can also be used to detect polygons that rotate in
** the wrong direction.  Polygons are suppose to be counter-clockwise (CCW).
** This routine returns a negative value for clockwise (CW) polygons.
*//*
** SQL Function:      geopoly_xform(poly, A, B, C, D, E, F)
**
** Transform and/or translate a polygon as follows:
**
**      x1 = A*x0 + B*y0 + E
**      y1 = C*x0 + D*y0 + F
**
** For a translation:
**
**      geopoly_xform(poly, 1, 0, 0, 1, x-offset, y-offset)
**
** Rotate by R around the point (0,0):
**
**      geopoly_xform(poly, cos(R), sin(R), -sin(R), cos(R), 0, 0)
*//*
** SQL function:     geopoly_svg(X, ....)
**
** Interpret X as a polygon and render it as a SVG <polyline>.
** Additional arguments are added as attributes to the <polyline>.
*//*
** SQL function:     geopoly_json(X)
**
** Interpret X as a polygon and render it as a JSON array
** of coordinates.  Or, if X is not a valid polygon, return NULL.
*//*
** Implementation of the geopoly_blob(X) function.
**
** If the input is a well-formed Geopoly BLOB or JSON string
** then return the BLOB representation of the polygon.  Otherwise
** return NULL.
*//* The value to decode *//* Context for error messages *//*
** Given a function parameter, try to interpret it as a polygon, either
** in the binary format or JSON text.  Compute a GeoPoly object and
** return a pointer to that object.  Or if the input is not a well-formed
** polygon, put an error message in sqlite3_context and return NULL.
*//* Remove the redundant vertex at the end *//*
** If the input is a well-formed JSON array of coordinates with at least
** four coordinates and where each coordinate is itself a two-value array,
** then convert the JSON into a GeoPoly object and return a pointer to
** that object.
**
** If any error occurs, return NULL.
*//* The sqlite3AtoF() routine is much much faster than atof(), if it
     ** is available *//* Parse out a number.  Write the value into *pVal if pVal!=0.
** return non-zero on success and zero if the next token is not a number.
*//* Skip whitespace.  Return the next non-whitespace character. *//* Do a 4-byte byte swap *//* Array of vertexes.  From sqlite3_malloc64() *//* Space allocated to a[] *//* Number of vertexes in a[] *//* Unparsed input *//*
** State of a parse of a GeoJSON input.
*//* Macros to access coordinates of a GeoPoly.
** We have to use these macros, rather than just say p->a[i] in order
** to silence (incorrect) UBSAN warnings if the array index is too large.
*//* The size of a memory allocation needed for a GeoPoly object sufficient
** to hold N coordinate pairs.
*//* 2*nVertex values. X (longitude) first, then Y *//* Header for on-disk representation *//* Number of vertexes *//*
** Internal representation of a polygon.
**
** The polygon consists of a sequence of vertexes.  There is a line
** segment between each pair of vertexes, and one final segment from
** the last vertex back to the first.  (This differs from the GeoJSON
** standard in which the final vertex is a repeat of the first.)
**
** The polygon follows the right-hand rule.  The area to the right of
** each segment is "outside" and the area to the left is "inside".
**
** The on-disk representation consists of a 4-byte header followed by
** the values.  The 4-byte header is:
**
**      encoding    (1 byte)   0=big-endian, 1=little-endian
**      nvertex     (3 bytes)  Number of vertexes as a big-endian integer
**
** Enough space is allocated for 4 coordinates, to work around over-zealous
** warnings coming from some compiler (notably, clang). In reality, the size
** of each GeoPoly memory allocate is adjusted as necessary so that the
** GeoPoly.a[] array at the end is the appropriate size.
*//* Datatype for coordinates
*//* Compiler and version *//* JSON NULL - back to original code *//*
** Growing our own isspace() routine this way is twice as fast as
** the library isspace() function.
*//* The following stuff repeats things found in json1 *//* Use the standard library for separate compilation *//* Use the SQLite core versions if this routine is part of the
   ** SQLite amalgamation *//* Character class routines *//* Enable -DGEOPOLY_ENABLE_DEBUG for debugging facilities *//* #include <stdlib.h> *//*
** 2018-05-25
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file implements an alternative R-Tree virtual table that
** uses polygons to express the boundaries of 2-dimensional objects.
**
** This file is #include-ed onto the end of "rtree.c" so that it has
** access to all of the R-Tree internals.
*//************** Begin file geopoly.c *****************************************//************** Include geopoly.c in the middle of rtree.c *******************//* Conditionally include the geopoly code *//*
** Usage:
**
**   rtreecheck(<rtree-table>);
**   rtreecheck(<database>, <rtree-table>);
**
** Invoking this SQL function runs an integrity-check on the named rtree
** table. The integrity-check verifies the following:
**
**   1. For each cell in the r-tree structure (%_node table), that:
**
**       a) for each dimension, (coord1 <= coord2).
**
**       b) unless the cell is on the root node, that the cell is bounded
**          by the parent cell on the parent node.
**
**       c) for leaf nodes, that there is an entry in the %_rowid
**          table corresponding to the cell's rowid value that
**          points to the correct node.
**
**       d) for cells on non-leaf nodes, that there is an entry in the
**          %_parent table mapping from the cell's child node to the
**          node that it resides on.
**
**   2. That there are the same number of entries in the %_rowid table
**      as there are leaf cells in the r-tree structure, and that there
**      is a leaf cell that corresponds to each entry in the %_rowid table.
**
**   3. That there are the same number of entries in the %_parent table
**      as there are non-leaf cells in the r-tree structure, and that
**      there is a non-leaf cell that corresponds to each entry in the
**      %_parent table.
*//* True for a quick_check *//* Name of the virtual table *//* Schema in which the virtual table lives *//* The virtual table to check *//*
** Implementation of the xIntegrity method for Rtree.
*//* Finalize SQL statements used by the integrity-check *//* Do the actual integrity-check *//* Find number of dimensions in the rtree table. *//* Find the number of auxiliary columns *//* Initialize the context object *//* Number of extra columns. *//* Used to find column count of rtree table *//* Common context for various routines *//* OUT: sqlite3_malloc'd report text *//* Name of rtree table to check *//* Name of db ("main", "temp" etc.) *//* Database handle to access db through *//*
** This function does the bulk of the work for the rtree integrity-check.
** It is called by rtreecheck(), which is the SQL function implementation.
*//*
** The second argument to this function must be either "_rowid" or
** "_parent". This function checks that the number of entries in the
** %_rowid or %_parent table is exactly nExpect. If not, it adds
** an error message to the report in the RtreeCheck object indicated
** by the first argument.
*//* Node to check *//* Buffer containing parent coords *//* Depth of iNode (0==leaf) *//*
** Run rtreecheck() checks on node iNode, which is at depth iDepth within
** the r-tree structure. Argument aParent points to the array of coordinates
** that bound node iNode on the parent node.
**
** If any problems are discovered, an error message is appended to the
** report accumulated in the RtreeCheck object.
*//* printf("%e, %e\n", c1.u.f, c2.u.f); *//* Pointer to parent coordinates *//* Pointer to cell coordinates *//* Cell number to use in error messages *//* Node id to use in error messages *//*
** Argument pCell points to an array of coordinates stored on an rtree page.
** This function checks that the coordinates are internally consistent (no
** x1>x2 conditions) and adds an error message to the RtreeCheck object
** if they are not.
**
** Additionally, if pParent is not NULL, then it is assumed to point to
** the array of coordinates on the parent page that bound the page
** containing pCell. In this case it is also verified that the two
** sets of coordinates are mutually consistent and an error message added
** to the RtreeCheck object if they are not.
*//* Expected value for mapping *//* Key for mapping *//* True for a leaf cell, false for interior *//* RtreeCheck object *//*
** This function is used to check that the %_parent (if bLeaf==0) or %_rowid
** (if bLeaf==1) table contains a specified entry. The schemas of the
** two tables are:
**
**   CREATE TABLE %_parent(nodeno INTEGER PRIMARY KEY, parentnode INTEGER)
**   CREATE TABLE %_rowid(rowid INTEGER PRIMARY KEY, nodeno INTEGER, ...)
**
** In both cases, this function checks that there exists an entry with
** IPK value iKey and the second column set to iVal.
**
*//*
** This function is a no-op if there is already an error code stored
** in the RtreeCheck object indicated by the first argument. NULL is
** returned in this case.
**
** Otherwise, the contents of rtree table node iNode are loaded from
** the database and copied into a buffer obtained from sqlite3_malloc().
** If no error occurs, a pointer to the buffer is returned and (*pnNode)
** is set to the size of the buffer in bytes.
**
** Or, if an error does occur, NULL is returned and an error code left
** in the RtreeCheck object. The final value of *pnNode is undefined in
** this case.
*//*
** The second and subsequent arguments to this function are a printf()
** style format string and arguments. This function formats the string and
** appends it to the report being accumuated in pCheck.
*//* Format string and trailing args *//*
** The second and subsequent arguments to this function are a format string
** and printf style arguments. This function formats the string and attempts
** to compile it as an SQL statement.
**
** If successful, a pointer to the new SQL statement is returned. Otherwise,
** NULL is returned and an error code left in RtreeCheck.rc.
*//*
** Reset SQL statement pStmt. If the sqlite3_reset() call returns an error,
** and RtreeCheck.rc==SQLITE_OK, set RtreeCheck.rc to the error code.
*//* Number of lines in zReport *//* Message to report *//* Number of non-leaf cells in table *//* Number of leaf cells in table *//* Statements to query %_parent/%_rowid *//* Statement used to retrieve nodes *//* Number of dimensions for this rtree tbl *//* True for rtree_i32 table *//* Name of rtree table *//* Database containing rtree table *//*
** Context object passed between the various routines that make up the
** implementation of integrity-check function rtreecheck().
*//* This routine implements an SQL function that returns the "depth" parameter
** from the front of a blob that is an r-tree node.  For example:
**
**     SELECT rtreedepth(data) FROM rt_node WHERE nodeno=1;
**
** The depth value is 0 for all nodes other than the root node, and the root
** node always has nodeno=1, so the example above is the primary use for this
** routine.  This routine is intended for testing and analysis only.
*//*
** Implementation of a scalar function that decodes r-tree nodes to
** human readable strings. This can be used for debugging and analysis.
**
** The scalar function takes two arguments: (1) the number of dimensions
** to the rtree (between 1 and 5, inclusive) and (2) a blob of data containing
** an r-tree node.  For a two-dimensional r-tree structure called "rt", to
** deserialize all nodes, a statement like:
**
**   SELECT rtreenode(2, data) FROM rt_node;
**
** The human readable string takes the form of a Tcl list with one
** entry for each cell in the r-tree node. Each entry is itself a
** list, containing the 8-byte rowid/pageno followed by the
** <num-dimension>*2 coordinates.
*//* Aux columns counted by a u8 *//* 0 *//*
** This function is the implementation of both the xConnect and xCreate
** methods of the r-tree virtual table.
**
**   argv[0]   -> module name
**   argv[1]   -> database name
**   argv[2]   -> table name
**   argv[...] -> column names...
*//*
** Return the length of a token
*//* Rtree handle *//*
** This function is called from within the xConnect() or xCreate() method to
** determine the node-size used by the rtree table being created or connected
** to. If successful, pRtree->iNodeSize is populated and SQLITE_OK returned.
** Otherwise, an SQLite error code is returned.
**
** If this function is being called as part of an xConnect(), then the rtree
** table already exists. In this case the node-size is determined by inspecting
** the root node of the tree.
**
** Otherwise, for an xCreate(), use 64 bytes less than the database page-size.
** This ensures that each node is stored on a single database page. If the
** database page-size is so large that more than RTREE_MAXCELLS entries
** would fit in a single node, use a smaller node-size.
*//*
** The second argument to this function contains the text of an SQL statement
** that returns a single integer value. The statement is compiled and executed
** using database connection db. If successful, the integer value returned
** is written to *piVal and SQLITE_OK returned. Otherwise, an SQLite error
** code is returned and the value of *piVal after returning is not defined.
*//* An UPSERT is very slightly slower than REPLACE, but it is needed
       ** if there are auxiliary columns *//* Read and write the xxx_parent table *//* Read and write the xxx_rowid table *//* Write the xxx_node table *//*
** This function populates the pRtree->nRowEst variable with an estimate
** of the number of rows in the virtual table. If possible, this is based
** on sqlite_stat1 data. Otherwise, use RTREE_DEFAULT_ROWEST.
*//*
** The xSavepoint method.
**
** This module does not need to do anything to support savepoints. However,
** it uses this hook to close any open blob handle. This is done because a
** DROP TABLE command - which fortunately always opens a savepoint - cannot
** succeed if there are any open blob handles. i.e. if the blob handle were
** not closed here, the following would fail:
**
**   BEGIN;
**     INSERT INTO rtree...
**     DROP TABLE <tablename>;    -- Would fail with SQLITE_LOCKED
**   COMMIT;
*//*
** The xRename method for rtree module virtual tables.
*//*
** Called when a transaction completes (either by COMMIT or ROLLBACK).
** The sqlite3_blob object should be released at this point.
*//*
** Called when a transaction starts.
*//* Figure out the rowid of the new row. *//* Populate the cell.aCoord[] array. The first coordinate is aData[3].
    **
    ** NB: nData can only be less than nDim*2+3 if the rtree is mis-declared
    ** with "column" that are interpreted as table constraints.
    ** Example:  CREATE VIRTUAL TABLE bad USING rtree(x,y,CHECK(y>5));
    ** This problem was discovered after years of use, so we silently ignore
    ** these kinds of misdeclared tables to avoid breaking any legacy.
    *//* Constraint handling. A write operation on an r-tree table may return
  ** SQLITE_CONSTRAINT for two reasons:
  **
  **   1. A duplicate rowid value, or
  **   2. The supplied data violates the "x2>=x1" constraint.
  **
  ** In the first case, if the conflict-handling mode is REPLACE, then
  ** the conflicting row can be removed before proceeding. In the second
  ** case, SQLITE_CONSTRAINT must be returned regardless of the
  ** conflict-handling mode specified by the user.
  *//* Set to 1 after new rowid is determined *//*
** The xUpdate method for rtree module virtual tables.
*//*
** A constraint has failed while inserting a row into an rtree table.
** Assuming no OOM error occurs, this function sets the error message
** (at pRtree->base.zErrMsg) to an appropriate value and returns
** SQLITE_CONSTRAINT.
**
** Parameter iCol is the index of the leftmost column involved in the
** constraint failure. If it is 0, then the constraint that failed is
** the unique constraint on the id column. Otherwise, it is the rtree
** (c1<=c2) constraint on columns iCol and iCol+1 that has failed.
**
** If an OOM occurs, SQLITE_NOMEM is returned instead of SQLITE_CONSTRAINT.
*//* !defined(SQLITE_RTREE_INT_ONLY) *//*
** Convert an sqlite3_value into an RtreeValue (presumably a float)
** while taking care to round toward negative or positive, respectively.
*//* Round away from zero *//* Round towards zero *//*
** Rounding constants for float->double conversion.
*//* Release the reference to the root node. *//* Re-insert the contents of any underfull nodes removed from the tree. *//* tag-20210916a *//* Check if the root node now has exactly one child. If so, remove
  ** it, schedule the contents of the child for reinsertion and
  ** reduce the tree height by one.
  **
  ** This is equivalent to copying the contents of the child into
  ** the root node (the operation that Gutman's paper says to perform
  ** in this scenario).
  *//* Delete the corresponding entry in the <rtree>_rowid table. *//* Delete the cell in question from the leaf node. *//* Obtain a reference to the leaf node that contains the entry
  ** about to be deleted.
  *//* Obtain a reference to the root node to initialize Rtree.iDepth *//* Root node of rtree structure *//* Index of iDelete cell in pLeaf *//* Leaf node containing record iDelete *//*
** Remove the entry with rowid=iDelete from the r-tree structure.
*//*
** Select a currently unused rowid for a new r-tree record.
*//* Find a node to store this cell in. pNode->iNode currently contains
    ** the height of the sub-tree headed by the cell.
    *//*
** Insert cell pCell into node pNode. Node pNode is the head of a
** subtree iHeight high (leaf nodes have iHeight==0).
*//* If the node is not the tree root and now has less than the minimum
  ** number of cells, remove it from the tree. Otherwise, update the
  ** cell in the parent node so that it tightly contains the updated
  ** node.
  *//* Remove the cell from the node. This call just moves bytes around
  ** the in-memory node image, so it cannot fail.
  *//*
** Delete the cell at index iCell of node pNode. After removing the
** cell, adjust the r-tree data structure if required.
*//* Bounding box for pNode *//* Remove the node from the in-memory hash table and link it into
  ** the Rtree.pDeleted list. Its contents will be re-inserted later on.
  *//* Remove the xxx_parent entry. *//* Remove the xxx_node entry. *//* Remove the entry in the parent cell. *//* Before setting pChild->pParent, test that we are not creating a
      ** loop of references (as we would if, say, pChild==pParent). We don't
      ** want to do this as it leads to a memory leak when trying to delete
      ** the referenced counted node structures.
      *//* Node number of parent node *//* Used to test for reference loops *//*
** If node pLeaf is not the root of the r-tree and its pParent pointer is
** still NULL, load all ancestor nodes of pLeaf into memory and populate
** the pLeaf->pParent chain all the way up to the root node.
**
** This operation is required when a row is deleted (or updated - an update
** is implemented as a delete followed by an insert). SQLite provides the
** rowid of the row to delete, which can be used to find the leaf on which
** the entry resides (argument pLeaf). Once the leaf is located, this
** function is called to determine its ancestry.
*//* Ensure both child nodes have node numbers assigned to them by calling
  ** nodeWrite(). Node pRight always needs a node number, as it was created
  ** by nodeNew() above. But node pLeft sometimes already has a node number.
  ** In this case avoid the all to nodeWrite().
  *//* Allocate an array and populate it with a copy of pCell and
  ** all cells from node pLeft. Then zero the original node.
  *//*
** Implementation of the R*-tree variant of SplitNode from Beckman[1990].
*//* Check that the sort worked *//*
** Arguments aIdx, aCell and aSpare all point to arrays of size
** nIdx. The aIdx array contains the set of integers from 0 to
** (nIdx-1) in no particular order. This function sorts the values
** in aIdx according to dimension iDim of the cells in aCell. The
** minimum value of dimension iDim is considered first, the
** maximum used to break ties.
**
** The aSpare array is used as temporary working space by the
** sorting algorithm.
*//*
** Write mapping (iNode->iPar) to the <rtree>_parent table.
*//*
** Write mapping (iRowid->iNode) to the <rtree>_rowid table.
*//* This cell was just inserted *//* Adjust ancestry of this node. *//* Rtree table *//*
** A cell with the same content as pCell has just been inserted into
** the node pNode. This function updates the bounding box cells in
** all ancestor elements.
*//* No cells of pNode will completely contain pCell.  So pick the
      ** cell of pNode that grows by the least amount when pCell is added.
      ** Break ties by selecting the smaller cell.
      *//* First check to see if there is are any cells in pNode that completely
    ** contains pCell.  If two or more cells in pNode completely contain pCell
    ** then pick the smallest.
    *//* OUT: Selected leaf page *//* Height of sub-tree rooted at pCell *//* Cell to insert into rtree *//*
** This function implements the ChooseLeaf algorithm from Gutman[84].
** ChooseSubTree in r*tree terminology.
*//*
** Return true if the area covered by p2 is a subset of the area covered
** by p1. False otherwise.
*//*
** Store the union of cells p1 and p2 in p1.
*//*
** Return the margin length of cell p. The margin length is the sum
** of the objects size in each dimension.
*//*
** Return the N-dimensional volumn of the cell stored in *p.
*//* This strategy involves a two rowid lookups on an B-Tree structures
      ** and then a linear search of an R-Tree node. This should be
      ** considered almost as quick as a direct rowid lookup (for which
      ** sqlite uses an internal cost of 0.0). It is expected to return
      ** a single row.
      *//* We have an equality constraint on the rowid. Use strategy 1. *//* Check if there exists a MATCH constraint - even an unusable one. If there
  ** is, do not consider the lookup-by-rowid plan as using such a plan would
  ** require the VDBE to evaluate the MATCH constraint, which is not currently
  ** possible. *//* Estimated rows returned by this scan *//* True if there exists a MATCH constraint *//*
** Rtree virtual table module xBestIndex method. There are three
** table scan strategies to choose from (in order from most to
** least desirable):
**
**   idxNum     idxStr        Strategy
**   ------------------------------------------------
**     1        Unused        Direct lookup by rowid.
**     2        See below     R-tree query or full-table scan.
**   ------------------------------------------------
**
** If strategy 1 is used, then idxStr is not meaningful. If strategy
** 2 is used, idxStr is formatted to contain 2 bytes for each
** constraint used. The first two bytes of idxStr correspond to
** the constraint in sqlite3_index_info.aConstraintUsage[] with
** (argvIndex==1) etc.
**
** The first of each pair of bytes in idxStr identifies the constraint
** operator as follows:
**
**   Operator    Byte Value
**   ----------------------
**      =        0x41 ('A')
**     <=        0x42 ('B')
**      <        0x43 ('C')
**     >=        0x44 ('D')
**      >        0x45 ('E')
**   MATCH       0x46 ('F')
**   ----------------------
**
** The second of each pair of bytes identifies the coordinate column
** to which the constraint applies. The leftmost coordinate column
** is 'a', the second from the left 'b' etc.
*//* Because pCsr->bPoint was FALSE *//* Due to the resetCursor() call above *//* A MATCH operator. The right-hand-side must be a blob that
            ** can be cast into an RtreeMatchArg object. One created using
            ** an sqlite3_rtree_geometry_callback() SQL user function.
            *//*
** Rtree virtual table module xFilter method.
*//* Callback information *//* BLOB returned by geometry function *//*
** This function is called to configure the RtreeConstraint object passed
** as the second argument for a MATCH constraint. The value passed as the
** first argument to this function is the right-hand operand to the MATCH
** operator.
*//* Write the node-id here *//* Write the node here *//* The rowid searching for *//* RTree to search *//*
** Use nodeAcquire() to obtain the leaf node containing the record with
** rowid iRowid. If successful, set *ppLeaf to point to the node and
** return SQLITE_OK. If there is no such record in the table, set
** *ppLeaf to 0 and return SQLITE_OK. If an error occurs, set *ppLeaf
** to zero and return an SQLite error code.
*//*
** Rtree virtual table module xColumn method.
*//*
** Rtree virtual table module xRowid method.
*//* Move to the next entry that matches the configured constraints. *//*
** Rtree virtual table module xNext method.
*//*
** Continue the search on cursor pCur until the front of the queue
** contains an entry suitable for returning as a result-set row,
** or until the RtreeSearchPoint queue is empty, indicating that the
** query has completed.
*//* Remove the search point with the lowest current score.
*//* Tracing routines for the RtreeSearchPoint queue *//* Level for the new search point *//* Score for the new search point *//*
** Allocate a new RtreeSearchPoint and return a pointer to it.  Return
** NULL if malloc fails.
*//*
** Push a new element onto the priority queue
*//*
** Get the RtreeNode for the search point with the lowest score.
*//*
** Return the search point with the lowest current score.
*//*
** Interchange two search points in a cursor.
*//*
** Compare two search points.  Return negative, zero, or positive if the first
** is less than, equal to, or greater than the second.
**
** The rScore is the primary key.  Smaller rScore values come first.
** If the rScore is a tie, then use iLevel as the tie breaker with smaller
** iLevel values coming first.  In this way, if rScore is the same for all
** SearchPoints, then iLevel becomes the deciding factor and the result
** is a depth-first search, which is the desired default behavior.
*//*
** Return the index of the cell containing a pointer to node pNode
** in its parent. If pNode is the root node, return -1.
*//*
** One of the cells in node pNode is guaranteed to have a 64-bit
** integer value equal to iRowid. Return the index of this cell.
*//* Never satisfied *//* Always satisfied *//* Coordinate value converted to a double *//* Adjust downward, as appropriate *//* Raw cell content as appears on disk *//* True if RTree holds integer coordinates *//* The constraint to test *//*
** Check the leaf RTree cell given by pCellData against constraint p.
** If this constraint is not satisfied, set *peWithin to NOT_WITHIN.
** If the constraint is satisfied, leave *peWithin unchanged.
**
** The constraint is of the form:  xN op $val
**
** The op is given by p->op.  The xN is p->iCoord-th coordinate in
** pCellData.  $val is given by p->u.rValue.
*//* val now holds the upper bound of the coordinate pair *//* val now holds the lower bound of the coordinate pair *//* p->iCoord might point to either a lower or upper bound coordinate
  ** in a coordinate pair.  But make pCellData point to the lower bound.
  *//* Coordinate value convert to a double *//*
** Check the internal RTree node given by pCellData against constraint p.
** If this constraint cannot be satisfied by any child within the node,
** set *peWithin to NOT_WITHIN.
*//* Decoded coordinates *//* Translator union *//* Callback return code *//* No. of coordinates *//* Callback info *//* OUT: visibility of the cell *//* OUT: score for the cell *//* Container of this cell *//* Raw cell content *//* True if RTree holding integer coordinates *//*
** Check the RTree node or entry given by pCellData and p against the MATCH
** constraint pConstraint.
*//* Coordinate decoded *//*
** Convert raw bits from the on-disk RTree record into a coordinate value.
** The on-disk format is big-endian and needs to be converted for little-
** endian platforms.  The on-disk record stores integer coordinates if
** eInt is true and it stores 32-bit floating point records if eInt is
** false.  a[] is the four bytes of the on-disk record to be decoded.
** Store the results in "r".
**
** There are five versions of this macro.  The last one is generic.  The
** other four are various architectures-specific optimizations.
*//*
** Rtree virtual table module xEof method.
**
** Return non-zero if the cursor does not currently point to a valid
** record (i.e if the scan has finished), or zero otherwise.
*//*
** Rtree virtual table module xClose method.
*//* Used to iterate through constraint array *//*
** Reset a cursor back to its initial state.
*//*
** Rtree virtual table module xOpen method.
*//*
** Rtree virtual table module xDestroy method.
*//*
** Rtree virtual table module xDisconnect method.
*//*
** Decrement the r-tree reference count. When the reference count reaches
** zero the structure is deleted.
*//*
** Increment the r-tree reference count.
*//*
** Rtree virtual table module xConnect method.
*//*
** Rtree virtual table module xCreate method.
*//* Forward declaration for the function that does the work of
** the virtual table module xCreate() and xConnect() methods.
*//* OUT: Write the cell contents here *//* Index of the cell within the node *//* The node containing the cell to be read *//* The overall R-Tree *//*
** Deserialize cell iCell of node pNode. Populate the structure pointed
** to by pCell with the results.
*//* OUT: Space to write result to *//* Which coordinate to extract *//* The index of the cell within the node *//* The node from which to extract a coordinate *//*
** Return coordinate iCoord from cell iCell in node pNode.
*//* The cell index from which to extract the ID *//* The node from which to extract the ID *//*
** Return the 64-bit integer value associated with cell iCell of
** node pNode. If pNode is a leaf node, this is a rowid. If it is
** an internal node, then the 64-bit integer is a child page number.
*//*
** Release a reference to a node. If the node is dirty and the reference
** count drops to zero, the node data is written to the database.
*//*
** If the node is dirty, write it out to the database.
*//* Maximum number of cells for pNode *//* Current number of cells in pNode *//* The cell to be inserted *//* Write new cell into this node *//*
** Insert the contents of cell pCell into node pNode. If the insert
** is successful, return SQLITE_OK.
**
** If there is not enough free space in pNode, return SQLITE_FULL.
*//*
** Remove the cell with index iCell from node pNode.
*//* Index into pNode into which pCell is written *//* The cell to write *//* The node into which the cell is to be written *//*
** Overwrite cell iCell of node pNode with the contents of pCell.
*//* If no error has occurred so far, check if the "number of entries"
  ** field on the node is too large. If so, set the return code to
  ** SQLITE_CORRUPT_VTAB.
  *//* If the root node was just loaded, set pRtree->iDepth to the height
  ** of the r-tree structure. A height of zero means all data is stored on
  ** the root node. A height of one means the children of the root node
  ** are the leaves, and so on. If the depth as specified on the root node
  ** is greater than RTREE_MAX_DEPTH, the r-tree structure must be corrupt.
  *//* If unable to open an sqlite3_blob on the desired row, that can only
    ** be because the shadow tables hold erroneous data. *//* Check if the requested node is already in the hash table. If so,
  ** increase its reference count and return it.
  *//* OUT: Acquired node *//* Either the parent node or NULL *//* Node number to load *//* R-tree structure *//*
** Obtain a reference to an r-tree node.
*//*
** Clear the Rtree.pNodeBlob object
*//*
** Allocate and return new r-tree node. Initially, (RtreeNode.iNode==0),
** indicating that node has not yet been assigned a node number. It is
** assigned a node number when nodeWrite() is called to write the
** node contents out to the database.
*//*
** Remove node pNode from the node hash table.
*//*
** Add node pNode to the node hash table.
*//*
** Search the node hash table for node iNode. If found, return a pointer
** to it. Otherwise, return 0.
*//*
** Given a node number iNode, return the corresponding key to use
** in the Rtree.aHash table.
*//*
** Clear the content of node p (set all bytes to 0x00).
*//*
** Increment the reference count of node p.
*//*
** Functions to serialize a 16 bit integer, 32 bit real number and
** 64 bit integer. The value returned is the number of bytes written
** to the argument buffer (always 2, 4 and 8 respectively).
*//*
** Functions to deserialize a 16 bit integer, 32 bit real number and
** 64 bit integer. The deserialized value is returned.
*//* What version of MSVC is being used.  0 means MSVC is not being used *//* Replicate changes at tag-20230904a *//*
** Macros to determine whether the machine is big or little endian,
** and whether or not that determination is run-time or compile-time.
**
** For best performance, an attempt is made to guess at the byte-order
** using C-preprocessor macros.  If that is unsuccessful, or if
** -DSQLITE_RUNTIME_BYTEORDER=1 is set, then byte-order is determined
** at run-time.
*//* #      include <cmnintrin.h> *//* #      include <intrin.h> *//*
** Make sure that the compiler intrinsics we desire are enabled when
** compiling with an appropriate version of MSVC unless prevented by
** the SQLITE_DISABLE_INTRINSIC define.
*//* The testcase() macro should already be defined in the amalgamation.  If
** it is not, make it a no-op.
*//* What version of GCC is being used.  0 means GCC is not being used .
** Note that the GCC_VERSION macro will also be set correctly when using
** clang, since clang works hard to be gcc compatible.  So the gcc
** optimizations will also work when compiling with clang.
*//* Values for parameters to the SQL function *//* Original SQL parameter values *//* Number of parameters to the SQL function *//* Info about the callback functions *//* Size of this object *//*
** An instance of this structure (in the form of a BLOB) is returned by
** the SQL functions that sqlite3_rtree_geometry_callback() and
** sqlite3_rtree_query_callback() create, and is read as the right-hand
** operand to the MATCH operator of an R-Tree.
*//*
** This object becomes the sqlite3_user_data() for the SQL functions
** that are created by sqlite3_rtree_geometry_callback() and
** sqlite3_rtree_query_callback() and which appear on the right of MATCH
** operators in order to constrain a search.
**
** xGeom and xQueryFunc are the callback functions.  Exactly one of
** xGeom and xQueryFunc fields is non-NULL, depending on whether the
** SQL function was created using sqlite3_rtree_geometry_callback() or
** sqlite3_rtree_query_callback().
**
** This object is deleted automatically by the destructor mechanism in
** sqlite3_create_function_v2().
*//* Bounding box coordinates *//* Node or entry ID *//*
** A single cell from a node, deserialized
*//* Return the number of cells in a node  *//* Next node in this hash collision chain *//* Content of the node, as should be on disk *//* True if the node needs to be written to disk *//* Number of references to this node *//* The node number *//* Parent node *//*
** An rtree structure node.
*//* @ *//* ? *//* Special operators available only on cursors.  Needs to be consecutive
** with the normal values above, but must be less than RTREE_MATCH.  These
** are used in the cursor for contraints such as x=NULL (RTREE_FALSE) or
** x<'xyz' (RTREE_TRUE) *//* G: New-style sqlite3_rtree_query_callback() *//* F: Old-style sqlite3_rtree_geometry_callback() *//* E *//* D *//* C *//* B *//* A *//* Possible values for RtreeConstraint.op *//* xGeom and xQueryFunc argument *//* Constraint value. *//* Constraining operation *//* Index of constrained coordinate *//*
** A search constraint.
*//*
** The argument is an RtreeCoord. Return the value stored within the RtreeCoord
** formatted as a RtreeDValue (double or int64). This macro assumes that local
** variable pRtree points to the Rtree structure associated with the
** RtreeCoord.
*//* Unsigned for byte-order conversions *//* Integer value *//* Floating point value *//*
** A coordinate can be either a floating point number or a integer.  All
** coordinates within a single R-Tree are always of the same time.
*//* Return the Rtree of a RtreeCursor *//* Number of queued entries by iLevel *//* Rtree node cache *//* Cached next search point *//* Statement to read aux-data *//* Priority queue for search points *//* iLevel value for root of the tree *//* Number of slots used in aPoint[] *//* Number of slots allocated for aPoint[] *//* Search constraints. *//* Copy of idxNum search parameter *//* True if pReadAux is valid *//* True if sPoint is valid *//* True if at end of search *//*
** An rtree cursor object.
*//*
** Number of entries in the cursor RtreeNode cache.  The first entry is
** used to cache the RtreeNode for RtreeCursor.sPoint.  The remaining
** entries cache the RtreeNode for the first elements of the priority queue.
*//*
** The smallest possible node-size is (512-64)==448 bytes. And the largest
** supported cell size is 48 bytes (8 byte rowid + ten 4 byte coordinates).
** Therefore all non-root nodes must contain at least 3 entries. Since
** 3^40 is greater than 2^64, an r-tree structure always has a depth of
** 40 or less.
*//*
** The minimum number of cells allowed for a node is a third of the
** maximum. In Gutman's notation:
**
**     m = M/3
**
** If an R*-tree "Reinsert" operation is required, the same number of
** cells are removed from the overfull node and reinserted into the tree.
*//* Cell index within the node *//* PARTLY_WITHIN or FULLY_WITHIN *//* 0=entries.  1=leaf node.  2+ for higher *//* Node ID *//* The score for this node.  Smallest goes first. *//*
** When doing a search of an r-tree, instances of the following structure
** record intermediate results from the tree walk.
**
** The id is always a node-id.  For iLevel>=1 the id is the node-id of
** the node that the RtreeSearchPoint represents.  When iLevel==0, however,
** the id is of the parent node and the cell that RtreeSearchPoint
** represents is the iCell-th entry in the parent node.
*//*
** Set the Rtree.bCorrupt flag
*//* Low accuracy coordinate *//* High accuracy coordinate *//*
** If SQLITE_RTREE_INT_ONLY is defined, then this virtual table will
** only deal with integer coordinates.  No floating point operations
** will be done.
*//* Possible values for Rtree.eCoordType: *//* Hash table of in-memory nodes. *//* Statement for writing to the "aux:" fields, if there are any *//* Statements to read/write/delete a record from xxx_parent *//* Statements to read/write/delete a record from xxx_rowid *//* Statements to read/write/delete a record from xxx_node *//* Blob I/O on xxx_node *//* List of nodes removed during a CondenseTree operation. List is
  ** linked together via the pointer normally used for hash chains -
  ** RtreeNode.pNext. RtreeNode.iNode stores the depth of the sub-tree
  ** headed by the node (leaf nodes have RtreeNode.iNode==0).
  *//* SQL for statement to read aux data *//* Number RtreeNodes with positive nRef *//* Estimated number of rows in this table *//* Current number of users of this structure *//* Name of the %_node table *//* Name of r-tree table *//* Name of database containing r-tree table *//* Current depth of the r-tree structure *//* Shadow table corruption detected *//* Number of initial not-null aux columns *//* # of auxiliary columns in %_rowid *//* True if inside write transaction *//* Bytes consumed per cell *//* RTREE_COORD_REAL32 or RTREE_COORD_INT32 *//* Twice the number of dimensions *//* Number of dimensions *//* Size in bytes of each node in the node table *//*
** An rtree virtual-table object.
*//* The xBestIndex method of this virtual table requires an estimate of
** the number of rows in the virtual table to calculate the costs of
** various strategies. If possible, this estimate is loaded from the
** sqlite_stat1 table (with RTREE_MIN_ROWEST as a hard-coded minimum).
** Otherwise, if no sqlite_stat1 entry is available, use
** RTREE_DEFAULT_ROWEST.
*//* Size of hash table Rtree.aHash. This hash table is not expected to
** ever contain very many entries, so a fixed number of buckets is
** used.
*//* Maximum number of auxiliary columns *//* The rtree may have between 1 and RTREE_MAX_DIMENSIONS dimensions. *//*  The following macro is used to suppress compiler warnings.
*//* Macro to check for 4-byte alignment.  Only used inside of assert() *//*
** If building separately, we will need some setup that is normally
** found in sqliteInt.h
*//* In the SQLite core *//*
** Database Format of R-Tree Tables
** --------------------------------
**
** The data structure for a single virtual r-tree table is stored in three
** native SQLite tables declared as follows. In each case, the '%' character
** in the table name is replaced with the user-supplied name of the r-tree
** table.
**
**   CREATE TABLE %_node(nodeno INTEGER PRIMARY KEY, data BLOB)
**   CREATE TABLE %_parent(nodeno INTEGER PRIMARY KEY, parentnode INTEGER)
**   CREATE TABLE %_rowid(rowid INTEGER PRIMARY KEY, nodeno INTEGER, ...)
**
** The data for each node of the r-tree structure is stored in the %_node
** table. For each node that is not the root node of the r-tree, there is
** an entry in the %_parent table associating the node with its parent.
** And for each row of data in the table, there is an entry in the %_rowid
** table that maps from the entries rowid to the id of the node that it
** is stored on.  If the r-tree contains auxiliary columns, those are stored
** on the end of the %_rowid table.
**
** The root node of an r-tree always exists, even if the r-tree table is
** empty. The nodeno of the root node is always 1. All other nodes in the
** table must be the same size as the root node. The content of each node
** is formatted as follows:
**
**   1. If the node is the root node (node 1), then the first 2 bytes
**      of the node contain the tree depth as a big-endian integer.
**      For non-root nodes, the first 2 bytes are left unused.
**
**   2. The next 2 bytes contain the number of entries currently
**      stored in the node.
**
**   3. The remainder of the node contains the node entries. Each entry
**      consists of a single 8-byte integer followed by an even number
**      of 4-byte coordinates. For leaf nodes the integer is the rowid
**      of a record. For internal nodes it is the node number of a
**      child page.
*//*
** 2001 September 15
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains code for implementations of the r-tree and r*-tree
** algorithms packaged as an SQLite virtual table module.
*//************** Begin file rtree.c *******************************************//************** End of json.c ************************************************//* !defined(SQLITE_OMIT_VIRTUALTABLE) && !defined(SQLITE_OMIT_JSON) *//*
** Register the JSON table-valued functions
*//*                            | | |  | | |                              *//*     Number of arguments ---, | |  | | ,--- Flags                     *//*                              | |  | |                                *//*             Uses cache ------, |  | ,---- Returns JSONB              *//*                                |  |                                  *//*   sqlite3_result_subtype() ----,  ,--- sqlite3_value_subtype()       *//*
** Register JSON functions.
*//* !defined(SQLITE_OMIT_JSON) *//* The methods of the json_tree virtual table. *//* The methods of the json_each virtual table *//* Start a search on a new JSON string *//* Both JSON and ROOT are supplied.  Plan 3 *//* Only JSON supplied.  Plan 1 *//* No JSON input.  Leave estimatedCost at the huge value that it was
    ** initialized to to discourage the query planner from selecting this
    ** plan. *//* If there are any unusable constraints on JSON or ROOT, then reject
    ** this entire plan *//* This implementation assumes that JSON and ROOT are the last two
  ** columns in the table *//* Mask of usable == constraints JSON and ROOT *//* Mask of unusable JSON and ROOT constraints *//* Index of constraints for JSON and ROOT *//* Loop counter or computed array index *//* The query strategy is to look for an equality constraint on the json
** column.  Without such a constraint, the table cannot operate.  idxNum is
** 1 if the constraint is found, 3 if the constraint and zRoot are found,
** and 0 otherwise.
*//* Return the current rowid value *//* Return the value of a column *//* Length of the path for rowid==0 in bRecursive mode.
*//* Advance the cursor to the next element for json_tree() *//*
** Append the path name for the current element.
*//*
** If the cursor is currently pointing at the label of a object entry,
** then return the index of the value.  For all other cases, return the
** current pointer position, which is the value.
*//* Return TRUE if the jsonEachCursor object has been advanced off the end
** of the JSON object *//* Destructor for a jsonEachCursor object *//* Reset a JsonEachCursor back to its original state.  Free any memory
** held. *//* constructor for a JsonEachCursor object for json_tree(). *//* constructor for a JsonEachCursor object for json_each(). *//* destructor for json_each virtual table *//* The xBestIndex method assumes that the JSON and ROOT columns are
** the last two columns in the table.  Should this ever changes, be
** sure to update the xBestIndex method. *//* Constructor for the json_each virtual table *//* Parse of the input JSON *//* Current path *//* Parent elements of i *//* Space allocated for aParent[] *//* Current nesting depth *//* True for json_tree().  False for json_each() *//* Type of the container for element i *//* Size of the root path in bytes *//* EOF when i equals or exceeds this value *//* Index in sParse.aBlob[] of current row *//* Key for JSONB_ARRAY *//* Length of path *//* First byte past the end *//* Start of the value *//* Start of object or array *//****************************************************************************
** The json_each virtual table
****************************************************************************//*
** json_group_obj(NAME,VALUE)
**
** Return a JSON object composed of all names and values in the aggregate.
*//* pStr is always non-NULL since jsonArrayStep() or jsonObjectStep() will
  ** always have been called to initialize it *//*
** This method works for both json_group_array() and json_group_object().
** It works by removing the first element of the group by searching forward
** to the first comma (",") that is not within a string and deleting all
** text through that comma.
*//*
** json_group_array(VALUE)
**
** Return a JSON array composed of all values in the aggregate.
*//****************************************************************************
** Aggregate SQL function implementations
****************************************************************************//* Because s.oom is false *//* Convert byte-offset s.iErr into a character offset *//* NULL input or OOM *//* Error position to be returned *//*
** json_error_position(JSON)
**
** If the argument is NULL, return NULL
**
** If the argument is BLOB, do a full validity check and return non-zero
** if the check fails.  The return value is the approximate 1-based offset
** to the byte of the element that contains the first error.
**
** Otherwise interpret the argument is TEXT (even if it is numeric) and
** return the 1-based character position for where the parser first recognized
** that the input was not valid JSON, or return 0 if the input text looks
** ok.  JSON-5 extensions are accepted.
*//* no break *//* Fall through into interpreting the input as text.  See note
      ** above at tag-20240123-a. *//* Strict checking.  Check by translating BLOB->TEXT->BLOB.  If
          ** no errors occur, call that a "strict check". *//* Superficial checking only - accomplished by the
          ** jsonFuncArgMightBeBinary() call above. *//* Incorrect legacy behavior was to return FALSE for a NULL input *//* The parse *//*
** json_valid(JSON)
** json_valid(JSON, FLAGS)
**
** Check the JSON argument to see if it is well-formed.  The FLAGS argument
** encodes the various constraints on what is meant by "well-formed":
**
**     0x01      Canonical RFC-8259 JSON text
**     0x02      JSON text with optional JSON-5 extensions
**     0x04      Superficially appears to be JSONB
**     0x08      Strictly well-formed JSONB
**
** If the FLAGS argument is omitted, it defaults to 1.  Useful values for
** FLAGS include:
**
**    1          Strict canonical JSON text
**    2          JSON text perhaps with JSON-5 extensions
**    4          Superficially appears to be JSONB
**    5          Canonical JSON text or superficial JSONB
**    6          JSON-5 text or superficial JSONB
**    8          Strict JSONB
**    9          Canonical JSON text or strict JSONB
**    10         JSON-5 text or strict JSONB
**
** Other flag combinations are redundant.  For example, every canonical
** JSON text is also well-formed JSON-5 text, so FLAG values 2 and 3
** are the same.  Similarly, any input that passes a strict JSONB validation
** will also pass the superficial validation so 12 through 15 are the same
** as 8 through 11 respectively.
**
** This routine runs in linear time to validate text and when doing strict
** JSONB validation.  Superficial JSONB validation is constant time,
** assuming the BLOB is already in memory.  The performance advantage
** of superficial JSONB validation is why that option is provided.
** Application developers can choose to do fast superficial validation or
** slower strict validation, according to their specific needs.
**
** Only the lower four bits of the FLAGS argument are currently used.
** Higher bits are reserved for future expansion.   To facilitate
** compatibility, the current implementation raises an error if any bit
** in FLAGS is set other than the lower four bits.
**
** The original circa 2015 implementation of the JSON routines in
** SQLite only supported canonical RFC-8259 JSON text and the json_valid()
** function only accepted one argument.  That is why the default value
** for the FLAGS argument is 1, since FLAGS=1 causes this routine to only
** recognize canonical RFC-8259 JSON text as valid.  The extra FLAGS
** argument was added when the JSON routines were extended to support
** JSON5-like extensions and binary JSONB stored in BLOBs.
**
** Return Values:
**
**   *   Raise an error if FLAGS is outside the range of 1 to 15.
**   *   Return NULL if the input is NULL
**   *   Return 1 if the input is well-formed.
**   *   Return 0 if the input is not well-formed.
*//* Pretty printing context *//* The output string *//*
** json_pretty(JSON)
** json_pretty(JSON, INDENT)
**
** Return text that is a pretty-printed rendering of the input JSON.
** If the argument is not valid JSON, return NULL.
**
** The INDENT argument is text that is used for indentation.  If omitted,
** it defaults to four spaces (the same as PostgreSQL).
*//*
** json_type(JSON)
** json_type(JSON, PATH)
**
** Return the top-level "type" of a JSON string.  json_type() raises an
** error if either the JSON or PATH inputs are not well-formed.
*//*
** json_set(JSON, PATH, VALUE, ...)
**
** Set the value at PATH to VALUE.  Create the PATH if it does not already
** exist.  Overwrite existing values that do exist.
** If JSON or PATH is malformed, throw an error.
**
** json_insert(JSON, PATH, VALUE, ...)
**
** Create PATH and initialize it to VALUE.  If PATH already exists, this
** routine is a no-op.  If JSON or PATH is malformed, throw an error.
*//*
** json_replace(JSON, PATH, VALUE, ...)
**
** Replace the value at PATH with VALUE.  If PATH does not already exist,
** this routine is a no-op.  If JSON or PATH is malformed, throw an error.
*//* json_remove(j,'$') returns NULL *//* Subroutine return code *//* Path of element to be removed *//*
** json_remove(JSON, PATH, ...)
**
** Remove the named elements from JSON and return the result.  malformed
** JSON or PATH arguments result in an error.
*//*
** Implementation of the json_object(NAME,VALUE,...) function.  Return a JSON
** object that contains all name/value given in arguments.  Or if any name
** is not a string or if any value is a BLOB, throw an error.
*//* Result code *//* The PATCH *//* The TARGET *//*
** Implementation of the json_mergepatch(JSON1,JSON2) function.  Return a JSON
** object that is the result of running the RFC 7396 MergePatch() algorithm
** on the two arguments.
*//* Line 14 *//* No match and patch value is not NULL *//* Algorithm line 13 *//* Algorithm line 12 *//*  vvvvvv----- No OOM on a delete-only edit *//* Patch value is NULL.  Algorithm line 09 *//* A match was found.  Algorithm line 08 *//* true if the patch and target labels match *//* Algorithm line 07 *//* Algorithm line 05 *//* Line 03 *//* Total size of the target, header+payload *//* Total size of the patch, header+payload *//* Algorithm line 02 *//* Payload size of the patch value *//* Header size for the patch value *//* Start of patch value *//* Payload size of the patch label *//* Size of header on the patch label *//* Start of patch label *//* Node type of the patch label *//* First byte past the end of the patch *//* Cursor position while scanning the patch *//* Payload size for the target value *//* Header size of the target value *//* Index of the target value *//* Size of the target label payload *//* Header size in bytes for the target label *//* Index of the label *//* Node type of the target label *//* Current first byte past end of target *//* Original first byte past end of target, before edit *//* First label in the target object *//* Cursor position while scanning the target object *//* Return values from jsonbPayloadSize() *//* Type of a single node *//* Index of PATCH in pPatch->aBlob[] *//* Index of TARGET in pTarget->aBlob[] *//* The JSON parser that contains the TARGET *//*
** RFC-7396 MergePatch for two JSONB blobs.
**
** pTarget is the target. pPatch is the patch.  The target is updated
** in place.  The patch is read-only.
**
** The original RFC-7396 algorithm is this:
**
**   define MergePatch(Target, Patch):
**     if Patch is an Object:
**       if Target is not an Object:
**         Target = {} # Ignore the contents and set it to an empty Object
**     for each Name/Value pair in Patch:
**         if Value is null:
**           if Name exists in Target:
**             remove the Name/Value pair from Target
**         else:
**           Target[Name] = MergePatch(Target[Name], Value)
**       return Target
**     else:
**       return Patch
**
** Here is an equivalent algorithm restructured to show the actual
** implementation:
**
** 01   define MergePatch(Target, Patch):
** 02      if Patch is not an Object:
** 03         return Patch
** 04      else: // if Patch is an Object
** 05         if Target is not an Object:
** 06            Target = {}
** 07      for each Name/Value pair in Patch:
** 08         if Name exists in Target:
** 09            if Value is null:
** 10               remove the Name/Value pair from Target
** 11            else
** 12               Target[name] = MergePatch(Target[Name], Value)
** 13         else if Value is not NULL:
** 14            if Value is not an Object:
** 15               Target[name] = Value
** 16            else:
** 17               Target[name] = MergePatch('{}',value)
** 18      return Target
**  |
**  ^---- Line numbers referenced in comments in the implementation
*//* Out-of-memory condition *//* Malformed PATCH blob *//* Malformed TARGET blob *//* Success *//*
** Return codes for jsonMergePatch()
*//* Return NULL if not found *//* The -> and ->> operators accept abbreviated PATH arguments.  This
      ** is mostly for compatibility with PostgreSQL, but also for
      ** convenience.
      **
      **     NUMBER   ==>  $[NUMBER]     // PG compatible
      **     LABEL    ==>  $.LABEL       // PG compatible
      **     [NUMBER] ==>  $[NUMBER]     // Not PG.  Purely for convenience
      **
      ** Updated 2024-05-27:  If the NUMBER is negative, then PG counts from
      ** the right of the array.  Hence for negative NUMBER:
      **
      **     NUMBER   ==>  $[#NUMBER]    // PG compatible
      *//* With a single PATH argument *//* String for array result *//* Flags associated with the function *//*
** json_extract(JSON, PATH, ...)
** "->"(JSON,PATH)
** "->>"(JSON,PATH)
**
** Return the element described by PATH.  Return NULL if that PATH element
** is not found.
**
** If JSON_JSON is set or if more that one PATH argument is supplied then
** always return a JSON representation of the result.  If JSON_SQL is set,
** then always return an SQL representation of the result.  If neither flag
** is present and argc==2, then return JSON for objects and arrays and SQL
** for all other values.
**
** When multiple PATH arguments are supplied, the result is a JSON array
** containing the result of each PATH.
**
** Abbreviated JSON path expressions are allows if JSON_ABPATH, for
** compatibility with PG.
*//* True if the string is all alphanumerics and underscores *//*
** json_array_length(JSON)
** json_array_length(JSON, PATH)
**
** Return the number of elements in the top-level JSON array.
** Return 0 if the input is not a well-formed JSON array.
*//*
** Implementation of the json_array(VALUE,...) function.  Return a JSON
** array that contains all values given in arguments.  Or if any argument
** is a BLOB, throw an error.
*//*
** Implementation of the json_quote(VALUE) function.  Return a JSON value
** corresponding to the SQL value input.  Mostly this means putting
** double-quotes around strings and returning the unquoted string "null"
** when given a NULL input.
*//****************************************************************************
** Scalar SQL function implementations
****************************************************************************//*
** SQL function:   json_parse(JSON)
**
** Parse JSON using jsonParseFuncArg().  Return text that is a
** human-readable dump of the binary JSONB for the input parameter.
*//* Generate output into this sqlite3_str object *//* Indent by this many spaces *//* Do not render this byte or any byte after this one *//* Start rendering here *//* JSON content *//*
** Decode JSONB bytes in aBlob[] starting at iStart through but not
** including iEnd.  Indent the
** content by nIndent spaces.
*//****************************************************************************
** SQL functions used for testing and debugging
****************************************************************************//*
** Make the return value of a JSON function either the raw JSONB blob
** or make it JSON text, depending on whether the JSON_BLOB flag is
** set on the function.
*//* If the blob is not valid JSONB, fall through into trying to cast
    ** the blob into text which is then interpreted as JSON.  (tag-20240123-a)
    **
    ** This goes against all historical documentation about how the SQLite
    ** JSON functions were suppose to work.  From the beginning, blob was
    ** reserved for expansion and a blob value should have raised an error.
    ** But it did not, due to a bug.  And many applications came to depend
    ** upon this buggy behavior, espeically when using the CLI and reading
    ** JSON text using readfile(), which returns a blob.  For this reason
    ** we will continue to support the bug moving forward.
    ** See for example https://sqlite.org/forum/forumpost/012136abd5292b8d
    *//* Value taken from cache *//* Value to be returned *//* Datatype of pArg *//*
** Generate a JsonParse object, containing valid JSONB in aBlob and nBlob,
** from the SQL function argument pArg.  Return a pointer to the new
** JsonParse object.
**
** Ownership of the new JsonParse object is passed to the caller.  The
** caller should invoke jsonParseFree() on the return value when it
** has finished using it.
**
** If any errors are detected, an appropriate error messages is set
** using sqlite3_result_error() or the equivalent and this routine
** returns NULL.  This routine also returns NULL if the pArg argument
** is an SQL NULL value, but no error message is set in that case.  This
** is so that SQL functions that are given NULL arguments will return
** a NULL value.
*//*
** If pArg is a blob that seems like a JSONB blob, then initialize
** p to point to that JSONB and return TRUE.  If pArg does not seem like
** a JSONB blob, then return FALSE;
**
** This routine is only called if it is already known that pArg is a
** blob.  The only open question is whether or not the blob appears
** to be a JSONB blob.
*//* JEDIT_INS, JEDIT_REPL, or JEDIT_SET *//* argv[0] is a BLOB that seems likely to be a JSONB.  Subsequent
** arguments come in parse where each pair contains a JSON path and
** content to insert or set at that patch.  Do the updates
** and return the result.
**
** The specific operation is determined by eEdit, which can be one
** of JEDIT_INS, JEDIT_REPL, or JEDIT_SET.
*//* The path with the problem *//* The function call containing the error *//*
** Generate a bad path error.
**
** If ctx is not NULL then push the error message into ctx and return NULL.
** If ctx is NULL, then return the text of the error message.
*//*
** pArg is a function argument that might be an SQL value or a JSON
** value.  Figure out what it is and encode it as a JSONB blob.
** Return the results in pParse.
**
** pParse is uninitialized upon entry.  This routine will handle the
** initialization of pParse.  The result will be contained in
** pParse->aBlob and pParse->nBlob.  pParse->aBlob might be dynamically
** allocated (if pParse->nBlobAlloc is greater than zero) in which case
** the caller is responsible for freeing the space allocated to pParse->aBlob
** when it has finished with it.  Or pParse->aBlob might be a static string
** or a value obtained from sqlite3_value_blob(pArg).
**
** If the argument is a BLOB that is clearly not a JSONB, then this
** function might set an error message in ctx and return non-zero.
** It might also set an error message and return non-zero on an OOM error.
*//* end for() *//* Silently ignore illegal unicode *//* Translate JSON formatted string into raw text *//* return text JSON.  Disregard user-data *//* Return value for this function *//* Index of the node *//* Complete JSON parse tree *//*
** Return the value of the BLOB node at index i.
**
** If the value is a primitive, return it as an SQL value.
** If the value is an array or object, return it as either
** JSON text or the BLOB encoding, depending on the JSON_B flag
** on the userdata.
*//*
** Convert a JSON BLOB into text and make that text the return value
** of an SQL function.
*//* Because pPasre->oom!=0 *//* Because pParse->oom!=0 *//* Header of the label to be inserted *//* BLOB encoding of the value to be inserted *//* Total bytes to insert (label+value) *//* v is the index of the value *//* k is the index of the label text *//* j is the index of a label *//* json_set() or json_replace() *//* Already exists, so json_insert() is a no-op *//* Label if iRoot is a value of in an object *//* The path to search *//* Begin the search at this element of aBlob[] *//* The JSON to search *//*
** Search along zPath to find the Json element specified.  Return an
** index into pParse->aBlob[] for the start of that element's value.
**
** If the value found by this routine is the value half of label/value pair
** within an object, then set pPath->iLabel to the start of the corresponding
** label, before returning.
**
** Return one of the JSON_LOOKUP error codes if problems are seen.
**
** This routine will also modify the blob.  If pParse->eEdit is one of
** JEDIT_DEL, JEDIT_REPL, JEDIT_INS, or JEDIT_SET, then changes might be
** made to the selected value.  If an edit is performed, then the return
** value does not necessarily point to the select element.  If an edit
** is performed, the return value is only useful for detecting error
** conditions.
*//* Error code only *//* Construct the binary substructure *//* No substructure.  Just insert what is given in pParse. *//* Tail of the path that determins substructure *//* Populate this with the blob data to insert *//* The original JSONB that is being edited *//* This helper routine for jsonLookupStep() populates pIns with
** binary data that is to be inserted into pParse.
**
** In the common case, pIns just points to pParse->aIns and pParse->nIns.
** But if the zPath of the original edit operation includes path elements
** that go deeper, additional substructure must be created.
**
** For example:
**
**     json_insert('{}', '$.a.b.c', 123);
**
** The search stops at '$.a'  But additional substructure must be
** created for the ".b.c" part of the patch so that the final result
** is:  {"a":{"b":{"c"::123}}}.  This routine populates pIns with
** the binary equivalent of {"b":{"c":123}} so that it can be inserted.
**
** The caller is responsible for resetting pIns when it has finished
** using the substructure.
*//*
** Error returns from jsonLookupStep()
*//* Simpliest case:  Neither label contains escapes.  A simple
    ** memcmp() is sufficient. *//* True if zRight is escape-free *//* Size of the right label in bytes *//* The right label *//* True if zLeft contains no escapes *//* Size of the left label in bytes *//* The left label *//*
** Compare two object labels.  Return 1 if they are equal and
** 0 if they differ.  Return -1 if an OOM occurs.
*//*exit-by-return*//*
** Compare two object labels.  Return 1 if they are equal and
** 0 if they differ.
**
** In this version, we know that one or the other or both of the
** two comparands contains an escape sequence.
*//*
** Input z[0..n] defines JSON escape sequence including the leading '\\'.
** Decode that escape sequence into a single character.  Write that
** character into *piOut.  Return the number of bytes in the escape sequence.
**
** If there is a syntax error of some kind (for example too few characters
** after the '\\' to complete the encoding) then *piOut is set to
** JSON_INVALID_CHAR.
*//*
** Return the number of escaped newlines to be ignored.
** An escaped newline is a one of the following byte sequences:
**
**    0x5c 0x0a
**    0x5c 0x0d
**    0x5c 0x0d 0x0a
**    0x5c 0xe2 0x80 0xa8
**    0x5c 0xe2 0x80 0xa9
*//* Bytes of content to insert *//* Content to insert *//* Number of bytes to remove *//* First byte to be removed *//* The JSONB to be modified is in pParse->aBlob *//*
** Modify the JSONB blob at pParse->aBlob by removing nDel bytes of
** content beginning at iDel, and replacing them with nIns bytes of
** content given by aIns.
**
** nDel may be zero, in which case no bytes are removed.  But iDel is
** still important as new bytes will be insert beginning at iDel.
**
** aIns may be zero, in which case space is created to hold nIns bytes
** beginning at iDel, but that space is uninitialized.
**
** Set pParse->oom if an OOM occurs.
*//*
** Edit the payload size of the element at iRoot by the amount in
** pParse->delta.
*//*
** Given that a JSONB_ARRAY object starts at offset i, return
** the number of entries in that array.
*//* Return true if the input pJson
**
** For performance reasons, this routine does not do a detailed check of the
** input BLOB to ensure that it is well-formed.  Hence, false positives are
** possible.  False negatives should never occur, however.
*//* Start rendering at this index *//* Pretty-printing context *//*
** Translate the binary JSONB representation of JSON beginning at
** pParse->aBlob[i] into a JSON text string.  Append the JSON
** text onto the end of pOut.  Return the index in pParse->aBlob[]
** of the first byte past the end of the element that is translated.
**
** This is a variant of jsonTranslateBlobToText() that "pretty-prints"
** the output.  Extra whitespace is inserted to make the JSON easier
** for humans to read.
**
** If an error is detected in the BLOB input, the pOut->eErr flag
** might get set to JSTRING_MALFORMED.  But not all BLOB input errors
** are detected.  So a malformed JSONB input might either result
** in an error, or in incorrect JSON.
**
** The pOut->eErr JSTRING_OOM flag is set on a OOM.
*//* Append indentation to the pretty JSON under construction *//* Current level of indentation *//* Bytes in zIndent[] *//* Use this text for indentation *//* Generate pretty output into this string *//* The BLOB being rendered *//* Context for recursion of json_pretty()
*//* '\' followed by either U+2028 or U+2029 is ignored as
            ** whitespace.  Not that in UTF8, U+2028 is 0xe2 0x80 0x29.
            ** U+2029 is the same except for the last byte *//* Float literal missing digits beside "." *//* Integer literal in hexadecimal notation *//* Write JSON here *//* the complete parse of the JSON *//*
** Translate the binary JSONB representation of JSON beginning at
** pParse->aBlob[i] into a JSON text string.  Append the JSON
** text onto the end of pOut.  Return the index in pParse->aBlob[]
** of the first byte past the end of the element that is translated.
**
** If an error is detected in the BLOB input, the pOut->eErr flag
** might get set to JSTRING_MALFORMED.  But not all BLOB input errors
** are detected.  So a malformed JSONB input might either result
** in an error, or in incorrect JSON.
**
** The pOut->eErr JSTRING_OOM flag is set on a OOM.
*//* The byte at index i is a node type-code.  This routine
** determines the payload size for that node and writes that
** payload size in to *pSz.  It returns the offset from i to the
** beginning of the payload.  Return 0 on error.
*//*
** The input string pStr is a well-formed JSON text string.  Convert
** this into the JSONB format and make it the return value of the
** SQL function.
*//* Report errors here *//* Initialize and fill this JsonParse object *//*
** Parse a complete JSON string.  Return 0 on success or non-zero if there
** are any errors.  If an error occurs, free all memory held by pParse,
** but not pParse itself.
**
** pParse must be initialized to an empty parse object prior to calling
** this routine.
*//* End switch(z[i]) *//* Syntax error *//* fall-through into the default case that checks for NaN *//* End of file *//* Object label/value separator *//* List separator *//* End of [...] *//* End of {...} *//* JSON5 allows for "+Infinity" and "-Infinity" using exactly
          ** that case.  SQLite also allows these in any case and it allows
          ** "+inf" and "-inf". *//* Bit 0x01:  JSON5.   Bit 0x02:  FLOAT *//* Parse number *//* Control characters are not allowed in canonical JSON string
        ** literals, but are allowed in JSON5 string literals. *//*exit-by-break*//* Parse string *//* Parse array *//* strspn() is not helpful here *//* Parse object *//*
** Translate a single element of JSON text at pParse->zJson[i] into
** its equivalent binary JSONB representation.  Append the translation into
** pParse->aBlob[] beginning at pParse->nBlob.  The size of
** pParse->aBlob[] is increased as necessary.
**
** Return the index of the first character past the end of the element parsed,
** or one of the following special result codes:
**
**      0    End of input
**     -1    Syntax error or OOM
**     -2    '}' seen   \
**     -3    ']' seen    \___  For these returns, pParse->iErr is set to
**     -4    ',' seen    /     the index in zJson[] of the seen character
**     -5    ':' seen   /
*//* Control characters in JSON5 string literals are ok *//* 0: initial.  1: '.' seen  2: 'e' seen *//* Checked by caller *//* One more than the last byte of the element *//* Start of element as pParse->aBlob[i] *//* Input JSONB.  Only aBlob and nBlob are used *//*
** Check a single element of the JSONB in pParse for validity.
**
** The element to be checked starts at offset i and must end at on the
** last byte before iEnd.
**
** Return 0 if everything is correct.  Return the 1-based byte offset of the
** error if a problem is detected.  (In other words, if the error is at offset
** 0, return 1).
*//*
** If z[0] is 'u' and is followed by exactly 4 hexadecimal character,
** then set *pOp to JSONB_TEXTJ and return true.  If not, do not make
** any changes to *pOp and return false.
*//* OOM error.  Error state recorded in pParse->oom. *//* Change the payload size for the node at index i to be szPayload.
*//* The payload.  Might be NULL *//* Number of bytes of payload *//* Node type.  One of JSONB_* *//* The JsonParse object under construction *//* Append an node type byte together with the payload size and
** possibly also the payload.
**
** If aPayload is not NULL, then it is a pointer to the payload which
** is also appended.  If aPayload is NULL, the pParse->aBlob[] array
** is resized (if necessary) so that it is big enough to hold the
** payload, but the payload is not appended and pParse->nBlob is left
** pointing to where the first byte of payload will eventually be.
*//* Slow version of jsonBlobAppendNode() that first resizes the
** pParse->aBlob structure.
*//* Append a single character.
*//* Expand pParse->aBlob and append one bytes.
*//*
** If pParse->aBlob is not previously editable (because it is taken
** from sqlite3_value_blob(), as indicated by the fact that
** pParse->nBlobAlloc==0 and pParse->nBlob>0) then make it editable
** by making a copy into space obtained from malloc.
**
** Return true on success.  Return false on OOM.
*//*
** Expand pParse->aBlob so that it holds at least N bytes.
**
** Return the number of errors.
*//****************************************************************************
** Utility routines for dealing with the binary BLOB representation of JSON
****************************************************************************//*
** Report the wrong number of arguments for json_insert(), json_replace()
** or json_set().
*//*
** Extra floating-point literals to allow in JSON.
*//*exit by "goto whitespace_done"*//*
** Return the number of bytes of JSON5 whitespace at the beginning of
** the input string z[].
**
** JSON5 whitespace consists of any of the following characters:
**
**    Unicode  UTF-8         Name
**    U+0009   09            horizontal tab
**    U+000a   0a            line feed
**    U+000b   0b            vertical tab
**    U+000c   0c            form feed
**    U+000d   0d            carriage return
**    U+0020   20            space
**    U+00a0   c2 a0         non-breaking space
**    U+1680   e1 9a 80      ogham space mark
**    U+2000   e2 80 80      en quad
**    U+2001   e2 80 81      em quad
**    U+2002   e2 80 82      en space
**    U+2003   e2 80 83      em space
**    U+2004   e2 80 84      three-per-em space
**    U+2005   e2 80 85      four-per-em space
**    U+2006   e2 80 86      six-per-em space
**    U+2007   e2 80 87      figure space
**    U+2008   e2 80 88      punctuation space
**    U+2009   e2 80 89      thin space
**    U+200a   e2 80 8a      hair space
**    U+2028   e2 80 a8      line separator
**    U+2029   e2 80 a9      paragraph separator
**    U+202f   e2 80 af      narrow no-break space (NNBSP)
**    U+205f   e2 81 9f      medium mathematical space (MMSP)
**    U+3000   e3 80 80      ideographical space
**    U+FEFF   ef bb bf      byte order mark
**
** In addition, comments between '/', '*' and '*', '/' and
** from '/', '/' to end-of-line are also considered to be whitespace.
*//*
** Return true if z[] begins with 4 (or more) hexadecimal digits
*//*
** Return true if z[] begins with 2 (or more) hexadecimal digits
*//*
** Convert a 4-byte hex string into an integer
*//*
** Translate a single byte of Hex into an integer.
** This routine only gives a correct answer if h really is a valid hexadecimal
** character:  0..9a..fA..F.  But unlike sqlite3HexToInt(), it does not
** assert() if the digit is not hex.
*//**************************************************************************
** Utility routines for the JSON text parser
**************************************************************************//*
** Decrement the reference count on the JsonParse object.  When the
** count reaches zero, free the object.
*//*
** Reclaim all memory allocated by a JsonParse object.  But do not
** delete the JsonParse object itself.
*//**************************************************************************
** Utility routines for dealing with JsonParse objects
**************************************************************************//* Where to cache *//* JSONB source or NULL *//* Make the text in p (which is probably a generated JSON text string)
** the result of the SQL function.
**
** The JsonString is reset.
**
** If pParse and ctx are both non-NULL, then the SQL string in p is
** loaded into the zJson field of the pParse object as a RCStr and the
** pParse is added to the cache.
*//* Value to append *//* Append to this JSON string *//*
** Append an sqlite3_value (such as a function parameter) to the JSON
** string under construction in p.
*//* The following while() is the 4-way unwound equivalent of
    **
    **     while( k<N && jsonIsOk[z[k]] ){ k++; }
    *//* Append the N-byte string in zIn to the end of the JsonString string
** under construction.  Enclose the string in double-quotes ("...") and
** escape any double-quotes or backslash characters contained within the
** string.
**
** This routine is a high-runner.  There is a measurable performance
** increase associated with unwinding the jsonIsOk[] loop.
*//* c is a control character.  Append the canonical JSON representation
** of that control character to p.
**
** This routine assumes that the output buffer has already been enlarged
** sufficiently to hold the worst-case encoding plus a nul terminator.
*//* Append a comma separator to the output buffer, if the previous
** character is not '[' or '{'.
*//* Make sure there is a zero terminator on p->zBuf[]
**
** Return true on success.  Return false if an OOM prevents this
** from happening.
*//* Remove a single character from the end of the string
*//* Append a single character
*//* Append formatted text (not to exceed N bytes) to the JsonString.
*//* Append N bytes from zIn onto the end of the JsonString string.
*//* Enlarge pJson->zBuf so that it can hold at least N more bytes.
** Return zero on success.  Return non-zero on an OOM error
*//* Report an out-of-memory (OOM) condition
*//* Free all allocated memory and reset the JsonString object back to its
** initial state.
*//* Initialize the JsonString object
*//* Turn uninitialized bulk memory into a valid JsonString object
** holding a zero-length string.
*//**************************************************************************
** Utility routines for dealing with JsonString objects
**************************************************************************//* Make the matching entry the most recently used entry *//* Function argument containing SQL text *//* The SQL statement context holding the cache *//*
** Search for a cached translation the json text supplied by pArg.  Return
** the JsonParse object if found.  Return NULL if not found.
**
** When a match if found, the matching entry is moved to become the
** most-recently used entry if it isn't so already.
**
** The JsonParse object returned still belongs to the Cache and might
** be deleted at any moment.  If the caller whants the JsonParse to
** linger, it needs to increment the nPJRef reference counter.
*//* The parse object to be added to the cache *//*
** Insert a new entry into the cache.  If the cache is full, expel
** the least recently used entry.  Return SQLITE_OK on success or a
** result code otherwise.
**
** Cache entries are stored in age order, oldest first.
*//*
** Free a JsonCache object.
*//**************************************************************************
** Utility routines for dealing with JsonCache objects
**************************************************************************//**************************************************************************
** Forward references
**************************************************************************//* Return non-NULL even if there is an error *//* Generate a writable JsonParse object *//*
** Allowed values for the flgs argument to jsonParseFuncArg();
*//*
** Maximum nesting depth of JSON for this implementation.
**
** This limit is needed to avoid a stack overflow in the recursive
** descent parser.  A depth of 1000 is far deeper than any sane JSON
** should go.  Historical note: This limit was 2000 prior to version 3.42.0
*//* Insert or overwrite *//* Insert if not exists *//* Overwrite if exists *//* Delete if exists *//* Allowed values for JsonParse.eEdit *//* Content to be inserted *//* Location of label if search landed on an object value *//* Number of bytes to insert *//* Size change due to the edit *//* Edit operation to apply *//* Search and edit information.  See jsonLookupStep() *//* Do not modify. *//* True if input uses non-standard features like JSON5 *//* True if zJson is an RCStr *//* Set to true if out of memory *//* Nesting depth *//* Error location in zJson[] *//* Number of references to this object *//* Length of the zJson string in bytes *//* The database connection to which this object belongs *//* Json text used for parsing *//* Bytes allocated to aBlob[].  0 if aBlob is external *//* Bytes of aBlob[] actually used *//* JSONB representation of JSON value *//* A parsed JSON value.  Lifecycle:
**
**   1.  JSON comes in and is parsed into a JSONB value in aBlob.  The
**       original text is stored in zJson.  This step is skipped if the
**       input is JSONB instead of text JSON.
**
**   2.  The aBlob[] array is searched using the JSON path notation, if needed.
**
**   3.  Zero or more changes are made to aBlob[] (via json_remove() or
**       json_replace() or json_patch() or similar).
**
**   4.  New JSON text is generated from the aBlob[] for output.  This step
**       is skipped if the function is one of the jsonb_* functions that
**       returns JSONB instead of text JSON.
*//* Use the BLOB output format *//* json_set(), not json_insert() *//* Allow abbreviated JSON path specs *//* Result is always SQL *//* Result is always JSON *//*
** Bit values for the flags passed into various SQL function implementations
** via the sqlite3_user_data() value.
*//* Ascii for "J" *//* The "subtype" set for text JSON values passed through using
** sqlite3_result_subtype() and sqlite3_value_subtype().
*//* Error already sent to sqlite3_result *//* Malformed JSONB *//* Allowed values for JsonString.eErr *//* Initial static space *//* True if an error has been encountered *//* True if zBuf is static space *//* Bytes of zBuf[] currently used *//* Bytes of storage available in zBuf[] *//* Append JSON content here *//* Function context - put error messages here *//* An instance of this object represents a JSON string
** under construction.  Really, this is a generic string accumulator
** that can be and is used to create strings other than JSON.
**
** If the generated string is longer than will fit into the zSpace[] buffer,
** then it will be an RCStr string.  This aids with caching of large
** JSON strings.
*//* One line for each cache entry *//* Number of active entries in the cache *//* A cache mapping JSON text into JSONB blobs.
**
** Each cache entry is a JsonParse object with the following restrictions:
**
**    *   The bReadOnly flag must be set
**
**    *   The aBlob[] array must be owned by the JsonParse object.  In other
**        words, nBlobAlloc must be non-zero.
**
**    *   eEdit and delta must be zero.
**
**    *   zJson must be an RCStr.  In other words bJsonIsRCStr must be true.
*//*
** jsonUnescapeOneChar() returns this invalid code point if it encounters
** a syntax error.
*//* Max number of cache entries *//* Cache entry *//*
** Magic number used for the JSON parse cache in sqlite3_get_auxdata()
*//* Objects *//*
** Characters that are special to JSON.  Control characters,
** '"' and '\\' and '\''.  Actually, '\'' is not special to
** canonical JSON, but it is special in JSON-5, so we include
** it in the set of special characters.
*//*
** The set of all space characters recognized by jsonIsspace().
** Useful as the second argument to strspn().
*//*
** Growing our own isspace() routine this way is twice as fast as
** the library isspace() function, resulting in a 7% overall performance
** increase for the text-JSON parser.  (Ubuntu14.10 gcc 4.8.4 x64 with -Os).
*//* Human-readable names for the JSONB values.  The index for each
** string must correspond to the JSONB_* integer above.
*//* An object *//* An array *//* SQL text that needs escaping for JSON *//* Text with JSON-5 escape *//* Text with JSON escapes *//* Text compatible with both JSON and SQL *//* float with JSON5 extensions *//* float acceptable to JSON and SQL *//* integer in 0x000 notation *//* integer acceptable to JSON and SQL *//* "false" *//* "true" *//* "null" *//* JSONB element types
*//* #include "sqliteInt.h" *//*
** 2015-08-12
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** SQLite JSON functions.
**
** This file began as an extension in ext/misc/json1.c in 2015.  That
** extension proved so useful that it has now been moved into the core.
**
** The original design stored all JSON as pure text, canonical RFC-8259.
** Support for JSON-5 extensions was added with version 3.42.0 (2023-05-16).
** All generated JSON text still conforms strictly to RFC-8259, but text
** with JSON-5 extensions is accepted as input.
**
** Beginning with version 3.45.0 (circa 2024-01-01), these routines also
** accept BLOB values that have JSON encoded using a binary representation
** called "JSONB".  The name JSONB comes from PostgreSQL, however the on-disk
** format SQLite JSONB is completely different and incompatible with
** PostgreSQL JSONB.
**
** Decoding and interpreting JSONB is still O(N) where N is the size of
** the input, the same as text JSON.  However, the constant of proportionality
** for JSONB is much smaller due to faster parsing.  The size of each
** element in JSONB is encoded in its header, so there is no need to search
** for delimiters using persnickety syntax rules.  JSONB seems to be about
** 3x faster than text JSON as a result.  JSONB is also tends to be slightly
** smaller than text JSON, by 5% or 10%, but there are corner cases where
** JSONB can be slightly larger.  So you are not far mistaken to say that
** a JSONB blob is the same size as the equivalent RFC-8259 text.
**
**
** THE JSONB ENCODING:
**
** Every JSON element is encoded in JSONB as a header and a payload.
** The header is between 1 and 9 bytes in size.  The payload is zero
** or more bytes.
**
** The lower 4 bits of the first byte of the header determines the
** element type:
**
**    0:   NULL
**    1:   TRUE
**    2:   FALSE
**    3:   INT        -- RFC-8259 integer literal
**    4:   INT5       -- JSON5 integer literal
**    5:   FLOAT      -- RFC-8259 floating point literal
**    6:   FLOAT5     -- JSON5 floating point literal
**    7:   TEXT       -- Text literal acceptable to both SQL and JSON
**    8:   TEXTJ      -- Text containing RFC-8259 escapes
**    9:   TEXT5      -- Text containing JSON5 and/or RFC-8259 escapes
**   10:   TEXTRAW    -- Text containing unescaped syntax characters
**   11:   ARRAY
**   12:   OBJECT
**
** The other three possible values (13-15) are reserved for future
** enhancements.
**
** The upper 4 bits of the first byte determine the size of the header
** and sometimes also the size of the payload.  If X is the first byte
** of the element and if X>>4 is between 0 and 11, then the payload
** will be that many bytes in size and the header is exactly one byte
** in size.  Other four values for X>>4 (12-15) indicate that the header
** is more than one byte in size and that the payload size is determined
** by the remainder of the header, interpreted as a unsigned big-endian
** integer.
**
**   Value of X>>4         Size integer        Total header size
**   -------------     --------------------    -----------------
**        12           1 byte (0-255)                2
**        13           2 byte (0-65535)              3
**        14           4 byte (0-4294967295)         5
**        15           8 byte (0-1.8e19)             9
**
** The payload size need not be expressed in its minimal form.  For example,
** if the payload size is 10, the size can be expressed in any of 5 different
** ways: (1) (X>>4)==10, (2) (X>>4)==12 following by on 0x0a byte,
** (3) (X>>4)==13 followed by 0x00 and 0x0a, (4) (X>>4)==14 followed by
** 0x00 0x00 0x00 0x0a, or (5) (X>>4)==15 followed by 7 bytes of 0x00 and
** a single byte of 0x0a.  The shorter forms are preferred, of course, but
** sometimes when generating JSONB, the payload size is not known in advance
** and it is convenient to reserve sufficient header space to cover the
** largest possible payload size and then come back later and patch up
** the size when it becomes known, resulting in a non-minimal encoding.
**
** The value (X>>4)==15 is not actually used in the current implementation
** (as SQLite is currently unable handle BLOBs larger than about 2GB)
** but is included in the design to allow for future enhancements.
**
** The payload follows the header.  NULL, TRUE, and FALSE have no payload and
** their payload size must always be zero.  The payload for INT, INT5,
** FLOAT, FLOAT5, TEXT, TEXTJ, TEXT5, and TEXTROW is text.  Note that the
** "..." or '...' delimiters are omitted from the various text encodings.
** The payload for ARRAY and OBJECT is a list of additional elements that
** are the content for the array or object.  The payload for an OBJECT
** must be an even number of elements.  The first element of each pair is
** the label and must be of type TEXT, TEXTJ, TEXT5, or TEXTRAW.
**
** A valid JSONB blob consists of a single element, as described above.
** Usually this will be an ARRAY or OBJECT element which has many more
** elements as its content.  But the overall blob is just a single element.
**
** Input validation for JSONB blobs simply checks that the element type
** code is between 0 and 12 and that the total size of the element
** (header plus payload) is the same as the size of the BLOB.  If those
** checks are true, the BLOB is assumed to be JSONB and processing continues.
** Errors are only raised if some other miscoding is discovered during
** processing.
**
** Additional information can be found in the doc/jsonb.md file of the
** canonical SQLite source tree.
*//************** Begin file json.c ********************************************//************** End of fts3_unicode2.c ***************************************//* !defined(SQLITE_DISABLE_FTS3_UNICODE) *//* defined(SQLITE_ENABLE_FTS3) || defined(SQLITE_ENABLE_FTS4) *//* Each unsigned integer in the following array corresponds to a contiguous
  ** range of unicode codepoints that are not either letters or numbers (i.e.
  ** codepoints for which this function should return 0).
  **
  ** The most significant 22 bits in each 32-bit value contain the first
  ** codepoint in the range. The least significant 10 bits are used to store
  ** the size of the range (always at least 1). In other words, the value
  ** ((C<<22) + N) represents a range of N codepoints starting with codepoint
  ** C. It is not possible to represent a range larger than 1023 codepoints
  ** using this format.
  *//*
** Return true if the argument corresponds to a unicode codepoint
** classified as either a letter or a number. Otherwise false.
**
** The results are undefined if the value passed to this function
** is less than zero.
*//************** Begin file fts3_unicode2.c ***********************************//************** End of fts3_unicode.c ****************************************//* ifndef SQLITE_DISABLE_FTS3_UNICODE *//*
** Set *ppModule to a pointer to the sqlite3_tokenizer_module
** structure for the unicode tokenizer.
*//* Set the output variables and return. *//* If the cursor is not at EOF, read the next character *//* Write the folded case of the last character read to the output *//* Grow the output buffer if required. *//* Scan past any delimiter characters before the start of the next token.
  ** Return SQLITE_DONE early if this takes us all the way to the end of
  ** the input.  *//* OUT: Number of bytes at *paToken *//* OUT: Token text *//*
** Extract the next token from a tokenization cursor.  The cursor must
** have been opened by a prior call to simpleOpen().
*//*
** Close a tokenization cursor previously opened by a call to
** simpleOpen() above.
*//* OUT: New cursor object *//* Size of string aInput in bytes *//* Unrecognized argument *//* OUT: New tokenizer handle *//* Size of array argv[] *//*
** Return true if, for the purposes of tokenization, codepoint iCode is
** considered a token character (not a separator).
*//* Number of valid entries in array aNew[] *//* New aiException[] array *//* Length of z in bytes *//* Array of characters to make exceptions *//* Replace Isalnum() return value with this *//* Tokenizer to add exceptions to *//*
** As part of a tokenchars= or separators= option, the CREATE VIRTUAL TABLE
** statement has specified that the tokenizer for this table shall consider
** all characters in string zIn/nIn to be separators (if bAlnum==0) or
** token characters (if bAlnum==1).
**
** For each codepoint in the zIn/nIn string, this function checks if the
** sqlite3FtsUnicodeIsalnum() function already returns the desired result.
** If so, no action is taken. Otherwise, the codepoint is added to the
** unicode_tokenizer.aiException[] array. For the purposes of tokenization,
** the return value of sqlite3FtsUnicodeIsalnum() is inverted for all
** codepoints in the aiException[] array.
**
** If a standalone diacritic mark (one that sqlite3FtsUnicodeIsdiacritic()
** identifies as a diacritic) occurs in the zIn/nIn string it is ignored.
** It is not possible to change the behavior of the tokenizer with respect
** to these codepoints.
*//*
** Destroy a tokenizer allocated by unicodeCreate().
*//* space allocated at zToken *//* storage for current token *//* Index of next token to be returned *//* Current offset within aInput[] *//* Size of aInput[] in bytes *//* Input text being tokenized *//*
** 2012 May 24
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** Implementation of the "unicode" full-text-search tokenizer.
*//************** Begin file fts3_unicode.c ************************************//************** End of fts3_snippet.c ****************************************//* Retrieve matchinfo() data. *//* Second arg to matchinfo() function *//* FTS3 table cursor *//*
** Implementation of matchinfo() function.
*//* All offsets for this column have been gathered. *//* TermOffset associated with next token *//* Position of next token *//* Used to loop through terms *//* Initialize a tokenizer iterator to iterate through column iCol. *//* Retreive the text stored in column iCol. If an SQL NULL is stored
    ** in column iCol, jump immediately to the next iteration of the loop.
    ** If an OOM occurs while retrieving the data (this can happen if SQLite
    ** needs to transform the data from utf-16 to utf-8), return SQLITE_NOMEM
    ** to the caller.
    *//* Initialize the contents of sCtx.aTerm[] for column iCol. This
    ** operation may fail if the database contains corrupt records.
    *//* Dummy argument used with xNext() *//* Tokenizer cursor *//* Loop through the table columns, appending offset information to
  ** string-buffer res for each column.
  *//* If a query restart will be required, do it here, rather than later of
  ** after pointers to poslist buffers that may be invalidated by a restart
  ** have been saved.  *//* Allocate the array of TermOffset iterators. *//* Count the number of terms in the query *//* Context for fts3ExprTermOffsetInit() *//* Result string *//* Column currently being processed *//* Number of tokens in query *//* SQLite function call context *//*
** Implementation of offsets() function.
*//*
** If expression pExpr is a phrase expression that uses an MSR query,
** restart it as a regular, non-incremental query. Return SQLITE_OK
** if successful, or an SQLite error code otherwise.
*//* First position in position-list *//* Pointer to position list for phrase *//* For looping through nTerm phrase terms *//* Number of tokens in phrase *//*
** This function is an sqlite3Fts3ExprIterate() callback used by sqlite3Fts3Offsets().
*//* Column of table to populate aTerm for *//* Offset of this term from read positions *//* Position just read from pList *//* Position-list *//* If all query phrases seen by fts3BestSnippet() are present in at least
    ** one of the nSnippet snippet fragments, break out of the loop.
    *//* Find the best snippet of nFToken tokens in column iRead. *//* Loop through all columns of the table being considered for snippets.
      ** If the iCol argument to this function was negative, this means all
      ** columns of the FTS3 table. Otherwise, only column iCol is considered.
      *//* Best score of columns checked so far *//* Bitmask of phrases seen by BestSnippet() *//* Bitmask of phrases covered by snippet *//* Loop counter 0..nSnippet-1 *//* Limit the snippet length to 64 tokens. *//* Number of tokens in each fragment *//* Maximum of 4 fragments per snippet *//* Number of fragments in this snippet *//* The returned text includes up to four fragments of text extracted from
  ** the data in the current row. The first iteration of the for(...) loop
  ** below attempts to locate a single fragment of text nToken tokens in
  ** size that contains at least one instance of all phrases in the query
  ** expression that appear in the current row. If such a fragment of text
  ** cannot be found, the second iteration of the loop attempts to locate
  ** a pair of fragments, and so on.
  *//* Approximate number of tokens in snippet *//* Extract snippet from this column *//* Snippet ellipsis text - "<b>...</b>" *//* Snippet end text - "</b>" *//* Snippet start text - "<b>" *//* Allocate space for Fts3Cursor.aMatchinfo[] and Fts3Cursor.zMatchinfo. *//* Determine the number of integers in the buffer returned by this call. *//* Determine the number of phrases in the query *//* Used to iterate through zArg *//* Number of u32 elements in match-info *//* If Fts3Cursor.pMIBuffer is NULL, then this is the first time the
  ** matchinfo function has been called for this query. In this case
  ** allocate the array used to accumulate the matchinfo data and
  ** initialize those elements that are constant for every row.
  *//* If there is cached matchinfo() data, but the format string for the
  ** cache does not match the format string for this request, discard
  ** the cached data. *//* Collect 'global' stats as well as local *//* Second argument to matchinfo() function *//* FTS3 Cursor object *//* Return results here *//*
** Populate pCsr->aMatchinfo[] with data for the current row. The
** 'matchinfo' data is an array of 32-bit unsigned integers (C type u32).
*//* First byte past end of length array *//* Aggregate column length array *//* Matchinfo format string *//* Matchinfo context object *//* True to grab the global stats *//* FTS3 cursor object *//*
** Populate the buffer pInfo->aMatchinfo[] with an array of integers to
** be returned by the matchinfo() function. Argument zArg contains the
** format string passed as the second argument to matchinfo (or the
** default value "pcx" if no second argument was specified). The format
** string has already been validated and the pInfo->aMatchinfo[] array
** is guaranteed to be large enough for the output.
**
** If bGlobal is true, then populate all fields of the matchinfo() output.
** If it is false, then assume that those fields that do not change between
** rows (i.e. FTS3_MATCHINFO_NPHRASE, NCOL, NDOC, AVGLENGTH and part of HITS)
** have already been populated.
**
** Return SQLITE_OK if successful, or an SQLite error code if an error
** occurs. If a value other than SQLITE_OK is returned, the state the
** pInfo->aMatchinfo[] buffer is left in is undefined.
*//* This iterator is already at EOF for this column. *//* LCS for the current iterator positions *//* The iterator to advance by one position *//* Number of iterators in aIter not at EOF *//* LCS value for this column *//* Allocate and populate the array of LcsIterator objects. The array
  ** contains one element for each matchable phrase in the query.
  **//*
** This function implements the FTS3_MATCHINFO_LCS matchinfo() flag.
**
** If the call is successful, the longest-common-substring lengths for each
** column are written into the first nCol elements of the pInfo->aMatchinfo[]
** array before returning. SQLITE_OK is returned in this case.
**
** Otherwise, if an error occurs, an SQLite error code is returned and the
** data written to the first nCol elements of pInfo->aMatchinfo[] is
** undefined.
*//*
** Advance the iterator passed as an argument to the next position. Return
** 1 if the iterator is at EOF or if it now points to the start of the
** position list for the next column.
*//* Pointer to MatchInfo structure *//* Phrase number (numbered from zero) *//* Phrase expression node *//*
** If LcsIterator.iCol is set to the following value, the iterator has
** finished iterating through all offsets for all columns.
*//* Cursor used to iterate through aDoclist *//* Tokens count up to end of this phrase *//* Pointer to phrase expression *//*
** An instance of the following structure is used to store state while
** iterating through a multi-column position-list corresponding to the
** hits for a single phrase on a single row in order to calculate the
** values for a matchinfo() FTS3_MATCHINFO_LCS request.
*//* Number of integers output by cArg *//* Phrase number *//*
** sqlite3Fts3ExprIterate() callback used to collect the "local" part of the
** FTS3_MATCHINFO_HITS array. The local stats are those elements of the
** array that are different for each row returned by the query.
*//*
** sqlite3Fts3ExprIterate() callback used to collect the "global" matchinfo
** stats for a single query.
**
** sqlite3Fts3ExprIterate() callback to load the 'global' elements of a
** FTS3_MATCHINFO_HITS matchinfo array. The global stats are those elements
** of the matchinfo array that are constant for all rows returned by the
** current query.
**
** Argument pCtx is actually a pointer to a struct of type MatchInfo. This
** function populates Matchinfo.aMatchinfo[] as follows:
**
**   for(iCol=0; iCol<nCol; iCol++){
**     aMatchinfo[3*iPhrase*nCol + 3*iCol + 1] = X;
**     aMatchinfo[3*iPhrase*nCol + 3*iCol + 2] = Y;
**   }
**
** where X is the number of matches for phrase iPhrase is column iCol of all
** rows of the table. Y is the number of rows for which column iCol contains
** at least one instance of phrase iPhrase.
**
** If the phrase pExpr consists entirely of deferred tokens, then all X and
** Y values are set to nDoc, where nDoc is the number of documents in the
** file system. This is done because the full-text index doclist is required
** to calculate these values properly, and the full-text index doclist is
** not available for deferred tokens.
*//*
** Gather the results for matchinfo directives 'y' and 'b'.
*//* Matchinfo context *//*
** This function gathers 'y' or 'b' data for a single phrase.
*//* A column-list is terminated by either a 0x01 or 0x00. *//*
** This function is used to count the entries in a column-list (a
** delta-encoded list of term offsets within a single column of a single
** row). When this function is called, *ppCollist should point to the
** beginning of the first varint in the column-list (the varint that
** contains the position of the first matching term in the column data).
** Before returning, *ppCollist is set to point to the first byte after
** the last varint in the column-list (either the 0x00 signifying the end
** of the position-list, or the 0x01 that precedes the column number of
** the next column in the position-list).
**
** The number of elements in the column-list is returned.
*//* Set isHighlight to true if this term should be highlighted. *//* Now that the shift has been done, check if the initial "..." are
      ** required. They are required if (a) this is not the first fragment,
      ** or (b) this fragment does not begin at position 0 of its column.
      *//* Special case - the last token of the snippet is also the last token
        ** of the column. Append any punctuation that occurred between the end
        ** of the previous token and the end of the document to the output.
        ** Then break out of the loop. *//* Variable DUMMY1 is initialized to a negative value above. Elsewhere
    ** in the FTS code the variable that the third argument to xNext points to
    ** is initialized to zero before the first (*but not necessarily
    ** subsequent*) call to xNext(). This is done for a particular application
    ** that needs to know whether or not the tokenizer is being used for
    ** snippet generation or for some other purpose.
    **
    ** Extreme care is required when writing code to depend on this
    ** initialization. It is not a documented part of the tokenizer interface.
    ** If a tokenizer is used directly by any code outside of FTS, this
    ** convention might not be respected.  *//* True for highlighted terms *//* Offset in zDoc of end of token *//* Offset in zDoc of start of token *//* Dummy argument used with tokenizer *//* Open a token cursor on the document. *//* Tokenizer cursor open on zDoc/nDoc *//* Tokenizer module methods object *//* Query column to extract text from *//* Highlight-mask for snippet *//* First token of snippet *//* True after snippet is shifted *//* Byte offset of end of current token *//* Current token number of document *//* Size of zDoc in bytes *//* Document text to extract snippet from *//* Write output here *//* String inserted between snippets *//* String inserted after highlighted term *//* String inserted before highlighted term *//* Number of tokens in extracted snippet *//* True for final fragment in snippet *//* Fragment number *//* Snippet to extract *//* FTS3 Cursor *//*
** Extract the snippet text for fragment pFragment from cursor pCsr and
** append it to string buffer pOut.
*//* Open a cursor on zDoc/nDoc. Check if there are (nSnippet+nDesired)
      ** or more tokens in zDoc/nDoc.
      *//* Token counter *//* Number of tokens to shift snippet by *//* Ideally, the start of the snippet should be pushed forward in the
    ** document nDesired tokens. This block checks if there are actually
    ** nDesired tokens to the right of the snippet. If so, *piPos and
    ** *pHlMask are updated to shift the snippet nDesired tokens to the
    ** right. Otherwise, the snippet is shifted by the number of tokens
    ** available.
    *//* Ideal number of tokens to shift forward *//* Tokens to the right of last highlight *//* Tokens to the left of first highlight *//* Local copy of initial highlight-mask *//* IN/OUT: Mask of tokens to highlight *//* IN/OUT: First token of snippet *//* Size of buffer zDoc in bytes *//* Number of tokens desired for snippet *//* Language id to use in tokenizing *//* FTS3 table snippet comes from *//*
** The fts3BestSnippet() function often selects snippets that end with a
** query term. That is, the final term of the snippet is always a term
** that requires highlighting. For example, if 'X' is a highlighted term
** and '.' is a non-highlighted term, BestSnippet() may select:
**
**     ........X.....X
**
** This function "shifts" the beginning of the snippet forward in the
** document so that there are approximately the same number of
** non-highlighted terms to the right of the final highlighted term as there
** are to the left of the first highlighted term. For example, to this:
**
**     ....X.....X....
**
** This is done as part of extracting the snippet text, not when selecting
** the snippet. Snippet selection is done based on doclists only, so there
** is no way for fts3BestSnippet() to know whether or not the document
** actually contains terms that follow the final highlighted term.
*//* Append the data to the string buffer. *//* If there is insufficient space allocated at StrBuffer.z, use realloc()
  ** to grow the buffer until so that it is big enough to accomadate the
  ** appended data.
  *//* Size of zAppend in bytes (or -1) *//* Pointer to data to append to buffer *//*
** Append a string to the string-buffer passed as the first argument.
**
** If nAppend is negative, then the length of the string zAppend is
** determined using strlen().
*//* Loop through all candidate snippets. Store the best snippet in
     ** *pFragment. Store its associated 'score' in iBestScore.
     *//* Set the *pmSeen output variable. *//* Initialize the contents of the SnippetIter object. Then iterate through
  ** the set of phrases in the expression to populate the aPhrase[] array.
  *//* Now that it is known how many phrases there are, allocate and zero
  ** the required space using malloc().
  *//* Iterate through the phrases in the expression to count them. The same
  ** callback makes sure the doclists are loaded for each phrase.
  *//* Best snippet score found so far *//* Number of bytes of space to allocate *//* Iterates through snippet candidates *//* OUT: Score of snippet pFragment *//* OUT: Best snippet found *//* IN/OUT: Mask of phrases seen *//* Mask of phrases already covered *//* Index of column to create snippet from *//* Cursor to create snippet for *//* Desired snippet length *//*
** Select the fragment of text consisting of nFragment contiguous tokens
** from column iCol that represent the "best" snippet. The best snippet
** is the snippet with the highest score, where scores are calculated
** by adding:
**
**   (a) +1 point for each occurrence of a matchable phrase in the snippet.
**
**   (b) +1000 points for the first occurrence of each matchable phrase in
**       the snippet for which the corresponding mCovered bit is not set.
**
** The selected snippet parameters are stored in structure *pFragment before
** returning. The score of the selected snippet is stored in *piScore
** before returning.
*//*
** This function is an sqlite3Fts3ExprIterate() callback used by
** fts3BestSnippet().  Each invocation populates an element of the
** SnippetIter.aPhrase[] array.
*//* Set the output variables before returning. *//* Mask of tokens to highlight in snippet *//* Mask of phrases covered by this snippet *//* Score of this snippet *//* OUT: Bitmask of terms to highlight *//* OUT: Bitmask of phrases covered *//* OUT: "Score" for this snippet *//* OUT: First token of proposed snippet *//* Bitmask of phrases already covered *//* Snippet iterator *//*
** Retrieve information about the current candidate snippet of snippet
** iterator pIter.
*//* Advance the 'head' iterator of each phrase to the first offset that
    ** is greater than or equal to (iNext+nSnippet).
    *//* The SnippetIter object has just been initialized. The first snippet
    ** candidate always starts at offset 0 (even if this candidate has a
    ** score of 0.0).
    *//*
** Advance the snippet iterator to the next candidate snippet.
*//*
** Advance the position list iterator specified by the first two
** arguments so that it points to the first element with a value greater
** than or equal to parameter iNext.
*//* Context for sqlite3Fts3ExprIterate() *//* OUT: Number of tokens in query *//* OUT: Number of phrases in query *//* Fts3 cursor for current query *//*
** Load the doclists for each phrase in the query associated with FTS3 cursor
** pCsr.
**
** If pnPhrase is not NULL, then *pnPhrase is set to the number of matchable
** phrases in the expression (all phrases except those directly or
** indirectly descended from the right-hand-side of a NOT operator). If
** pnToken is not NULL, then it is set to the number of tokens in all
** matchable phrases of the expression.
*//*
** This is an sqlite3Fts3ExprIterate() callback used while loading the
** doclists for each phrase into Fts3Expr.aDoclist[]/nDoclist. See also
** fts3ExprLoadDoclists().
*//* Variable used as the phrase counter *//* Second argument to pass to callback *//* Callback function to invoke for phrases *//* Expression to iterate phrases of *//*
** Iterate through all phrase nodes in an FTS3 query, except those that
** are part of a sub-tree that is the right-hand-side of a NOT operator.
** For each phrase node found, the supplied callback function is invoked.
**
** If the callback function returns anything other than SQLITE_OK,
** the iteration is abandoned and the error code returned immediately.
** Otherwise, SQLITE_OK is returned after a callback has been made for
** all eligible phrase nodes.
*//* Type of expression node pExpr *//* Pointer to phrase counter *//*
** Helper function for sqlite3Fts3ExprIterate() (see below).
*//*
** This function is used to help iterate through a position-list. A position
** list is a list of unique integers, sorted from smallest to largest. Each
** element of the list is represented by an FTS3 varint that takes the value
** of the difference between the current element and the previous one plus
** two. For example, to store the position-list:
**
**     4 9 113
**
** the three varints:
**
**     6 7 106
**
** are encoded.
**
** When this function is called, *pp points to the start of an element of
** the list. *piPos contains the value of the previous entry in the list.
** After it returns, *piPos contains the value of the next element of the
** list and *pp is advanced to the following varint.
*//*
** End of MatchinfoBuffer code.
*************************************************************************//*
** Free a MatchinfoBuffer object allocated using fts3MIBufferNew()
*//*
** Allocate a two-slot MatchinfoBuffer object.
*//*************************************************************************
** Start of MatchinfoBuffer code.
*//* Allocated size of buffer z in bytes *//* Length of z in bytes (excl. nul-term) *//* Pointer to buffer containing string *//*
** The snippet() and offsets() functions both return text values. An instance
** of the following structure is used to accumulate those values while the
** functions are running. See fts3StringAppend() for details.
*//* Set if global data is loaded *//*
** An instance of this structure is used to manage a pair of buffers, each
** (nElem * sizeof(u32)) bytes in size. See the MatchinfoBuffer code below
** for details.
*//* Pre-allocated buffer *//* Number of docs in database *//* Number of matchable phrases in query *//*
** This type is used as an sqlite3Fts3ExprIterate() context object while
** accumulating the data returned by the matchinfo() function.
*//* Mask of snippet terms to highlight *//* Mask of query phrases covered *//* Index of first token in snippet *//* Column snippet is extracted from *//* Position list data following iTail *//* Next value in trailing position list *//* Position list data following iHead *//* Next value in position list *//* Pointer to start of phrase position list *//* First token of current snippet *//* Array of size nPhrase *//* Requested snippet length (in tokens) *//* Cursor snippet is being generated from *//*
** The following types are used as part of the implementation of the
** fts3BestSnippet() routine.
*//* Number of tokens seen so far *//* Number of phrases seen so far *//*
** Used as an sqlite3Fts3ExprIterate() context when loading phrase doclists to
** Fts3Expr.aDoclist[]/nDoclist.
*//*
** The default value for the second argument to matchinfo().
*//* nCol*nPhrase values *//* 3*nCol*nPhrase values *//* nCol values *//* 1 value *//*
** Characters that may appear in the second argument to matchinfo().
*//*
** 2009 Oct 23
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
*//************** Begin file fts3_snippet.c ************************************//************** End of fts3_write.c ******************************************//*
** Flush any data in the pending-terms hash table to disk. If successful,
** merge all segments in the database (including the new segment, if
** there was any data to flush) into a single segment.
*//* If this is an INSERT or UPDATE operation, insert the new record. *//* If this is a DELETE or UPDATE operation, remove the old record. *//* The new rowid is not NULL (in this case the rowid will be
      ** automatically assigned and there is no chance of a conflict), and
      ** the statement is either an INSERT or an UPDATE that modifies the
      ** rowid column. So if the conflict mode is REPLACE, then delete any
      ** existing row with rowid=pNewRowid.
      **
      ** Or, if the conflict mode is not REPLACE, insert the new record into
      ** the %_content table. If we hit the duplicate rowid constraint (or any
      ** other error) while doing so, return immediately.
      **
      ** This branch may also run if pNewRowid contains a value that cannot
      ** be losslessly converted to an integer. In this case, the eventual
      ** call to fts3InsertData() (either just below or further on in this
      ** function) will return SQLITE_MISMATCH. If fts3DeleteByRowid is
      ** invoked, it will delete zero rows (since no row will have
      ** docid=$pNewRowid if $pNewRowid is not an integer value).
      *//* Find the value object that holds the new rowid value. *//* If this is an INSERT operation, or an UPDATE that modifies the rowid
  ** value, then this operation requires constraint handling.
  **
  ** If the on-conflict mode is REPLACE, this means that the existing row
  ** should be deleted from the database before inserting the new row. Or,
  ** if the on-conflict mode is other than REPLACE, then this method must
  ** detect the conflict and return SQLITE_CONSTRAINT before beginning to
  ** modify the database file.
  *//* Allocate space to hold the change in document sizes *//* Check for a "special" INSERT operation. One of the form:
  **
  **   INSERT INTO xyz(xyz) VALUES('command');
  *//* INSERT or UPDATE operations *//* DELETE operations *//* At this point it must be known if the %_stat table exists or not.
  ** So bHasStat may not be 2.  *//* Net change in number of documents *//* Sizes of deleted documents *//* Sizes of inserted documents *//* FTS3 vtab object *//*
** This function does the work for the xUpdate method of FTS3 virtual
** tables. The schema of the virtual table being:
**
**     CREATE TABLE <table name>(
**       <user columns>,
**       <table name> HIDDEN,
**       docid HIDDEN,
**       <langid> HIDDEN
**     );
**
**
*//* Deleting this row means the whole table is empty. In this case
        ** delete the contents of all three tables and throw away any
        ** data in the pendingTerms hash table.  *//* Deleting *pRowid leaves the table empty *//* True if *pRowid really is in the table *//* IN/OUT: Decrement if row is deleted *//*
** SQLite value pRowid contains the rowid of a row that may or may not be
** present in the FTS3 table. If it is, delete it and adjust the contents
** of subsiduary data structures accordingly.
*//* Column that token must appear in (or -1) *//* Token to defer *//* Fts3 table cursor *//*
** Add an entry for token pToken to the pCsr->pDeferred list.
*//* Position of token in zText *//* Dummy variables *//* Number of bytes in token *//* Used to iterate through deferred tokens *//* Docid of the row pCsr points to *//*
** Generate deferred-doclists for all tokens in the pCsr->pDeferred list
** based on the row that pCsr currently points to.
**
** A deferred-doclist is like any other doclist with position information
** included, except that it only contains entries for a single row of the
** table, not for all rows.
*//*
** Free all entries in the pCsr->pDeffered list. Entries are added to
** this list using sqlite3Fts3DeferToken().
*//*
** Delete all cached deferred doclists. Deferred doclists are cached
** (allocated) by the sqlite3Fts3CacheDeferredDoclists() function.
*//*
** Handle a 'special' INSERT of the form:
**
**   "INSERT INTO tbl(tbl) VALUES(<expr>)"
**
** Argument pVal contains the result of <expr>. Currently the only
** meaningful value to insert is the text 'optimize'.
*//* FTS3 table handle *//*
** Run the integrity-check. If no error occurs and the current contents of
** the FTS index are correct, return SQLITE_OK. Or, if the contents of the
** FTS index are incorrect, return SQLITE_CORRUPT_VTAB.
**
** Or, if an error (e.g. an OOM or IO error) occurs, return an SQLite
** error code.
**
** The integrity-check works as follows. For each token and indexed token
** prefix in the document set, a 64-bit checksum is calculated (by code
** in fts3ChecksumEntry()) based on the following:
**
**     + The index number (0 for the main index, 1 for the first prefix
**       index etc.),
**     + The token (or token prefix) text itself,
**     + The language-id of the row it appears in,
**     + The docid of the row it appears in,
**     + The column it appears in, and
**     + The tokens position within that column.
**
** The checksums for all entries in the index are XORed together to create
** a single checksum for the entire index.
**
** The integrity-check code calculates the same checksum in two ways:
**
**     1. By scanning the contents of the FTS index, and
**     2. By scanning and tokenizing the content table.
**
** If the two checksums are identical, the integrity-check is deemed to have
** passed.
*//* This block calculates the checksum according to the %_content table *//* This block calculates the checksum according to the FTS index. *//* Statement to return all language-ids *//* Checksum based on %_content contents *//* Checksum based on FTS index contents *//*
** Check if the contents of the FTS index match the current contents of the
** content table. If no error occurs and the contents do match, set *pbOk
** to true and return SQLITE_OK. Or if the contents do not match, set *pbOk
** to false before returning.
**
** If an error occurs (e.g. an OOM or IO error), return an SQLite error
** code. The final value of *pbOk is undefined in this case.
*//* OUT: Return code *//* Index to cksum (0..p->nIndex-1) *//* Language id to return cksum for *//*
** Return a checksum of all entries in the FTS index that correspond to
** language id iLangid. The checksum is calculated by XORing the checksums
** of each individual entry (see fts3ChecksumEntry()) together.
**
** If successful, the checksum value is returned and *pRc set to SQLITE_OK.
** Otherwise, if an error occurs, *pRc is set to an SQLite error code. The
** return value is undefined in this case.
*//* Position *//* Docid for current row. *//* Index (0..Fts3Table.nIndex-1) *//* Language id for current row *//* Pointer to buffer containing term *//*
** Return a 64-bit checksum for the FTS index entry specified by the
** arguments to this function.
*//* Nul-terminated string containing boolean *//*
** Process statements of the form:
**
**    INSERT INTO table(table) VALUES('automerge=X');
**
** where X is an integer.  X==0 means to turn automerge off.  X!=0 means
** turn it on.  The setting is persistent.
*//* If the first integer value is followed by a ',',  read the second
  ** integer value. *//* Read the first integer value *//* Nul-terminated string containing "A,B" *//*
** Process statements of the form:
**
**    INSERT INTO table(table) VALUES('merge=A,B');
**
** A and B are integers that decode to be the number of leaf pages
** written for the merge, and the minimum number of segments on a level
** before it will be selected for a merge, respectively.
*//*
** Convert the text beginning at *pz into an integer and return
** its value.  Advance *pz to point to the first character past
** the integer.
**
** This function used for parameters to merge= and incrmerge=
** commands.
*//* Write the hint values into the %_stat table for the next incr-merger *//* Update or delete the input segments *//* Open a cursor to iterate through the contents of the oldest nSeg
    ** indexes of absolute level iAbsLevel. If this cursor is opened using
    ** the 'hint' parameters, it is possible that there are less than nSeg
    ** segments available in level iAbsLevel. In this case, no work is
    ** done on iAbsLevel - fall through to the next iteration of the loop
    ** to start work on some other level.  *//* If nSeg is less that zero, then there is no level with at least
    ** nMin segments and no hint in the %_stat table. No work to do.
    ** Exit early in this case.  *//* This undoes the effect of the HintPop() above - so that no entry
        ** is removed from the hint blob.  *//* Based on the scan in the block above, it is known that there
        ** are no levels with a relative level smaller than that of
        ** iAbsLevel with more than nSeg segments, or if nSeg is -1,
        ** no levels with more than nMin segments. Use this to limit the
        ** value of nHintSeg to avoid a large memory allocation in case the
        ** merge-hint is corrupt*//* Hint number of segments *//* Hint level *//* If the hint read from the %_stat table is not empty, check if the
    ** last entry in it specifies a relative level smaller than or equal
    ** to the level identified by the block above (if any). If so, this
    ** iteration of the loop will work on merging at the hinted level.
    *//* Search the %_segdir table for the absolute level with the smallest
    ** relative level number that contains at least nMin segments, if any.
    ** If one is found, set iAbsLevel to the absolute level number and
    ** nSeg to nMin. If no level with at least nMin segments can be found,
    ** set nSeg to -1.
    *//* Largest idx in level (iAbsLevel+1) *//* True if attempting to append *//* SQL used to determine iAbsLevel *//* Allocate space for the cursor, filter and writer objects *//* True if blob 'hint' has been modified *//* Hint read from %_stat table *//* Absolute level number to work on *//* Filter used with cursor pCsr *//* Cursor used to read input data *//* Number of leaf pages yet to  be written *//*
** Attempt an incremental merge that writes nMerge leaf blocks.
**
** Incremental merges happen nMin segments at a time. The segments
** to be merged are the nMin oldest segments (the ones with the smallest
** values for the _segdir.idx field) in the highest level that contains
** at least nMin segments. Multiple merges might occur in an attempt to
** write the quota of nMerge leaf blocks.
*//*
** Read the last entry (most recently pushed) from the hint blob *pHint
** and then remove the entry. Write the two values read to *piAbsLevel and
** *pnInput before returning.
**
** If no error occurs, return SQLITE_OK. If the hint blob in *pHint does
** not contain at least two valid varints, return SQLITE_CORRUPT_VTAB.
*//* Second varint to store in hint *//* First varint to store in hint *//* Hint blob to append to *//*
** If *pRc is not SQLITE_OK when this function is called, it is a no-op.
** Otherwise, append an entry to the hint stored in blob *pHint. Each entry
** consists of two varints, the absolute level number of the input segments
** and the number of input segments.
**
** If successful, leave *pRc set to SQLITE_OK and return. If an error occurs,
** set *pRc to an SQLite error code before returning.
*//*
** Load an incr-merge hint from the database. The incr-merge hint, if one
** exists, is stored in the rowid==1 row of the %_stat table.
**
** If successful, populate blob *pHint with the value read from the %_stat
** table and return SQLITE_OK. Otherwise, if an error occurs, return an
** SQLite error code.
*//*
** Store an incr-merge hint in the database.
*//* The incremental merge did not copy all the data from this
      ** segment to the upper level. The segment is modified in place
      ** so that it contains no keys smaller than zTerm/nTerm. *//* Seg-reader is at EOF. Remove the entire input segment. *//* Find the Fts3SegReader object with Fts3SegReader.iIdx==i. It is hiding
    ** somewhere in the pCsr->apSegment[] array.  *//* Number of segments not deleted *//* Chomp all segments opened by this cursor *//* Absolute level containing segments *//* FTS table handle *//*
** This function is called after an incrmental-merge operation has run to
** merge (or partially merge) two or more segments from absolute level
** iAbsLevel.
**
** Each input segment is either removed from the db completely (if all of
** its data was copied to the output segment by the incrmerge operation)
** or modified in place so that it no longer contains those entries that
** have been duplicated in the output segment.
*//* Variable iNewStart now contains the first valid leaf node. *//* Statement used to fetch segdir *//* Old value for iStartBlock *//* New value for iStartBlock *//* Block id *//* Buffer used for any other block *//* New root page image *//* Number of bytes in buffer zTerm *//* Remove terms smaller than this *//* Index within level of segment to modify *//* Absolute level of segment to modify *//*
** Remove all terms smaller than zTerm/nTerm from segment iIdx in absolute
** level iAbsLevel. This may involve deleting entries from the %_segments
** table, and modifying existing entries in both the %_segments and %_segdir
** tables.
**
** SQLITE_OK is returned if the segment is updated successfully. Or an
** SQLite error code otherwise.
*//* Populate new node buffer *//* Allocate required output space *//* True for a leaf node *//* Previous term written to new node *//* Reader object *//* OUT: Block number in next layer down *//* Omit all terms smaller than this *//* OUT: Write new node image here *//* Size of aNode in bytes *//* Current node image *//*
** The first two arguments are a pointer to and the size of a segment b-tree
** node. The node may be a leaf or an internal node.
**
** This function creates a new node image in blob object *pNew by copying
** all terms that are greater than or equal to zTerm/nTerm (for leaf nodes)
** or greater than zTerm/nTerm (for internal nodes) from aNode/nNode.
*//* Update statement to modify idx values *//* Select statement to read idx values *//* Allocated size of aIdx[] *//* Valid entries in aIdx[] *//* Array of remaining idx values *//* Absolute level to repack *//*
** One or more segments have just been removed from absolute level iAbsLevel.
** Update the 'idx' values of the remaining segments in the level so that
** the idx values are a contiguous sequence starting from 0.
*//* Index of %_segdir entry to delete *//* Absolute level to delete from *//*
** Remove an entry from the %_segdir table. This involves running the
** following two statements:
**
**   DELETE FROM %_segdir WHERE level = :iAbsLevel AND idx = :iIdx
**   UPDATE %_segdir SET idx = idx - 1 WHERE level = :iAbsLevel AND idx > :iIdx
**
** The DELETE statement removes the specific %_segdir level. The UPDATE
** statement ensures that the remaining segments have contiguously allocated
** idx values.
*//* Set up the array of NodeWriter objects *//* Insert the marker in the %_segments table to make sure nobody tries
  ** to steal the space just allocated. This is also used to identify
  ** appendable segments.  *//* Calculate the first block to use in the output segment *//* Calculate nLeafEst. *//* SQL used to determine first block *//* SQL used to determine nLeafEst *//* Blocks allocated for leaf nodes *//* Cursor that data will be read from *//* Index of new output segment *//* Absolute level of input segments *//* Fts3 table handle *//*
** Allocate an appendable output segment on absolute level iAbsLevel+1
** with idx value iIdx.
**
** In the %_segdir table, a segment is defined by the values in three
** columns:
**
**     start_block
**     leaves_end_block
**     end_block
**
** When an appendable segment is allocated, it is estimated that the
** maximum number of leaf blocks that may be required is the sum of the
** number of leaf blocks consumed by the input segments, plus the number
** of input segments, multiplied by two. This value is stored in stack
** variable nLeafEst.
**
** A total of 16*nLeafEst blocks are allocated when an appendable segment
** is created ((1 + end_block - start_block)==16*nLeafEst). The contiguous
** array of leaf nodes starts at the first block allocated. The array
** of interior nodes that are parents of the leaf nodes start at block
** (start_block + (1 + end_block - start_block) / 16). And so on.
**
** In the actual code below, the value "16" is replaced with the
** pre-processor macro FTS_MAX_APPENDABLE_HEIGHT.
*//* SQL used to find output index *//* OUT: Next free index at iAbsLevel+1 *//* Absolute index of input segments *//* FTS Table handle *//*
** Determine the largest segment index value that exists within absolute
** level iAbsLevel+1. If no error occurs, set *piIdx to this value plus
** one before returning SQLITE_OK. Or, if there are no segments at all
** within level iAbsLevel, set *piIdx to zero.
**
** If an error occurs, return an SQLite error code. The final value of
** *piIdx is undefined in this case.
*//* It is possible to append to this segment. Set up the IncrmergeWriter
      ** object to do so.  *//* Check that zKey/nKey is larger than the largest key the candidate *//* Check for the zero-length marker in the %_segments table *//* Read the %_segdir entry for index iIdx absolute level (iAbsLevel+1) *//* Set to true if segment is appendable *//* Return code from sqlite3_reset() *//* Size of aRoot[] in bytes *//* Pointer to %_segdir.root buffer *//* Value of %_segdir.end_block *//* Value of %_segdir.leaves_end_block *//* Value of %_segdir.start_block *//* SELECT to read %_segdir entry *//* Number of bytes in nKey *//* First key to write *//* Index of candidate output segment *//*
** This function is called when initializing an incremental-merge operation.
** It checks if the existing segment with index value iIdx at absolute level
** (iAbsLevel+1) can be appended to by the incremental merge. If it can, the
** merge-writer object *pWriter is initialized to write to it.
**
** An existing segment can be appended to by an incremental merge if:
**
**   * It was initially created as an appendable segment (with all required
**     space pre-allocated), and
**
**   * The first key read from the input (arguments zKey and nKey) is
**     greater than the largest key currently stored in the potential
**     output segment.
*//* Statement to query database with *//* Result to set *pbRes to *//*
** Query to see if the entry in the %_segments table with blockid iEnd is
** NULL. If no error occurs and the entry is NULL, set *pbRes 1 before
** returning. Otherwise, set *pbRes to 0.
**
** Or, if an error occurs while querying the database, return an SQLite
** error code. The final value of *pbRes is undefined in this case.
**
** This is used to test if a segment is an "appendable" segment. If it
** is, then a NULL entry has been inserted into the %_segments table
** with blockid %_segdir.end_block.
*//* RHS of comparison *//* LHS of comparison *//*
** Compare the term in buffer zLhs (size in bytes nLhs) with that in
** zRhs (size in bytes nRhs) using memcmp. If one term is a prefix of
** the other, it is considered to be smaller than the other.
**
** Return -ve if zLhs is smaller than zRhs, 0 if it is equal, or +ve
** if it is greater.
*//* root *//* end_block *//* leaves_end_block *//* start_block *//* idx *//* Write the %_segdir record. *//* Flush all currently outstanding nodes to disk. *//* The entire output segment fits on a single node. Normally, this means
  ** the node would be stored as a blob in the "root" column of the %_segdir
  ** table. However, this is not permitted in this case. The problem is that
  ** space has already been reserved in the %_segments table, and so the
  ** start_block and end_block fields of the %_segdir table must be populated.
  ** And, by design or by accident, released versions of FTS cannot handle
  ** segments that fit entirely on the root node with start_block!=0.
  **
  ** Instead, create a synthetic root node that contains nothing but a
  ** pointer to the single content node. So that the segment consists of a
  ** single leaf and a single interior (root) node.
  **
  ** Todo: Better might be to defer allocating space in the %_segments
  ** table until we are sure it is needed.
  *//* Empty output segment. This is a no-op. *//* Set iRoot to the index in pWriter->aNodeWriter[] of the output segment
  ** root node. If the segment fits entirely on a single leaf node, iRoot
  ** will be set to 0. If the root node is the parent of the leaves, iRoot
  ** will be 1. And so on.  *//* NodeWriter for root node *//* Index of root in pWriter->aNodeWriter *//* Used to iterate through non-root layers *//* Merge-writer object *//*
** This function is called to release all dynamic resources held by the
** merge-writer object pWriter, and if no error has occurred, to flush
** all outstanding node buffers held by pWriter to disk.
**
** If *pRc is not SQLITE_OK when this function is called, then no attempt
** is made to write any data to disk. Instead, this function serves only
** to release outstanding resources.
**
** Otherwise, if *pRc is initially SQLITE_OK and an error occurs while
** flushing buffers to disk, *pRc is set to an SQLite error code before
** returning.
*//* Advance to the next output block *//* Add the current term to the parent node. The term added to the
    ** parent must:
    **
    **   a) be greater than the largest term on the leaf node just written
    **      to the database (still available in pLeaf->key), and
    **
    **   b) be less than or equal to the term about to be added to the new
    **      leaf node (zTerm/nTerm).
    **
    ** In other words, it must be the prefix of zTerm 1 byte longer than
    ** the common prefix (if any) of zTerm and pWriter->zTerm.
    *//* If the current block is not empty, and if adding this term/doclist
  ** to the current block would make it larger than Fts3Table.nNodeSize bytes,
  ** and if there is still room for another leaf page, write this block out to
  ** the database. *//* Object used to write leaf nodes *//* Size of suffix (nTerm - nPrefix) *//* Size of prefix shared with previous term *//* Total space in bytes required on leaf *//* Cursor containing term and doclist *//*
** Append the current term and doclist pointed to by cursor pCsr to the
** appendable b-tree segment opened for writing by pWriter.
**
** Return SQLITE_OK if successful, or an SQLite error code otherwise.
*//* Node must have already been started. There must be a doclist for a
  ** leaf node, and there must not be a doclist for an internal node.  *//* Size of term suffix in bytes *//* Size of term prefix in bytes *//* True if this is the first term written *//* Size of aDoclist in bytes *//* Doclist (or NULL) to write *//* New term to write *//* Buffer containing previous term written *//* Current node image to append to *//*
** Append a term and (optionally) doclist to the FTS segment node currently
** stored in blob *pNode. The node need not contain any terms, but the
** header must be written before this function is called.
**
** A node header is a single 0x00 byte for a leaf node, or a height varint
** followed by the left-hand-child varint for an internal node.
**
** The term to be appended is passed via arguments zTerm/nTerm. For a
** leaf node, the doclist is passed as aDoclist/nDoclist. For an internal
** node, both aDoclist and nDoclist must be passed 0.
**
** If the size of the value in blob pPrev is zero, then this is the first
** term written to the node. Otherwise, pPrev contains a copy of the
** previous term. Before this function returns, it is updated to contain a
** copy of zTerm/nTerm.
**
** It is assumed that the buffer associated with pNode is already large
** enough to accommodate the new entry. The buffer associated with pPrev
** is extended by this function if requrired.
**
** If an error (i.e. OOM condition) occurs, an SQLite error code is
** returned. Otherwise, SQLITE_OK.
*//* Otherwise, flush the current node of layer iLayer to disk.
      ** Then allocate a new, empty sibling node. The key will be written
      ** into the parent of this node. *//* If the current node of layer iLayer contains zero keys, or if adding
      ** the key to it will not cause it to grow to larger than nNodeSize
      ** bytes in size, write the key here.  *//* Figure out how much space the key will consume if it is written to
    ** the current node of layer iLayer. Due to the prefix compression,
    ** the space required changes depending on which node the key is to
    ** be added to.  *//* Bytes at zTerm *//* Term to write to internal node *//*
** This function is called while writing an FTS segment each time a leaf o
** node is finished and written to disk. The key (zTerm/nTerm) is guaranteed
** to be greater than the largest key on the node just written, but smaller
** than or equal to the first key that will be written to the next leaf
** node.
**
** The block id of the leaf node just written to disk may be found in
** (pWriter->aNodeWriter[0].iBlock) when this function is called.
*//* An internal node. *//* Figure out if this is a leaf or an internal node. *//*
** Initialize a node-reader object to read the node in buffer aNode/nNode.
**
** If successful, SQLITE_OK is returned and the NodeReader object set to
** point to the first entry on the node (if any). Otherwise, an SQLite
** error code is returned.
*//*
** Release all dynamic resources held by node-reader object *p.
*//* Bytes to append to the prefix *//* Bytes to copy from previous term *//* True for first term on the node *//*
** Attempt to advance the node-reader object passed as the first argument to
** the next entry on the node.
**
** Return an error code if an error occurs (SQLITE_NOMEM is possible).
** Otherwise return SQLITE_OK. If there is no next entry on the node
** (e.g. because the current entry is the last) set NodeReader->aNode to
** NULL to indicate EOF. Otherwise, populate the NodeReader structure output
** variables for the new entry.
*//*
** If *pRc is not SQLITE_OK when this function is called, it is a no-op.
** Otherwise, if the allocation at pBlob->a is not already at least nMin
** bytes in size, extend (realloc) it to be so.
**
** If an OOM error occurs, set *pRc to SQLITE_NOMEM and leave pBlob->a
** unmodified. Otherwise, if the allocation succeeds, update pBlob->nAlloc
** to reflect the new size of the pBlob->a[] buffer.
*//* Pointer to doclist *//* Pointer to child node *//* Output variables. Containing the current node entry. *//* Current offset within aNode[] *//*
** An object of the following type is used to read data from a single
** FTS segment node. See the following functions:
**
**     nodeReaderInit()
**     nodeReaderNext()
**     nodeReaderRelease()
*//* If true, store 0 for segment size *//* Bytes of leaf page data so far *//* Block number of last allocated block *//* Block number of first allocated block *//* Index of *output* segment in iAbsLevel+1 *//* Number of leaf pages flushed *//* Space allocated for leaf blocks *//*
** An object of this type contains the state required to create or append
** to an appendable b-tree segment.
*//* Current block image *//* Last key written to the current block *//* Current block id *//*
** This structure is used to build up buffers containing segment b-tree
** nodes (blocks).
*//* Allocated size of a[] (nAlloc>=n) *//* Number of valid bytes of data in a[] *//* Pointer to allocation *//*
** An instance of the following structure is used as a dynamic buffer
** to build up nodes or other blobs of data in.
**
** The function blobGrowBuffer() is used to extend the allocation.
*//* segdir.root *//* segdir.end_block *//* segdir.leaves_end_block *//* segdir.start_block *//* Allocate space for the Fts3MultiSegReader.aCsr[] array *//* Bytes allocated at pCsr->apSegment[] *//* Statement used to read %_segdir entry *//* Cursor object to populate *//* Number of segments to merge *//* Absolute level to open *//*
** This function opens a cursor used to read the input data for an
** incremental merge operation. Specifically, it opens a cursor to scan
** the oldest nSeg segments (idx=0 through idx=(nSeg-1)) in absolute
** level iAbsLevel.
*//* Compose and prepare an SQL statement to loop through the content table *//*
** This function is called when the user executes the following statement:
**
**     INSERT INTO <tbl>(<tbl>) VALUES('rebuild');
**
** The entire FTS index is discarded and rebuilt. If the table is one
** created using the content=xxx option, then the new index is based on
** the current contents of the xxx table. Otherwise, it is rebuilt based
** on the contents of the %_content table.
*//*
** Merge the entire database so that there is one segment for each
** iIndex/iLangid combination.
*//* Result code from subfunctions *//* Statement for reading and writing *//* Array of integers that becomes the BLOB *//* Size of BLOB written into %_stat *//* Storage for BLOB written into %_stat *//* Change in the number of documents *//* Size decreases *//* Size increases *//* Table being updated *//* The result code *//*
** Record 0 of the %_stat table contains a blob consisting of N varints,
** where N is the number of user defined columns in the fts3 table plus
** two. If nCol is the number of user defined columns, then values of the
** varints are set as follows:
**
**   Varint 0:       Total number of rows in the table.
**
**   Varint 1..nCol: For each column, the total number of tokens stored in
**                   the column for all rows of the table.
**
**   Varint 1+nCol:  The total size, in bytes, of all text values in all
**                   columns of all rows of the table.
**
*//* Statement used to insert the encoding *//* Number of bytes in the BLOB *//* The BLOB encoding of the document size *//* Sizes of each column, in tokens *//* Table into which to insert *//*
** Insert the sizes (in tokens) for each column of the document
** with docid equal to p->iPrevDocid.  The sizes are encoded as
** a blob of varints.
*//* size of the BLOB *//* The BLOB containing the varints *//* Write the integer values *//* The number of integers to decode *//*
** Decode a blob of varints into N integers
*//* Write number of bytes if zBuf[] used here *//* Write the BLOB here *//* The integer values *//* The number of integers to encode *//*
** Encode N integers as varints into a blob.
*//* Determine the auto-incr-merge setting if unknown.  If enabled,
  ** estimate the number of leaf blocks of content to be written
  *//*
** Flush the contents of pendingTerms to level 0 segments.
*//* This call is to merge all segments at level iLevel. find the next
    ** available segment index at level iLevel+1. The call to
    ** fts3AllocateSegdirIdx() will merge the segments at level iLevel+1 to
    ** a single iLevel+2 segment if necessary.  *//* This call is to merge all segments in the database to a single
    ** segment. The level of the new segment is equal to the numerically
    ** greatest segment level currently present in the database for this
    ** index. The idx of the new segment is always 0.  *//* Max level number for this index/langid *//* True to ignore empty segments *//* Cursor to iterate through level(s) *//* Segment term filter condition *//* Used to write the new, merged, segment *//* Level/index to create new segment at *//* Index of new segment *//* Level to merge *//* Index in p->aIndex[] to merge *//* Language id to merge *//*
** Merge all level iLevel segments in the database into a single
** iLevel+1 segment. Or, if iLevel<0, merge all segments into a
** single segment with a level equal to the numerically largest level
** currently present in the database.
**
** If this function is called with iLevel<0, but there is only one
** segment in the database, SQLITE_DONE is returned immediately.
** Otherwise, if successful, SQLITE_OK is returned. If an error occurs,
** an SQLite error code is returned.
*//* Move level -1 to level iAbsLevel *//* Loop through all %_segdir entries for segments in this index with
        ** levels equal to or greater than iAbsLevel. As each entry is visited,
        ** updated it to set (level = -1) and (idx = N), where N is 0 for the
        ** oldest segment in the range, 1 for the next oldest, and so on.
        **
        ** In other words, move all segments being promoted to level -1,
        ** setting the "idx" fields as appropriate to keep them in the same
        ** order. The contents of level -1 (which is never used, except
        ** transiently here), will be moved back to level iAbsLevel below.  *//* If nSize==0, then the %_segdir.end_block field does not not
        ** contain a size value. This happens if it was written by an
        ** old version of FTS. In this case it is not possible to determine
        ** the size of the segment, and so segment promotion does not
        ** take place.  *//* Loop through all entries in the %_segdir table corresponding to
    ** segments in this index on levels greater than iAbsLevel. If there is
    ** at least one such segment, and it is possible to determine that all
    ** such segments are smaller than nLimit bytes in size, they will be
    ** promoted to level iAbsLevel.  *//* Size of new segment at iAbsLevel *//* Absolute level just updated *//*
** A segment of size nByte bytes has just been written to absolute level
** iAbsLevel. Promote any segments that should be promoted as a result.
*//*
** Decode the "end_block" field, selected by column iCol of the SELECT
** statement passed as the first argument.
**
** The "end_block" field may contain either an integer, or a text field
** containing the text representation of two non-negative integers separated
** by one or more space (0x20) characters. In the first case, set *piEndBlock
** to the integer value and *pnByte to zero before returning. In the second,
** set *piEndBlock to the first value and *pnByte to the second.
*//* Calculate the 'docid' delta value to write into the merged
          ** doclist. *//* Number of segments that share a docid *//* The current term of the first nMerge entries in the array
      ** of Fts3SegReader objects is the same. The doclists must be merged
      ** and a single term returned with the merged doclist.
      *//* Previous docid stored in doclist *//* Size of doclist *//* If this is a prefix-search, and if the term that apSegment[0] points
    ** to does not share a suffix with pFilter->zTerm/nTerm, then all
    ** required callbacks have been made. In this case exit early.
    **
    ** Similarly, if this is a search for an exact match, and the first term
    ** of segment apSegment[0] is not a match, exit early.
    *//* If all the seg-readers are at EOF, we're finished. return SQLITE_OK. *//* Advance the first pCsr->nAdvance entries in the apSegment[] array
    ** forward. Then sort the list in order of current term again.
    *//* Used to iterate through segment-readers *//*
** This function is called on a MultiSegReader that has been started using
** sqlite3Fts3MsrIncrStart(). One or more calls to MsrIncrNext() may also
** have been made. Calling this function puts the MultiSegReader in such
** a state that if the next two calls are:
**
**   sqlite3Fts3SegReaderStart()
**   sqlite3Fts3SegReaderStep()
**
** then the entire doclist for the term is available in
** MultiSegReader.aDoclist/nDoclist.
*//* Advance each of the segments to point to the first docid. *//* Determine how many of the segments actually point to zTerm/nTerm. *//* Advance each segment iterator until it points to the term zTerm/nTerm. *//* Number of bytes in zTerm *//* Term to iterate through a doclist for *//* Column to match on. *//* Restrictions on range of iteration *//* If the Fts3SegFilter defines a specific term (or term prefix) to search
  ** for, then advance each segment iterator until it points to a term of
  ** equal or greater value than the specified term. This prevents many
  ** unnecessary merge/sort operations for the case where single segment
  ** b-tree leaf nodes contain more than one term.
  *//* Length of zTerm in bytes *//* Term searched for (or NULL) *//* OUT: Size of position list in bytes *//* OUT: Pointer to position list *//* OUT: Docid value *//* Multi-segment-reader handle *//*
** Cache data in the Fts3MultiSegReader.aBuffer[] buffer (overwriting any
** existing data). Grow the buffer if required.
**
** If successful, return SQLITE_OK. Otherwise, if an OOM error is encountered
** trying to resize the buffer, return SQLITE_NOMEM.
*//* IN/OUT: Size of buffer *ppList in bytes *//* IN/OUT: Pointer to position list *//* Zero out anything following *ppList *//* Column to filter on *//*
** When this function is called, buffer *ppList (size *pnList bytes) contains
** a position list that may (or may not) feature multiple columns. This
** function adjusts the pointer *ppList and the length *pnList so that they
** identify the subset of the position list that corresponds to column iCol.
**
** If there are no entries in the input position list for column iCol, then
** *pnList is set to zero before returning.
**
** If parameter bZero is non-zero, then any part of the input list following
** the end of the output list is zeroed before returning.
*//* SQL statement to delete rows *//* Size of array apSegment *//* Array of SegReader objects *//* Level of %_segdir entries to delete *//* Index for p->aIndex *//* Language id *//*
** This function is used after merging multiple segments into a single large
** segment to delete the old, now redundant, segment b-trees. Specifically,
** it:
**
**   1) Deletes all %_segments entries for the segments associated with
**      each of the SegReader objects in the array passed as the third
**      argument, and
**
**   2) deletes all %_segdir entries with level iLevel, or all %_segdir
**      entries regardless of level if (iLevel<0).
**
** SQLITE_OK is returned if successful, otherwise an SQLite error code.
*//* Segment to delete *//*
** Delete all entries in the %_segments table associated with the segment
** opened with seg-reader pSeg. This function does not affect the contents
** of the %_segdir table.
*//* Set pStmt to the compiled version of:
  **
  **   SELECT max(level) FROM %Q.'%q_segdir' WHERE level BETWEEN ? AND ?
  **
  ** (1024 is actually the value of macro FTS3_SEGDIR_PREFIXLEVEL_STR).
  *//*
** iAbsLevel is an absolute level that may be assumed to exist within
** the database. This function checks if it is the largest level number
** within its index. Assuming no error occurs, *pbMax is set to 1 if
** iAbsLevel is indeed the largest level, or 0 otherwise, and SQLITE_OK
** is returned. If an error occurs, an error code is returned and the
** final value of *pbMax is undefined.
*//*
** Set *pnMax to the largest segment level in the database for the index
** iIndex.
**
** Segment levels are stored in the 'level' column of the %_segdir table.
**
** Return SQLITE_OK if successful, or an SQLite error code if not.
*//* If using the content=xxx option, assume the table is never empty *//*
** The first value in the apVal[] array is assumed to contain an integer.
** This function tests if there exist any documents with docid values that
** are different from that integer. i.e. if deleting the document with docid
** pRowid would mean the FTS3 table were empty.
**
** If successful, *pisEmpty is set to true if the table is empty except for
** document pRowid, or false otherwise, and SQLITE_OK is returned. If an
** error occurs, an SQLite error code is returned.
*//*
** Release all memory held by the SegmentWriter object passed as the
** first argument.
*//* The entire tree fits on the root node. Write it to the segdir table. *//* Size of buffer zRoot *//* Pointer to buffer containing root node *//* Largest leaf block id written to db *//* Largest block id written to database *//* Value for 'idx' column of %_segdir *//* Value for 'level' column of %_segdir *//* SegmentWriter to flush to the db *//*
** Flush all data associated with the SegmentWriter object pWriter to the
** database. This function must be called after all terms have been added
** to the segment using fts3SegWriterAdd(). If successful, SQLITE_OK is
** returned. Otherwise, an SQLite error code.
*//* Save the current term so that it can be used to prefix-compress the next.
  ** If the isCopyTerm parameter is true, then the buffer pointed to by
  ** zTerm is transient, so take a copy of the term data. Otherwise, just
  ** store a copy of the pointer.
  *//* Append the prefix-compressed term and doclist to the buffer. *//* If the buffer currently allocated is too small for this entry, realloc
  ** the buffer to make it large enough.
  *//* Increase the total number of bytes written to account for the new entry. *//* Doclist data *//* Term suffix *//* varint containing suffix size *//* varint containing prefix size *//* Add the current term to the interior node tree. The term added to
    ** the interior tree must:
    **
    **   a) be greater than the largest term on the leaf node just written
    **      to the database (still available in pWriter->zTerm), and
    **
    **   b) be less than or equal to the term about to be added to the new
    **      leaf node (zTerm/nTerm).
    **
    ** In other words, it must be the prefix of zTerm 1 byte longer than
    ** the common prefix (if any) of zTerm and pWriter->zTerm.
    *//* The current leaf node is full. Write it out to the database. *//* Figure out how many bytes are required by this new entry *//* If nSuffix is zero or less, then zTerm/nTerm must be a prefix of
  ** pWriter->zTerm/pWriter->nTerm. i.e. must be equal to or less than when
  ** compared with BINARY collation. This indicates corruption.  *//* Find the next free blockid in the %_segments table *//* Allocate a buffer in which to accumulate data *//* Allocate the SegmentWriter structure *//* Number of bytes required on leaf page *//* Pointer to buffer containing doclist *//* True if buffer zTerm must be copied *//* IN/OUT: SegmentWriter handle *//*
** Add a term to the segment being constructed by the SegmentWriter object
** *ppWriter. When adding the first term to a segment, *ppWriter should
** be passed NULL. This function will allocate a new SegmentWriter object
** and return it via the input/output variable *ppWriter in this case.
**
** If successful, SQLITE_OK is returned. Otherwise, an SQLite error code.
*//*
** Free all memory allocations associated with the tree pTree.
*//* Root node of the tree. *//* OUT: Size of root node in bytes *//* OUT: Data for root node *//* OUT: Block id of last entry written *//* Block id of next free slot in %_segments *//* Block id of first leaf node *//* Height of this node in tree *//* SegmentNode handle *//*
** Write the buffer for the segment node pTree and all of its peers to the
** database. Then call this function recursively to write the parent of
** pTree and its peers to the database.
**
** Except, if pTree is a root node, do not write it to the database. Instead,
** set output variables *paRoot and *pnRoot to contain the root node.
**
** If successful, SQLITE_OK is returned and output variable *piLast is
** set to the largest blockid written to the database (or zero if no
** blocks were written to the db). Otherwise, an SQLite error code is
** returned.
*//*
** Helper function for fts3NodeWrite().
*//* If control flows to here, it was not possible to append zTerm to the
  ** current node. Create a new node (a right-sibling of the current node).
  ** If this is the first node in the tree, the term is added to it.
  **
  ** Otherwise, the term is not added to the new node, it is left empty for
  ** now. Instead, the term is inserted into the parent of pTree. If pTree
  ** has no parent, one is created here.
  *//* There is no prefix-length field for first term in a node *//* An unusual case: this is the first term to be added to the node
        ** and the static node buffer (p->nNodeSize bytes) is not large
        ** enough. Use a separately malloced buffer instead This wastes
        ** p->nNodeSize bytes, but since this scenario only comes about when
        ** the database contain two terms that share a prefix of almost 2KB,
        ** this is not expected to be a serious problem.
        *//* If nSuffix is zero or less, then zTerm/nTerm must be a prefix of
    ** pWriter->zTerm/pWriter->nTerm. i.e. must be equal to or less than when
    ** compared with BINARY collation. This indicates corruption.  *//* Suffix length *//* Number of bytes of prefix compression *//* Required space after adding zTerm *//* Current size of node in bytes *//* First try to append the term to the current node. Return early if
  ** this is possible.
  *//* True if zTerm/nTerm is transient *//* IN/OUT: SegmentNode handle *//*
** Add term zTerm to the SegmentNode. It is guaranteed that zTerm is larger
** (according to memcmp) than the previous term.
*//* Size of buffer zNext in bytes *//* Buffer containing next term *//* Size of buffer zPrev in bytes *//* Buffer containing previous term *//*
** Return the size of the common prefix (if any) shared by zPrev and
** zNext, in bytes. For example,
**
**   fts3PrefixCompress("abc", 3, "abcdef", 6)   // returns 3
**   fts3PrefixCompress("abX", 3, "abcdef", 6)   // returns 2
**   fts3PrefixCompress("abX", 3, "Xbcdef", 6)   // returns 0
*//* Number of bytes in buffer zRoot *//* Blob value for "root" field *//* Bytes of leaf data in segment *//* Value for "end_block" field *//* Value for "leaves_end_block" field *//* Value for "start_block" field *//* Value for "idx" field *//* Value for "level" field (absolute level) *//*
** Insert a record into the %_segdir table.
*//*
** Find the largest relative level number in the table. If successful, set
** *pnMax to this value and return SQLITE_OK. Otherwise, if an error occurs,
** set *pnMax to zero and return an SQLite error code.
*//* Size of buffer z in bytes *//* Pointer to buffer containing block data *//* Block id for new block *//*
** Insert a record into the %_segments table.
*//* Check that the list really is sorted now. *//* Comparison function *//* Unsorted entry count *//* Size of apSegment array *//* Array to sort entries of *//*
** Argument apSegment is an array of nSegment elements. It is known that
** the final (nSegment-nSuspect) members are already in sorted order
** (according to the comparison function provided). This function shuffles
** the array around until all entries are in sorted order.
*//* Size of term zTerm in bytes *//* Term to compare to *//* Segment reader object *//*
** Compare the term that the Fts3SegReader object passed as the first argument
** points to with the term specified by arguments zTerm and nTerm.
**
** If the pSeg iterator is already at EOF, return 0. Otherwise, return
** -ve if the pSeg term is less than zTerm/nTerm, 0 if the two terms are
** equal, or +ve if the pSeg term is greater than zTerm/nTerm.
*//*
** A different comparison function for SegReader structures. In this
** version, it is assumed that each SegReader points to an entry in
** a doclist for identical terms. Comparison is made as follows:
**
**   1) EOF (end of doclist in this case) is greater than not EOF.
**
**   2) By current docid.
**
**   3) By segment age. An older segment is considered larger.
*//*
** Compare the entries pointed to by two Fts3SegReader structures.
** Comparison is as follows:
**
**   1) EOF is greater than not EOF.
**
**   2) The current terms (if any) are compared using memcmp(). If one
**      term is a prefix of another, the longer term is considered the
**      larger.
**
**   3) By segment age. An older segment is considered larger.
*//* The query is a simple term lookup that matches at most one term in
    ** the index. All that is required is a straight hash-lookup.
    **
    ** Because the stack address of pE may be accessed via the aElem pointer
    ** below, the "Fts3HashElem *pE" must be declared so that it is valid
    ** within this entire function, not just this "else{...}" block.
    *//* If more than one term matches the prefix, sort the Fts3HashElem
    ** objects in term order using qsort(). This uses the same comparison
    ** callback as is used when flushing terms to disk.
    *//* Size of allocated array at aElem *//* Size of array at aElem *//* Array of term hash entries to scan *//* Fts3SegReader object to return *//* OUT: SegReader for pending-terms *//* True for a prefix iterator *//* Size of buffer zTerm *//*
** This function is used to allocate an Fts3SegReader that iterates through
** a subset of the terms stored in the Fts3Table.pendingTerms array.
**
** If the isPrefixIter parameter is zero, then the returned SegReader iterates
** through each term in the pending-terms table. Or, if isPrefixIter is
** non-zero, it iterates through each term and its prefixes. For example, if
** the pending terms hash table contains the terms "sqlite", "mysql" and
** "firebird", then the iterator visits the following 'terms' (in the order
** shown):
**
**   f fi fir fire fireb firebi firebir firebird
**   m my mys mysq mysql
**   s sq sql sqli sqlit sqlite
**
** Whereas if isPrefixIter is zero, the terms visited are:
**
**   firebird mysql sqlite
*//*
** This is a comparison function used as a qsort() callback when sorting
** an array of pending terms by term. This occurs as part of flushing
** the contents of the pending-terms hash table to the database.
*//* The entire segment is stored in the root node. *//* Bytes to allocate segment root node *//* Newly allocated SegReader object *//* OUT: Allocated Fts3SegReader *//* Size of buffer containing root node *//* Buffer containing root node *//* Final block of segment *//* Final leaf to traverse *//* First leaf to traverse *//* True for a lookup only *//* Segment "age". *//*
** Allocate a new SegReader object.
*//*
** Free all allocations associated with the iterator passed as the
** second argument.
*//* If there are no more entries in the doclist, set pOffsetList to
    ** NULL. Otherwise, set Fts3SegReader.iDocid to the next docid and
    ** Fts3SegReader.pOffsetList to point to the next offset list before
    ** returning.
    *//* List may have been edited in place by fts3EvalNearTrim() *//* If required, populate the output variables with a pointer to and the
    ** size of the previous offset-list.
    *//* The following line of code (and the "p++" below the while() loop) is
      ** normally all that is required to move pointer p to the desired
      ** position. The exception is if this node is being loaded from disk
      ** incrementally and pointer "p" now points to the first byte past
      ** the populated part of pReader->aNode[].
      *//* Pointer p currently points at the first byte of an offset list. The
    ** following block advances it to point one byte past the end of
    ** the same offset list. *//* A pending-terms seg-reader for an FTS4 table that uses order=desc.
    ** Pending-terms doclists are always built up in ascending order, so
    ** we have to iterate through them backwards here. *//* OUT: Length of *ppOffsetList in bytes *//* OUT: Pointer to current position-list *//* Reader to advance to next docid *//*
** Advance the SegReader to point to the next docid in the doclist
** associated with the current term.
**
** If arguments ppOffsetList and pnOffsetList are not NULL, then
** *ppOffsetList is set to point to the first column-offset list
** in the doclist entry (i.e. immediately past the docid varint).
** *pnOffsetList is set to the length of the set of column-offset
** lists, not including the nul-terminator byte. For example:
*//*
** Set the SegReader to point to the first docid in the doclist associated
** with the current term.
*//* Check that the doclist does not appear to extend past the end of the
  ** b-tree node. And that the final byte of the doclist is 0x00. If either
  ** of these statements is untrue, then the data structure is corrupt.
  *//* Both nPrefix and nSuffix were read by fts3GetVarint32() and so are
  ** between 0 and 0x7FFFFFFF. But the sum of the two may cause integer
  ** overflow - hence the (i64) casts.  *//* Because of the FTS3_NODE_PADDING bytes of padding, the following is
  ** safe (no risk of overread) even if the node data is corrupted. *//* If iCurrentBlock>=iLeafEndBlock, this is an EOF condition. All leaf
    ** blocks have already been traversed.  *//* Number of bytes in term suffix *//* Number of bytes in term prefix *//* Cursor variable *//* Return code of various sub-routines *//*
** Move the iterator passed as the first argument to the next term in the
** segment. If successful, SQLITE_OK is returned. If there is no next term,
** SQLITE_DONE. Otherwise, an SQLite error code.
*//*
** Set an Fts3SegReader cursor to point at EOF.
*//*
** Close the blob handle at p->pSegments, if it is open. See comments above
** the sqlite3Fts3ReadBlock() function for details.
*//* pnBlob must be non-NULL. paBlob may be NULL or non-NULL. *//* OUT: Bytes actually loaded *//* OUT: Size of blob data *//* OUT: Blob data in malloc'd buffer *//* Access the row with blockid=$iBlockid *//*
** The %_segments table is declared as follows:
**
**   CREATE TABLE %_segments(blockid INTEGER PRIMARY KEY, block BLOB)
**
** This function reads data from a single row of the %_segments table. The
** specific row is identified by the iBlockid parameter. If paBlob is not
** NULL, then a buffer is allocated using sqlite3_malloc() and populated
** with the contents of the blob stored in the "block" column of the
** identified table row is. Whether or not paBlob is NULL, *pnBlob is set
** to the size of the blob in bytes before returning.
**
** If an error occurs, or the table does not contain the specified row,
** an SQLite error code is returned. Otherwise, SQLITE_OK is returned. If
** paBlob is non-NULL, then it is the responsibility of the caller to
** eventually free the returned buffer.
**
** This function may leave an open sqlite3_blob* handle in the
** Fts3Table.pSegments variable. This handle is reused by subsequent calls
** to this function. The handle may be closed by calling the
** sqlite3Fts3SegmentsClose() function. Reusing a blob handle is a handy
** performance improvement, but the blob handle should always be closed
** before control is returned to the user (to prevent a lock being held
** on the database file for longer than necessary). Thus, any virtual table
** method (xFilter etc.) that may directly or indirectly call this function
** must call sqlite3Fts3SegmentsClose() before returning.
*//* If iNext is FTS3_MERGE_COUNT, indicating that level iLevel is already
    ** full, merge all segments in level iLevel into a single iLevel+1
    ** segment and allocate (newly freed) index 0 at level iLevel. Otherwise,
    ** if iNext is less than FTS3_MERGE_COUNT, allocate index iNext.
    *//* Set variable iNext to the next available segdir index at level iLevel. *//* Result of query pNextIdx *//* Query for next idx at level iLevel *//*
** This function allocates a new level iLevel index in the segdir table.
** Usually, indexes are allocated within a level sequentially starting
** with 0, so the allocated index is one greater than the value returned
** by:
**
**   SELECT max(idx) FROM %_segdir WHERE level = :iLevel
**
** However, if there are already FTS3_MERGE_COUNT indexes at the requested
** level, they are merged into a single level (iLevel+1) segment and the
** allocated index is 0.
**
** If successful, *piIdx is set to the allocated index slot and SQLITE_OK
** returned. Otherwise, an SQLite error code is returned.
*//*
** Forward declaration to account for the circular dependency between
** functions fts3SegmentMerge() and fts3AllocateSegdirIdx().
*//* OUT: Set to true if row really does exist *//* Sizes of deleted document written here *//* The docid to be deleted *//* The FTS table to delete from *//*
** The first element in the apVal[] array is assumed to contain the docid
** (an integer) of a row about to be deleted. Remove all terms from the
** full-text index.
*//* Delete everything from the shadow tables. Except, leave %_content as
  ** is if bContent is false.  *//* Discard the contents of the pending-terms hash table. *//*
** Remove all data from the FTS3 table. Clear the hash table containing
** pending terms.
*//* Execute the statement to insert the record. Set *piDocid to the
  ** new docid value.
  *//* A rowid/docid conflict. *//* There is a quirk here. The users INSERT statement may have specified
  ** a value for the "rowid" field, for the "docid" field, or for both.
  ** Which is a problem, since "rowid" and "docid" are aliases for the
  ** same value. For example:
  **
  **   INSERT INTO fts3tbl(rowid, docid) VALUES(1, 2);
  **
  ** In FTS3, this is an error. It is an error to specify non-NULL values
  ** for both docid and some other rowid alias.
  *//* Locate the statement handle used to insert data into the %_content
  ** table. The SQL for this statement is:
  **
  **   INSERT INTO %_content VALUES(?, ?, ?, ...)
  **
  ** The statement features N '?' variables, where N is the number of user
  ** defined columns in the FTS3 table, plus one for the docid field.
  *//* INSERT INTO %_content VALUES(...) *//* OUT: Docid for row just inserted *//* Array of values to insert *//* Full-text table *//*
** This function is called by the xUpdate() method for an INSERT operation.
** The apVal parameter is passed a copy of the apVal argument passed by
** SQLite to the xUpdate() method. i.e:
**
**   apVal[0]                Not used for INSERT.
**   apVal[1]                rowid
**   apVal[2]                Left-most user-defined column
**   ...
**   apVal[p->nColumn+1]     Right-most user-defined column
**   apVal[p->nColumn+2]     Hidden column with same name as table
**   apVal[p->nColumn+3]     Hidden "docid" column (alias for rowid)
**   apVal[p->nColumn+4]     Hidden languageid column
*//*
** This function is called by the xUpdate() method as part of an INSERT
** operation. It adds entries for each term in the new record to the
** pendingTerms hash table.
**
** Argument apVal is the same as the similarly named argument passed to
** fts3InsertData(). Parameter iDocid is the docid of the new row.
*//*
** Discard the contents of the pending-terms hash tables.
*//* TODO(shess) Explore whether partially flushing the buffer on
  ** forced-flush would provide better performance.  I suspect that if
  ** we ordered the doclists by size and flushed the largest until the
  ** buffer was half empty, that would let the less frequent terms
  ** generate longer doclists.
  *//* Docid of row being written *//* Language id of row being written *//* True if this op is a delete *//* Full-text table handle *//*
** Calling this function indicates that subsequent calls to
** fts3PendingTermsAdd() are to add term/position-list pairs for the
** contents of the document with docid iDocid.
*//* Add the term to each of the prefix indexes that it is not too
    ** short for. *//* Add the term to the terms index *//* Positions cannot be negative; we use -1 as a terminator internally.
    ** Tokens must have a non-zero length.
    *//* If the user has inserted a NULL value, this function may be called with
  ** zText==0. In this case, add zero token entries to the hash table and
  ** return early. *//* IN/OUT: Incr. by number tokens inserted *//* Column into which text is being inserted *//* Text of document to be inserted *//* Language id to use *//* Table into which text will be inserted *//*
** Tokenize the nul-terminated string zText and add all tokens to the
** pending-terms hash-table. The docid used is that currently stored in
** p->iPrevDocid, and the column is specified by argument iCol.
**
** If successful, SQLITE_OK is returned. Otherwise, an SQLite error code.
*//* Malloc failed while inserting the new entry. This can only
      ** happen if there was no previous entry for this token.
      *//* Pending terms hash table to add entry to *//*
** Add an entry to one of the pending-terms hash tables.
*//*
** Free a PendingList object allocated by fts3PendingListAppend().
*//* Position of term for entry to add *//* Column for entry to add *//* Docid for entry to add *//* IN/OUT: PendingList structure *//*
** Add a docid/column/position entry to a PendingList structure. Non-zero
** is returned if the structure is sqlite3_realloced as part of adding
** the entry. Otherwise, zero.
**
** If an OOM error occurs, *pRc is set to SQLITE_NOMEM before returning.
** Zero is always returned in this case. Otherwise, if no OOM error occurs,
** it is set to SQLITE_OK.
*//* Append the new serialized varint to the end of the list. *//* Allocate or grow the PendingList as required. *//* Value to append to data *//* IN/OUT: Pointer to PendingList struct *//*
** Append a single varint to a PendingList buffer. SQLITE_OK is returned
** if successful, or an SQLite error code otherwise.
**
** This function also serves to allocate the PendingList structure itself.
** For example, to create a new PendingList structure containing two
** varints:
**
**   PendingList *p = 0;
**   fts3PendingListAppendVarint(&p, 1);
**   fts3PendingListAppendVarint(&p, 2);
*//* "SELECT * FROM %_segdir WHERE level = ? ORDER BY ..." *//* "SELECT * FROM %_segdir WHERE level BETWEEN ? AND ? ORDER BY ..." *//* OUT: Compiled statement *//* Level to select (relative level) *//* Index for p->aIndex[] *//* Language being queried *//* FTS3 table *//*
** Set *ppStmt to a statement handle that may be used to iterate through
** all rows in the %_segdir table, from oldest to newest. If successful,
** return SQLITE_OK. If an error occurs while preparing the statement,
** return an SQLite error code.
**
** There is only ever one instance of this SQL statement compiled for
** each FTS3 table.
**
** The statement returns the following columns from the %_segdir table:
**
**   0: idx
**   1: start_block
**   2: leaves_end_block
**   3: end_block
**   4: root
*//* First absolute level for iLangid/iIndex *//* Level of segments *//* Index in p->aIndex[] *//*
** FTS maintains a separate indexes for each language-id (a 32-bit integer).
** Within each language id, a separate index is maintained to store the
** document terms, and each configured prefix size (configured the FTS
** "prefix=" option). And each index consists of multiple levels ("relative
** levels").
**
** All three of these values (the language id, the specific index and the
** level within the index) are encoded in 64-bit integer values stored
** in the %_segdir table on disk. This function is used to convert three
** separate component values into the single 64-bit integer value that
** can be used to query the %_segdir table.
**
** Specifically, each language-id/index combination is allocated 1024
** 64-bit integer level values ("absolute levels"). The main terms index
** for language-id 0 is allocate values 0-1023. The first prefix index
** (if any) for language-id 0 is allocated values 1024-2047. And so on.
** Language 1 indexes are allocated immediately following language 0.
**
** So, for a system with nPrefix prefix indexes configured, the block of
** absolute levels that corresponds to language-id iLangid and index
** iIndex starts at absolute level ((iLangid * (nPrefix+1) + iIndex) * 1024).
*//*
** This function ensures that the caller has obtained an exclusive
** shared-cache table-lock on the %_segdir table. This is required before
** writing data to the fts3 table. If this lock is not acquired first, then
** the caller may end up attempting to take this lock as part of committing
** a transaction, causing SQLite to return SQLITE_LOCKED or
** LOCKED_SHAREDCACHEto a COMMIT command.
**
** It is best to avoid this because if FTS3 returns any error when
** committing a transaction, the whole transaction will be rolled back.
** And this is not what users expect when they get SQLITE_LOCKED_SHAREDCACHE.
** It can still happen if the user locks the underlying tables directly
** instead of accessing them via FTS.
*//* Parameters to bind *//* Index of statement to evaluate *//* The FTS3 table *//*
** Similar to fts3SqlStmt(). Except, after binding the parameters in
** array apVal[] to the SQL statement identified by eStmt, the statement
** is executed.
**
** Returns SQLITE_OK if the statement is successfully executed, or an
** SQLite error code otherwise.
*//* Docid to read size data for *//* Statement requested from fts3SqlStmt() *//* Docid to bind for SQL_SELECT_DOCSIZE *//* 39 *//* 38 *//* Update statements used while promoting segments *//* 37 *//* Return segments in order from oldest to newest.*//* 36 *//* SQL_SELECT_MXLEVEL
**   Return the largest relative level in the FTS index or indexes.  *//* 35 *//* SQL_SELECT_INDEXES
**   Return the list of valid segment indexes for absolute level ?  *//* 34 *//* SQL_SEGMENT_IS_APPENDABLE
**   Return a single row if the segment with end_block=? is appendable. Or
**   no rows otherwise.  *//* 33 *//* SQL_CHOMP_SEGDIR
**   Update the start_block (:1) and root (:2) fields of the %_segdir
**   entry located on absolute level :3 with index :4.  *//* 32 *//* SQL_SELECT_SEGDIR
**   Read a single entry from the %_segdir table. The entry from absolute
**   level :1 with index value :2.  *//* 31 *//* SQL_SHIFT_SEGDIR_ENTRY
**   Modify the idx value for the segment with idx=:3 on absolute level :2
**   to :1.  *//* 30 *//* SQL_DELETE_SEGDIR_ENTRY
**   Delete the %_segdir entry on absolute level :1 with index :2.  *//* 29 *//* Estimate the upper limit on the number of leaf nodes in a new segment
** created by merging the oldest :2 segments from absolute level :1. See
** function sqlite3Fts3Incrmerge() for details.  *//* 28 *//* This statement is used to determine which level to read the input from
** when performing an incremental merge. It returns the absolute level number
** of the oldest level in the db that contains at least ? segments. Or,
** if no level in the FTS index contains more than ? segments, the statement
** returns zero rows.  *//* 27 *//* 26 *//* 25 *//* 24 *//* 23 *//* 22 *//* 21 *//* 20 *//* 19 *//* 18 *//* 17 *//* 16 *//* 15 *//* 14 *//* 13 *//* 12 *//* 11 *//* 10 *//* 9  *//* 8  *//* 7  *//* 6  *//* 5  *//* 4  *//* 3  *//* 2  *//* 1  *//* 0  *//* Values to bind to statement *//* One of the SQL_XXX constants above *//*
** This function is used to obtain an SQLite prepared statement handle
** for the statement identified by the second argument. If successful,
** *pp is set to the requested statement handle and SQLITE_OK returned.
** Otherwise, an SQLite error code is returned and *pp is set to 0.
**
** If argument apVal is not NULL, then it must point to an array with
** at least as many entries as the requested statement has bound
** parameters. The values are bound to the statements parameters before
** returning.
*//*
** Valid values for the second argument to fts3SqlStmt().
*//* Node data *//* Bytes of valid data so far *//* Malloc'd space (possibly) used for zTerm *//* Size of malloc'd buffer at zMalloc *//* Pointer to previous term buffer *//* Number of terms written to node so far *//* Pointer to left-most node of this depth *//* Pointer to right-sibling *//* Parent node (or NULL for root node) *//*
** Type SegmentNode is used by the following three functions to create
** the interior part of the segment b+-tree structures (everything except
** the leaf nodes). These functions and type are only ever used by code
** within the fts3SegWriterXXX() family of functions described above.
**
**   fts3NodeAddTerm()
**   fts3NodeWrite()
**   fts3NodeFree()
**
** When a b+tree is written to the database (either as a result of a merge
** or the pending-terms table being flushed), leaves are written into the
** database file as soon as they are completely populated. The interior of
** the tree is assembled in memory and written out only once all leaves have
** been populated and stored. This is Ok, as the b+-tree fanout is usually
** very large, meaning that the interior of the tree consumes relatively
** little memory.
*//* Number of bytes of leaf data written *//* Pointer to block from malloc() *//* Bytes of data in aData *//* Size of allocation at aData *//* Next free slot in %_segments *//* First slot in %_segments written *//* Pointer to interior tree structure *//*
** An instance of this structure is used to create a segment b-tree in the
** database. The internal details of this type are only accessed by the
** following functions:
**
**   fts3SegWriterAdd()
**   fts3SegWriterFlush()
**   fts3SegWriterFree()
*//* For descending pending seg-readers only *//* The following variables are used by fts3SegReaderNextDocid() to iterate
  ** through the current doclist (aDoclist/nDoclist).
  *//* Size of doclist in current entry *//* Pointer to doclist of current entry *//* Allocated size of zTerm buffer *//* Pointer to current term *//* Number of bytes in current term *//* Variables set by fts3SegReaderNext(). These may be read directly
  ** by the caller. They are valid from the time SegmentReaderNew() returns
  ** until SegmentReaderNext() returns something other than SQLITE_OK
  ** (i.e. SQLITE_DONE).
  *//* If not NULL, blob handle to read node *//* If >0, bytes of buffer aNode[] loaded *//* Size of buffer at aNode (or 0) *//* Pointer to node data (or NULL) *//* Current leaf block (or 0) *//* Rowid of final block in segment (or 0) *//* Rowid of final leaf block to traverse *//* Rowid of first leaf block to traverse *//* True for a root-only reader *//* Index within level, or 0x7FFFFFFF for PT *//*
** An instance of this structure is used to iterate through the terms on
** a contiguous set of segment b-tree leaf nodes. Although the details of
** this structure are only manipulated by code in this file, opaque handles
** of type Fts3SegReader* are also used by code in fts3.c to iterate through
** terms when querying the full-text index. See functions:
**
**   sqlite3Fts3SegReaderNew()
**   sqlite3Fts3SegReaderFree()
**   sqlite3Fts3SegReaderIterate()
**
** Methods used to manipulate Fts3SegReader structures:
**
**   fts3SegReaderNext()
**   fts3SegReaderFirstDocid()
**   fts3SegReaderNextDocid()
*//* Doclist is assembled here *//* Next in list of deferred tokens *//* Column token must occur in *//* Pointer to corresponding expr token *//*
** Each cursor has a (possibly empty) linked list of the following objects.
*//*
** An instance of the following data structure is used to build doclists
** incrementally. See function fts3PendingListAppend() for details.
*//*
** If FTS_LOG_MERGES is defined, call sqlite3_log() to report each automatic
** and incremental merge operation that takes place. This is used for
** debugging FTS only, it should not usually be turned on in production
** systems.
*//*
** The values that may be meaningfully bound to the :1 parameter in
** statements SQL_REPLACE_STAT and SQL_SELECT_STAT.
*//*
** Under certain circumstances, b-tree nodes (doclists) can be loaded into
** memory incrementally instead of all at once. This can be a big performance
** win (reduced IO and CPU) if SQLite stops calling the virtual table xNext()
** method before retrieving all query results (as may happen, for example,
** if a query has a LIMIT clause).
**
** Incremental loading is used for b-tree nodes FTS3_NODE_CHUNK_THRESHOLD
** bytes and larger. Nodes are loaded in chunks of FTS3_NODE_CHUNKSIZE bytes.
** The code is written so that the hard lower-limit for each of these values
** is 1. Clearly such small values would be inefficient, but can be useful
** for testing purposes.
**
** If this module is built with SQLITE_TEST defined, these constants may
** be overridden at runtime for testing purposes. File fts3_test.c contains
** a Tcl interface to read and write the values.
*//*
** When full-text index nodes are loaded from disk, the buffer that they
** are loaded into has the following number of bytes of padding at the end
** of it. i.e. if a full-text index node is 900 bytes in size, then a buffer
** of 920 bytes is allocated for it.
**
** This means that if we have a pointer into a buffer containing node data,
** it is always safe to read up to two varints from it without risking an
** overread, even if the node data is corrupted.
*//*
** 2009 Oct 23
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file is part of the SQLite FTS3 extension module. Specifically,
** this file contains code to insert, update and delete rows from FTS3
** tables. It also contains code to merge FTS3 b-tree segments. Some
** of the sub-routines used to merge segments are also used by the query
** code in fts3.c.
*//************** Begin file fts3_write.c **************************************//************** End of fts3_tokenize_vtab.c **********************************//*
** Register the fts3tok module with database connection db. Return SQLITE_OK
** if successful or an error code if sqlite3_create_module() fails.
*//* OUT: Rowid value *//*
** xRowid - Return the current rowid for the cursor.
*//* CREATE TABLE x(input, token, start, end, position) *//*
** xColumn - Return a column value.
*//*
** xEof - Return true if the cursor is at EOF, or false otherwise.
*//*
** xFilter - Initialize a cursor to point at the start of its data.
*//*
** xNext - Advance the cursor to the next row, if any.
*//*
** xClose - Close a cursor.
*//*
** Reset the tokenizer cursor passed as the only argument. As if it had
** just been returned by fts3tokOpenMethod().
*//*
** xOpen - Open a cursor.
*//*
** xBestIndex - Analyze a WHERE and ORDER BY clause.
*//*
** This function does the work for both the xDisconnect and xDestroy methods.
** These tables have no persistent representation of their own, so xDisconnect
** and xDestroy are identical operations.
*//* Hash table of tokenizers *//*
** This function does all the work for both the xConnect and xCreate methods.
** These tables have no persistent representation of their own, so xConnect
** and xCreate are identical operations.
**
**   argv[0]: module name
**   argv[1]: database name
**   argv[2]: table name
**   argv[3]: first argument (tokenizer name)
*//*
** Schema of the tokenizer table.
*//* Input array *//* Number of elements in argv[] *//*
** The second argument, argv[], is an array of pointers to nul-terminated
** strings. This function makes a copy of the array and strings into a
** single block of memory. It then dequotes any of the strings that appear
** to be quoted.
**
** If successful, output parameter *pazDequote is set to point at the
** array of dequoted strings and SQLITE_OK is returned. The caller is
** responsible for eventually calling sqlite3_free() to free the array
** in this case. Or, if an error occurs, an SQLite error code is returned.
** The final value of *pazDequote is undefined in this case.
*//*
** Query FTS for the tokenizer implementation named zName.
*//* Current 'pos' value *//* Current 'end' value *//* Current 'start' value *//* Size of zToken in bytes *//* Current 'token' value *//* Current 'rowid' value *//* Cursor to iterate through zInput *//*
** Virtual table cursor structure.
*//*
** Virtual table structure.
*//*
** 2013 Apr 22
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This file contains code for the "fts3tokenize" virtual table module.
** An fts3tokenize virtual table is created as follows:
**
**   CREATE VIRTUAL TABLE <tbl> USING fts3tokenize(
**       <tokenizer-name>, <arg-1>, ...
**   );
**
** The table created has the following schema:
**
**   CREATE TABLE <tbl>(input, token, start, end, position)
**
** When queried, the query must include a WHERE clause of type:
**
**   input = <string>
**
** The virtual table module tokenizes this <string>, using the FTS3
** tokenizer specified by the arguments to the CREATE VIRTUAL TABLE
** statement and returns one row for each token in the result. With
** fields set as follows:
**
**   input:   Always set to a copy of <string>
**   token:   A token from the input.
**   start:   Byte offset of the token within the input <string>.
**   end:     Byte offset of the byte immediately following the end of the
**            token within the input string.
**   pos:     Token offset of token within input.
**
*//************** Begin file fts3_tokenize_vtab.c ******************************//************** End of fts3_tokenizer1.c *************************************//*
** Allocate a new simple tokenizer.  Return a pointer to the new
** tokenizer in *ppModule
*//* TODO(shess) This needs expansion to handle UTF-8
        ** case-insensitivity.
        *//* Count non-delimiter characters. *//* Scan past delimiter characters *//* no space allocated, yet. *//* start tokenizing at the beginning *//* String to be tokenized *//* Mark non-alphanumeric ASCII characters as delimiters *//* We explicitly don't support UTF-8 delimiters for now. *//* TODO(shess) Delimiters need to remain the same from run to run,
  ** else we need to reindex.  One solution would be a meta-table to
  ** track such information in the database, then we'd only want this
  ** information on the initial create.
  *//* space allocated to zToken buffer *//* index of next token to be returned *//* current position in pInput *//* size of the input *//* input we are tokenizing *//* flag ASCII delimiters *//*
** The code in this file is only compiled if:
**
**     * The FTS3 module is being built as an extension
**       (in which case SQLITE_CORE is not defined), or
**
**     * The FTS3 module is being built into the core of
**       SQLite (in which case SQLITE_ENABLE_FTS3 is defined).
*//*
** 2006 Oct 10
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** Implementation of the "simple" full-text-search tokenizer.
*//************** Begin file fts3_tokenizer1.c *********************************//************** End of fts3_tokenizer.c **************************************//*
** Set up SQL objects in database db used to access the contents of
** the hash table pointed to by argument pHash. The hash table must
** been initialized to use string keys, and to take a private copy
** of the key when a value is inserted. i.e. by a call similar to:
**
**    sqlite3Fts3HashInit(pHash, FTS3_HASH_STRING, 1);
**
** This function adds a scalar function (see header comment above
** fts3TokenizerFunc() in this file for details) and, if ENABLE_TABLE is
** defined at compilation time, a temporary virtual table (see header
** comment above struct HashTableVtab) to the database schema. Both
** provide read/write access to the contents of *pHash.
**
** The third argument to this function, zName, is used as the name
** of both the scalar and, if created, the virtual table.
*//* Test the storage function *//* Test the query function *//*
** Implementation of the scalar function fts3_tokenizer_internal_test().
** This function is used for testing only, it is not included in the
** build unless SQLITE_TEST is defined.
**
** The purpose of this is to test that the fts3_tokenizer() function
** can be used as designed by the C-code in the queryTokenizer and
** registerTokenizer() functions above. These two functions are repeated
** in the README.tokenizer file as an example, so it is important to
** test them.
**
** To run the tests, evaluate the fts3_tokenizer_internal_test() scalar
** function with no arguments. An assert() will fail if a problem is
** detected. i.e.:
**
**     SELECT fts3_tokenizer_internal_test();
**
*//*
** Implementation of a special SQL scalar function for testing tokenizers
** designed to be used in concert with the Tcl testing framework. This
** function must be called with two or more arguments:
**
**   SELECT <function-name>(<key-name>, ..., <input-string>);
**
** where <function-name> is the name passed as the second argument
** to the sqlite3Fts3InitHashTable() function (e.g. 'fts3_tokenizer')
** concatenated with the string '_test' (e.g. 'fts3_tokenizer_test').
**
** The return value is a string that may be interpreted as a Tcl
** list. For each token in the <input-string>, three elements are
** added to the returned list. The first is the token position, the
** second is the token text (folded, stemmed, etc.) and the third is the
** substring of <input-string> associated with the token. For example,
** using the built-in "simple" tokenizer:
**
**   SELECT fts_tokenizer_test('simple', 'I don't see how');
**
** will return the string:
**
**   "{0 i I 1 dont don't 2 see see 3 how how}"
**
*//* Pointer to nul-term of zCopy *//* OUT: Set to malloced error message *//* OUT: Tokenizer (if applicable) *//* Tokenizer name *//* Tokenizer hash table *//* No more tokens here *//* Find the start of the next token. *//* 7x *//* 6x *//* 5x *//* 4x *//* 3x *//* 2x *//* 1x *//* 0x *//*
** Implementation of the SQL scalar function for accessing the underlying
** hash table. This function may be called as follows:
**
**   SELECT <function-name>(<key-name>);
**   SELECT <function-name>(<key-name>, <pointer>);
**
** where <function-name> is the name passed as the second argument
** to the sqlite3Fts3InitHashTable() function (e.g. 'fts3_tokenizer').
**
** If the <pointer> argument is specified, it must be a blob value
** containing a pointer to be stored as the hash data corresponding
** to the string <key-name>. If <pointer> is not specified, then
** the string <key-name> must already exist in the has table. Otherwise,
** an error is returned.
**
** Whether or not the <pointer> argument is specified, the value returned
** is a blob containing the pointer stored as the hash data corresponding
** to string <key-name> (after the hash-table is updated, if applicable).
*//*
** Return true if the two-argument version of fts3_tokenizer()
** has been activated via a prior call to sqlite3_db_config(db,
** SQLITE_DBCONFIG_ENABLE_FTS3_TOKENIZER, 1, 0);
*//*
** 2007 June 22
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This is part of an SQLite module implementing full-text search.
** This particular file implements the generic tokenizer interface.
*//************** Begin file fts3_tokenizer.c **********************************//************** End of fts3_porter.c *****************************************//*
** Allocate a new porter tokenizer.  Return a pointer to the new
** tokenizer in *ppModule
*//*
** The set of routines that implement the porter-stemmer tokenizer
*//* OUT: *pzToken is the token text *//* Cursor returned by porterOpen *//*
** Extract the next token from a tokenization cursor.  The cursor must
** have been opened by a prior call to porterOpen().
*//* x0 x1 x2 x3 x4 x5 x6 x7 x8 x9 xA xB xC xD xE xF *//*
** Characters that can be part of a token.  We assume any character
** whose value is greater than 0x80 (any UTF character) can be
** part of a token.  In other words, delimiters all must have
** values of 0x7f or lower.
*//* z[] is now the stemmed word in reverse order.  Flip it back
  ** around into forward order and return.
  *//* Step 5b *//* Step 5a *//* Step 4 *//* Step 3 *//* Step 2 *//* Step 1c *//* Do nothing.  The work was all in the test *//* Step 1b *//* Step 1a *//* The use of a character not in [a-zA-Z] means that we fallback
      ** to the copy stemmer *//* The word is too big or too small for the porter stemmer.
    ** Fallback to the copy stemmer *//*
** Stem the input word zIn[0..nIn-1].  Store the output in zOut.
** zOut is at least big enough to hold nIn bytes.  Write the actual
** size of the output word (exclusive of the '\0' terminator) into *pnOut.
**
** Any upper-case characters in the US-ASCII character set ([A-Z])
** are converted to lower case.  Upper-case UTF characters are
** unchanged.
**
** Words that are longer than about 20 bytes are stemmed by retaining
** a few bytes from the beginning and the end of the word.  If the
** word contains digits, 3 bytes are taken from the beginning and
** 3 bytes from the end.  For long words without digits, 10 bytes
** are taken from each end.  US-ASCII case folding still applies.
**
** If the input word contains not digits but does characters not
** in [a-zA-Z] then no stemming is attempted and this routine just
** copies the input into the input into the output with US-ASCII
** case folding.
**
** Stemming never increases the length of the word.  So there is
** no chance of overflowing the zOut buffer.
*//*
** This is the fallback stemmer used when the porter stemmer is
** inappropriate.  The input word is copied into the output with
** US-ASCII case folding.  If the input word is too long (more
** than 20 bytes if it contains no digits or more than 6 bytes if
** it contains digits) then word is truncated to 20 or 6 bytes
** by taking 10 or 3 bytes from the beginning and end.
*//* Condition that must be true *//* ... change the ending to this (not reversed) *//* If the ending matches this... (Reversed) *//* The word being stemmed (Reversed) *//*
** If the word ends with zFrom and xCond() is true for the stem
** of the word that preceeds the zFrom ending, then change the
** ending to zTo.
**
** The input word *pz and zFrom are both in reverse order.  zTo
** is in normal order.
**
** Return TRUE if zFrom matches.  Return FALSE if zFrom does not
** match.  Not that TRUE is returned even if xCond() fails and
** no substitution occurs.
*//*
** Return TRUE if the word ends with three letters which
** are consonant-vowel-consonent and where the final consonant
** is not 'w', 'x', or 'y'.
**
** The word is reversed here.  So we are really checking the
** first three letters and the first one cannot be in [wxy].
*//*
** Return TRUE if the word ends in a double consonant.
**
** The text is reversed here. So we are really looking at
** the first two characters of z[].
*//*
** Return TRUE if there is a vowel anywhere within z[0..n-1]
*//* Like mgt0 above except we are looking for a value of m>1 instead
** or m>0
*//* Like mgt0 above except we are looking for a value of m which is
** exactly 1
*//*
** Let any sequence of one or more vowels be represented by V and let
** C be sequence of one or more consonants.  Then every word can be
** represented as:
**
**           [C] (VC){m} [V]
**
** In prose:  A word is an optional consonant followed by zero or
** vowel-consonant pairs followed by an optional vowel.  "m" is the
** number of vowel consonant pairs.  This routine computes the value
** of m for the first i bytes of a word.
**
** Return true if the m-value for z is 1 or more.  In other words,
** return true if z contains at least one vowel that is followed
** by a consonant.
**
** In this routine z[] is in reverse order.  So we are really looking
** for an instance of a consonant followed by a vowel.
*//*
** isConsonant() and isVowel() determine if their first character in
** the string they point to is a consonant or a vowel, according
** to Porter ruls.
**
** A consonate is any letter other than 'a', 'e', 'i', 'o', or 'u'.
** 'Y' is a consonant unless it follows another consonant,
** in which case it is a vowel.
**
** In these routine, the letters are in reverse order.  So the 'y' rule
** is that 'y' is a consonant unless it is followed by another
** consonent.
*//*
** Vowel or consonant
*//*
** Close a tokenization cursor previously opened by a call to
** porterOpen() above.
*//*
** Prepare to begin tokenizing a particular string.  The input
** string to be tokenized is zInput[0..nInput-1].  A cursor
** used to incrementally tokenize this string is returned in
** *ppCursor.
*//* current position in zInput *//*
** Class derived from sqlite3_tokenizer_cursor
*//* Base class *//*
** Class derived from sqlite3_tokenizer
*//*
** 2006 September 30
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** Implementation of the full-text-search tokenizer that implements
** a Porter stemmer.
*//************** Begin file fts3_porter.c *************************************//************** End of fts3_hash.c *******************************************//* The hash function *//* New element added to the pH *//* Used to loop thru the element list *//* the hash of the key modulo hash table size *//* Raw hash value of the key *//* The data *//* Number of bytes in the key *//* The key *//* The hash table to insert into *//* Insert an element into the hash table pH.  The key is pKey,nKey
** and the data is "data".
**
** If no element exists with a matching key, then a new
** element is created.  A copy of the key is made if the copyKey
** flag is set.  NULL is returned.
**
** If another element already exists with the same key, then the
** new data replaces the old data and the old data is returned.
** The key is not copied in this instance.  If a malloc fails, then
** the new data is returned and the hash table is unchanged.
**
** If the "data" parameter to this function is NULL, then the
** element corresponding to "key" is removed from the hash table.
*//* The element that matches key (if any) *//*
** Attempt to locate an element of the hash table pH with a key
** that matches pKey,nKey.  Return the data for this element if it is
** found, or NULL if there is no match.
*//* A hash on key *//* Hash value for the element *//* The element to be removed from the pH *//* The pH containing "elem" *//* Remove a single entry from the hash table given a pointer to that
** element and a hash on the element's key.
*//* comparison function *//* Number of elements left to test *//* The hash for this key. *//* The key we are searching for *//* The pH to be searched *//* This function (for internal use only) locates an element in an
** hash table that matches the given key.  The hash for this key has
** already been computed and is passed as the 4th parameter.
*//* For looping over existing elements *//* The new hash table *//* Resize the hash table so that it cantains "new_size" buckets.
** "new_size" must be a power of 2.  The hash table might fail
** to resize if sqliteMalloc() fails.
**
** Return non-zero if a memory allocation error occurs.
*//* First element already in pEntry *//* The element to be inserted *//* The entry into which pNew is inserted *//* The complete hash table *//* Link an element into the hash table
*//*
** Return a pointer to the appropriate hash function given the key class.
**
** For help in interpreted the obscure C code in the function definition,
** see the header comment on the previous function.
*//*
** Return a pointer to the appropriate hash function given the key class.
**
** The C syntax in this function definition may be unfamilar to some
** programmers, so we provide the following additional explanation:
**
** The name of the function is "ftsHashFunction".  The function takes a
** single parameter "keyClass".  The return value of ftsHashFunction()
** is a pointer to another function.  Specifically, the return value
** of ftsHashFunction() is a pointer to a function that takes two parameters
** with types "const void*" and "int" and returns an "int".
*//*
** Hash and comparison functions when the mode is FTS3_HASH_BINARY
*//*
** Hash and comparison functions when the mode is FTS3_HASH_STRING
*//* For looping over all elements of the table *//* Remove all entries from a hash table.  Reclaim all memory.
** Call this routine to delete a hash table or to reset a hash table
** to the empty state.
*//* Turn bulk memory into a hash table object by initializing the
** fields of the Hash structure.
**
** "pNew" is a pointer to the hash table that is to be initialized.
** keyClass is one of the constants
** FTS3_HASH_BINARY or FTS3_HASH_STRING.  The value of keyClass
** determines what kind of key the hash table will use.  "copyKey" is
** true if the hash table should make its own private copy of keys and
** false if it should just use the supplied pointer.
*//*
** Malloc and Free functions
*//* #include "fts3_hash.h" *//*
** 2001 September 22
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This is the implementation of generic hash-tables used in SQLite.
** We've modified it slightly to serve as a standalone hash table
** implementation for the full-text indexing module.
*//************** Begin file fts3_hash.c ***************************************//************** End of fts3_expr.c *******************************************//*
** Register the query expression parser test function fts3_exprtest()
** with database connection db.
*//*
** This is the implementation of a scalar SQL function used to test the
** expression parser. It should be called as follows:
**
**   fts3_exprtest(<tokenizer>, <expr>, <column 1>, ...);
**
** The first argument, <tokenizer>, is the name of the fts3 tokenizer used
** to parse the query expression (see README.tokenizers). The second argument
** is the query expression to parse. Each subsequent argument is the name
** of a column of the fts3 table that the query expression may refer to.
** For example:
**
**   SELECT fts3_exprtest('simple', 'Bill col2:Bloggs', 'col1', 'col2');
*//*
** Return a pointer to a buffer containing a text representation of the
** expression passed as the first argument. The buffer is obtained from
** sqlite3_malloc(). It is the responsibility of the caller to use
** sqlite3_free() to release the memory. If an OOM condition is encountered,
** NULL is returned.
**
** If the second argument is not NULL, then its contents are prepended to
** the returned expression text and then freed using sqlite3_free().
*//****************************************************************************
*****************************************************************************
** Everything after this point is just test code.
*//*
** Free a parsed fts3 query expression allocated by sqlite3Fts3ExprParse().
**
** This function would be simpler if it recursively called itself. But
** that would mean passing a sufficiently large expression to ExprParse()
** could cause a stack overflow.
*//*
** Free a single node of an expression tree.
*//* Rebalance the expression. And check that its depth does not exceed
  ** SQLITE_FTS3_MAX_EXPR_DEPTH.  *//* OUT: Parsed query structure *//* Text of MATCH query *//* Default column to query *//* Number of entries in azCol[] *//* True to allow FTS4-only syntax *//* Array of column names for fts3 table *//* Language id for tokenizer *//* Tokenizer module *//*
** Parameters z and n contain a pointer to and length of a buffer containing
** an fts3 query expression, respectively. This function attempts to parse the
** query expression and create a tree of Fts3Expr structures representing the
** parsed expression. If successful, *ppExpr is set to point to the head
** of the parsed expression tree and SQLITE_OK is returned. If an error
** occurs, either SQLITE_NOMEM (out-of-memory error) or SQLITE_ERROR (parse
** error) is returned and *ppExpr is set to 0.
**
** If parameter n is a negative number, then z is assumed to point to a
** nul-terminated string and the length is determined using strlen().
**
** The first parameter, pTokenizer, is passed the fts3 tokenizer module to
** use to normalize query tokens while parsing the expression. The azCol[]
** array, which is assumed to contain nCol entries, should contain the names
** of each column in the target fts3 table, in order from left to right.
** Column names must be nul-terminated strings.
**
** The iDefaultCol parameter should be passed the index of the table column
** that appears on the left-hand-side of the MATCH operator (the default
** column to match against for tokens for which a column name is not explicitly
** specified as part of the query string), or -1 if tokens may by default
** match any table column.
*//* Check for mismatched parenthesis *//*
** This function is similar to sqlite3Fts3ExprParse(), with the following
** differences:
**
**   1. It does not do expression rebalancing.
**   2. It does not check that the expression does not exceed the
**      maximum allowable depth.
**   3. Even if it fails, *ppExpr may still be set to point to an
**      expression tree. It should be deleted using sqlite3Fts3ExprFree()
**      in this case.
*//* An error occurred. Delete the contents of the apLeaf[] array
          ** and pFree list. Everything else is cleaned up by the call to
          ** sqlite3Fts3ExprFree(pRoot) below.  *//* Link pParent into the free node list. It will be used as an
          ** internal node of the new tree.  *//* Remove pParent from the original tree. *//* Set $p to point to the next leaf in the tree of eType nodes *//* If that was the last leaf node, break out of the loop *//* Current parent of p *//* This loop runs once for each leaf in the tree of eType nodes. *//* Set $p to point to the left-most leaf in the tree of eType nodes. *//* Type of node in this tree *//* List of free nodes. Linked by pParent. *//* Initial root node *//*
** This function attempts to transform the expression tree at (*pp) to
** an equivalent but more balanced form. The tree is modified in place.
** If successful, SQLITE_OK is returned and (*pp) set to point to the
** new root expression node.
**
** nMaxDepth is the maximum allowable depth of the balanced sub-tree.
**
** Otherwise, if an error occurs, an SQLite error code is returned and
** expression (*pp) freed.
*//*
** Return SQLITE_ERROR if the maximum depth of the expression tree passed
** as the only argument is more than nMaxDepth.
*//* This test catches attempts to make either operand of a NEAR
           ** operator something other than a phrase. For example, either of
           ** the following:
           **
           **    (bracketed expression) NEAR phrase
           **    phrase NEAR (bracketed expression)
           **
           ** Return an error in either case.
           *//* Insert an implicit AND operator. *//* The isRequirePhrase variable is set to true if a phrase or
          ** an expression contained in parenthesis is required. If a
          ** binary operator (AND, OR, NOT or NEAR) is encounted when
          ** isRequirePhrase is set, this is a syntax error.
          *//* Create an implicit NOT operator. *//* Only used in legacy parse mode *//* OUT: Number of bytes consumed *//* fts3 query parse context *//*
** Parse the fts3 query expression found in buffer z, length n. This function
** returns either when the end of the buffer is reached or an unmatched
** closing bracket - ')' - is encountered.
**
** If successful, SQLITE_OK is returned, *ppExpr is set to point to the
** parsed form of the expression and *pnConsumed is set to the number of
** bytes read from buffer z. Otherwise, *ppExpr is set to 0 and SQLITE_NOMEM
** (out of memory error) or SQLITE_ERROR (parse error) is returned.
*//* New binary node to insert into expression tree *//* Node most recently inserted into the tree *//* Pointer to the root node of a tree *//*
** Argument ppHead contains a pointer to the current head of a query
** expression tree being parsed. pPrev is the expression node most recently
** inserted into the tree. This function adds pNew, which is always a binary
** operator node, into the expression tree based on the relative precedence
** of pNew and the existing nodes of the tree. This may result in the head
** of the tree changing, in which case *ppHead is set to the new root node.
*//*
** The argument is an Fts3Expr structure for a binary operator (any type
** except an FTSQUERY_PHRASE). Return an integer value representing the
** precedence of the operator. Lower values have a higher precedence (i.e.
** group more tightly). For example, in the C language, the == operator
** groups more tightly than ||, and would therefore have a higher precedence.
**
** When using the new fts3 query syntax (when SQLITE_ENABLE_FTS3_PARENTHESIS
** is defined), the order of the operators in precedence from highest to
** lowest is:
**
**   NEAR
**   NOT
**   AND (including implicit ANDs)
**   OR
**
** Note that when using the old query syntax, the OR operator has a higher
** precedence than the AND operator.
*//* If control flows to this point, this must be a regular token, or
  ** the end of the input. Read a regular token using the sqlite3_tokenizer
  ** interface. Before doing so, figure out if there is an explicit
  ** column specifier for the token.
  **
  ** TODO: Strangely, it is not possible to associate a column specifier
  ** with a quoted phrase, only with a single token. Not sure if this was
  ** an implementation artifact or an intentional decision when fts3 was
  ** first implemented. Whichever it was, this module duplicates the
  ** limitation.
  *//* See if we are dealing with a quoted phrase. If this is the case, then
  ** search for the closing quote and pass the whole string to getNextString()
  ** for processing. This is easy to do, as fts3 has no syntax for escaping
  ** a quote character embedded in a string.
  *//* Turns out that wasn't a keyword after all. This happens if the
      ** user has supplied a token such as "ORacle". Continue.
      *//* At this point this is probably a keyword. But for that to be true,
      ** the next byte must contain either whitespace, an open or close
      ** parenthesis, a quote character, or EOF.
      *//* If this is a "NEAR" keyword, check for an explicit nearness. *//* See if we are dealing with a keyword. *//* Skip over any whitespace before checking for a keyword, an open or
  ** close bracket, or a quoted string.
  *//* Keyword code *//* Only valid in paren mode *//* Length of the keyword *//* Keyword text *//* OUT: expression *//*
** The output variable *ppExpr is populated with an allocated Fts3Expr
** structure, or set to 0 if the end of the input buffer is reached.
**
** Returns an SQLite error code. SQLITE_OK if everything works, SQLITE_NOMEM
** if a malloc failure occurs, or SQLITE_ERROR if a parse error is encountered.
** If SQLITE_ERROR is returned, pContext is populated with an error message.
*//* The final Fts3Expr data structure, including the Fts3Phrase,
  ** Fts3PhraseToken structures token buffers are all stored as a single
  ** allocation so that the expression can be freed with a single call to
  ** sqlite3_free(). Setting this up requires a two pass approach.
  **
  ** The first pass, in the block below, uses a tokenizer cursor to iterate
  ** through the tokens in the expression. This pass uses fts3ReallocOrFree()
  ** to assemble data in two dynamic buffers:
  **
  **   Buffer p: Points to the Fts3Expr structure, followed by the Fts3Phrase
  **             structure, followed by the array of Fts3PhraseToken
  **             structures. This pass only populates the Fts3PhraseToken array.
  **
  **   Buffer zTemp: Contains copies of all tokens.
  **
  ** The second pass, in the block that begins "if( rc==SQLITE_DONE )" below,
  ** appends buffer zTemp to buffer p, and fills in the Fts3Expr and Fts3Phrase
  ** structures.
  *//*
** Buffer zInput, length nInput, contains the contents of a quoted string
** that appeared as part of an fts3 query expression. Neither quote character
** is included in the buffer. This function attempts to tokenize the entire
** input buffer and create an Fts3Expr structure of type FTSQUERY_PHRASE
** containing the results.
**
** If successful, SQLITE_OK is returned and *ppExpr set to point at the
** allocated Fts3Expr structure. Otherwise, either SQLITE_NOMEM (out of memory
** error) or SQLITE_ERROR (tokenization error) is returned and *ppExpr set
** to 0.
*//*
** Enlarge a memory allocation.  If an out-of-memory allocation occurs,
** then free the old allocation.
*//* total space to allocate *//* Set variable i to the maximum number of bytes of input to tokenize. *//* Value for Fts3Phrase.iColumn *//*
** Extract the next token from buffer z (length n) using the tokenizer
** and other information (column names etc.) in pParse. Create an Fts3Expr
** structure of type FTSQUERY_PHRASE containing a phrase consisting of this
** single token and set *ppExpr to point to it. If the end of the buffer is
** reached before a token is found, set *ppExpr to zero. It is the
** responsibility of the caller to eventually deallocate the allocated
** Fts3Expr structure (if any) by passing it to sqlite3_free().
**
** Return SQLITE_OK if successful, or SQLITE_NOMEM if a memory allocation
** fails.
*//*
** Function getNextNode(), which is called by fts3ExprParse(), may itself
** call fts3ExprParse(). So this forward declaration is required.
*//*
** Allocate nByte bytes of memory using sqlite3_malloc(). If successful,
** zero the memory before returning a pointer to it. If unsuccessful,
** return NULL.
*//*
** This function is equivalent to the standard isspace() function.
**
** The standard isspace() can be awkward to use safely, because although it
** is defined to accept an argument of type int, its behavior when passed
** an integer that falls outside of the range of the unsigned char type
** is undefined (and sometimes, "undefined" means segfault). This wrapper
** is defined to accept an argument of type char, and always returns 0 for
** any values that fall outside of the range of the unsigned char type (i.e.
** negative values).
*//* Number of nested brackets *//* True if getNextNode() sees a unary - *//* Language id used with tokenizer *//*
** isNot:
**   This variable is used by function getNextNode(). When getNextNode() is
**   called, it sets ParseContext.isNot to true if the 'next node' is a
**   FTSQUERY_PHRASE with a unary "-" attached to it. i.e. "mysql" in the
**   FTS3 query "sqlite -mysql". Otherwise, ParseContext.isNot is set to
**   zero.
*//*
** Default span for NEAR operators.
*//*
** By default, this module parses the legacy syntax that has been
** traditionally used by fts3. Or, if SQLITE_ENABLE_FTS3_PARENTHESIS
** is defined, then it uses the new syntax. The differences between
** the new and the old syntaxes are:
**
**  a) The new syntax supports parenthesis. The old does not.
**
**  b) The new syntax supports the AND and NOT operators. The old does not.
**
**  c) The old syntax supports the "-" token qualifier. This is not
**     supported by the new syntax (it is replaced by the NOT operator).
**
**  d) When using the old syntax, the OR operator has a greater precedence
**     than an implicit AND. When using the new, both implicity and explicit
**     AND operators have a higher precedence than OR.
**
** If compiled with SQLITE_TEST defined, then this module exports the
** symbol "int sqlite3_fts3_enable_parentheses". Setting this variable
** to zero causes the module to use the old syntax. If it is set to
** non-zero the new syntax is activated. This is so both syntaxes can
** be tested using a single build of testfixture.
**
** The following describes the syntax supported by the fts3 MATCH
** operator in a similar format to that used by the lemon parser
** generator. This module does not use actually lemon, it uses a
** custom parser.
**
**   query ::= andexpr (OR andexpr)*.
**
**   andexpr ::= notexpr (AND? notexpr)*.
**
**   notexpr ::= nearexpr (NOT nearexpr|-TOKEN)*.
**   notexpr ::= LP query RP.
**
**   nearexpr ::= phrase (NEAR distance_opt nearexpr)*.
**
**   distance_opt ::= .
**   distance_opt ::= / INTEGER.
**
**   phrase ::= TOKEN.
**   phrase ::= COLUMN:TOKEN.
**   phrase ::= "TOKEN TOKEN TOKEN...".
*//*
** 2008 Nov 28
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This module contains code that implements a parser for fts3 query strings
** (the right-hand argument to the MATCH operator). Because the supported
** syntax is relatively simple, the whole tokenizer/parser system is
** hand-coded.
*//************** Begin file fts3_expr.c ***************************************//************** End of fts3_aux.c ********************************************//*
** Register the fts3aux module with database connection db. Return SQLITE_OK
** if successful or an error code if sqlite3_create_module() fails.
*//* languageid *//* occurrences *//* documents *//* col *//* term *//* If the user specified a negative value for the languageid, use zero
    ** instead. This works, as the "languageid=?" constraint will also
    ** be tested by the VDBE layer. The test will always be false (since
    ** this module will not return a row with a negative languageid), and
    ** so the overall query will return zero rows.  *//* In case this cursor is being reused, close and zero it. *//* Index of languageid=? value in apVal *//* Index of term<=? value in apVal *//* Index of term>=? value in apVal *//* Index of term=? value in apVal *//* Language id to query *//* State 3. The integer just read is a column number. *//* 2 or greater. A position. *//* 0x01. Next integer will be a column number. *//* 0x00. Next integer will be a docid. *//* fall through *//* State 1. In this state we are expecting either a 1, indicating
        ** that the following integer will be a column number, or the
        ** start of a position list for column 0.
        **
        ** The only difference between state 1 and state 2 is that if the
        ** integer encountered in state 1 is not 0 or 1, then we need to
        ** increment the column 0 "nDoc" count for this term.
        *//* State 0. In this state the integer just read was a docid. *//* Increment our pretend rowid value. *//* Pointer to cursor object to return *//* Search for equality and range constraints on the "term" column.
  ** And equality constraints on the hidden "languageid" column. *//* This vtab delivers always results in "ORDER BY term ASC" order. *//* Next free argvIndex value *//* Free any prepared statements held *//* The user should invoke this in one of two forms:
  **
  **     CREATE VIRTUAL TABLE xxx USING fts4aux(fts4-table);
  **     CREATE VIRTUAL TABLE xxx USING fts4aux(fts4-table-db, fts4-table);
  *//* Virtual table object to return *//* value returned by declare_vtab() *//* Bytes of space to allocate here *//* Result of strlen(zFts3) *//* Result of strlen(zDb) *//* Name of fts3 table *//* Name of database (e.g. "main") *//*
** This function does all the work for both the xConnect and xCreate methods.
** These tables have no persistent representation of their own, so xConnect
** and xCreate are identical operations.
*//*
** Schema of the terms table.
*//* 'occurrences' values for current csr row *//* 'documents' values for current csr row *//* Size of aStat[] array *//* Current value of 'col' column *//* True if cursor is at EOF *//* Byte-length of string zStop *//* Must be right after "base" *//*
** 2011 Jan 27
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
*//************** Begin file fts3_aux.c ****************************************//************** End of fts3.c ************************************************//*
** Initialize API pointer table, if required.
*//*
** Return SQLITE_CORRUPT_VTAB.
*//*
** Free all components of the Fts3Phrase structure that were allocated by
** the eval module. Specifically, this means to free:
**
**   * the contents of pPhrase->doclist, and
**   * any Fts3MultiSegReader objects held by phrase tokens.
*//* This is the descendent of an OR node. In this case we cannot use
    ** an incremental phrase. Load the entire doclist for the phrase
    ** into memory in this case.  *//* Check if this phrase descends from an OR expression node. If not,
    ** return NULL. Otherwise, the entry that corresponds to docid
    ** pCsr->iPrevId may lie earlier in the doclist buffer. Or, if the
    ** tree that the node is part of has been marked as EOF, but the node
    ** itself is not EOF, then it may point to an earlier entry. *//* Closest non-deferred ancestor of pNear *//* Most senior NEAR ancestor (or pExpr) *//* Used to iterate from pExpr to root *//* For DOCID_CMP macro *//* If this phrase is applies specifically to some column other than
  ** column iCol, return a NULL pointer.  *//* Column to return position list for *//* Phrase to return doclist for *//*
** The expression pExpr passed as the second argument to this function
** must be of type FTSQUERY_PHRASE.
**
** The returned value is either NULL or a pointer to a buffer containing
** a position-list indicating the occurrences of the phrase in column iCol
** of the current row.
**
** More specifically, the returned buffer contains 1 varint for each
** occurrence of the phrase in the column, stored using the normal (delta+2)
** compression and is terminated by either an 0x01 or 0x00 byte. For example,
** if the requested column contains "a b X c d X X" and the position-list
** for 'X' is requested, the buffer returned may contain:
**
**     0x04 0x05 0x03 0x01   or   0x04 0x05 0x03 0x00
**
** This function works regardless of whether or not the phrase is deferred,
** incremental, or neither.
*//* Array to write results into (see above) *//* Phrase expression *//* FTS cursor handle *//*
** This function is used by the matchinfo() module to query a phrase
** expression node for the following information:
**
**   1. The total number of occurrences of the phrase in each column of
**      the FTS table (considering all rows), and
**
**   2. For each column, the number of rows in the table for which the
**      column contains at least one instance of the phrase.
**
** If no error occurs, SQLITE_OK is returned and the values for each column
** written into the array aiOut as follows:
**
**   aiOut[iCol*3 + 1] = Number of occurrences
**   aiOut[iCol*3 + 2] = Number of rows containing at least one instance
**
** Caveats:
**
**   * If a phrase consists entirely of deferred tokens, then all output
**     values are set to the number of documents in the table. In other
**     words we assume that very common tokens occur exactly once in each
**     column of each row of the table.
**
**   * If a phrase contains some deferred tokens (and some non-deferred
**     tokens), count the potential occurrence identified by considering
**     the non-deferred tokens instead of actual phrase occurrences.
**
**   * If the phrase is part of a NEAR expression, then only phrase instances
**     that meet the NEAR constraint are included in the counts.
*//* Caution: pRoot may iterate through docids in ascending or descending
      ** order. For this reason, even though it seems more defensive, the
      ** do loop can not be written:
      **
      **   do {...} while( pRoot->iDocid<iDocid && rc==SQLITE_OK );
      *//* Advance to the next document *//* Ensure the %_content statement is reset. *//* Allocate space for the aMSI[] array of each FTSQUERY_PHRASE node *//* Find the root of the NEAR expression *//* Root of NEAR expression *//* FTSQUERY_PHRASE expression *//*
** Expression pExpr must be of type FTSQUERY_PHRASE.
**
** If it is not already allocated and populated, this function allocates and
** populates the Fts3Expr.aMI[] array for expression pExpr. If pExpr is part
** of a NEAR expression, then it also allocates and populates the same array
** for all other phrases that are part of the NEAR expression.
**
** SQLITE_OK is returned if the aMI[] array is successfully allocated and
** populated. Otherwise, if an error occurs, an SQLite error code is returned.
*//*
** This is an sqlite3Fts3ExprIterate() callback. If the Fts3Expr.aMI[] array
** has not yet been allocated, allocate and zero it. Otherwise, just zero
** it.
*//* aMI[iCol*3 + 1] = Number of occurrences
        ** aMI[iCol*3 + 2] = Number of rows containing at least one instance
        *//*
** After allocating the Fts3Expr.aMI[] array for each phrase in the
** expression rooted at pExpr, the cursor iterates through all rows matched
** by pExpr, calling this function for each row. This function increments
** the values in Fts3Expr.aMI[] according to the position-list currently
** found in Fts3Expr.pPhrase->doclist.pList for each of the phrase
** expression nodes.
*//*
** Expression node pExpr is an MSR phrase. This function restarts pExpr
** so that it is a regular phrase query, not an MSR. SQLITE_OK is returned
** if successful, or an SQLite error code otherwise.
*//*
** Restart interation for expression pExpr so that the next call to
** fts3EvalNext() visits the first row. Do not allow incremental
** loading or merging of phrase doclists for this iteration.
**
** If *pRc is other than SQLITE_OK when this function is called, it is
** a no-op. If an error occurs within this function, *pRc is set to an
** SQLite error code before returning.
*//* Check if the cursor is past the end of the docid range specified
  ** by Fts3Cursor.iMinDocid/iMaxDocid. If so, set the EOF flag.  *//*
** Advance to the next document that matches the FTS expression in
** Fts3Cursor.pExpr.
*//* Free the position-lists accumulated for each deferred token above. *//* If there are one or more deferred tokens, load the current row into
    ** memory and scan it to determine the position list for each deferred
    ** token. Then, see if this row is really a match, considering deferred
    ** tokens and NEAR operators (neither of which were taken into account
    ** earlier, by fts3EvalNextRow()).
    *//*
** This function is called as the second part of each xNext operation when
** iterating through the results of a full-text query. At this point the
** cursor points to a row that matches the query expression, with the
** following caveats:
**
**   * Up until this point, "NEAR" operators in the expression have been
**     treated as "AND".
**
**   * Deferred tokens have not yet been considered.
**
** If *pRc is not SQLITE_OK when this function is called, it immediately
** returns 0. Otherwise, it tests whether or not after considering NEAR
** operators and deferred tokens the current row is still a match for the
** expression. It returns 1 if both of the following are true:
**
**   1. *pRc is SQLITE_OK when this function returns, and
**
**   2. After scanning the current FTS table row for the deferred tokens,
**      it is determined that the row does *not* match the query.
**
** Or, if no error occurs and it seems the current row does match the FTS
** query, return 0.
*//* If the NEAR expression does not match any rows, zero the doclist for
        ** all phrases involved in the NEAR. This is because the snippet(),
        ** offsets() and matchinfo() functions are not supposed to recognize
        ** any instances of phrases that are part of unmatched NEAR queries.
        ** For example if this expression:
        **
        **    ... MATCH 'a OR (b NEAR c)'
        **
        ** is matched against a row containing:
        **
        **        'a b d e'
        **
        ** then any snippet() should ony highlight the "a" term, not the "b"
        ** (as "b" is part of a non-matching NEAR clause).
        *//* Expr to test. May or may not be root. *//*
** This function is a helper function for sqlite3Fts3EvalTestDeferred().
** Assuming no error occurs or has occurred, It returns non-zero if the
** expression passed as the second argument matches the row that pCsr
** currently points to, or zero if it does not.
**
** If *pRc is not SQLITE_OK when this function is called, it is a no-op.
** If an error occurs during execution of this function, *pRc is set to
** the appropriate SQLite error code. In this case the returned value is
** undefined.
*//* Allocate temporary working space. *//* Temp space for PoslistNearMerge() *//* Bytes of temp space *//* The following block runs if pExpr is the root of a NEAR query.
  ** For example, the query:
  **
  **         "w" NEAR "x" NEAR "y" NEAR "z"
  **
  ** which is represented in tree form as:
  **
  **                               |
  **                          +--NEAR--+      <-- root of NEAR query
  **                          |        |
  **                     +--NEAR--+   "z"
  **                     |        |
  **                +--NEAR--+   "y"
  **                |        |
  **               "w"      "x"
  **
  ** The right-hand child of a NEAR node is always a phrase. The
  ** left-hand child may be either a phrase or a NEAR node. There are
  ** no exceptions to this - it's the way the parser in fts3_expr.c works.
  *//*
** If *pRc is not SQLITE_OK, or if pExpr is not the root node of a NEAR
** cluster, then this function returns 1 immediately.
**
** Otherwise, it checks if the current row really does match the NEAR
** expression, using the data currently stored in the position lists
** (Fts3Expr->pPhrase.doclist.pList/nList) for each phrase in the expression.
**
** If the current row is a match, the position list associated with each
** phrase in the NEAR expression is edited in place to contain only those
** phrase instances sufficiently close to their peers to satisfy all NEAR
** constraints. In this case it returns 1. If the NEAR expression does not
** match the current row, 0 is returned. The position lists may or may not
** be edited if 0 is returned.
*//* Neither the RHS or LHS are deferred. *//* RHS is entirely deferred. So we assume it matches every row.
          ** Advance the LHS iterator to find the next row visited. *//* LHS is entirely deferred. So we assume it matches every row.
          ** Advance the RHS iterator to find the next row visited. *//* Used by DOCID_CMP() macro *//* Expr. to advance to next matching row *//* FTS Cursor handle *//*
** This function is a no-op if *pRc is other than SQLITE_OK when it is called.
** Otherwise, it advances the expression passed as the second argument to
** point to the next matching row in the database. Expressions iterate through
** matching rows in docid order. Ascending order if Fts3Cursor.bDesc is zero,
** or descending if it is non-zero.
**
** If an error occurs, *pRc is set to an SQLite error code. Otherwise, if
** successful, the following variables in pExpr are set:
**
**   Fts3Expr.bEof                (non-zero if EOF - there is no next row)
**   Fts3Expr.iDocid              (valid if bEof==0. The docid of the next row)
**
** If the expression is of type FTSQUERY_PHRASE, and the expression is not
** at EOF, then the following variables are populated with the position list
** for the phrase for the visited row:
**
**   FTs3Expr.pPhrase->doclist.nList        (length of pList in bytes)
**   FTs3Expr.pPhrase->doclist.pList        (pointer to position list)
**
** It says above that this function advances the expression to the next
** matching row. This is usually true, but there are the following exceptions:
**
**   1. Deferred tokens are not taken into account. If a phrase consists
**      entirely of deferred tokens, it is assumed to match every row in
**      the db. In this case the position-list is not populated at all.
**
**      Or, if a phrase contains one or more deferred tokens and one or
**      more non-deferred tokens, then the expression is advanced to the
**      next possible match, considering only non-deferred tokens. In other
**      words, if the phrase is "A B C", and "B" is deferred, the expression
**      is advanced to the next row that contains an instance of "A * C",
**      where "*" may match any single token. The position list in this case
**      is populated as for "A * C" before returning.
**
**   2. NEAR is treated as AND. If the expression is "x NEAR y", it is
**      advanced to point to the next row that matches "x AND y".
**
** See sqlite3Fts3EvalTestDeferred() for details on testing if a row is
** really a match, taking into account deferred tokens and NEAR operators.
*//* The phrase object to trim the doclist of *//* IN/OUT: Tokens in phrase of *paPoslist *//* IN/OUT: Position list *//* Temporary space to use *//* NEAR distance. As in "NEAR/nNear". *//*
** This function is called to edit the position list associated with
** the phrase object passed as the fifth argument according to a NEAR
** condition. For example:
**
**     abc NEAR/5 "def ghi"
**
** Parameter nNear is passed the NEAR distance of the expression (5 in
** the example above). When this function is called, *paPoslist points to
** the position list, and *pnToken is the number of phrase tokens in the
** phrase on the other side of the NEAR operator to pPhrase. For example,
** if pPhrase refers to the "def ghi" phrase, then *paPoslist points to
** the position list associated with phrase "abc".
**
** All positions in the pPhrase position list that are not sufficiently
** close to a position in the *paPoslist position list are removed. If this
** leaves 0 positions, zero is returned. Otherwise, non-zero.
**
** Before returning, *paPoslist is set to point to the position lsit
** associated with pPhrase. And *pnToken is set to the number of tokens in
** pPhrase.
*//*
** Invalidate the current position list for phrase pPhrase.
*//* Determine which, if any, tokens in the expression should be deferred. *//* Allocate a MultiSegReader for each token in the expression. *//*
** This function is called from within the xFilter method. It initializes
** the full-text query currently stored in pCsr->pExpr. To iterate through
** the results of a query, the caller does:
**
**    fts3EvalStart(pCsr);
**    while( 1 ){
**      fts3EvalNext(pCsr);
**      if( pCsr->bEof ) break;
**      ... return row pCsr->iPrevId to the caller ...
**    }
*//* Either this is the cheapest token in the entire query, or it is
        ** part of a multi-token phrase. Either way, the entire doclist will
        ** (eventually) be loaded into memory. It may as well be now. *//* Set nLoad4 to the value of (4^nOther) for the next iteration of the
      ** for-loop. Except, limit the value to 2^24 to prevent it from
      ** overflowing the 32-bit integer it is stored in. *//* The number of overflow pages to load for this (and therefore all
      ** subsequent) tokens is greater than the estimated number of pages
      ** that will be loaded if all subsequent tokens are deferred.
      *//* Set pTC to point to the cheapest remaining token. *//* Set to cheapest remaining token. *//* Used to iterate through aTC[] array. *//* Iterate through all tokens in this AND/NEAR cluster, in ascending order
  ** of the number of overflow pages that will be loaded by the pager layer
  ** to retrieve the entire doclist for the token from the full-text index.
  ** Load the doclists for tokens that are either:
  **
  **   a. The cheapest token in the entire query (i.e. the one visited by the
  **      first iteration of this loop), or
  **
  **   b. Part of a multi-token phrase.
  **
  ** After each token doclist is loaded, merge it with the others from the
  ** same phrase and count the number of documents that the merged doclist
  ** contains. Set variable "nMinEst" to the smallest number of documents in
  ** any phrase doclist for which 1 or more token doclists have been loaded.
  ** Let nOther be the number of other phrases for which it is certain that
  ** one or more tokens will not be deferred.
  **
  ** Then, for each token, defer it if loading the doclist would result in
  ** loading N or more overflow pages into memory, where N is computed as:
  **
  **    (nMinEst + 4^nOther - 1) / (4^nOther)
  *//* Obtain the average docsize (in pages). *//* Count the tokens in this AND/NEAR cluster. If none of the doclists
  ** associated with the tokens spill onto overflow pages, or if there is
  ** only 1 token, exit early. No tokens to defer in this case. *//* Tokens are never deferred for FTS tables created using the content=xxx
  ** option. The reason being that it is not guaranteed that the content
  ** table actually contains the same data as the index. To prevent this from
  ** causing any problems, the deferred token optimization is completely
  ** disabled for content=xxx tables. *//* (Phrases that will be loaded)^4. *//* The minimum count for any phrase so far. *//* Total number of tokens in cluster *//* Total overflow pages used by doclists *//* Iterator variable for various purposes *//* Number of pages per doc loaded *//* Number of entries in aTC[] *//* Array of expression tokens and costs *//* Consider tokens with this root node *//*
** This function is called to select the tokens (if any) that will be
** deferred. The array aTC[] has already been populated when this is
** called.
**
** This function is called once for each AND/NEAR cluster in the
** expression. Each invocation determines which tokens to defer within
** the cluster with root node pRoot. See comments above the definition
** of struct Fts3TokenAndCost for more details.
**
** If no error occurs, SQLITE_OK is returned and sqlite3Fts3DeferToken()
** called on each token to defer. Otherwise, an SQLite error code is
** returned.
*//* If %_stat.value set to X'' *//* The average document size, which is required to calculate the cost
    ** of each doclist, has not yet been determined. Read the required
    ** data from the %_stat table to calculate it.
    **
    ** Entry 0 of the %_stat table is a blob containing (nCol+1) FTS3
    ** varints, where nCol is the number of columns in the FTS3 table.
    ** The first varint is the number of documents currently stored in
    ** the table. The following nCol varints contain the total amount of
    ** data stored in all rows of each column of the table, from left
    ** to right.
    *//*
** Determine the average document (row) size in pages. If successful,
** write this value to *pnPage and return SQLITE_OK. Otherwise, return
** an SQLite error code.
**
** The average document size in pages is calculated by first calculating
** determining the average size in bytes, B. If B is less than the amount
** of data that will fit on a single leaf page of an intkey table in
** this database, then the average docsize is 1. Otherwise, it is 1 plus
** the number of overflow pages consumed by a record B bytes in size.
*//* Write new OR root to *(*ppOr)++ *//* Write new entries to *(*ppTC)++ *//* Expression to consider *//* Root of current AND/NEAR cluster *//*
** This function is used to populate an allocated Fts3TokenAndCost array.
**
** If *pRc is not SQLITE_OK when this function is called, it is a no-op.
** Otherwise, if an error occurs during execution, *pRc is set to an
** SQLite error code.
*//* The column the token must match *//* Number of overflow pages to load doclist *//* Root of NEAR/AND cluster *//* The token itself *//* Position of token in phrase *//* The phrase the token belongs to *//*
** An array of the following structures is assembled as part of the process
** of selecting tokens to defer before the query starts executing (as part
** of the xFilter() method). There is one element in the array for each
** token in the FTS expression.
**
** Tokens are divided into AND/NEAR clusters. All tokens in a cluster belong
** to phrases that are connected only by AND and NEAR operators (not OR or
** NOT). When determining tokens to defer, each AND/NEAR cluster is considered
** separately. The root of a tokens AND/NEAR cluster is stored in
** Fts3TokenAndCost.pRoot.
*//* Expression to initialize phrases in *//*
**
** If *pRc is not SQLITE_OK when this function is called, it is a no-op.
** Otherwise, fts3EvalPhraseStart() is called on all phrases within the
** expression. Also the Fts3Expr.bDeferred variable is set to true for any
** expressions for which all descendent tokens are deferred.
**
** If parameter bOptOk is zero, then it is guaranteed that the
** Fts3Phrase.doclist.aAll/nAll variables contain the entire doclist for
** each phrase in the expression (subject to deferred token processing).
** Or, if bOptOk is non-zero, then one or more tokens within the expression
** may be loaded incrementally, meaning doclist.aAll/nAll is not available.
**
** If an error occurs within this function, *pRc is set to an SQLite error
** code before returning.
*//* OUT: Set to 1 if EOF *//* Phrase object to advance to next docid *//*
** Attempt to move the phrase iterator to point to the next matching docid.
** If an error occurs, return an SQLite error code. Otherwise, return
** SQLITE_OK.
**
** If there is no "next" entry and no error occurs, then *pbEof is set to
** 1 before returning. Otherwise, if no error occurs and the iterator is
** successfully advanced, *pbEof is set to 0.
*//* Check if the current entries really are a phrase match *//* Keep advancing iterators until they all point to the same document *//* Advance the iterator for each token in the phrase once. *//* Used to iterate through tokens *//* Largest docid for all iterators *//* This is only called if it is guaranteed that the phrase has at least
  ** one incremental token. In which case the bIncr flag is set. *//*
** The phrase iterator passed as the second argument:
**
**   * features at least one token that uses an incremental doclist, and
**
**   * does not contain any deferred tokens.
**
** Advance it to the next matching documnent in the database and populate
** the Fts3Doclist.pList and nList fields.
**
** If there is no "next" entry and no error occurs, then *pbEof is set to
** 1 before returning. Otherwise, if no error occurs and the iterator is
** successfully advanced, *pbEof is set to 0.
**
** If an error occurs, return an SQLite error code. Otherwise, return
** SQLITE_OK.
*//* OUT: True if iterator is at EOF *//* OUT: Docid and doclist for new entry *//* Specific token to advance *//* Phrase to advance token of *//*
** Token pToken is an incrementally loaded token that is part of a
** multi-token phrase. Advance it to the next matching document in the
** database and populate output variable *p with the details of the new
** entry. Or, if the iterator has reached EOF, set *pbEof to true.
**
** If an error occurs, return an SQLite error code. Otherwise, return
** SQLITE_OK.
*//*
** Helper type used by fts3EvalIncrPhraseNext() and incrPhraseTokenNext().
*//* pIter now points just past the 0x00 that terminates the position-
    ** list for document pDL->iDocid. However, if this position-list was
    ** edited in place by fts3EvalNearTrim(), then pIter may not actually
    ** point to the start of the next docid value. The following line deals
    ** with this case by advancing pIter past the zero-padding added by
    ** fts3EvalNearTrim().  *//* We have already reached the end of this doclist. EOF. *//* 1 byte past end of aAll *//* Used to iterate through aAll *//*
** Advance the iterator pDL to the next entry in pDL->aAll/nAll. Set *pbEof
** to true if EOF is reached.
*//* OUT: End-of-file flag *//* IN/OUT: Docid pointer *//* IN/OUT: Iterator pointer *//* Length of aDoclist in bytes *//* Pointer to entire doclist *//* True if the doclist is desc *//*
** Iterate forwards through a doclist.
*//* OUT: List length pointer *//*
** This function is used to iterate backwards (from the end to start)
** through doclists. It is used by this module to iterate through phrase
** doclists in reverse and by the fts3_write.c module to iterate through
** pending-terms lists when writing to databases with "order=desc".
**
** The doclist may be sorted in ascending (parameter bDescIdx==0) or
** descending (parameter bDescIdx==1) order of docid. Regardless, this
** function iterates from the end of the doclist to the beginning.
*//* Load the full doclist for the phrase into memory. *//* Use the incremental approach. *//* Determine if doclists may be loaded from disk incrementally. This is
  ** possible if the bOptOk argument is true, the FTS doclists will be
  ** scanned in forward order, and the phrase consists of
  ** MAX_INCR_PHRASE_TOKENS or fewer tokens, none of which are are "^first"
  ** tokens or prefix tokens that cannot use a prefix-index.  *//*
** This function is called for each Fts3Phrase in a full-text query
** expression to initialize the mechanism for returning rows. Once this
** function has been called successfully on an Fts3Phrase, it may be
** used with fts3EvalPhraseNext() to iterate through the matching docids.
**
** If parameter bOptOk is true, then the phrase may (or may not) use the
** incremental loading strategy. Otherwise, the entire doclist is loaded into
** memory within this call.
**
** SQLITE_OK is returned if no error occurs, otherwise an SQLite error code.
*//*
** Maximum number of tokens a phrase may have to be considered for the
** incremental doclists strategy.
*//* SQLITE_DISABLE_FTS4_DEFERRED *//* Token number of previous deferred token *//* Number of bytes in aPoslist *//* Position list for deferred tokens *//* Used to iterate through phrase tokens *//*
** This function is called on each phrase after the position lists for
** any deferred tokens have been loaded into memory. It updates the phrases
** current position list to include only those positions that are really
** instances of the phrase (after considering deferred tokens). If this
** means that the phrase does not appear in the current row, doclist.pList
** and doclist.nList are both zeroed.
**
** SQLITE_OK is returned if no error occurs, otherwise an SQLite error code.
*//* Phrase object *//*
** Load the doclist for phrase p into p->doclist.aAll/nAll. The loaded doclist
** does not take deferred tokens into account.
**
** SQLITE_OK is returned if no error occurs, otherwise an SQLite error code.
*//* Number of bytes in pList *//* Token pList/nList corresponds to *//* Phrase to merge pList/nList into *//* FTS Table pointer *//*
** Arguments pList/nList contain the doclist for token iToken of phrase p.
** It is merged into the main doclist stored in p->doclist.aAll/nAll.
**
** This function assumes that pList points to a buffer allocated using
** sqlite3_malloc(). This function takes responsibility for eventually
** freeing the buffer.
**
** SQLITE_OK is returned if successful, or SQLITE_NOMEM if an error occurs.
*//* OUT: Total number of OR nodes in expr. *//* OUT: Total number of tokens in phrase. *//* Allocate readers for this expression *//*
** Allocate an Fts3MultiSegReader for each token in the expression headed
** by pExpr.
**
** An Fts3SegReader object is a cursor that can seek or scan a range of
** entries within a single segment b-tree. An Fts3MultiSegReader uses multiple
** Fts3SegReader objects internally to provide an interface to seek or scan
** within the union of all segments of a b-tree. Hence the name.
**
** If the allocated Fts3MultiSegReader just seeks to a single entry in a
** segment b-tree (if the term is not a prefix or it is a prefix for which
** there exists prefix b-tree of the right length) then it may be traversed
** and merged incrementally. Otherwise, it has to be merged into an in-memory
** doclist and then traversed.
*//* An error has occurred. Delete the hash table and return the error code. *//* Create the virtual table wrapper around the hash-table and overload
  ** the four scalar functions. If this is successful, register the
  ** module with sqlite.
  *//* Load the built-in tokenizers into the hash table *//* Allocate and initialize the hash-table used to store tokenizers. *//*
** Initialize the fts3 extension. If this extension is built as part
** of the sqlite library, then this function is called directly by
** SQLite. If fts3 is built as a dynamically loadable extension, this
** function is called by the sqlite3_extension_init() entry point.
*//*
** The fts3 built-in tokenizers - "simple", "porter" and "icu"- are
** implemented in files fts3_tokenizer1.c, fts3_porter.c and fts3_icu.c
** respectively. The following three forward declarations are for functions
** declared in these files used to retrieve the respective implementations.
**
** Calling sqlite3Fts3SimpleTokenizerModule() sets the value pointed
** to by the argument to point to the "simple" tokenizer implementation.
** And so on.
*//*
** This function is registered as the module destructor (called when an
** FTS3 enabled database connection is closed). It frees the memory
** allocated for the tokenizer hash table.
*//* True if this is a quick_check *//* Name of the pVTab table *//* Name of schema in which pVtab lives *//* The virtual table to be checked *//*
** Implementation of the xIntegrity() method on the FTS3/FTS4 virtual
** table.
*//* As it happens, the pending terms table is always empty here. This is
  ** because an "ALTER TABLE RENAME TABLE" statement inside a transaction
  ** always opens a savepoint transaction. And the xSavepoint() method
  ** flushes the pending terms table. But leave the (no-op) call to
  ** PendingTermsFlush() in in case that changes.
  *//*
** Implementation of FTS3 xRename method. Rename an fts3 table.
*//* Cursor handle passed through apVal[0] *//*
** Implementation of the matchinfo() function for FTS3
*//*
** Implementation of the special optimize() function for FTS3. This
** function merges all segments in the database to a single segment.
** Example usage is:
**
**   SELECT optimize(t) FROM t LIMIT 1;
**
** where 't' is the name of an FTS3 table.
*//*
** Implementation of the offsets() function for FTS3
*//* There must be at least one argument passed to this function (otherwise
  ** the non-overloaded version would have been called instead of this one).
  *//* Default number of tokens in snippet *//* Size of apVal[] array *//*
** Implementation of the snippet() function for FTS3
*//* OUT: Store cursor handle here *//* argv[0] passed to function *//* SQL function call context *//*
** Helper function used by the implementation of the overloaded snippet(),
** offsets() and optimize() SQL functions.
**
** If the value passed as the third argument is a blob of size
** sizeof(Fts3Cursor*), then the blob contents are copied to the
** output variable *ppCsr and SQLITE_OK is returned. Otherwise, an error
** message is written to context pContext and SQLITE_ERROR returned. The
** string passed via zFunc is used as part of the error message.
*//* At this point p points to that preceding byte without the 0x80 bit
  ** set. So to find the start of the poslist, skip forward 2 bytes then
  ** over a varint.
  **
  ** Normally. The other case is that p==pStart and the poslist to return
  ** is the first in the doclist. In this case do not skip forward 2 bytes.
  ** The second part of the if condition (c==0 && *ppPoslist>&p[2])
  ** is required for cases where the first byte of a doclist and the
  ** doclist is empty. For example, if the first docid is 10, a doclist
  ** that begins with:
  **
  **   0x0A 0x00 <next docid delta varint>
  *//* Search backwards for a varint with value zero (the end of the previous
  ** poslist). This is an 0x00 byte preceded by some byte that does not
  ** have the 0x80 bit set.  *//* Skip backwards passed any trailing 0x00 bytes added by NearTrim() *//*
** When called, *ppPoslist must point to the byte immediately following the
** end of a position-list. i.e. ( (*ppPoslist)[-1]==POS_END ). This function
** moves *ppPoslist so that it instead points to the first byte of the
** same position list.
*//*
** Implementation of xCommit() method. This is a no-op. The contents of
** the pending-terms hash-table have already been flushed into the database
** by fts3SyncMethod().
*//*
** If it is currently unknown whether or not the FTS table has an %_stat
** table (if p->bHasStat==2), attempt to determine this (set p->bHasStat
** to 0 or 1). Return SQLITE_OK if successful, or an SQLite error code
** if an error occurs.
*//* Incr-merge parameter A *//* Maximum relative level value in db *//* Minimum amount of incr-merge work to do *//* Following an incremental-merge operation, assuming that the input
  ** segments are not completely consumed (the usual case), they are updated
  ** in place to remove the entries that have already been merged. This
  ** involves updating the leaf block that contains the smallest unmerged
  ** entry and each block (if any) between the leaf and the root node. So
  ** if the height of the input segment b-trees is N, and input segments
  ** are merged eight at a time, updating the input segments at the end
  ** of an incremental-merge requires writing (8*(1+N)) blocks. N is usually
  ** small - often between 0 and 2. So the overhead of the incremental
  ** merge is somewhere between 8 and 24 blocks. To avoid this overhead
  ** dwarfing the actual productive work accomplished, the incremental merge
  ** is only attempted if it will write at least 64 leaf blocks. Hence
  ** nMinMerge.
  **
  ** Of course, updating the input segments also involves deleting a bunch
  ** of blocks from the segments table. But this is not considered overhead
  ** as it would also be required by a crisis-merge that used the same input
  ** segments.
  *//*
** Implementation of xSync() method. Flush the contents of the pending-terms
** hash-table to the database.
*//*
** This function is the implementation of the xUpdate callback used by
** FTS3 virtual tables. It is invoked by SQLite each time a row is to be
** inserted, updated or deleted.
*//* A user column. Or, if this is a full-table scan, possibly the
      ** language-id column. Seek the cursor. *//* The docid column *//* The special 'table-name' column *//* The column value supplied by SQLite must be in range. *//*
** This is the xColumn method, called by SQLite to request a value from
** the row that the supplied cursor currently points to.
**
** If:
**
**   (iCol <  p->nColumn)   -> The value of the iCol'th user column.
**   (iCol == p->nColumn)   -> Magic column with the same name as the table.
**   (iCol == p->nColumn+1) -> Docid column
**   (iCol == p->nColumn+2) -> Langid column
*//*
** This is the xRowid method. The SQLite core calls this routine to
** retrieve the rowid for the current row of the result set. fts3
** exposes %_content.docid as the rowid for the virtual table. The
** rowid should be written to *pRowid.
*//* Compile a SELECT statement for this cursor. For a full-table-scan, the
  ** statement loops through all rows of the %_content table. For a
  ** full-text query or docid lookup, the statement retrieves a single
  ** row by docid.
  *//* Set the lower and upper bounds on docids to return *//* In case the cursor has been used before, clear it now. *//* Collect arguments into local variables *//* The "docid <= ?" constraint, if any *//* The "docid >= ?" constraint, if any *//* The "langid = ?" constraint, if any *//* The MATCH or rowid constraint, if any *//* SQL statement used to access %_content *//*
** This is the xFilter interface for the virtual table.  See
** the virtual table xFilter method documentation for additional
** information.
**
** If idxNum==FTS3_FULLSCAN_SEARCH then do a full table scan against
** the %_content table.
**
** If idxNum==FTS3_DOCID_SEARCH then do a docid lookup for a single entry
** in the %_content table.
**
** If idxNum>=FTS3_FULLTEXT_SEARCH then use the full text index.  The
** column on the left-hand side of the MATCH operator is column
** number idxNum-FTS3_FULLTEXT_SEARCH, 0 indexed.  argv[0] is the right-hand
** side of the MATCH operator.
*//*
** If the numeric type of argument pVal is "integer", then return it
** converted to a 64-bit signed integer. Otherwise, return a copy of
** the second parameter, iDefault.
*//*
** Advance the cursor to the next row in the %_content table that
** matches the search criteria.  For a MATCH search, this will be
** the next row that matches. For a full-table scan, this will be
** simply the next row in the %_content table.  For a docid lookup,
** this routine simply sets the EOF flag.
**
** Return SQLITE_OK if nothing goes wrong.  SQLITE_OK is returned
** even if we reach end-of-file.  The fts3EofMethod() will be called
** subsequently to determine whether or not an EOF was hit.
*//* Skip over position list *//* Skip docid varint *//* Cursor *//* Pointer to one byte after EOF *//*
** This function counts the total number of docids in the doclist stored
** in buffer aList[], size nList bytes.
**
** If the isPoslist argument is true, then it is assumed that the doclist
** contains a position-list following each docid. Otherwise, it is assumed
** that the doclist is simply a list of docids stored as delta encoded
** varints.
*//* Segment term filter configuration *//* Object for pair-wise doclist merging *//* Seg-reader cursor for this term *//* OUT: Malloced result buffer *//* OUT: Size of buffer at *ppOut *//* Column to query (or -ve for all columns) *//* Token to query for *//*
** This function retrieves the doclist for the specified term (or term
** prefix) from the database.
*//*
** Free an Fts3MultiSegReader allocated by fts3TermSegReaderCursor().
*//* True once an index has been found *//* Object to allocate and return *//* OUT: Allocated seg-reader cursor *//* True for a prefix search *//* Term to query for *//* Virtual table cursor handle *//*
** Open an Fts3MultiSegReader to scan the doclist for term zTerm/nTerm. Or,
** if isPrefix is true, to scan the doclist for all terms for which
** zTerm/nTerm is a prefix. If successful, return SQLITE_OK and write
** a pointer to the new Fts3MultiSegReader to *ppSegcsr. Otherwise, return
** an SQLite error code.
**
** It is the responsibility of the caller to free this object by eventually
** passing it to fts3SegReaderCursorFree()
**
** SQLITE_OK is returned if no error occurs, otherwise an SQLite error code.
** Output parameter *ppSegcsr is set to 0 if an error occurs.
*//* Fts3MultiSegReader to modify *//* Term to scan doclist of *//* FTS virtual table handle *//*
** In addition to its current configuration, have the Fts3MultiSegReader
** passed as the 4th argument also scan the doclist for term zTerm/nTerm.
**
** SQLITE_OK is returned if no error occurs, otherwise an SQLite error code.
*//* True to scan from zTerm to EOF *//* Level of segments to scan *//* Index to search (from 0 to p->nIndex-1) *//* Language-id to search *//*
** Set up a cursor object for iterating through a full-text index or a
** single level therein.
*//* If zTerm is not NULL, and this segment is not stored entirely on its
      ** root node, the range of leaves scanned can be reduced. Do this. *//* Read the values returned by the SELECT into local variables. *//* If iLevel is less than 0 and this is not a scan, include a seg-reader
  ** for the pending-terms. If this is a scan, then this call must be being
  ** made by an fts4aux module, not an FTS table. In this case calling
  ** Fts3SegReaderPending might segfault, as the data structures used by
  ** fts4aux are not completely populated. So it's easiest to filter these
  ** calls out here.  *//* Result of sqlite3_reset() *//* Statement to iterate through segments *//*
** Add seg-reader objects to the Fts3MultiSegReader object passed as the
** 8th argument.
**
** This function returns SQLITE_OK if successful, or an SQLite error code
** otherwise.
*//*
** Append SegReader object pNew to the end of the pCsr->apSegment[] array.
*//* If this is the first term selected, copy the doclist to the output
    ** buffer using memcpy().
    **
    ** Add FTS3_VARINT_MAX bytes of unused space to the end of the
    ** allocation. This is so as to ensure that the buffer is big enough
    ** to hold the current doclist AND'd with any other doclist. If the
    ** doclists are stored in order=ASC order, this padding would not be
    ** required (since the size of [doclistA AND doclistB] is always less
    ** than or equal to the size of [doclistA] in that case). But this is
    ** not true for order=DESC. For example, a doclist containing (1, -1)
    ** may be smaller than (-1), as in the first example the -1 may be stored
    ** as a single-byte delta, whereas in the second it must be stored as a
    ** FTS3_VARINT_MAX byte varint.
    **
    ** Similar padding is added in the fts3DoclistOrMerge() function.
    *//* TermSelect object to merge into *//*
** Merge the doclist aDoclist/nDoclist into the TermSelect object passed
** as the first argument. The merge is an "OR" merge (see function
** fts3DoclistOrMerge() for details).
**
** This function is called with the doclist for each term that matches
** a queried prefix. It merges all these doclists into one, the doclist
** for the specified prefix. Since there can be a very large number of
** doclists to merge, the merging is done pair-wise using the TermSelect
** object.
**
** This function returns SQLITE_OK if the merge is successful, or an
** SQLite error code (SQLITE_NOMEM) if an error occurs.
*//* Loop through the doclists in the aaOutput[] array. Merge them all
  ** into a single doclist.
  *//*
** Merge all doclists in the TermSelect.aaOutput[] array into a single
** doclist stored in TermSelect.aaOutput[0]. If successful, delete all
** other doclists (except the aaOutput[0] one) and return SQLITE_OK.
**
** If an OOM error occurs, return SQLITE_NOMEM. In this case it is
** the responsibility of the caller to free any doclists left in the
** TermSelect.aaOutput[] array.
*//* True once iDelta has been written *//* Size of pList in bytes *//* Position list (no 0x00 term) *//* Varint that may be written to pOut *//*
** Argument pList points to a position list nList bytes in size. This
** function checks to see if the position list contains any entries for
** a token in position 0 (of any column). If so, it writes argument iDelta
** to the output buffer pOut, followed by a position list consisting only
** of the entries from pList at position 0, and terminated by an 0x00 byte.
** The value returned is the number of bytes written to pOut (if any).
*//* IN/OUT: Right/output doclist *//* Left doclist *//* Distance from left to right (1=adjacent) *//* True if arguments are desc *//*
** This function does a "phrase" merge of two doclists. In a phrase merge,
** the output contains a copy of each position from the right-hand input
** doclist for which there is a position in the left-hand input doclist
** exactly nDist tokens before it.
**
** If the docids in the input doclists are sorted in ascending order,
** parameter bDescDoclist should be false. If they are sorted in ascending
** order, it should be passed a non-zero value.
**
** The right-hand input doclist is overwritten by this function.
*//* Allocate space for the output. Both the input and output doclists
  ** are delta encoded. If they are in ascending order (bDescDoclist==0),
  ** then the first docid in each list is simply encoded as a varint. For
  ** each subsequent docid, the varint stored is the difference between the
  ** current and previous docid (a positive number - since the list is in
  ** ascending order).
  **
  ** The first docid written to the output is therefore encoded using the
  ** same number of bytes as it is in whichever of the input lists it is
  ** read from. And each subsequent docid read from the same input list
  ** consumes either the same or less bytes as it did in the input (since
  ** the difference between it and the previous value in the output must
  ** be a positive value less than or equal to the delta value read from
  ** the input list). The same argument applies to all but the first docid
  ** read from the 'other' list. And to the contents of all position lists
  ** that will be copied and merged from the input to the output.
  **
  ** However, if the first docid copied to the output is a negative number,
  ** then the encoding of the first docid from the 'other' input list may
  ** be larger in the output than it was in the input (since the delta value
  ** may be a larger positive integer than the actual docid).
  **
  ** The space required to store the output is therefore the sum of the
  ** sizes of the two inputs, plus enough space for exactly one of the input
  ** docids to grow.
  **
  ** A symetric argument may be made if the doclists are in descending
  ** order.
  *//* OUT: Malloc'd doclist *//* Second doclist *//* First doclist *//*
** This function does an "OR" merge of two doclists (output contains all
** positions contained in either argument doclist). If the docids in the
** input doclists are sorted in ascending order, parameter bDescDoclist
** should be false. If they are sorted in ascending order, it should be
** passed a non-zero value.
**
** If no error occurs, *paOut is set to point at an sqlite3_malloc'd buffer
** containing the output doclist and SQLITE_OK is returned. In this case
** *pnOut is set to the number of bytes in the output doclist.
**
** If an error occurs, an SQLite error code is returned. The output values
** are undefined in this case.
*//* #define DOCID_CMP(i1, i2) ((bDescDoclist?-1:1) * (i64)((u64)i1-i2)) *//*
** This macro is used by various functions that merge doclists. The two
** arguments are 64-bit docid values. If the value of the stack variable
** bDescDoclist is 0 when this macro is invoked, then it returns (i1-i2).
** Otherwise, (i2-i1).
**
** Using this makes it easier to write code that can merge doclists that are
** sorted in either ascending or descending order.
*//* Write this value to the list *//* IN/OUT: True after first int written *//* IN/OUT: Previous value written to list *//* True for descending docids *//* IN/OUT: Output pointer *//*
** This function is used to write a single varint to a buffer. The varint
** is written to *pp. Before returning, *pp is set to point 1 byte past the
** end of the value written.
**
** If *pbFirst is zero when this function is called, the value written to
** the buffer is that of parameter iVal.
**
** If *pbFirst is non-zero when this function is called, then the value
** written is either (iVal-*piPrev) (if bDescIdx is zero) or (*piPrev-iVal)
** (if bDescIdx is non-zero).
**
** Before returning, this function always sets *pbFirst to 1 and *piPrev
** to the value of parameter iVal.
*//* IN/OUT: Integer value *//* True if docids are descending *//* End of buffer *//* IN/OUT: Point to read varint from *//*
** This function is used to read a single varint from a buffer. Parameter
** pEnd points 1 byte past the end of the buffer. When this function is
** called, if *pp points to pEnd or greater, then the end of the buffer
** has been reached. In this case *pp is set to 0 and the function returns.
**
** If *pp does not point to or past pEnd, then a single varint is read
** from *pp. *pp is then set to point 1 byte past the end of the read varint.
**
** If bDescIdx is false, the value read is added to *pVal before returning.
** If it is true, the value read is subtracted from *pVal before this
** function returns.
*//* Size each output buffer in bytes *//* Malloc'd output buffers *//*
** An instance of this function is used to merge together the (potentially
** large number of) doclists for each term that matches a prefix query.
** See function fts3TermSelectMerge() for details.
*//* IN/OUT: Right input list *//* IN/OUT: Left input list *//* Maximum difference in token positions *//* Temporary buffer space *//*
** Merge two position-lists as required by the NEAR operator. The argument
** position lists correspond to the left and right phrases of an expression
** like:
**
**     "phrase 1" NEAR "phrase number 2"
**
** Position list *pp1 corresponds to the left-hand side of the NEAR
** expression and *pp2 to the right. As usual, the indexes in the position
** lists are the offsets of the last token in each phrase (tokens "1" and "2"
** in the example above).
**
** The output position list - written to *pp - is a copy of *pp2 with those
** entries that are not sufficiently NEAR entries in *pp1 removed.
*//* Advance pointer p1 or p2 (whichever corresponds to the smaller of
    ** iCol1 and iCol2) so that it points to either the 0x00 that marks the
    ** end of the position list, or the 0x01 that precedes the next
    ** column-number in the position list.
    *//* As above, iCol2==0 indicates corruption. *//* iCol1==0 indicates corruption. Column 0 does not have a POS_COLUMN
    ** entry, so this is actually end-of-doclist. *//* Never set both isSaveLeft and isExact for the same invocation. *//* If *pp1 is exactly nTokens before *pp2 *//* Save the left position *//* IN/OUT: Preallocated output buffer *//*
** This function is used to merge two position lists into one. When it is
** called, *pp1 and *pp2 must both point to position lists. A position-list is
** the part of a doclist that follows each document id. For example, if a row
** contains:
**
**     'a b c'|'x y z'|'a b b a'
**
** Then the position list for this row for token 'b' would consist of:
**
**     0x02 0x01 0x02 0x03 0x03 0x00
**
** When this function returns, both *pp1 and *pp2 are left pointing to the
** byte following the 0x00 terminator of their respective position lists.
**
** If isSaveLeft is 0, an entry is added to the output position list for
** each position in *pp2 for which there exists one or more positions in
** *pp1 so that (pos(*pp2)>pos(*pp1) && pos(*pp2)-pos(*pp1)<=nToken). i.e.
** when the *pp1 token appears before the *pp2 token, but not more than nToken
** slots before it.
**
** e.g. nToken==1 searches for adjacent positions.
*//* At this point, both p1 and p2 point to the start of column-lists
      ** for the same column (the column with index iCol1 and iCol2).
      ** A column-list is a list of non-negative delta-encoded varints, each
      ** incremented by 2 before being stored. Each list is terminated by a
      ** POS_END (0) or POS_COLUMN (1). The following block merges the two lists
      ** and writes the results to buffer p. p is left pointing to the byte
      ** after the list written. No terminator (POS_END or POS_COLUMN) is
      ** written to the output.
      *//* Last position from pp2 *//* Last position from pp1 *//* The current column index in pp2 *//* The current column index in pp1 *//* Right input list *//* Left input list *//*
** Compute the union of two position lists.  The output written
** into *pp contains all positions of both *pp1 and *pp2 in sorted
** order and with any duplicates removed.  All pointers are
** updated appropriately.   The caller is responsible for insuring
** that there is enough space in *pp to hold the complete output.
*//* Output pointer *//* Number of bytes written *//*
** If parameter iCol is not 0, write an POS_COLUMN (1) byte followed by
** the value of iCol encoded as a varint to *pp.   This will start a new
** column list.
**
** Set *pp to point to the byte just after the last byte written before
** returning (do not modify it if iCol==0). Return the total number of bytes
** written (0 if iCol==0).
*//* IN/OUT: Value read from position-list *//* IN/OUT: Pointer into position-list buffer *//*
** This function is used to help parse position-lists. When this function is
** called, *pp may point to the start of the next varint in the position-list
** being parsed, or it may point to 1 byte past the end of the position-list
** (in which case **pp will be a terminator bytes POS_END (0) or
** (1)).
**
** If *pp points past the end of the current position-list, set *pi to
** POSITION_LIST_END and return. Otherwise, read the next varint from *pp,
** increment the current value of *pi by the value read, and set *pp to
** point to the next value before returning.
**
** Before calling this routine *pi must be initialized to the value of
** the previous position, or zero if we are reading the first position
** in the position-list.  Because positions are delta-encoded, the value
** of the previous position is needed in order to compute the value of
** the next position.
*//*
** Value used to signify the end of an position-list. This must be
** as large or larger than any value that might appear on the
** position-list, even a position list that has been corrupted.
*//* A column-list is terminated by either a 0x01 or 0x00 byte that is
  ** not part of a multi-byte varint.
  *//*
** When this function is called, *ppPoslist is assumed to point to the
** start of a column-list. After it returns, *ppPoslist points to the
** to the terminator (POS_COLUMN or POS_END) byte of the column-list.
**
** A column-list is list of delta-encoded positions for a single column
** within a single document within a doclist.
**
** The column-list is terminated either by a POS_COLUMN varint (1) or
** a POS_END varint (0).  This routine leaves *ppPoslist pointing to
** the POS_COLUMN or POS_END that terminates the column-list.
**
** If pp is not NULL, then the contents of the column-list are copied
** to *pp. *pp is set to point to the first byte past the last byte copied
** before this function returns.  The POS_COLUMN or POS_END terminator
** is not copied into *pp.
*//* Advance past the POS_END terminator byte *//* The end of a position list is marked by a zero encoded as an FTS3
  ** varint. A single POS_END (0) byte. Except, if the 0 byte is preceded by
  ** a byte with the 0x80 bit set, then it is not a varint 0, but the tail
  ** of some other, multi-byte, value.
  **
  ** The following while-loop moves pEnd to point to the first byte that is not
  ** immediately preceded by a byte with the 0x80 bit set. Then increments
  ** pEnd once more so that it points to the byte immediately following the
  ** last byte in the position-list.
  *//*
** When this function is called, *ppPoslist is assumed to point to the
** start of a position-list. After it returns, *ppPoslist points to the
** first byte after the position-list.
**
** A position list is list of positions (delta encoded) and columns for
** a single document record of a doclist.  So, in other words, this
** routine advances *ppPoslist so that it points to the next docid in
** the doclist, or to the first byte past the end of the doclist.
**
** If pp is not NULL, then the contents of the position list are copied
** to *pp. *pp is set to point to the first byte past the last byte copied
** before this function returns.
*//*
** This function is used to create delta-encoded serialized lists of FTS3
** varints. Each call to this function appends a single varint to a list.
*//* Size of zBlob in bytes *//* Blob read from %_segments table *//* Selected leaf node *//* Size of buffer at zNode *//* Buffer containing segment interior node *//* Term to select leaves for *//*
** The buffer pointed to by argument zNode (size nNode bytes) contains an
** interior node of a b-tree segment. The zTerm buffer (size nTerm bytes)
** contains a term. This function searches the sub-tree headed by the zNode
** node for the range of leaf nodes that may contain the specified term
** or terms for which the specified term is a prefix.
**
** If piLeaf is not NULL, then *piLeaf is set to the blockid of the
** left-most leaf node in the tree that may contain the specified term.
** If piLeaf2 is not NULL, then *piLeaf2 is set to the blockid of the
** right-most leaf node that may contain a term for which the specified
** term is a prefix.
**
** It is possible that the range of returned leaf nodes does not contain
** the specified term or any terms for which it is a prefix. However, if the
** segment does contain any such terms, they are stored within the identified
** range. Because this function only inspects interior segment nodes (and
** never loads leaf nodes into memory), it is not possible to be sure.
**
** If an error occurs, an error code other than SQLITE_OK is returned.
*//* Compare the term we are searching for with the term just loaded from
    ** the interior node. If the specified term is greater than or equal
    ** to the term from the interior node, then all terms on the sub-tree
    ** headed by node iChild are smaller than zTerm. No need to search
    ** iChild.
    **
    ** If the interior node term is larger than the specified term, then
    ** the tree headed by iChild may contain the specified term.
    *//* Load the next term on the node into zBuffer. Use realloc() to expand
    ** the size of zBuffer if required.  *//* Size of term prefix *//* Size of term suffix *//* memcmp() result *//* Skip over the 'height' varint that occurs at the start of every
  ** interior node. Then load the blockid of the left-child of the b-tree
  ** node into variable iChild.
  **
  ** Even if the data structure on disk is corrupted, this (reading two
  ** varints from the buffer) does not risk an overread. If zNode is a
  ** root node, then the buffer comes from a SELECT statement. SQLite does
  ** not make this guarantee explicitly, but in practice there are always
  ** either more than 20 bytes of allocated space following the nNode bytes of
  ** contents, or two zero bytes. Or, if the node is read from the %_segments
  ** table, then there are always 20 bytes of zeroed padding following the
  ** nNode bytes of content (see sqlite3Fts3ReadBlock() for details).
  *//* Total term size *//* Block id of child node to descend to *//* True when processing first term on page *//* Size of allocated buffer *//* Buffer to load terms into *//* End of interior node buffer *//* Cursor to iterate through node *//* OUT: Selected child node *//*
** This function is used to process a single interior node when searching
** a b-tree for a term or term prefix. The node data is passed to this
** function via the zNode/nNode parameters. The term to search for is
** passed in zTerm/nTerm.
**
** If piFirst is not NULL, then this function sets *piFirst to the blockid
** of the child node that heads the sub-tree that may contain the term.
**
** If piLast is not NULL, then *piLast is set to the right-most child node
** that heads a sub-tree that may contain a term for which zTerm/nTerm is
** a prefix.
**
** If an OOM error occurs, SQLITE_NOMEM is returned. Otherwise, SQLITE_OK.
*//* If no row was found and no error has occurred, then the %_content
          ** table is missing a row that is present in the full-text index.
          ** The data structures are corrupt.  *//*
** Position the pCsr->pStmt statement so that it is on the row
** of the %_content table that contains the last match.  Return
** SQLITE_OK on success.
*//*
** If pCsr->pStmt has not been prepared (i.e. if pCsr->pStmt==0), then
** compose and prepare an SQL statement of the form:
**
**    "SELECT <columns> FROM %_content WHERE rowid = ?"
**
** (or the equivalent for a content=xxx table) and set pCsr->pStmt to
** it. If an error occurs, return an SQLite error code.
*//*
** Free all resources currently held by the cursor passed as the only
** argument.
*//*
** Finalize the statement handle at pCsr->pStmt.
**
** Or, if that statement handle is one created by fts3CursorSeekStmt(),
** and the Fts3Table.pSeekStmt slot is currently NULL, save the statement
** pointer there instead of finalizing it.
*//* Allocate a buffer large enough for an Fts3Cursor structure. If the
  ** allocation succeeds, zero it and return SQLITE_OK. Otherwise,
  ** if the allocation fails, return SQLITE_NOMEM.
  *//* Allocated cursor *//* Regardless of the strategy selected, FTS can deliver rows in rowid (or
  ** docid) order. Both ascending and descending are possible.
  *//* If using a docid=? or rowid=? strategy, set the UNIQUE flag. *//* Equality constraint on the langid column *//* A MATCH constraint. Use a full-text search.
    **
    ** If there is more than one MATCH constraint available, use the first
    ** one encountered. If there is both a MATCH constraint and a direct
    ** rowid/docid lookup, prefer the MATCH strategy. This is done even
    ** though the rowid/docid lookup is faster than a MATCH query, selecting
    ** it would lead to an "unable to use function MATCH in the requested
    ** context" error.
    *//* A direct lookup on the rowid or docid column. Assign a cost of 1.0. *//* There exists an unusable MATCH constraint. This means that if
        ** the planner does elect to use the results of this call as part
        ** of the overall query plan the user will see an "unable to use
        ** function MATCH in the requested context" error. To discourage
        ** this, return a very high cost here.  *//* True if this constraint is on docid *//* By default use a full table scan. This is an expensive option,
  ** so search through the constraints to see if a more efficient
  ** strategy is possible.
  *//* Index of docid<=x constraint, if present *//* Index of docid>=x constraint, if present *//* Index of langid=x constraint, if present *//* Index of constraint to use *//*
** Implementation of the xBestIndex method for FTS3 tables. There
** are three possible strategies, in order of preference:
**
**   1. Direct lookup by rowid or docid.
**   2. Full-text search using a MATCH operator on a non-docid column.
**   3. Linear scan of %_content table.
*//*
** Set the pIdxInfo->estimatedRows variable to nRow. Unless this
** extension is currently being used by a version of SQLite too old to
** support estimatedRows. In that case this function is a no-op.
*//*
** The xConnect() and xCreate() methods for the virtual table. All the
** work is done in function fts3InitVtab().
*//* Declare the table schema to SQLite. *//* Figure out the page-size for the database. This is required in order to
  ** estimate the cost of loading large doclists from the database.  *//* Check to see if a legacy fts3 table has been "upgraded" by the
  ** addition of a %_stat table so that it can use incremental merge.
  *//* If this is an xCreate call, create the underlying tables in the
  ** database. TODO: For xConnect(), it could verify that said tables exist.
  *//* Fill in the abNotindexed array *//* Fill in the azColumn array *//* Fill in the zName and zDb fields of the vtab structure. *//* 0xff means setting unknown *//* Space for azColumn strings *//* zDb *//* abNotindexed *//* aIndex *//* azColumn *//* Fts3Table *//* Allocate and populate the Fts3Table structure. *//* If a languageid= option was specified, remove the language id
      ** column from the aCol[] array. *//* If a content=xxx option was specified, the following:
  **
  **   1. Ignore any compress= and uncompress= options.
  **
  **   2. If no column names were specified as part of the CREATE VIRTUAL
  **      TABLE statement, use all columns from the content table.
  *//* Otherwise, the argument is a column name. *//* NOTINDEXED *//* LANGUAGEID *//* CONTENT *//* ORDER *//* UNCOMPRESS *//* COMPRESS *//* PREFIX *//* MATCHINFO *//* 7 -> NOTINDEXED *//* 6 -> LANGUAGEID *//* 5 -> CONTENT *//* 4 -> ORDER *//* 3 -> UNCOMPRESS *//* 2 -> COMPRESS *//* 1 -> PREFIX *//* 0 -> MATCHINFO *//* Check if it is an FTS4 special argument. *//* Check if this is a tokenizer specification *//* Loop through all of the arguments passed by the user to the FTS3/4
  ** module (i.e. all the column names and special arguments). This loop
  ** does the following:
  **
  **   + Figures out the number of columns the FTSX table will have, and
  **     the number of bytes of space that must be allocated to store copies
  **     of the column names.
  **
  **   + If there is a tokenizer specification included in the arguments,
  **     initializes the tokenizer pTokenizer.
  *//* Size of azNotindexed[] array *//* The set of notindexed= columns *//* languageid=? parameter (or NULL) *//* content=? parameter (or NULL) *//* uncompress=? parameter (or NULL) *//* compress=? parameter (or NULL) *//* Prefix parameter value (or NULL) *//* True to store descending indexes *//* True to omit %_docsize table *//* The results of parsing supported FTS4 key=value options: *//* Array of indexes for this table *//* Size of aIndex[] array *//* Tokenizer for this table *//* True for FTS4, false for FTS3 *//* Bytes required to hold table name *//* Bytes required to hold database name *//* Space for holding column names *//* Number of columns in the FTS table *//* Bytes required to hold all column names *//* Column index *//* Size of allocation used for *p *//* Pointer to allocated vtab *//*
** This function is the implementation of both the xConnect and xCreate
** methods of the FTS3 virtual table.
**
** The argv[] array contains the following:
**
**   argv[0]   -> module name  ("fts3" or "fts4")
**   argv[1]   -> database name
**   argv[2]   -> table name
**   argv[...] -> "column name" and other module argument fields.
*//* Set the output variables. *//* Allocate and populate the array to return. *//* Loop through the returned columns. Set nStr to the number of bytes of
    ** space required to store a copy of each column name, including the
    ** nul-terminator byte.  *//* Number of table columns *//* Size of all column names (incl. 0x00) *//* Compiled version of zSql *//* "SELECT *" statement on zTbl *//* OUT: error message *//* OUT: Bytes of string content *//* OUT: Size of array *pazCol *//* OUT: Malloc'd array of column names *//* Name of content table *//* Name of db (i.e. "main", "temp" etc.) *//*
** This function is called when initializing an FTS4 table that uses the
** content=xxx option. It determines the number of and names of the columns
** of the new FTS4 table.
**
** The third argument passed to this function is the value passed to the
** config=xxx option (i.e. "xxx"). This function queries the database for
** a table of that name. If found, the output variables are populated
** as follows:
**
**   *pnCol:   Set to the number of columns table xxx has,
**
**   *pnStr:   Set to the total amount of space required to store a copy
**             of each columns name, including the nul-terminator.
**
**   *pazCol:  Set to point to an array of *pnCol strings. Each string is
**             the name of the corresponding column in table xxx. The array
**             and its contents are allocated using a single allocation. It
**             is the responsibility of the caller to free this allocation
**             by eventually passing the *pazCol value to sqlite3_free().
**
** If the table cannot be found, an error code is returned and the output
** variables are undefined. Or, if an OOM is encountered, SQLITE_NOMEM is
** returned (and the output variables are undefined).
*//* Number of entries in array *//* Allocated array *//* OUT: Array of indexes for this table *//* OUT: size of *apIndex[] array *//* ABC in prefix=ABC parameter to parse *//*
** This function is called to allocate an array of Fts3Index structures
** representing the indexes maintained by the current FTS table. FTS tables
** always maintain the main "terms" index, but may also maintain one or
** more "prefix" indexes, depending on the value of the "prefix=" parameter
** (if any) specified as part of the CREATE VIRTUAL TABLE statement.
**
** Argument zParam is passed the value of the "prefix=" option if one was
** specified, or NULL otherwise.
**
** If no error occurs, SQLITE_OK is returned and *apIndex set to point to
** the allocated array. *pnIndex is set to the number of elements in the
** array. If an error does occur, an SQLite error code is returned.
**
** Regardless of whether or not an error is returned, it is the responsibility
** of the caller to call sqlite3_free() on the output array to free it.
*//*
** This function interprets the string at (*pp) as a non-negative integer
** value. It reads the integer and sets *pnOut to the value read, then
** sets *pp to point to the byte immediately following the last byte of
** the integer value.
**
** Only decimal digits ('0'..'9') may be part of an integer value.
**
** If *pp does not being with a decimal digit SQLITE_ERROR is returned and
** the output value undefined. Otherwise SQLITE_OK is returned.
**
** This function is used when parsing the "prefix=" FTS4 parameter.
*//*
** Buffer z contains a positive integer value encoded as utf-8 text.
** Decode this value and store it in *pnOut, returning the number of bytes
** consumed. If an overflow error occurs return a negative value.
*//*
** Return a list of N comma separated question marks, where N is the number
** of columns in the %_content table (one for the docid plus one for each
** user-defined text column).
**
** If argument zFunc is not NULL, then all but the first question mark
** is preceded by zFunc and an open bracket, and followed by a closed
** bracket. For example, if zFunc is "zip" and the FTS3 table has three
** user-defined text columns, the following string is returned:
**
**     "?, zip(?), zip(?), zip(?)"
**
** The pointer returned points to a buffer allocated by sqlite3_malloc(). It
** is the responsibility of the caller to eventually free it.
**
** If *pRc is not SQLITE_OK when this function is called, it is a no-op (and
** a NULL pointer is returned). Otherwise, if an OOM error is encountered
** by this function, NULL is returned and *pRc is set to SQLITE_NOMEM. If
** no error occurs, *pRc is left unmodified.
*//*
** Return a list of comma separated SQL expressions and a FROM clause that
** could be used in a SELECT statement such as the following:
**
**     SELECT <list of expressions> FROM %_content AS x ...
**
** to return the docid, followed by each column of text data in order
** from left to write. If parameter zFunc is not NULL, then instead of
** being returned directly each column of text data is passed to an SQL
** function named zFunc first. For example, if zFunc is "unzip" and the
** table has the three user-defined columns "a", "b", and "c", the following
** string is returned:
**
**     "docid, unzip(x.'a'), unzip(x.'b'), unzip(x.'c') FROM %_content AS x"
**
** The pointer returned points to a buffer allocated by sqlite3_malloc(). It
** is the responsibility of the caller to eventually free it.
**
** If *pRc is not SQLITE_OK when this function is called, it is a no-op (and
** a NULL pointer is returned). Otherwise, if an OOM error is encountered
** by this function, NULL is returned and *pRc is set to SQLITE_NOMEM. If
** no error occurs, *pRc is left unmodified.
*//*
** Return a copy of input string zInput enclosed in double-quotes (") and
** with all double quote characters escaped. For example:
**
**     fts3QuoteId("un \"zip\"")   ->    "un \"\"zip\"\""
**
** The pointer returned points to memory obtained from sqlite3_malloc(). It
** is the callers responsibility to call sqlite3_free() to release this
** memory.
*//* Arguments for printf format string *//* Printf format string to append *//* IN/OUT: Pointer to string buffer *//*
** Append the output of a printf() style formatting to an existing string.
*//*
** "Special" FTS4 arguments are column specifications of the following form:
**
**   <key> = <value>
**
** There may not be whitespace surrounding the "=" character. The <value>
** term may be quoted, but the <key> may not.
*//* Compiled "PRAGMA %Q.page_size" statement *//* SQL text "PRAGMA %Q.page_size" *//*
** Store the current database page-size in bytes in p->nPgsz.
**
** If *pRc is non-zero when this function is called, it is a no-op.
** Otherwise, if an error occurs, an SQLite error code is stored in *pRc
** before returning.
*//* Create other tables *//* Create the content table *//* Create a list of user columns for the content table *//* Columns of %_content table *//*
** Create the backing store tables (%_content, %_segments and %_segdir)
** required by the FTS3 table passed as the only argument. This is done
** as part of the vtab xCreate() method.
**
** If the p->bHasDocsize boolean is true (indicating that this is an
** FTS4 table, not an FTS3 table) then also create the %_docsize and
** %_stat tables required by FTS4.
*//*
** Create the %_stat table if it does not already exist.
*//* Create the whole "CREATE TABLE" statement to pass to SQLite *//* Create a list of user columns for the virtual table *//* List of user defined columns *//* SQL statement passed to declare_vtab() *//*
** Invoke sqlite3_declare_vtab() to declare the schema for the FTS3 table
** passed as the first argument. This is done as part of the xConnect()
** and xCreate() methods.
**
** If *pRc is non-zero when this function is called, it is a no-op.
** Otherwise, if an error occurs, an SQLite error code is stored in *pRc
** before returning.
*//* If everything has worked, invoke fts3DisconnectMethod() to free the
  ** memory associated with the Fts3Table structure and return SQLITE_OK.
  ** Otherwise, return an SQLite error code.
  *//* Drop the shadow tables *//* Name of database (e.g. "main", "temp") *//* Arguments to the format string *//* Format string for SQL *//* Database in which to run SQL *//* Success code *//*
** Construct one or more SQL statements from the format string given
** and then evaluate those statements. The success code is written
** into *pRc.
**
** If *pRc is initially non-zero then this routine is a no-op.
*//*
** Write an error message into *pzErr
*//* Invoke the tokenizer destructor to free the tokenizer. *//* Pointer p now points at the first byte past the varint we are
  ** interested in. So, unless the doclist is corrupt, the 0x80 bit is
  ** clear on character p[-1]. *//*
** When this function is called, *pp points to the first byte following a
** varint that is part of a doclist (or position-list, or any other list
** of varints). This function moves *pp to point to the start of that varint,
** and sets *pVal by the varint value.
**
** Argument pStart points to the first byte of the doclist that the
** varint is part of.
*//*
** Read a single varint from the doclist at *pp and advance *pp to point
** to the first byte past the end of the varint.  Add the value of the varint
** to *pVal.
*//* If the first byte was a '[', then the close-quote character is a ']' *//* Index of next byte to write to output *//* Index of next byte to read from input *//*
** Convert an SQL-style quoted string into a normal string by removing
** the quote characters.  The conversion is done in-place.  If the
** input does not begin with a quote character, then this routine
** is a no-op.
**
** Examples:
**
**     "abc"   becomes   abc
**     'xyz'   becomes   xyz
**     [pqr]   becomes   pqr
**     `mno`   becomes   mno
**
*//*
** Return the number of bytes required to encode v as a varint
*//*
** Similar to sqlite3Fts3GetVarint(), except that the output is truncated to
** a non-negative 32-bit integer before it is returned.
*//*
** Read a 64-bit variable-length integer from memory starting at p[0] and
** not extending past pEnd[-1].
** Return the number of bytes read, or 0 on error.
** The value is stored in *v.
*//*
** Read a 64-bit variable-length integer from memory starting at p[0].
** Return the number of bytes read, or 0 on error.
** The value is stored in *v.
*//* turn off high bit in final byte *//*
** Write a 64-bit variable-length integer to memory starting at p[0].
** The length of data written will be between 1 and FTS3_VARINT_MAX bytes.
** The number of bytes written is returned.
*//*
** This variable is set to false when running tests for which the on disk
** structures should not be corrupt. Otherwise, true. If it is false, extra
** assert() conditions in the fts3 code are activated - conditions that are
** only true if it is guaranteed that the fts3 database is not corrupt.
*//* #include "fts3.h" *//* #include <stdarg.h> *//* #include <stddef.h> *//************** Continuing where we left off in fts3.c ***********************//************** End of fts3Int.h *********************************************//* _FTSINT_H *//* !SQLITE_CORE || SQLITE_ENABLE_FTS3 *//* fts3_unicode2.c (functions generated by parsing unicode text files) *//* fts3_tokenize_vtab.c *//* fts3_aux.c *//* fts3_expr.c *//* fts3_snippet.c *//* fts3_tokenizer.c *//* fts3.c *//* Size of aDoclist[] in bytes *//* Pointer to doclist buffer *//* Pointer to term buffer *//* Output values. Valid only after Fts3SegReaderStep() returns SQLITE_ROW. *//* True if a lookup of a single entry. *//* Cost of running iterator *//* Used by fts3.c only. *//* If >=0, filter for this column *//* Allocated size of aBuffer[] in bytes *//* Buffer to merge doclists in *//* Pointer to filter object *//* How many seg-readers to advance *//* Array of Fts3SegReader objects *//* Used internally by sqlite3Fts3SegReaderXXX() calls *//* Type passed as 4th argument to SegmentReaderIterate() *//* Flags allowed as part of the 4th argument to SegmentReaderIterate() *//* Special values interpreted by sqlite3SegReaderCursor() *//* fts3_write.c *//*
** Candidate values for Fts3Query.eType. Note that the order of the first
** four values is in order of precedence when parsing expressions. For
** example, the following:
**
**   "a OR b AND c NOT d NEAR e"
**
** is equivalent to:
**
**   "a OR (b AND (c NOT (d NEAR e)))"
*//* Index of this phrase in matchinfo() results *//* The following are used by the fts3_snippet.c module. *//* True if this expression is entirely deferred *//* True if iDocid is valid *//* True this expression is at EOF already *//* Current docid *//* The following are used by the fts3_eval.c module. *//* Valid if eType==FTSQUERY_PHRASE *//* Right operand *//* Left operand *//* pParent->pLeft==this or pParent->pRight==this *//* Valid if eType==FTSQUERY_NEAR *//* One of the FTSQUERY_XXX values defined below *//*
** A tree of these objects forms the RHS of a MATCH operator.
**
** If Fts3Expr.eType is FTSQUERY_PHRASE and isLoaded is true, then aDoclist
** points to a malloced buffer, size nDoclist bytes, containing the results
** of this phrase query in FTS3 doclist format. As usual, the initial
** "Length" field found in doclists stored on disk is omitted from this
** buffer.
**
** Variable aMI is used only for FTSQUERY_NEAR nodes to store the global
** matchinfo data. If it is not NULL, it points to an array of size nCol*3,
** where nCol is the number of columns in the queried FTS table. The array
** is populated as follows:
**
**   aMI[iCol*3 + 0] = Undefined
**   aMI[iCol*3 + 1] = Number of occurrences
**   aMI[iCol*3 + 2] = Number of rows containing at least one instance
**
** The aMI array is allocated using sqlite3_malloc(). It should be freed
** when the expression node is.
*//* One entry for each token in the phrase *//* Index of column this phrase must match *//* Number of tokens in the phrase *//* Variables below this point are populated by fts3_expr.c when parsing
  ** a MATCH expression. Everything above is part of the evaluation phase.
  *//* Used by sqlite3Fts3EvalPhrasePoslist() if this is a descendent of an
  ** OR condition.  *//* True if doclist is loaded incrementally *//* Cache of doclist for this phrase. *//* Segment-reader for this token *//* Deferred token object for this token *//* Variables above this point are populated when the expression is
  ** parsed (by code in fts3_expr.c). Below this point the variables are
  ** used when evaluating the expression. *//* True if token must appear at position 0 *//* True if token ends with a "*" character *//* Number of bytes in buffer z *//* Text of the token *//*
** A "phrase" is a sequence of one or more tokens that must match in
** sequence.  A single token is the base case and the most common case.
** For a sequence of tokens contained in double-quotes (i.e. "one two three")
** nToken will be the number of tokens in the string.
*//* Length of position list *//* Pointer to position list following iDocid *//* True if pList should be sqlite3_free()d *//* Current docid (if pList!=0) *//* Pointer to next docid *//* Size of a[] in bytes *//* Array containing doclist (or NULL) *//* docid<=? *//* docid>=? *//* languageid=? *//*
** The lower 16-bits of the sqlite3_index_info.idxNum value set by
** the xBestIndex() method contains the Fts3Cursor.eSearch value described
** above. The upper 16-bits contain a combination of the following
** bits, used to describe extra constraints on full-text searches.
*//* Full-text index search *//* Lookup by rowid on %_content table *//* Linear scan of %_content table *//*
** The Fts3Cursor.eSearch member is always set to one of the following.
** Actualy, Fts3Cursor.eSearch can be greater than or equal to
** FTS3_FULLTEXT_SEARCH.  If so, then Fts3Cursor.eSearch - 2 is the index
** of the column to be searched.  For example, in
**
**     CREATE VIRTUAL TABLE ex1 USING fts3(a,b,c,d);
**     SELECT docid FROM ex1 WHERE b MATCH 'one two three';
**
** Because the LHS of the MATCH operator is 2nd column "b",
** Fts3Cursor.eSearch will be set to FTS3_FULLTEXT_SEARCH+1.  (+0 for a,
** +1 for b, +2 for c, +3 for d.)  If the LHS of MATCH were "ex1"
** indicating that all columns should be searched,
** then eSearch would be set to FTS3_FULLTEXT_SEARCH+4.
*//* Buffer for matchinfo data *//* True when aMatchinfo[] needs filling in *//* Maximum docid to return *//* Minimum docid to return *//* Documents in table *//* Average size of database rows, in pages *//* An FTS3_EVAL_XX constant *//* True to sort in descending order *//* Size of buffer at aDoclist *//* List of docids for full-text queries *//* Pointer into the body of aDoclist *//* Previous id read from aDoclist *//* Deferred search tokens, if any *//* Language being queried for *//* Parsed MATCH query string *//* Prepared statement in use by the cursor *//* True if pStmt is a seek *//* True if must seek pStmt to %_content row *//* True if at End Of Results *//* Search strategy (see below) *//*
** When the core wants to read from the virtual table, it creates a
** virtual table cursor (an instance of the following structure) using
** the xOpen method. Cursors are destroyed using the xClose method.
*//* Macro to find the number of segments to merge *//* Number of segments in a level *//* True to disable the incremental doclist optimization. This is controled
  ** by special insert command 'test-no-incr-doclist'.  *//* Largest valid xSavepoint integer *//* True after xBegin but before xCommit/xRollback *//* State variables used for validating that the transaction control
  ** methods of the virtual table are called at appropriate times.  These
  ** values do not contribute to FTS functionality; they are used for
  ** verifying the operation of the SQLite core.
  *//* True if last operation was a delete *//* Langid of recently inserted document *//* Docid of most recently inserted document *//* Max pending data before flush to disk *//* Pending terms table for this index *//* Prefix length (0 for main terms index) *//* Size of aIndex[] *//*
  ** The following array of hash tables is used to buffer pending index
  ** updates during transactions. All pending updates buffered at any one
  ** time must share a common language-id (see the FTS4 langid= feature).
  ** The current language id is stored in variable iPrevLangid.
  **
  ** A single FTS4 table may have multiple full-text indexes. For each index
  ** there is an entry in the aIndex[] array. Index 0 is an index of all the
  ** terms that appear in the document set. Each subsequent index in aIndex[]
  ** is an index of prefixes of a specific length.
  **
  ** Variable nPendingData contains an estimate the memory consumed by the
  ** pending data structures, including hash table overhead, but not including
  ** malloc overhead.  When nPendingData exceeds nMaxPendingData, all hash
  ** tables are flushed to disk. Variable iPrevDocid is the docid of the most
  ** recently inserted record.
  *//* Blob handle open on %_segments table *//* Name of %_segments table *//* Page size for host database *//* True to ignore xSavepoint invocations *//* True if doclists are in reverse order *//* True if %_docsize table exists *//* True if %_stat table exists (2==unknown) *//* Soft limit for node size *//* Cache for fts3CursorSeekStmt() *//* Precompiled statements used by the implementation. Each of these
  ** statements is run and reset within a single virtual table API call.
  *//* Used to prevent recursive content= tbls *//* Number of leaf blocks added this trans *//* Value configured by 'automerge' *//* languageid=xxx option, or NULL *//* content=xxx option, or NULL *//* tokenizer for inserts and queries *//* True for 'notindexed' columns *//* column names.  malloced *//* number of named columns in virtual table *//* virtual table name *//* logical database name *//*
** A connection to a fulltext index is an instance of the following
** structure. The xCreate and xConnect methods create an instance
** of this structure and xDestroy and xDisconnect free that instance.
** All other methods receive a pointer to the structure as one of their
** arguments.
*//*
** The TESTONLY macro is used to enclose variable declarations or
** other bits of code that are needed to support the arguments
** within testcase() and assert() macros.
*//*
** Activate assert() only if SQLITE_TEST is enabled.
*//*
** Macro used to suppress compiler warnings for unused parameters.
*//* 8-byte signed integer *//* 8-byte unsigned integer *//* 4-byte unsigned integer *//* 2-byte (or larger) signed integer *//* 1-byte (or larger) unsigned integer *//*
** Internal types used by SQLite.
*//*
** Macros indicating that conditional expressions are always true or
** false.
*//*
** This section provides definitions to allow the
** FTS3 extension to be compiled outside of the
** amalgamation.
*//*
** The assert_fts3_nc() macro is similar to the assert() macro, except that it
** is used for assert() conditions that are true only if it can be
** guranteed that the database is not corrupt.
*//* Position-list terminator *//* Column-list terminator *//*
** Terminator values for position-lists and column-lists.
*//*
** The testcase() macro is only used by the amalgamation.  If undefined,
** make it a no-op.
*//*
** FTS4 virtual tables may maintain multiple indexes - one index of all terms
** in the document set and zero or more prefix indexes. All indexes are stored
** as one or more b+-trees in the %_segments and %_segdir tables.
**
** It is possible to determine which index a b+-tree belongs to based on the
** value stored in the "%_segdir.level" column. Given this value L, the index
** that the b+-tree belongs to is (L<<10). In other words, all b+-trees with
** level values between 0 and 1023 (inclusive) belong to index 0, all levels
** between 1024 and 2047 to index 1, and so on.
**
** It is considered impossible for an index to use more than 1024 levels. In
** theory though this may happen, but only after at least
** (FTS3_MERGE_COUNT^1024) separate flushes of the pending-terms tables.
*//*
** Maximum length of a varint encoded integer. The varint format is different
** from that used by SQLite, so the maximum length is 10, not 9.
*//*
** Macro to return the number of elements in an array. SQLite has a
** similar macro called ArraySize(). Use a different name to avoid
** a collision when building an amalgamation with built-in FTS3.
*//*
** This is the maximum amount of data (in bytes) to store in the
** Fts3Table.pendingTerms hash table. Normally, the hash table is
** populated as documents are inserted/updated/deleted in a transaction
** and used to create a new segment when the transaction is committed.
** However if this limit is reached midway through a transaction, a new
** segment is created and the hash table cleared immediately.
*//*
** This constant controls how often segments are merged. Once there are
** FTS3_MERGE_COUNT segments of level N, they are merged into a single
** segment of level N+1.
*//*
** This constant determines the maximum depth of an FTS expression tree
** that the library will create and use. FTS uses recursion to perform
** various operations on the query tree, so the disadvantage of a large
** limit is that it may allow very large queries to use large amounts
** of stack space (perhaps causing a stack overflow).
*//************** Continuing where we left off in fts3Int.h ********************//************** End of fts3_hash.h *******************************************//* _FTS3_HASH_H_ *//*
** Number of entries in a hash table
*//*
** Macros for looping over all elements of a hash table.  The idiom is
** like this:
**
**   Fts3Hash h;
**   Fts3HashElem *p;
**   ...
**   for(p=fts3HashFirst(&h); p; p=fts3HashNext(p)){
**     SomeStructure *pData = fts3HashData(p);
**     // do something with pData
**   }
*//*
** Shorthand for the functions above
*//*
** Access routines.  To delete, insert a NULL pointer.
*//*
** There are 2 different modes of operation for a hash table:
**
**   FTS3_HASH_STRING        pKey points to a string that is nKey bytes long
**                           (including the null-terminator, if any).  Case
**                           is respected in comparisons.
**
**   FTS3_HASH_BINARY        pKey points to binary data nKey bytes long.
**                           memcmp() is used to compare keys.
**
** A copy of the key is made if the copyKey parameter to fts3HashInit is 1.
*//* Key associated with this element *//* Data associated with this element *//* Next and previous elements in the table *//* Each element in the hash table is an instance of the following
** structure.  All elements are stored on a single doubly-linked list.
**
** Again, this structure is intended to be opaque, but it can't really
** be opaque because it is used by macros.
*//* Pointer to first entry with this hash *//* Number of entries with this hash *//* the hash table *//* Number of buckets in the hash table *//* The first element of the array *//* Number of entries in this table *//* True if copy of key made on insert *//* HASH_INT, _POINTER, _STRING, _BINARY *//* A complete hash table is an instance of the following structure.
** The internals of this structure are intended to be opaque -- client
** code should not attempt to access or modify the fields of this structure
** directly.  Change this structure only by using the routines below.
** However, many of the "procedures" and "functions" for modifying and
** accessing this structure are really macros, so we can't really make
** this structure opaque.
*//* Forward declarations of structures. *//*
** 2001 September 22
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This is the header file for the generic hash-table implementation
** used in SQLite.  We've modified it slightly to serve as a standalone
** hash table implementation for the full-text indexing module.
**
*//************** Begin file fts3_hash.h ***************************************//************** Include fts3_hash.h in the middle of fts3Int.h ***************//************** End of fts3_tokenizer.h **************************************//* _FTS3_TOKENIZER_H_ *//* Tokenizer implementations will typically add additional fields *//* Tokenizer for this cursor. *//* The module for this tokenizer *//*
  ** Configure the language id of a tokenizer cursor.
  *//***********************************************************************
  ** Methods below this point are only available if iVersion>=1.
  *//* OUT: Number of tokens returned before this one *//* OUT: Byte offset of end of token in input buffer *//* OUT: Byte offset of token in input buffer *//* OUT: Normalized text for token *//* TODO(shess) current implementation requires pInput to be
  ** nul-terminated.  This should either be fixed, or pInput/nBytes
  ** should be converted to zInput.
  *//*
  ** Retrieve the next token from the tokenizer cursor pCursor. This
  ** method should either return SQLITE_OK and set the values of the
  ** "OUT" variables identified below, or SQLITE_DONE to indicate that
  ** the end of the buffer has been reached, or an SQLite error code.
  **
  ** *ppToken should be set to point at a buffer containing the
  ** normalized version of the token (i.e. after any case-folding and/or
  ** stemming has been performed). *pnBytes should be set to the length
  ** of this buffer in bytes. The input text that generated the token is
  ** identified by the byte offsets returned in *piStartOffset and
  ** *piEndOffset. *piStartOffset should be set to the index of the first
  ** byte of the token in the input buffer. *piEndOffset should be set
  ** to the index of the first byte just past the end of the token in
  ** the input buffer.
  **
  ** The buffer *ppToken is set to point at is managed by the tokenizer
  ** implementation. It is only required to be valid until the next call
  ** to xNext() or xClose().
  *//*
  ** Destroy an existing tokenizer cursor. The fts3 module calls this
  ** method exactly once for each successful call to xOpen().
  *//* OUT: Created tokenizer cursor *//* Input buffer *//*
  ** Create a tokenizer cursor to tokenize an input buffer. The caller
  ** is responsible for ensuring that the input buffer remains valid
  ** until the cursor is closed (using the xClose() method).
  *//*
  ** Destroy an existing tokenizer. The fts3 module calls this method
  ** exactly once for each successful call to xCreate().
  *//* Tokenizer argument strings *//* Size of argv array *//*
  ** Create a new tokenizer. The values in the argv[] array are the
  ** arguments passed to the "tokenizer" clause of the CREATE VIRTUAL
  ** TABLE statement that created the fts3 table. For example, if
  ** the following SQL is executed:
  **
  **   CREATE .. USING fts3( ... , tokenizer <tokenizer-name> arg1 arg2)
  **
  ** then argc is set to 2, and the argv[] array contains pointers
  ** to the strings "arg1" and "arg2".
  **
  ** This method should return either SQLITE_OK (0), or an SQLite error
  ** code. If SQLITE_OK is returned, then *ppTokenizer should be set
  ** to point at the newly created tokenizer structure. The generic
  ** sqlite3_tokenizer.pModule variable should not be initialized by
  ** this callback. The caller will do so.
  *//*
  ** Structure version. Should always be set to 0 or 1.
  *//*
** Structures used by the tokenizer interface. When a new tokenizer
** implementation is registered, the caller provides a pointer to
** an sqlite3_tokenizer_module containing pointers to the callback
** functions that make up an implementation.
**
** When an fts3 table is created, it passes any arguments passed to
** the tokenizer clause of the CREATE VIRTUAL TABLE statement to the
** sqlite3_tokenizer_module.xCreate() function of the requested tokenizer
** implementation. The xCreate() function in turn returns an
** sqlite3_tokenizer structure representing the specific tokenizer to
** be used for the fts3 table (customized by the tokenizer clause arguments).
**
** To tokenize an input buffer, the sqlite3_tokenizer_module.xOpen()
** method is called. It returns an sqlite3_tokenizer_cursor object
** that may be used to tokenize a specific input buffer based on
** the tokenization rules supplied by a specific sqlite3_tokenizer
** object.
*//* TODO(shess) Only used for SQLITE_OK and SQLITE_DONE at this time.
** If tokenizers are to be allowed to call sqlite3_*() functions, then
** we will need a way to register the API consistently.
*//*
** 2006 July 10
**
** The author disclaims copyright to this source code.
**
*************************************************************************
** Defines the interface to tokenizers used by fulltext-search.  There
** are three basic components:
**
** sqlite3_tokenizer_module is a singleton defining the tokenizer
** interface functions.  This is essentially the class structure for
** tokenizers.
**
** sqlite3_tokenizer is used to define a particular tokenizer, perhaps
** including customization information defined at creation time.
**
** sqlite3_tokenizer_cursor is generated by a tokenizer to generate
** tokens from a particular input.
*//************** Begin file fts3_tokenizer.h **********************************//************** Include fts3_tokenizer.h in the middle of fts3Int.h **********//* If not building as part of the core, include sqlite3ext.h. *//*
** FTS4 is really an extension for FTS3.  It is enabled using the
** SQLITE_ENABLE_FTS3 macro.  But to avoid confusion we also all
** the SQLITE_ENABLE_FTS4 macro to serve as an alisse for SQLITE_ENABLE_FTS3.
*//* FTS3/FTS4 require virtual tables *//*
** 2009 Nov 12
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
*//************** Begin file fts3Int.h *****************************************//************** Include fts3Int.h in the middle of fts3.c ********************//* The full-text index is stored in a series of b+tree (-like)
** structures called segments which map terms to doclists.  The
** structures are like b+trees in layout, but are constructed from the
** bottom up in optimal fashion and are not updatable.  Since trees
** are built from the bottom up, things will be described from the
** bottom up.
**
**
**** Varints ****
** The basic unit of encoding is a variable-length integer called a
** varint.  We encode variable-length integers in little-endian order
** using seven bits * per byte as follows:
**
** KEY:
**         A = 0xxxxxxx    7 bits of data and one flag bit
**         B = 1xxxxxxx    7 bits of data and one flag bit
**
**  7 bits - A
** 14 bits - BA
** 21 bits - BBA
** and so on.
**
** This is similar in concept to how sqlite encodes "varints" but
** the encoding is not the same.  SQLite varints are big-endian
** are are limited to 9 bytes in length whereas FTS3 varints are
** little-endian and can be up to 10 bytes in length (in theory).
**
** Example encodings:
**
**     1:    0x01
**   127:    0x7f
**   128:    0x81 0x00
**
**
**** Document lists ****
** A doclist (document list) holds a docid-sorted list of hits for a
** given term.  Doclists hold docids and associated token positions.
** A docid is the unique integer identifier for a single document.
** A position is the index of a word within the document.  The first
** word of the document has a position of 0.
**
** FTS3 used to optionally store character offsets using a compile-time
** option.  But that functionality is no longer supported.
**
** A doclist is stored like this:
**
** array {
**   varint docid;          (delta from previous doclist)
**   array {                (position list for column 0)
**     varint position;     (2 more than the delta from previous position)
**   }
**   array {
**     varint POS_COLUMN;   (marks start of position list for new column)
**     varint column;       (index of new column)
**     array {
**       varint position;   (2 more than the delta from previous position)
**     }
**   }
**   varint POS_END;        (marks end of positions for this document.
** }
**
** Here, array { X } means zero or more occurrences of X, adjacent in
** memory.  A "position" is an index of a token in the token stream
** generated by the tokenizer. Note that POS_END and POS_COLUMN occur
** in the same logical place as the position element, and act as sentinals
** ending a position list array.  POS_END is 0.  POS_COLUMN is 1.
** The positions numbers are not stored literally but rather as two more
** than the difference from the prior position, or the just the position plus
** 2 for the first position.  Example:
**
**   label:       A B C D E  F  G H   I  J K
**   value:     123 5 9 1 1 14 35 0 234 72 0
**
** The 123 value is the first docid.  For column zero in this document
** there are two matches at positions 3 and 10 (5-2 and 9-2+3).  The 1
** at D signals the start of a new column; the 1 at E indicates that the
** new column is column number 1.  There are two positions at 12 and 45
** (14-2 and 35-2+12).  The 0 at H indicate the end-of-document.  The
** 234 at I is the delta to next docid (357).  It has one position 70
** (72-2) and then terminates with the 0 at K.
**
** A "position-list" is the list of positions for multiple columns for
** a single docid.  A "column-list" is the set of positions for a single
** column.  Hence, a position-list consists of one or more column-lists,
** a document record consists of a docid followed by a position-list and
** a doclist consists of one or more document records.
**
** A bare doclist omits the position information, becoming an
** array of varint-encoded docids.
**
**** Segment leaf nodes ****
** Segment leaf nodes store terms and doclists, ordered by term.  Leaf
** nodes are written using LeafWriter, and read using LeafReader (to
** iterate through a single leaf node's data) and LeavesReader (to
** iterate through a segment's entire leaf layer).  Leaf nodes have
** the format:
**
** varint iHeight;             (height from leaf level, always 0)
** varint nTerm;               (length of first term)
** char pTerm[nTerm];          (content of first term)
** varint nDoclist;            (length of term's associated doclist)
** char pDoclist[nDoclist];    (content of doclist)
** array {
**                             (further terms are delta-encoded)
**   varint nPrefix;           (length of prefix shared with previous term)
**   varint nSuffix;           (length of unshared suffix)
**   char pTermSuffix[nSuffix];(unshared suffix of next term)
**   varint nDoclist;          (length of term's associated doclist)
**   char pDoclist[nDoclist];  (content of doclist)
** }
**
** Here, array { X } means zero or more occurrences of X, adjacent in
** memory.
**
** Leaf nodes are broken into blocks which are stored contiguously in
** the %_segments table in sorted order.  This means that when the end
** of a node is reached, the next term is in the node with the next
** greater node id.
**
** New data is spilled to a new leaf node when the current node
** exceeds LEAF_MAX bytes (default 2048).  New data which itself is
** larger than STANDALONE_MIN (default 1024) is placed in a standalone
** node (a leaf node with a single term and doclist).  The goal of
** these settings is to pack together groups of small doclists while
** making it efficient to directly access large doclists.  The
** assumption is that large doclists represent terms which are more
** likely to be query targets.
**
** TODO(shess) It may be useful for blocking decisions to be more
** dynamic.  For instance, it may make more sense to have a 2.5k leaf
** node rather than splitting into 2k and .5k nodes.  My intuition is
** that this might extend through 2x or 4x the pagesize.
**
**
**** Segment interior nodes ****
** Segment interior nodes store blockids for subtree nodes and terms
** to describe what data is stored by the each subtree.  Interior
** nodes are written using InteriorWriter, and read using
** InteriorReader.  InteriorWriters are created as needed when
** SegmentWriter creates new leaf nodes, or when an interior node
** itself grows too big and must be split.  The format of interior
** nodes:
**
** varint iHeight;           (height from leaf level, always >0)
** varint iBlockid;          (block id of node's leftmost subtree)
** optional {
**   varint nTerm;           (length of first term)
**   char pTerm[nTerm];      (content of first term)
**   array {
**                                (further terms are delta-encoded)
**     varint nPrefix;            (length of shared prefix with previous term)
**     varint nSuffix;            (length of unshared suffix)
**     char pTermSuffix[nSuffix]; (unshared suffix of next term)
**   }
** }
**
** Here, optional { X } means an optional element, while array { X }
** means zero or more occurrences of X, adjacent in memory.
**
** An interior node encodes n terms separating n+1 subtrees.  The
** subtree blocks are contiguous, so only the first subtree's blockid
** is encoded.  The subtree at iBlockid will contain all terms less
** than the first term encoded (or all terms if no term is encoded).
** Otherwise, for terms greater than or equal to pTerm[i] but less
** than pTerm[i+1], the subtree for that term will be rooted at
** iBlockid+i.  Interior nodes only store enough term data to
** distinguish adjacent children (if the rightmost term of the left
** child is "something", and the leftmost term of the right child is
** "wicked", only "w" is stored).
**
** New data is spilled to a new interior node at the same height when
** the current node exceeds INTERIOR_MAX bytes (default 2048).
** INTERIOR_MIN_TERMS (default 7) keeps large terms from monopolizing
** interior nodes and making the tree too skinny.  The interior nodes
** at a given height are naturally tracked by interior nodes at
** height+1, and so on.
**
**
**** Segment directory ****
** The segment directory in table %_segdir stores meta-information for
** merging and deleting segments, and also the root node of the
** segment's tree.
**
** The root node is the top node of the segment's tree after encoding
** the entire segment, restricted to ROOT_MAX bytes (default 1024).
** This could be either a leaf node or an interior node.  If the top
** node requires more than ROOT_MAX bytes, it is flushed to %_segments
** and a new root interior node is generated (which should always fit
** within ROOT_MAX because it only needs space for 2 varints, the
** height and the blockid of the previous root).
**
** The meta-information in the segment directory is:
**   level               - segment level (see below)
**   idx                 - index within level
**                       - (level,idx uniquely identify a segment)
**   start_block         - first leaf node
**   leaves_end_block    - last leaf node
**   end_block           - last block (including interior nodes)
**   root                - contents of root node
**
** If the root node is a leaf node, then start_block,
** leaves_end_block, and end_block are all 0.
**
**
**** Segment merging ****
** To amortize update costs, segments are grouped into levels and
** merged in batches.  Each increase in level represents exponentially
** more documents.
**
** New documents (actually, document updates) are tokenized and
** written individually (using LeafWriter) to a level 0 segment, with
** incrementing idx.  When idx reaches MERGE_COUNT (default 16), all
** level 0 segments are merged into a single level 1 segment.  Level 1
** is populated like level 0, and eventually MERGE_COUNT level 1
** segments are merged to a single level 2 segment (representing
** MERGE_COUNT^2 updates), and so on.
**
** A segment merge traverses all segments at a given level in
** parallel, performing a straightforward sorted merge.  Since segment
** leaf nodes are written in to the %_segments table in order, this
** merge traverses the underlying sqlite disk structures efficiently.
** After the merge, all segment blocks from the merged level are
** deleted.
**
** MERGE_COUNT controls how often we merge segments.  16 seems to be
** somewhat of a sweet spot for insertion performance.  32 and 64 show
** very similar performance numbers to 16 on insertion, though they're
** a tiny bit slower (perhaps due to more overhead in merge-time
** sorting).  8 is about 20% slower than 16, 4 about 50% slower than
** 16, 2 about 66% slower than 16.
**
** At query time, high MERGE_COUNT increases the number of segments
** which need to be scanned and merged.  For instance, with 100k docs
** inserted:
**
**    MERGE_COUNT   segments
**       16           25
**        8           12
**        4           10
**        2            6
**
** This appears to have only a moderate impact on queries for very
** frequent terms (which are somewhat dominated by segment merge
** costs), and infrequent and non-existent terms still seem to be fast
** even with many segments.
**
** TODO(shess) That said, it would be nice to have a better query-side
** argument for MERGE_COUNT of 16.  Also, it is possible/likely that
** optimizations to things like doclist merging will swing the sweet
** spot around.
**
**
**
**** Handling of deletions and updates ****
** Since we're using a segmented structure, with no docid-oriented
** index into the term index, we clearly cannot simply update the term
** index when a document is deleted or updated.  For deletions, we
** write an empty doclist (varint(docid) varint(POS_END)), for updates
** we simply write the new doclist.  Segment merges overwrite older
** data for a particular docid with newer data, so deletes or updates
** will eventually overtake the earlier data and knock it out.  The
** query logic likewise merges doclists so that newer data knocks out
** older data.
*//*
** 2006 Oct 10
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This is an SQLite module implementing full-text search.
*//************** Begin file fts3.c ********************************************//************** End of notify.c **********************************************//*
** This is called when the database connection passed as an argument is
** being closed. The connection is removed from the blocked list.
*//* Leave STATIC_MAIN mutex *//* Remove connection p from the blocked connections list. *//* Step 3. *//* This occurs when the array of context pointers that need to
          ** be passed to the unlock-notify callback is larger than the
          ** aStatic[] array allocated on the stack and the attempt to
          ** allocate a larger array from the heap has failed.
          **
          ** This is a difficult situation to handle. Returning an error
          ** code to the caller is insufficient, as even if an error code
          ** is returned the transaction on connection db will still be
          ** closed and the unlock-notify callbacks on blocked connections
          ** will go unissued. This might cause the application to wait
          ** indefinitely for an unlock-notify callback that will never
          ** arrive.
          **
          ** Instead, invoke the unlock-notify callback with the context
          ** array already accumulated. We can then clear the array and
          ** begin accumulating any further context pointers without
          ** requiring any dynamic allocation. This is sub-optimal because
          ** it means that instead of one callback with a large array of
          ** context pointers the application will receive two or more
          ** callbacks with smaller arrays of context pointers, which will
          ** reduce the applications ability to prioritize multiple
          ** connections. But it is the best that can be done under the
          ** circumstances.
          *//* The aArg[] array needs to grow. *//* Step 2. *//* This loop runs once for each entry in the blocked-connections list. *//* Enter STATIC_MAIN mutex *//* Starter space for aArg[].  No malloc required *//* Dynamically allocated space for aArg[] *//* Arguments to the unlock callback *//* Number of entries in aArg[] *//* Unlock-notify cb to invoke *//*
** This function is called when
** the transaction opened by database db has just finished. Locks held
** by database connection db have been released.
**
** This function loops through each entry in the blocked connections
** list and does the following:
**
**   1) If the sqlite3.pBlockingConnection member of a list entry is
**      set to db, then set pBlockingConnection=0.
**
**   2) If the sqlite3.pUnlockConnection member of a list entry is
**      set to db, then invoke the configured unlock-notify callback and
**      set pUnlockConnection=0.
**
**   3) If the two steps above mean that pBlockingConnection==0 and
**      pUnlockConnection==0, remove the entry from the blocked connections
**      list.
*//*
** This function is called while stepping or preparing a statement
** associated with connection db. The operation will return SQLITE_LOCKED
** to the user because it requires a lock that will not be available
** until connection pBlocker concludes its current transaction.
*//* Deadlock detected. *//* The blocking transaction has been concluded. Or there never was a
    ** blocking transaction. In either case, invoke the notify callback
    ** immediately.
    *//*
** Register an unlock-notify callback.
**
** This is called after connection "db" has attempted some operation
** but has received an SQLITE_LOCKED error because another connection
** (call it pOther) in the same process was busy using the same shared
** cache.  pOther is found by looking at db->pBlockingConnection.
**
** If there is no blocking connection, the callback is invoked immediately,
** before this routine returns.
**
** If pOther is already blocked on db, then report SQLITE_LOCKED, to indicate
** a deadlock.
**
** Otherwise, make arrangements to invoke xNotify when pOther drops
** its locks.
**
** Each call to this routine overrides any prior callbacks registered
** on the same "db".  If xNotify==0 then any prior callbacks are immediately
** cancelled.
*//*
** Release the STATIC_MAIN mutex.
*//*
** Obtain the STATIC_MAIN mutex.
*//*
** Add connection db to the blocked connections list. It is assumed
** that it is not already a part of the list.
*//*
** Remove connection db from the blocked connections list. If connection
** db is not currently a part of the list, this function is a no-op.
*//* Verify property (2) *//* Verify property (1) *//*
** This function is a complex assert() that verifies the following
** properties of the blocked connections list:
**
**   1) Each entry in the list has a non-NULL value for either
**      pUnlockConnection or pBlockingConnection, or both.
**
**   2) All entries in the list that share a common value for
**      xUnlockNotify are grouped together.
**
**   3) If the argument db is not NULL, then none of the entries in the
**      blocked connections list have pUnlockConnection or pBlockingConnection
**      set to db. This is used when closing connection db.
*//*
** Head of a linked list of all sqlite3 objects created by this process
** for which either sqlite3.pBlockingConnection or sqlite3.pUnlockConnection
** is not NULL. This variable may only accessed while the STATIC_MAIN
** mutex is held.
*//*
** Public interfaces:
**
**   sqlite3ConnectionBlocked()
**   sqlite3ConnectionUnlocked()
**   sqlite3ConnectionClosed()
**   sqlite3_unlock_notify()
*//* Omit this entire file if SQLITE_ENABLE_UNLOCK_NOTIFY is not defined. *//* #include "btreeInt.h" *//*
** 2009 March 3
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file contains the implementation of the sqlite3_unlock_notify()
** API method and its associated functionality.
*//************** Begin file notify.c ******************************************//************** End of main.c ************************************************//* SQLITE_OMIT_COMPILEOPTION_DIAGS *//*
** Return the N-th compile-time option string.  If N is out of range,
** return a NULL pointer.
*//* Since nOpt is normally in single digits, a linear search is
  ** adequate. No need for a binary search. *//*
** Given the name of a compile-time option, return true if that option
** was used and false if not.
**
** The name can optionally begin with "SQLITE_" but the "SQLITE_" prefix
** is not required for a match.
*//* SQLITE_ENABLE_SNAPSHOT *//*
** Free a snapshot handle obtained from sqlite3_snapshot_get().
*//* SQLITE_OMIT_WAL *//*
** Recover as many snapshots as possible from the wal file associated with
** schema zDb of database db.
*//*
** Open a read-transaction on the snapshot identified by pSnapshot.
*//*
** Obtain a snapshot handle for the snapshot of database zDb currently
** being read by handle db.
*//*
** Return 1 if database is read-only or 0 if read/write.  Return -1 if
** no such database exists.
*//*
** Return the filename of the database associated with a database
** connection.
*//*
** Return the name of the N-th database schema.  Return NULL if N is out
** of range.
*//*
** Return the Btree pointer identified by zDbName.  Return NULL if not found.
*//*
** Translate a filename that was handed to a VFS routine into the corresponding
** database, journal, or WAL file.
**
** It is an error to pass this routine a filename string that was not
** passed into the VFS from the SQLite core.  Doing so is similar to
** passing free() a pointer that was not obtained from malloc() - it is
** an error that we cannot easily detect but that will likely cause memory
** corruption.
*//* return if parameter is missing *//* URI parameter sought *//* Filename as passed to xOpen *//*
** Return a 64-bit integer value for a query parameter.
*//*
** Return a boolean value for a query parameter.
*//*
** Return a pointer to the name of Nth query parameter of the filename.
*//*
** This is a utility routine, useful to VFS implementations, that checks
** to see if a database file was a URI that contained a specific query
** parameter, and if so obtains the value of the query parameter.
**
** The zFilename argument is the filename pointer passed into the xOpen()
** method of a VFS implementation.  The zParam argument is the name of the
** query parameter we seek.  This routine returns the value of the zParam
** parameter if it exists.  If the parameter does not exist, this routine
** returns a NULL pointer.
*//*
** Free memory obtained from sqlite3_create_filename().  It is a severe
** error to call this routine with any parameter other than a pointer
** previously obtained from sqlite3_create_filename() or a NULL pointer.
*//*
** Allocate memory to hold names for a database, journal file, WAL file,
** and query parameters.  The pointer returned is valid for use by
** sqlite3_filename_database() and sqlite3_uri_parameter() and related
** functions.
**
** Memory layout must be compatible with that generated by the pager
** and expected by sqlite3_uri_parameter() and databaseName().
*//*
** Append text z[] to the end of p[].  Return a pointer to the first
** character after then zero terminator on the new text in p[].
*//*
** The Pager stores the Database filename, Journal filename, and WAL filename
** consecutively in memory, in that order.  The database filename is prefixed
** by four zero bytes.  Locate the start of the database filename by searching
** backwards for the first byte following four consecutive zero bytes.
**
** This only works if the filename passed in was obtained from the Pager.
*//* SQLITE_UNTESTABLE *//* sqlite3_test_control(SQLITE_TESTCTRL_JSON_SELFCHECK, &onOff);
    **
    ** Activate or deactivate validation of JSONB that is generated from
    ** text.  Off by default, as the validation is slow.  Validation is
    ** only available if compiled using SQLITE_DEBUG.
    **
    ** If onOff is initially 1, then turn it on.  If onOff is initially
    ** off, turn it off.  If onOff is initially -1, then change onOff
    ** to be the current setting.
    *//* sqlite3_test_control(SQLITE_TESTCTRL_TUNE, id, *piValue)
    **
    ** If "id" is an integer between 1 and SQLITE_NTUNE then set the value
    ** of the id-th tuning parameter to *piValue.  If "id" is between -1
    ** and -SQLITE_NTUNE, then write the current value of the (-id)-th
    ** tuning parameter into *piValue.
    **
    ** Tuning parameters are for use during transient development builds,
    ** to help find the best values for constants in the query planner.
    ** Access tuning parameters using the Tuning(ID) macro.  Set the
    ** parameters in the CLI using ".testctrl tune ID VALUE".
    **
    ** Transient use only.  Tuning parameters should not be used in
    ** checked-in code.
    *//* sqlite3_test_control(SQLITE_TESTCTRL_LOGEST,
    **      double fIn,     // Input value
    **      int *pLogEst,   // sqlite3LogEstFromDouble(fIn)
    **      u64 *pInt,      // sqlite3LogEstToInt(*pLogEst)
    **      int *pLogEst2   // sqlite3LogEst(*pInt)
    ** );
    **
    ** Test access for the LogEst conversion routines.
    *//*  sqlite3_test_control(SQLITE_TESTCTRL_TRACEFLAGS, op, ptr)
    **
    **  "ptr" is a pointer to a u32.
    **
    **   op==0       Store the current sqlite3TreeTrace in *ptr
    **   op==1       Set sqlite3TreeTrace to the value *ptr
    **   op==2       Store the current sqlite3WhereTrace in *ptr
    **   op==3       Set sqlite3WhereTrace to the value *ptr
    *//* Silence harmless unused variable warning *//*  sqlite3_test_control(SQLITE_TESTCTRL_SEEK_COUNT,
    **    sqlite3 *db,    // Database connection
    **    u64 *pnSeek     // Write seek count here
    **  );
    **
    ** This test-control queries the seek-counter on the "main" database
    ** file.  The seek-counter is written into *pnSeek and is then reset.
    ** The seek-count is only available if compiled with SQLITE_DEBUG.
    *//*  sqlite3_test_control(SQLITE_TESTCTRL_RESULT_INTREAL, sqlite3_context*);
    **
    ** This test-control causes the most recent sqlite3_result_int64() value
    ** to be interpreted as a MEM_IntReal instead of as an MEM_Int.  Normally,
    ** MEM_IntReal values only arise during an INSERT operation of integer
    ** values into a REAL column, so they can be challenging to test.  This
    ** test-control enables us to write an intreal() SQL function that can
    ** inject an intreal() value at arbitrary places in an SQL statement,
    ** for testing purposes.
    *//* defined(YYCOVERAGE) *//*  sqlite3_test_control(SQLITE_TESTCTRL_PARSER_COVERAGE, FILE *out)
    **
    ** This test control (only available when SQLite is compiled with
    ** -DYYCOVERAGE) writes a report onto "out" that shows all
    ** state/lookahead combinations in the parser state machine
    ** which are never exercised.  If any state is missed, make the
    ** return code SQLITE_ERROR.
    *//*  sqlite3_test_control(SQLITE_TESTCTRL_IMPOSTER, db, dbName, onOff, tnum);
    **
    ** This test control is used to create imposter tables.  "db" is a pointer
    ** to the database connection.  dbName is the database name (ex: "main" or
    ** "temp") which will receive the imposter.  "onOff" turns imposter mode on
    ** or off.  "tnum" is the root page of the b-tree to which the imposter
    ** table should connect.
    **
    ** Enable imposter mode only when the schema has already been parsed.  Then
    ** run a single CREATE TABLE statement to construct the imposter table in
    ** the parsed schema.  Then turn imposter mode back off again.
    **
    ** If onOff==0 and tnum>0 then reset the schema for all databases, causing
    ** the schema to be reparsed the next time it is needed.  This has the
    ** effect of erasing all imposter tables.
    *//*   sqlite3_test_control(SQLITE_TESTCTRL_ISINIT);
    **
    ** Return SQLITE_OK if SQLite has been initialized and SQLITE_ERROR if
    ** not.
    *//*   sqlite3_test_control(SQLITE_TESTCTRL_SORTER_MMAP, db, nMax); *//*   sqlite3_test_control(SQLITE_TESTCTRL_VDBE_COVERAGE, xCallback, ptr);
    **
    ** Set the VDBE coverage callback function to xCallback with context
    ** pointer ptr.
    *//* Set the threshold at which OP_Once counters reset back to zero.
    ** By default this is 0x7ffffffe (over 2 billion), but that value is
    ** too big to test in a reasonable amount of time, so this control is
    ** provided to set a small and easily reachable reset value.
    *//*   sqlite3_test_control(SQLITE_TESTCTRL_EXTRA_SCHEMA_CHECKS, int);
    **
    ** Set or clear a flag that causes SQLite to verify that type, name,
    ** and tbl_name fields of the sqlite_schema table.  This is normally
    ** on, but it is sometimes useful to turn it off for testing.
    **
    ** 2020-07-22:  Disabling EXTRA_SCHEMA_CHECKS also disables the
    ** verification of rootpage numbers when parsing the schema.  This
    ** is useful to make it easier to reach strange internal error states
    ** during testing.  The EXTRA_SCHEMA_CHECKS setting is always enabled
    ** in production.
    *//*   sqlite3_test_control(SQLITE_TESTCTRL_NEVER_CORRUPT, int);
    **
    ** Set or clear a flag that indicates that the database file is always well-
    ** formed and never corrupt.  This flag is clear by default, indicating that
    ** database files might have arbitrary corruption.  Setting the flag during
    ** testing causes certain assert() statements in the code to be activated
    ** that demonstrate invariants on well-formed database files.
    *//*   sqlite3_test_control(SQLITE_TESTCTRL_INTERNAL_FUNCTIONS, sqlite3*);
    **
    ** Toggle the ability to use internal functions on or off for
    ** the database connection given in the argument.
    *//*   sqlite3_test_control(SQLITE_TESTCTRL_LOCALTIME_FAULT, onoff, xAlt);
    **
    ** If parameter onoff is 1, subsequent calls to localtime() fail.
    ** If 2, then invoke xAlt() instead of localtime().  If 0, normal
    ** processing.
    **
    ** xAlt arguments are void pointers, but they really want to be:
    **
    **    int xAlt(const time_t*, struct tm*);
    **
    ** xAlt should write results in to struct tm object of its 2nd argument
    ** and return zero on success, or return non-zero on failure.
    *//*  sqlite3_test_control(SQLITE_TESTCTRL_GETOPT, sqlite3 *db, int *N)
    **
    ** Write the current optimization settings into *N.  A zero bit means that
    ** the optimization is on, and a 1 bit means that the optimization is off.
    *//*  sqlite3_test_control(SQLITE_TESTCTRL_OPTIMIZATIONS, sqlite3 *db, int N)
    **
    ** Enable or disable various optimizations for testing purposes.  The
    ** argument N is a bitmask of optimizations to be disabled.  For normal
    ** operation N should be 0.  The idea is that a test program (like the
    ** SQL Logic Test or SLT test module) can run the same SQL multiple times
    ** with various optimizations disabled to verify that the same answer
    ** is obtained in every case.
    *//*
    **   sqlite3_test_control(SQLITE_TESTCTRL_BYTEORDER);
    **
    ** The integer returned reveals the byte-order of the computer on which
    ** SQLite is running:
    **
    **       1     big-endian,    determined at run-time
    **      10     little-endian, determined at run-time
    **  432101     big-endian,    determined at compile-time
    **  123410     little-endian, determined at compile-time
    *//*
    **  sqlite3_test_control(SQLITE_TESTCTRL_ALWAYS, int X)
    **
    ** This action provides a run-time test to see how the ALWAYS and
    ** NEVER macros were defined at compile-time.
    **
    ** The return value is ALWAYS(X) if X is true, or 0 if X is false.
    **
    ** The recommended test is X==2.  If the return value is 2, that means
    ** ALWAYS() and NEVER() are both no-op pass-through macros, which is the
    ** default setting.  If the return value is 1, then ALWAYS() is either
    ** hard-coded to true or else it asserts if its argument is false.
    ** The first behavior (hard-coded to true) is the case if
    ** SQLITE_TESTCTRL_ASSERT shows that assert() is disabled and the second
    ** behavior (assert if the argument to ALWAYS() is false) is the case if
    ** SQLITE_TESTCTRL_ASSERT shows that assert() is enabled.
    **
    ** The run-time test procedure might look something like this:
    **
    **    if( sqlite3_test_control(SQLITE_TESTCTRL_ALWAYS, 2)==2 ){
    **      // ALWAYS() and NEVER() are no-op pass-through macros
    **    }else if( sqlite3_test_control(SQLITE_TESTCTRL_ASSERT, 1) ){
    **      // ALWAYS(x) asserts that x is true. NEVER(x) asserts x is false.
    **    }else{
    **      // ALWAYS(x) is a constant 1.  NEVER(x) is a constant 0.
    **    }
    *//* Invoke these debugging routines so that the compiler does not
      ** issue "defined but not used" warnings. *//*side-effects-ok*//*
    **  sqlite3_test_control(SQLITE_TESTCTRL_ASSERT, int X)
    **
    ** This action provides a run-time test to see whether or not
    ** assert() was enabled at compile-time.  If X is true and assert()
    ** is enabled, then the return value is true.  If X is true and
    ** assert() is disabled, then the return value is zero.  If X is
    ** false and assert() is enabled, then the assertion fires and the
    ** process aborts.  If X is false and assert() is disabled, then the
    ** return value is zero.
    *//*
    **  sqlite3_test_control(SQLITE_TESTCTRL_PENDING_BYTE, unsigned int X)
    **
    ** Set the PENDING byte to the value in the argument, if X>0.
    ** Make no changes if X==0.  Return the value of the pending byte
    ** as it existing before this routine was called.
    **
    ** IMPORTANT:  Changing the PENDING byte from 0x40000000 results in
    ** an incompatible database file format.  Changing the PENDING byte
    ** while any database connection is open results in undefined and
    ** deleterious behavior.
    *//*
    **  sqlite3_test_control(BENIGN_MALLOC_HOOKS, xBegin, xEnd)
    **
    ** Register hooks to call to indicate which malloc() failures
    ** are benign.
    *//* A bug in MSVC prevents it from understanding pointers to functions
      ** types in the second argument to va_arg().  Work around the problem
      ** using a typedef.
      ** http://support.microsoft.com/kb/47961  <-- dead hyperlink
      ** Search at http://web.archive.org/ to find the 2015-03-16 archive
      ** of the link above to see the original text.
      ** sqlite3GlobalConfig.xTestCallback = va_arg(ap, int(*)(int));
      *//*
    **  sqlite3_test_control(FAULT_INSTALL, xCallback)
    **
    ** Arrange to invoke xCallback() whenever sqlite3FaultSim() is called,
    ** if xCallback is not NULL.
    **
    ** As a test of the fault simulator mechanism itself, sqlite3FaultSim(0)
    ** is called immediately after installing the new callback and the return
    ** value from sqlite3FaultSim(0) becomes the return from
    ** sqlite3_test_control().
    *//*
    **  sqlite3_test_control(BITVEC_TEST, size, program)
    **
    ** Run a test against a Bitvec object of size.  The program argument
    ** is an array of integers that defines the test.  Return -1 on a
    ** memory allocation error, 0 on success, or non-zero for an error.
    ** See the sqlite3BitvecBuiltinTest() for additional information.
    *//*  sqlite3_test_control(SQLITE_TESTCTRL_FK_NO_ACTION, sqlite3 *db, int b);
    **
    ** If b is true, then activate the SQLITE_FkNoAction setting.  If b is
    ** false then clearn that setting.  If the SQLITE_FkNoAction setting is
    ** abled, all foreign key ON DELETE and ON UPDATE actions behave as if
    ** they were NO ACTION, regardless of how they are defined.
    **
    ** NB:  One must usually run "PRAGMA writable_schema=RESET" after
    ** using this test-control, before it will take full effect.  failing
    ** to reset the schema can result in some unexpected behavior.
    *//*  sqlite3_test_control(SQLITE_TESTCTRL_PRNG_SEED, int x, sqlite3 *db);
    **
    ** Control the seed for the pseudo-random number generator (PRNG) that
    ** is built into SQLite.  Cases:
    **
    **    x!=0 && db!=0       Seed the PRNG to the current value of the
    **                        schema cookie in the main database for db, or
    **                        x if the schema cookie is zero.  This case
    **                        is convenient to use with database fuzzers
    **                        as it allows the fuzzer some control over the
    **                        the PRNG seed.
    **
    **    x!=0 && db==0       Seed the PRNG to the value of x.
    **
    **    x==0 && db==0       Revert to default behavior of using the
    **                        xRandomness method on the primary VFS.
    **
    ** This test-control also resets the PRNG so that the new seed will
    ** be used for the next call to sqlite3_randomness().
    *//*
    ** Restore the state of the PRNG to the last state saved using
    ** PRNG_SAVE.  If PRNG_SAVE has never before been called, then
    ** this verb acts like PRNG_RESET.
    *//*
    ** Save the current state of the PRNG.
    *//*
** Interface to the testing logic.
*//*
** Invoke the xFileControl method on a particular database.
*//*
** Enable or disable the extended result codes.
*//* This function works in milliseconds, but the underlying OsSleep()
  ** API uses microseconds. Hence the 1000's.
  *//*
** Sleep for a little while.  Return the amount of time slept.
*//* Whether the function call succeeded or failed, set the output parameters
  ** to whatever their local counterparts contain. If an error did occur,
  ** this has the effect of zeroing all output parameters.
  *//* The following block stores the meta information that will be returned
  ** to the caller in local variables zDataType, zCollSeq, notnull, primarykey
  ** and autoinc. At this point there are two possibilities:
  **
  **     1. The specified column name was rowid", "oid" or "_rowid_"
  **        and there is no explicitly declared IPK column.
  **
  **     2. The table is not a view and the column name identified an
  **        explicitly declared column. Copy meta information from *pCol.
  *//* Query for existence of table only *//* Find the column for which info is requested *//* Locate the table in question *//* Ensure the database schema has been loaded *//*
** Return meta information about a specific column of a database table.
** See comment in sqlite3.h (sqlite.h.in) for details.
*//*
** This is a convenience routine that makes sure that all thread-specific
** data for this thread has been deallocated.
**
** SQLite no longer uses thread-specific data so this routine is now a
** no-op.  It is retained for historical compatibility.
*//*
** The following routines are substitutes for constants SQLITE_CORRUPT,
** SQLITE_MISUSE, SQLITE_CANTOPEN, SQLITE_NOMEM and possibly other error
** constants.  They serve two purposes:
**
**   1.  Serve as a convenient place to set a breakpoint in a debugger
**       to detect when version error conditions occurs.
**
**   2.  Invoke sqlite3_log() to provide the source code location where
**       a low-level error is first detected.
*//*
** Test to see whether or not the database connection is in autocommit
** mode.  Return TRUE if it is and FALSE if not.  Autocommit mode is on
** by default.  Autocommit is disabled by a BEGIN statement and reenabled
** by the next COMMIT or ROLLBACK.
*//*
** This function is now an anachronism. It used to be used to recover from a
** malloc() failure, but SQLite now does this automatically.
*//* The client data itself *//* Name of the client data *//* Attach client data to this connection *//*
** Add new client data to a database connection.
*//*
** Find existing client data.
*//* SQLITE_OMIT_UTF16 *//*
** Register a collation sequence factory callback with the database handle
** db. Replace any previously installed collation sequence factory.
*//*
** Register a new collation sequence with the database handle db.
*//* zFilename encoded in UTF-8 instead of UTF-16 *//*
** Open a new database handle.
*//* Opening a db handle. Fourth parameter is passed 0. *//* Enable the lookaside-malloc subsystem *//* -DSQLITE_DEFAULT_LOCKING_MODE=1 makes EXCLUSIVE the default locking
  ** mode.  -DSQLITE_DEFAULT_LOCKING_MODE=0 make NORMAL the default locking
  ** mode.  Doing nothing at all also makes NORMAL the default.
  *//* Testing use only!!! The -DSQLITE_ENABLE_INTERNAL_FUNCTIONS=1 compile-time
  ** option gives access to internal functions by default.
  ** Testing use only!!! *//* Load automatic extensions - extensions that have been registered
  ** using the sqlite3_automatic_extension() API.
  *//* Load compiled-in extensions *//* Register all built-in functions, but do not attempt to read the
  ** database schema yet. This is delayed until the first time the database
  ** is accessed.
  *//* The default safety_level for the main database is FULL; for the temp
  ** database it is OFF. This matches the pager layer defaults.
  *//* Open the backend database driver *//* IMP: R-18321-05872 *//* READWRITE | CREATE *//* READWRITE *//* READONLY *//* Parse the filename/URI argument
  **
  ** Only allow sensible combinations of bits in the flags argument.
  ** Throw an error if any non-sense combination is used.  If we
  ** do not block illegal combinations here, it could trigger
  ** assert() statements in deeper layers.  Sensible combinations
  ** are:
  **
  **  1:  SQLITE_OPEN_READONLY
  **  2:  SQLITE_OPEN_READWRITE
  **  6:  SQLITE_OPEN_READWRITE | SQLITE_OPEN_CREATE
  *//* SQLITE_OS_UNIX && defined(SQLITE_OS_KV_OPTIONAL) *//* Process magic filenames ":localStorage:" and ":sessionStorage:" *//* Add the default collation sequence BINARY. BINARY works for both UTF-8
  ** and UTF-16, so add a version for each to avoid any unnecessary
  ** conversions. The only error that can occur here is a malloc() failure.
  **
  ** EVIDENCE-OF: R-52786-44878 SQLite defines three built-in collating
  ** functions:
  *//* The SQLITE_DQS compile-time option determines the default settings
** for SQLITE_DBCONFIG_DQS_DDL and SQLITE_DBCONFIG_DQS_DML.
**
**    SQLITE_DQS     SQLITE_DBCONFIG_DQS_DDL    SQLITE_DBCONFIG_DQS_DML
**    ----------     -----------------------    -----------------------
**     undefined               on                          on
**         3                   on                          on
**         2                   on                         off
**         1                  off                          on
**         0                  off                         off
**
** Legacy behavior is 3 (double-quoted string literals are allowed anywhere)
** and so that is the default.  But developers are encouraged to use
** -DSQLITE_DQS=0 (best) or -DSQLITE_DQS=1 (second choice) if possible.
*//* Beginning with version 3.37.0, using the VFS xFetch() API to memory-map
  ** the temporary files used to do external sorts (see code in vdbesort.c)
  ** is disabled. It can still be used either by defining
  ** SQLITE_ENABLE_SORTER_MMAP at compile time or by using the
  ** SQLITE_TESTCTRL_SORTER_MMAP test-control at runtime. *//* Any array of string ptrs will do *//* Allocate the sqlite data structure *//* Remove harmful bits from the flags parameter
  **
  ** The SQLITE_OPEN_NOMUTEX and SQLITE_OPEN_FULLMUTEX flags were
  ** dealt with in the previous code block.  Besides these, the only
  ** valid input flags for sqlite3_open_v2() are SQLITE_OPEN_READONLY,
  ** SQLITE_OPEN_READWRITE, SQLITE_OPEN_CREATE, SQLITE_OPEN_SHAREDCACHE,
  ** SQLITE_OPEN_PRIVATECACHE, SQLITE_OPEN_EXRESCODE, and some reserved
  ** bits.  Silently mask off all other flags.
  *//* Error message from sqlite3ParseUri() *//* Filename argument to pass to BtreeOpen() *//* True for threadsafe connections *//* Store allocated handle here *//* Name of the VFS to use *//* Operational flags *//* OUT: Returned database handle *//* Database filename UTF-8 encoded *//*
** This routine does the work of opening a database on behalf of
** sqlite3_open() and sqlite3_open16(). The database filename "zFilename"
** is UTF-8 encoded.
*//*
** This routine does the core work of extracting URI parameters from a
** database filename for the sqlite3_uri_parameter() interface.
*//* Check if there were any options specified that should be interpreted
    ** here. Options that are interpreted here include "vfs" and those that
    ** correspond to flags that may be passed to the sqlite3_open_v2()
    ** method. *//* end-of-options + empty journal filenames *//* An empty option name. Ignore this option altogether. *//* If ENABLE_URI_00_ERROR is defined, "%00" in a URI is an error. *//* This branch is taken when "%00" appears within the URI. In this
          ** case we ignore all text in the remainder of the path, name or
          ** value currently being parsed. So ignore the current character
          ** and skip to the next "?", "=" or "&", as appropriate. *//* Copy the filename and any query parameters into the zFile buffer.
    ** Decode %HH escape codes along the way.
    **
    ** Within this loop, variable eState may be set to 0, 1 or 2, depending
    ** on the parsing context. As follows:
    **
    **   0: Parsing file-name.
    **   1: Parsing name section of a name=value query parameter.
    **   2: Parsing value section of a name=value query parameter.
    *//* Discard the scheme and authority segments of the URI. *//* The following condition causes URIs with five leading / characters
      ** like file://///host/path to be converted into UNCs like //host/path.
      ** The correct URI for that UNC has only two or four leading / characters
      ** file://host/path or file:////host/path.  But 5 leading slashes is a
      ** common error, we are told, so we handle it as a special case. *//* 4-byte of 0x00 is the start of DB name marker *//* Make sure the SQLITE_OPEN_URI flag is set to indicate to the VFS xOpen
    ** method that there may be extra parameters following the file-name.  *//* Output character index *//* Input character index *//* Parser state when parsing URI *//* IMP: R-57884-37496 *//* IMP: R-51689-46548 *//* IMP: R-48725-32206 *//* OUT: Error message (if rc!=SQLITE_OK) *//* OUT: Filename component of URI *//* OUT: VFS to use *//* IN/OUT: SQLITE_OPEN_XXX flags *//* Nul-terminated URI to parse *//* VFS to use if no "vfs=xxx" query option *//*
** This function is used to parse both URIs and non-URI filenames passed by the
** user to API functions sqlite3_open() or sqlite3_open_v2(), and for database
** URIs specified as part of ATTACH statements.
**
** The first argument to this function is the name of the VFS to use (or
** a NULL to signify the default VFS) if the URI does not contain a "vfs=xxx"
** query parameter. The second argument contains the URI (or non-URI filename)
** itself. When this function is called the *pFlags variable should contain
** the default flags to open the database handle with. The value stored in
** *pFlags may be updated before returning if the URI filename contains
** "cache=xxx" or "mode=xxx" query parameters.
**
** If successful, SQLITE_OK is returned. In this case *ppVfs is set to point to
** the VFS that should be used to open the database file. *pzFile is set to
** point to a buffer containing the name of the file to open.  The value
** stored in *pzFile is a database name acceptable to sqlite3_uri_parameter()
** and is in the same format as names created using sqlite3_create_filename().
** The caller must invoke sqlite3_free_filename() (not sqlite3_free()!) on
** the value returned in *pzFile to avoid a memory leak.
**
** If an error occurs, then an SQLite error code is returned and *pzErrMsg
** may be set to point to a buffer containing an English language error
** message. It is the responsibility of the caller to eventually release
** this buffer by calling sqlite3_free().
*//* IMP: R-53341-35419 *//* IMP: R-51463-25634 *//* IMP: R-52476-28732 *//* EVIDENCE-OF: R-30189-54097 For each limit category SQLITE_LIMIT_NAME
  ** there is a hard upper bound set at compile-time by a C preprocessor
  ** macro called SQLITE_MAX_NAME. (The "_LIMIT_" in the name is changed to
  ** "_MAX_".)
  *//*
** Change the value of a limit.  Report the old value.
** If an invalid limit index is supplied, report -1.
** Make no changes but still report the old value if the
** new limit is negative.
**
** A new lower limit does not shrink existing constructs.
** It merely prevents new constructs that exceed the limit
** from forming.
*//*
** Make sure the hard limits are set to reasonable values
*//* IMP: R-38091-32352 *//*
** This array defines hard upper bounds on limit values.  The
** initializer must be kept in sync with the SQLITE_LIMIT_*
** #defines in sqlite3.h.
*//* If collation sequence pColl was created directly by a call to
    ** sqlite3_create_collation, and not generated by synthCollSeq(),
    ** then any copies made by synthCollSeq() need to be invalidated.
    ** Also, collation destructor - CollSeq.xDel() - function may need
    ** to be called.
    *//* Check if this call is removing or replacing an existing collation
  ** sequence. If so, and there are active VMs, return busy. If there
  ** are no active VMs, invalidate any pre-compiled statements.
  *//* If SQLITE_UTF16 is specified as the encoding type, transform this
  ** to one of SQLITE_UTF16LE or SQLITE_UTF16BE using the
  ** SQLITE_UTF16NATIVE macro. SQLITE_UTF16 is not used internally.
  *//*
** Create a new collating function for database "db".  The name is zName
** and the encoding is enc.
*//*
** Return a string that describes the kind of error specified in the
** argument.  For now, this simply calls the internal sqlite3ErrStr()
** function.
*//*
** Return the most recent error code generated by an SQLite routine. If NULL is
** passed to this function, we assume a malloc() failed during sqlite3_open().
*//* A malloc() may have failed within the call to sqlite3_value_text16()
    ** above. If this is the case, then the db->mallocFailed flag needs to
    ** be cleared before returning. Do this directly, instead of via
    ** sqlite3ApiExit(), to avoid setting the database handle error message.
    *//*
** Return UTF-16 encoded English language explanation of the most recent
** error.
*//*
** Return the byte offset of the most recent error
*//*
** Return UTF-8 encoded English language explanation of the most recent
** error.
*//*
** This function returns true if main-memory should be used instead of
** a temporary file for transient pager files and statement journals.
** The value returned depends on the value of db->temp_store (runtime
** parameter) and the compile time value of SQLITE_TEMP_STORE. The
** following table describes the relationship between these two values
** and this functions return value.
**
**   SQLITE_TEMP_STORE     db->temp_store     Location of temporary database
**   -----------------     --------------     ------------------------------
**   0                     any                file      (return 0)
**   1                     1                  file      (return 0)
**   1                     2                  memory    (return 1)
**   1                     0                  file      (return 0)
**   2                     1                  file      (return 0)
**   2                     2                  memory    (return 1)
**   2                     0                  memory    (return 1)
**   3                     any                memory    (return 1)
*//* See forum post a006d86f72 *//* True if SQLITE_BUSY has been encountered *//* Used to iterate through attached dbs *//*
** Run a checkpoint on database iDb. This is a no-op if database iDb is
** not currently open in WAL mode.
**
** If a transaction is open on the database being checkpointed, this
** function returns SQLITE_LOCKED and a checkpoint is not attempted. If
** an error occurs while running the checkpoint, an SQLite error code is
** returned (i.e. SQLITE_IOERR). Otherwise, SQLITE_OK.
**
** The mutex on database handle db should be held by the caller. The mutex
** associated with the specific b-tree being checkpointed is taken by
** this function while the checkpoint is running.
**
** If iDb is passed SQLITE_MAX_DB then all attached databases are
** checkpointed. If an error is encountered it is returned immediately -
** no attempt is made to checkpoint any remaining databases.
**
** Parameter eMode is one of SQLITE_CHECKPOINT_PASSIVE, FULL, RESTART
** or TRUNCATE.
*//* EVIDENCE-OF: R-41613-20553 The sqlite3_wal_checkpoint(D,X) is equivalent to
  ** sqlite3_wal_checkpoint_v2(D,X,SQLITE_CHECKPOINT_PASSIVE,0,0). *//*
** Checkpoint database zDb. If zDb is NULL, or if the buffer zDb points
** to contains a zero-length string, all attached databases are
** checkpointed.
*//* If there are no active statements, clear the interrupt flag at this
  ** point.  *//* This means process all schemas *//* EVIDENCE-OF: R-03996-12088 The M parameter must be a valid checkpoint
    ** mode: *//* Initialize the output variables to -1 in case an error occurs. *//* Schema to checkpoint *//*
** Checkpoint database zDb.
*//* First argument passed to xCallback() *//* Attach the hook to this db handle *//*
** Register a callback to be invoked each time a transaction is written
** into the write-ahead-log by this database connection.
*//*
** Configure an sqlite3_wal_hook() callback to automatically checkpoint
** a database after committing a transaction if there are nFrame or
** more frames in the log file. Passing zero or a negative value as the
** nFrame parameter disables automatic checkpoints entirely.
**
** The callback registered by this function replaces any existing callback
** registered using sqlite3_wal_hook(). Likewise, registering a callback
** using sqlite3_wal_hook() disables the automatic checkpoint mechanism
** configured by this function.
*//* Size of WAL *//* Database *//* Connection *//* Argument *//*
** The sqlite3_wal_hook() callback registered by sqlite3_wal_autocheckpoint().
** Invoke sqlite3_wal_checkpoint if the number of frames in the log file
** is greater than sqlite3.pWalArg cast to an integer (the value configured by
** wal_autocheckpoint()).
*//* Destructor for pArg *//* Argument to the function *//* Attach the hook to this database *//*
** Register a function to be invoked prior to each autovacuum that
** determines the number of pages to vacuum.
*//* SQLITE_ENABLE_PREUPDATE_HOOK *//* First callback argument *//*
** Register a callback to be invoked each time a row is updated,
** inserted or deleted using this database connection.
*//*
** Register a callback to be invoked each time a transaction is rolled
** back by this database connection.
*//* Function to invoke on each commit *//*
** Register a function to be invoked when a transaction commits.
** If the invoked function returns non-zero, then the commit becomes a
** rollback.
*//* SQLITE_OMIT_DEPRECATED *//*
** Register a profile function.  The pArg from the previously registered
** profile function is returned.
**
** A NULL profile function means that no profiling is executes.  A non-NULL
** profile is a pointer to a function that is invoked at the conclusion of
** each SQL statement that is run.
*//* Context *//* Callback to invoke *//* Mask of events to be traced *//* Trace this connection *//* Register a trace callback using the version-2 interface.
*//*
** Register a trace function.  The pArg from the previously registered trace
** is returned.
**
** A NULL trace function means that no tracing is executes.  A non-NULL
** trace is a pointer to a function that is invoked at the start of each
** SQL statement.
*//*
** Declare that a function has been overloaded by a virtual table.
**
** If the function already exists as a regular global function, then
** this routine is a no-op.  If the function does not exist, then create
** a new one that always throws a run-time error.
**
** When virtual tables intend to provide an overloaded function, they
** should call this routine to make sure the global function exists.
** A global function must exist in order for name resolution to work
** properly.
*//* Value of each argument *//* Number of arguments to the function *//* The function calling context *//*
** The following is the implementation of an SQL function that always
** fails with an error message stating that the function is used in the
** wrong context.  The sqlite3_overload_function() API might construct
** SQL function that use this routine so that the functions will exist
** for name resolution but are actually overloaded by the xFindFunction
** method of virtual tables.
*//*
** Create new user functions.
*//*
** Worker function used by utf-8 APIs that create new functions:
**
**    sqlite3_create_function()
**    sqlite3_create_function_v2()
**    sqlite3_create_window_function()
*//* If an older version of the function with a configured destructor is
  ** being replaced invoke the destructor function here. *//* Trying to delete a function that does not exist.  This is a no-op.
    ** https://sqlite.org/forum/forumpost/726219164b *//* Check if an existing function is being overridden or deleted. If so,
  ** and there are active VMs, then return SQLITE_BUSY. If a function
  ** is being overridden/deleted but there are no active VMs, allow the
  ** operation to continue but invalidate all precompiled statements.
  *//* tag-20230109-1*//* tag-20230109-1 *//* If SQLITE_UTF16 is specified as the encoding type, transform this
  ** to one of SQLITE_UTF16LE or SQLITE_UTF16BE using the
  ** SQLITE_UTF16NATIVE macro. SQLITE_UTF16 is not used internally.
  **
  ** If SQLITE_ANY is specified, add three versions of the function
  ** to the hash table.
  *//* The SQLITE_INNOCUOUS flag is the same bit as SQLITE_FUNC_UNSAFE.  But
  ** the meaning is inverted.  So flip the bit. *//* Both or neither of xValue, xInverse *//* Both or neither of xFinal and xStep *//* Not both xSFunc and xFinal *//* Must have a valid name *//*
** This function is exactly the same as sqlite3_create_function(), except
** that it is designed to be called by internal code. The difference is
** that if a malloc() fails in sqlite3_create_function(), an error code
** is returned and the mallocFailed flag cleared.
*//*
** Return true or false depending on whether or not an interrupt is
** pending on connection db.
*//*
** Cause any pending operation to stop at its earliest opportunity.
*//*
** This routine installs a default busy handler that waits for the
** specified number of milliseconds before returning 0.
*//*
** This routine sets the progress callback for an Sqlite database to the
** given callback function with the given argument. The progress callback will
** be invoked every nOps opcodes.
*//*
** This routine sets the busy callback for an Sqlite database to the
** given callback function with the given argument.
*//*
** Invoke the given busy handler.
**
** This routine is called when an operation failed to acquire a
** lock on VFS file pFile.
**
** If this routine returns non-zero, the lock is retried.  If it
** returns 0, the operation aborts with an SQLITE_BUSY error.
*//* This case for unix systems that lack usleep() support.  Sleeping
  ** must be done in increments of whole seconds *//* This case is for systems that have support for sleeping for fractions of
  ** a second.  Examples:  All windows systems, unix systems with nanosleep() *//* Number of times table has been busy *//*
** This routine implements a busy callback that sleeps and tries
** again until a timeout value is reached.  The timeout value is
** an integer number of milliseconds passed in as the first
** argument.
**
** Return non-zero to retry the lock.  Return zero to stop trying
** and cause SQLite to return SQLITE_BUSY.
*//* SQLITE_WARNING     *//* SQLITE_NOTICE      *//* SQLITE_NOTADB      *//* SQLITE_RANGE       *//* SQLITE_FORMAT      *//* SQLITE_AUTH        *//* SQLITE_NOLFS       *//* SQLITE_MISUSE      *//* SQLITE_MISMATCH    *//* SQLITE_CONSTRAINT  *//* SQLITE_TOOBIG      *//* SQLITE_SCHEMA      *//* SQLITE_EMPTY       *//* SQLITE_PROTOCOL    *//* SQLITE_CANTOPEN    *//* SQLITE_FULL        *//* SQLITE_NOTFOUND    *//* SQLITE_CORRUPT     *//* SQLITE_IOERR       *//* SQLITE_INTERRUPT   *//* SQLITE_READONLY    *//* SQLITE_NOMEM       *//* SQLITE_LOCKED      *//* SQLITE_BUSY        *//* SQLITE_ABORT       *//* SQLITE_PERM        *//* SQLITE_INTERNAL    *//* SQLITE_ERROR       *//* SQLITE_OK          *//*
** Return a static string that describes the kind of error specified in the
** argument.
*//*
** Return a static string containing the name corresponding to the error code
** specified in the argument.
*//* If one has been configured, invoke the rollback-hook callback *//* Any deferred constraint violations have now been resolved. *//* Obtain all b-tree mutexes before making any calls to BtreeRollback().
  ** This is important in case the transaction being rolled back has
  ** modified the database schema. If the b-tree mutexes are not taken
  ** here, then another shared-cache connection might sneak in between
  ** the database rollback and schema reset, which can cause false
  ** corruption reports in some cases.  *//*
** Rollback all database files.  If tripCode is not SQLITE_OK, then
** any write cursors are invalidated ("tripped" - as in "tripping a circuit
** breaker") and made to return tripCode if there are any further
** attempts to use that cursor.  Read cursors remain open and valid
** but are "saved" in case the table pages are moved around.
*//* The temp-database schema is allocated differently from the other schema
  ** objects (using sqliteMalloc() directly, instead of sqlite3BtreeSchema()).
  ** So it needs to be freed here. Todo: Why not roll the temp schema into
  ** the same sqliteMalloc() as the one that allocates the database
  ** structure?
  *//* Deallocates any cached error strings. *//* Invoke any destructors registered for collation sequence user data. *//* Tell the code in notify.c that the connection no longer holds any
  ** locks and does not require any further unlock-notify callbacks.
  *//* Free up the array of auxiliary databases *//* Clear the TEMP schema separately and last *//* Close all database connections *//* Free any outstanding Savepoint structures. *//* If a transaction is open, roll it back. This also ensures that if
  ** any database schemas have been modified by an uncommitted transaction
  ** they are reset. And that the required b-tree mutex is held to make
  ** the pager rollback and schema reset an atomic operation. *//* If we reach this point, it means that the database connection has
  ** closed all sqlite3_stmt and sqlite3_backup objects and has been
  ** passed to sqlite3_close (meaning that it is a zombie).  Therefore,
  ** go ahead and free all resources.
  *//* If there are outstanding sqlite3_stmt or sqlite3_backup objects
  ** or if the connection has not yet been closed by sqlite3_close_v2(),
  ** then just leave the mutex and return.
  *//* Hash table iterator *//*
** Close the mutex on database connection db.
**
** Furthermore, if database connection db is a zombie (meaning that there
** has been a prior call to sqlite3_close(db) or sqlite3_close_v2(db)) and
** every sqlite3_stmt has now been finalized and every sqlite3_backup has
** finished, then free all resources.
*//*
** Two variations on the public interface for closing a database
** connection. The sqlite3_close() version returns SQLITE_BUSY and
** leaves the connection open if there are unfinalized prepared
** statements or unfinished sqlite3_backups.  The sqlite3_close_v2()
** version forces the connection to become a zombie if there are
** unclosed resources, and arranges for deallocation when the last
** prepare statement or sqlite3_backup closes.
*//*
** Return the transaction state for a single databse, or the maximum
** transaction state over all attached databases if zSchema is null.
*//* Convert the connection into a zombie and then close it.
  *//* Closing the handle. Fourth parameter is passed the value 2. *//* Legacy behavior (sqlite3_close() behavior) is to return
  ** SQLITE_BUSY if the connection can not be closed immediately.
  *//* If a transaction is open, the disconnectAllVtab() call above
  ** will not have called the xDisconnect() method on any virtual
  ** tables in the db->aVTrans[] array. The following sqlite3VtabRollback()
  ** call will do so. We need to do this before the check for active
  ** SQL statements below, as the v-table implementation may be storing
  ** some prepared statements internally.
  *//* Force xDisconnect calls on all virtual tables *//* EVIDENCE-OF: R-63257-11740 Calling sqlite3_close() or
    ** sqlite3_close_v2() with a NULL pointer argument is a harmless no-op. *//*
** Close an existing SQLite database
*//*
** Return TRUE if database connection db has unfinalized prepared
** statements or unfinished sqlite3_backup objects.
*//*
** Disconnect all sqlite3_vtab objects that belong to database connection
** db. This is called when db is being closed.
*//*
** Invoke the destructor function associated with FuncDef p, if any. Except,
** if this is not the last copy of the function, do not invoke it. Multiple
** copies of a single function are created when create_function() is called
** with SQLITE_ANY as the encoding.
*//*
** Close all open savepoints. This function only manipulates fields of the
** database handle object, it does not close any savepoints that may be open
** at the b-tree/pager level.
*//*
** Return the number of changes since the database handle was opened.
*//*
** Return the number of changes in the most recent call to sqlite3_exec().
*//*
** Set the value returned by the sqlite3_last_insert_rowid() API function.
*//*
** Return the ROWID of the most recent insert
*//*
** Another built-in collating sequence: NOCASE.
**
** This collating sequence is intended to be used for "case independent
** comparison". SQLite's knowledge of upper and lower case equivalents
** extends only to the 26 characters used in the English language.
**
** At the moment there is only a UTF-8 implementation.
*//*
** Return true if CollSeq is the default built-in BINARY.
*//*
** This is the collating function named "RTRIM" which is always
** available.  Ignore trailing spaces.
*//* EVIDENCE-OF: R-65033-28449 The built-in BINARY collation compares
  ** strings byte by byte using the memcmp() function from the standard C
  ** library. *//*
** This is the default collating function named "BINARY" which is always
** available.
*//* IMP: R-42790-23372 *//* Mask of the bit in sqlite3.flags to set/clear *//* The opcode *//* IMP: R-04460-53386 *//* IMP: R-47871-25994 *//* IMP: R-26835-10964 *//* IMP: R-36257-52125 *//* IMP: R-06824-28531 *//*
** Configuration settings for an individual database connection
*//*
** Flush any dirty pages in the pager-cache for any attached database
** to disk.
*//*
** Free up as much memory as we can from the given database
** connection.
*//*
** Return the mutex associated with a database connection.
*//* SQLITE_OMIT_LOOKASIDE *//* SQLITE_OMIT_TWOSIZE_LOOKASIDE *//* IMP: R-61949-35727 *//* IMP: R-33038-09382 *//* The size of a lookaside slot after ROUNDDOWN8 needs to be larger
  ** than a pointer to be useful.
  *//* Free any existing lookaside buffer for this handle before
  ** allocating a new one so we don't have to have space for
  ** both at the same time.
  *//* Number smaller LOOKASIDE_SMALL-byte slots *//* Number of full-size slots *//*
** Set up the lookaside buffers for a database connection.
** Return SQLITE_OK on success.
** If lookaside is already active, return SQLITE_BUSY.
**
** The sz parameter is the number of bytes in each lookaside slot.
** The cnt parameter is the number of slots.  If pStart is NULL the
** space for the lookaside memory is obtained from sqlite3_malloc().
** If pStart is not NULL then it is sz*cnt bytes of memory to use for
** the lookaside memory.
*//* SQLITE_ENABLE_SORTER_REFERENCES *//* EVIDENCE-OF: R-34926-03360 SQLITE_CONFIG_WIN32_HEAPSIZE takes a 32-bit
      ** unsigned integer value that specifies the maximum size of the created
      ** heap. *//* IMP: R-04780-55815 *//* EVIDENCE-OF: R-53367-43190 If either argument to this option is
      ** negative, then that argument is changed to its compile-time default.
      **
      ** EVIDENCE-OF: R-34993-45031 The maximum allowed mmap size will be
      ** silently truncated if necessary so that it does not exceed the
      ** compile-time maximum mmap size set by the SQLITE_MAX_MMAP_SIZE
      ** compile-time option.
      *//* EVIDENCE-OF: R-58063-38258 SQLITE_CONFIG_MMAP_SIZE takes two 64-bit
      ** integer (sqlite3_int64) values that are the default mmap size limit
      ** (the default setting for PRAGMA mmap_size) and the maximum allowed
      ** mmap size limit. *//* EVIDENCE-OF: R-36592-02772 The SQLITE_CONFIG_COVERING_INDEX_SCAN
      ** option takes a single integer argument which is interpreted as a
      ** boolean in order to enable or disable the use of covering indices for
      ** full table scans in the query optimizer. *//* EVIDENCE-OF: R-25451-61125 The SQLITE_CONFIG_URI option takes a single
      ** argument of type int. If non-zero, then URI handling is globally
      ** enabled. If the parameter is zero, then URI handling is globally
      ** disabled. *//* EVIDENCE-OF: R-55548-33817 The compile-time setting for URI filenames
    ** can be changed at start-time using the
    ** sqlite3_config(SQLITE_CONFIG_URI,1) or
    ** sqlite3_config(SQLITE_CONFIG_URI,0) configuration calls.
    *//* MSVC is picky about pulling func ptrs from va lists.
      ** http://support.microsoft.com/kb/47961
      ** sqlite3GlobalConfig.xLog = va_arg(ap, void(*)(void*,int,const char*));
      *//* Record a pointer to the logger function and its first argument.
    ** The default is NULL.  Logging is disabled if the function pointer is
    ** NULL.
    *//* EVIDENCE-OF: R-61006-08918 If the memory pointer is not NULL then the
        ** alternative memory allocator is engaged to handle all of SQLites
        ** memory allocation needs. *//* EVIDENCE-OF: R-49920-60189 If the first pointer (the memory pointer)
        ** is NULL, then SQLite reverts to using its default memory allocator
        ** (the system malloc() implementation), undoing any prior invocation of
        ** SQLITE_CONFIG_MALLOC.
        **
        ** Setting sqlite3GlobalConfig.m to all zeros will cause malloc to
        ** revert to its default implementation when sqlite3_initialize() is run
        *//* cap min request size at 2^12 *//* EVIDENCE-OF: R-19854-42126 There are three arguments to
      ** SQLITE_CONFIG_HEAP: An 8-byte aligned pointer to the memory, the
      ** number of bytes in the memory buffer, and the minimum allocation size.
      *//* EVIDENCE-OF: R-06626-12911 The SQLITE_CONFIG_HEAP option is only
** available if SQLite is compiled with either SQLITE_ENABLE_MEMSYS3 or
** SQLITE_ENABLE_MEMSYS5 and returns SQLITE_ERROR if invoked otherwise. *//* EVIDENCE-OF: R-22035-46182 The SQLITE_CONFIG_GETPCACHE2 option takes a
      ** single argument which is a pointer to an sqlite3_pcache_methods2
      ** object. SQLite copies of the current page cache implementation into
      ** that object. *//* EVIDENCE-OF: R-63325-48378 The SQLITE_CONFIG_PCACHE2 option takes a
      ** single argument which is a pointer to an sqlite3_pcache_methods2
      ** object. This object specifies the interface to a custom page cache
      ** implementation. *//* now an error *//* EVIDENCE-OF: R-39100-27317 The SQLITE_CONFIG_PCACHE_HDRSZ option takes
      ** a single parameter which is a pointer to an integer and writes into
      ** that integer the number of extra bytes per page required for each page
      ** in SQLITE_CONFIG_PAGECACHE. *//* EVIDENCE-OF: R-18761-36601 There are three arguments to
      ** SQLITE_CONFIG_PAGECACHE: A pointer to 8-byte aligned memory (pMem),
      ** the size of each page cache line (sz), and the number of cache lines
      ** (N). *//* EVIDENCE-OF: R-61275-35157 The SQLITE_CONFIG_MEMSTATUS option takes
      ** single argument of type int, interpreted as a boolean, which enables
      ** or disables the collection of memory allocation statistics. *//* Cannot change at runtime *//* EVIDENCE-OF: R-51213-46414 The SQLITE_CONFIG_GETMALLOC option takes a
      ** single argument which is a pointer to an instance of the
      ** sqlite3_mem_methods structure. The sqlite3_mem_methods structure is
      ** filled with the currently defined memory allocation routines. *//* EVIDENCE-OF: R-55594-21030 The SQLITE_CONFIG_MALLOC option takes a
      ** single argument which is a pointer to an instance of the
      ** sqlite3_mem_methods structure. The argument specifies alternative
      ** low-level memory allocation routines to be used in place of the memory
      ** allocation routines built into SQLite. *//* Retrieve the current mutex implementation *//* IMP: R-14450-37597 *//* Specify an alternative mutex implementation *//* IMP: R-63666-48755 *//* Enable mutex on connections *//* Enable mutex on core *//* EVIDENCE-OF: R-41220-51800 This option sets the threading mode to
      ** Serialized. *//* IMP: R-59593-21810 *//* Disable mutex on connections *//* EVIDENCE-OF: R-14374-42468 This option sets the threading mode to
      ** Multi-thread. *//* IMP: R-20520-54086 *//* Disable mutex on core *//* EVIDENCE-OF: R-02748-19096 This option sets the threading mode to
      ** Single-thread. *//* IMP: R-54466-46756 *//* Mutex configuration options are only available in a threadsafe
    ** compile.
    *//* sqlite3_config() normally returns SQLITE_MISUSE if it is invoked while
  ** the SQLite library is in use.  Except, a few selected opcodes
  ** are allowed.
  *//*
** This API allows applications to modify the global configuration of
** the SQLite library at run-time.
**
** This routine should only be called when there are no outstanding
** database connections or memory allocations.  This routine is not
** threadsafe.  Failure to heed these warnings can lead to unpredictable
** behavior.
*//* The heap subsystem has now been shutdown and these values are supposed
    ** to be NULL or point to memory that was obtained from sqlite3_malloc(),
    ** which would rely on that heap subsystem; therefore, make sure these
    ** values cannot refer to heap memory that was just invalidated when the
    ** heap subsystem was shutdown.  This is only done if the current call to
    ** this function resulted in the heap subsystem actually being shutdown.
    *//*
** Undo the effects of sqlite3_initialize().  Must not be called while
** there are outstanding database connections or memory allocations or
** while any part of SQLite is otherwise in use in any thread.  This
** routine is not threadsafe.  But it is safe to invoke this routine
** on when SQLite is already shut down.  If SQLite is already shut down
** when this routine is invoked, then this routine is a harmless no-op.
*//* Do extra initialization steps requested by the SQLITE_EXTRA_INIT
  ** compile-time option.
  *//* This section of code's only "output" is via assert() statements. *//* The following is just a sanity check to make sure SQLite has
  ** been compiled correctly.  It is important to run this code, but
  ** we don't want to run it too often and soak up CPU cycles for no
  ** reason.  So we run it once during initialization.
  *//* Go back under the static mutex and clean up the recursive
  ** mutex to prevent a resource leak.
  *//* Do the rest of the initialization under the recursive mutex so
  ** that we will be able to handle recursive calls into
  ** sqlite3_initialize().  The recursive calls normally come through
  ** sqlite3_os_init() when it invokes sqlite3_vfs_register(), but other
  ** recursive calls might also be possible.
  **
  ** IMPLEMENTATION-OF: R-00140-37445 SQLite automatically serializes calls
  ** to the xInit method, so the xInit method need not be threadsafe.
  **
  ** The following mutex is what serializes access to the appdef pcache xInit
  ** methods.  The sqlite3_pcache_methods.xInit() all is embedded in the
  ** call to sqlite3PcacheInitialize().
  *//* If rc is not SQLITE_OK at this point, then either the malloc
  ** subsystem could not be initialized or the system failed to allocate
  ** the pInitMutex mutex. Return an error in either case.  *//* Initialize the malloc() system and the recursive pInitMutex mutex.
  ** This operation is protected by the STATIC_MAIN mutex.  Note that
  ** MutexAlloc() is called for a static mutex prior to initializing the
  ** malloc subsystem - this implies that the allocation of a static
  ** mutex must not require support from the malloc subsystem.
  *//* Make sure the mutex subsystem is initialized.  If unable to
  ** initialize the mutex subsystem, return early with the error.
  ** If the system is so sick that we are unable to allocate a mutex,
  ** there is not much SQLite is going to be able to do.
  **
  ** The mutex subsystem must take care of serializing its own
  ** initialization.
  *//* If SQLite is already completely initialized, then this call
  ** to sqlite3_initialize() should be a no-op.  But the initialization
  ** must be complete.  So isInit must not be set until the very end
  ** of this routine.
  *//* If the following assert() fails on some obscure processor/compiler
  ** combination, the work-around is to set the correct pointer
  ** size at compile-time using -DSQLITE_PTRSIZE=n compile-time option *//* Extra initialization needed *//* The main static mutex *//*
** Initialize SQLite.
**
** This routine must be called to initialize the memory allocation,
** VFS, and mutex subsystems prior to doing any serious work with
** SQLite.  But as long as you do not compile with SQLITE_OMIT_AUTOINIT
** this routine will be called automatically by key routines such as
** sqlite3_open().
**
** This routine is a no-op except on its very first call for the process,
** or for the first call after a call to sqlite3_shutdown.
**
** The first thread to call this routine runs the initialization to
** completion.  If subsequent threads call this routine before the first
** thread has finished the initialization process, then the subsequent
** threads must block until the first thread finishes with the initialization.
**
** The first thread might call this routine recursively.  Recursive
** calls to this routine should not block, of course.  Otherwise the
** initialization process would never complete.
**
** Let X be the first thread to enter this routine.  Let Y be some other
** thread.  Then while the initial invocation of this routine by X is
** incomplete, it is required that:
**
**    *  Calls to this routine from Y must block until the outer-most
**       call by X completes.
**
**    *  Recursive calls to this routine from thread X return immediately
**       without blocking.
*//*
** If the following global variable points to a string which is the
** name of a directory, then that directory will be used to store
** all database files specified with a relative pathname.
**
** See also the "PRAGMA data_store_directory" SQL command.
*//*
** If the following global variable points to a string which is the
** name of a directory, then that directory will be used to store
** temporary files.
**
** See also the "PRAGMA temp_store_directory" SQL command.
*//*
** If the following function pointer is not NULL and if
** SQLITE_ENABLE_IOTRACE is enabled, then messages describing
** I/O active are written using this function.  These messages
** are intended for debugging activity only.
*//*
** When compiling the test fixture or with debugging enabled (on Win32),
** this variable being set to non-zero will cause OSTRACE macros to emit
** extra diagnostic information.
*//* IMPLEMENTATION-OF: R-20790-14025 The sqlite3_threadsafe() function returns
** zero if and only if SQLite was compiled with mutexing code omitted due to
** the SQLITE_THREADSAFE compile-time option being set to 0.
*//* IMPLEMENTATION-OF: R-35210-63508 The sqlite3_libversion_number() function
** returns an integer equal to SQLITE_VERSION_NUMBER.
*//* SQLITE_API const char *sqlite3_sourceid(void){ return SQLITE_SOURCE_ID; } *//* IMPLEMENTATION-OF: R-25063-23286 The sqlite3_sourceid() function returns a
** pointer to a string constant whose value is the same as the
** SQLITE_SOURCE_ID C preprocessor macro. Except if SQLite is built using
** an edited copy of the amalgamation, then the last four characters of
** the hash might be different from SQLITE_SOURCE_ID.
*//* IMPLEMENTATION-OF: R-53536-42575 The sqlite3_libversion() function returns
** a pointer to the to the sqlite3_version[] string constant.
*//* IMPLEMENTATION-OF: R-46656-45156 The sqlite3_version[] string constant
** contains the text of SQLITE_VERSION macro.
*//*
** An array of pointers to extension initializer functions for
** built-in extensions.
*//*
** Forward declarations of external module initializer functions
** for modules that need them.
*//*
** This is an extension initializer that is a no-op and always
** succeeds, except that it fails if the fault-simulation is set
** to 500.
*//************** Continuing where we left off in main.c ***********************//************** End of sqliteicu.h *******************************************//* extern "C" *//*
** 2008 May 26
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This header file is used by programs that want to link against the
** ICU extension.  All it does is declare the sqlite3IcuInit() interface.
*//************** Begin file sqliteicu.h ***************************************//************** Include sqliteicu.h in the middle of main.c ******************//************** End of rtree.h ***********************************************//*
** 2008 May 26
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This header file is used by programs that want to link against the
** RTREE library.  All it does is declare the sqlite3RtreeInit() interface.
*//************** Begin file rtree.h *******************************************//************** Include rtree.h in the middle of main.c **********************//************** End of fts3.h ************************************************//*
** 2006 Oct 10
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
******************************************************************************
**
** This header file is used by programs that want to link against the
** FTS3 library.  All it does is declare the sqlite3Fts3Init() interface.
*//************** Begin file fts3.h ********************************************//************** Include fts3.h in the middle of main.c ***********************//*
** 2001 September 15
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** Main file for the SQLite library.  The routines in this file
** implement the programmer interface to the library.  Routines in
** other files are for internal use by SQLite and should not be
** accessed by users of the library.
*//************** Begin file main.c ********************************************//************** End of complete.c ********************************************//* SQLITE_OMIT_COMPLETE *//*
** This routine is the same as the sqlite3_complete() routine described
** above, except that the parameter is required to be UTF-16 encoded, not
** UTF-8.
*//* Operators and special symbols *//* SQLITE_OMIT_TRIGGER *//* Keywords and unquoted identifiers *//* single- and double-quoted strings *//* Grave-accent quoted symbols used by MySQL *//* Microsoft-style identifiers in [...] *//* SQL-style comments from "--" to end of line *//* C-style comments *//* White space is ignored *//* A semicolon *//* 2  NORMAL: *//* 1   START: *//* 0 INVALID: *//* State:       **  SEMI  WS  OTHER *//* Token:           *//* If triggers are not supported by this compile then the statement machine
  ** used to detect the end of a statement is much simpler
  *//* 7     END: *//* 6    SEMI: *//* 5 TRIGGER: *//* 4  CREATE: *//* 3 EXPLAIN: *//* State:       **  SEMI  WS  OTHER  EXPLAIN  CREATE  TEMP  TRIGGER  END *//* Token:                                                *//* A complex statement machine used to detect the end of a CREATE TRIGGER
  ** statement.  This is the normal case.
  *//* Value of the next token *//* Current state, using numbers defined in header comment *//*
** Return TRUE if the given SQL string ends in a semicolon.
**
** Special handling is require for CREATE TRIGGER statements.
** Whenever the CREATE TRIGGER keywords are seen, the statement
** must end with ";END;".
**
** This implementation uses a state machine with 8 states:
**
**   (0) INVALID   We have not yet seen a non-whitespace character.
**
**   (1) START     At the beginning or end of an SQL statement.  This routine
**                 returns 1 if it ends in the START state and 0 if it ends
**                 in any other state.
**
**   (2) NORMAL    We are in the middle of statement which ends with a single
**                 semicolon.
**
**   (3) EXPLAIN   The keyword EXPLAIN has been seen at the beginning of
**                 a statement.
**
**   (4) CREATE    The keyword CREATE has been seen at the beginning of a
**                 statement, possibly preceded by EXPLAIN and/or followed by
**                 TEMP or TEMPORARY
**
**   (5) TRIGGER   We are in the middle of a trigger definition that must be
**                 ended by a semicolon, the keyword END, and another semicolon.
**
**   (6) SEMI      We've seen the first semicolon in the ";END;" that occurs at
**                 the end of a trigger definition.
**
**   (7) END       We've seen the ";END" of the ";END;" that occurs at the end
**                 of a trigger definition.
**
** Transitions between states above are determined by tokens extracted
** from the input.  The following tokens are significant:
**
**   (0) tkSEMI      A semicolon.
**   (1) tkWS        Whitespace.
**   (2) tkOTHER     Any other SQL token.
**   (3) tkEXPLAIN   The "explain" keyword.
**   (4) tkCREATE    The "create" keyword.
**   (5) tkTEMP      The "temp" or "temporary" keyword.
**   (6) tkTRIGGER   The "trigger" keyword.
**   (7) tkEND       The "end" keyword.
**
** Whitespace never causes a state transition and is always ignored.
** This means that a SQL string of all whitespace is invalid.
**
** If we compile with SQLITE_OMIT_TRIGGER, all of the computation needed
** to recognize the end of a trigger can be omitted.  All we have to do
** is look for a semicolon that is not part of an string or comment.
*//*
** Token types used by the sqlite3_complete() routine.  See the header
** comments on that procedure for additional information.
*//*
** This is defined in tokenize.c.  We just have to import the definition.
*//*
** 2001 September 15
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** An tokenizer for SQL
**
** This file contains C code that implements the sqlite3_complete() API.
** This code used to be part of the tokenizer.c source file.  But by
** separating it out, the code will be automatically omitted from
** static links that do not use it.
*//************** Begin file complete.c ****************************************//************** End of tokenize.c ********************************************//* SQLITE_ENABLE_NORMALIZE *//* Fall through *//* sqlite3_str_new() never returns NULL *//* The normalized SQL string under construction *//* Bytes of normalized SQL generated so far *//* Value of nParent at start of RHS of IN operator *//* Start of RHS of IN operator in z[] *//* Number of nested levels of parentheses *//* Previous non-whitespace token *//* type of current token *//* length of current token *//* Next unread byte of zSql[] *//* The original SQL string *//* VM being reprepared *//*
** Compute a normalization of the SQL given by zSql[0..nSql-1].  Return
** the normalization in space obtained from sqlite3DbMalloc().  Or return
** NULL if anything goes wrong or if zSql is NULL.
*//*
** Insert a single space character into pStr if the current string
** ends with an identifier
*//* If the pParse->declareVtab flag is set, do not delete any table
    ** structure built up in pParse->pNewTable. The calling code (see vtab.c)
    ** will take responsibility for freeing the Table structure.
    *//* YYDEBUG *//* SQLITE_OMIT_WINDOWFUNC *//* Upon reaching the end of input, call the parser two more times
        ** with tokens TK_SEMI and 0, in that order. *//* Space to hold the Lemon-generated Parser object *//* Outer parse context, if any *//* Max length of an SQL string *//* type of the previous token *//* type of the next token *//* Length of the next token token *//* The LEMON-generated LALR(1) parser *//*
** Run the parser on the given SQL string.
*//* If it is not a BLOB literal, then it must be an ID, since no
      ** SQL keywords start with the letter 'x'.  Fall through *//* This token started out using characters that can appear in keywords,
        ** but z[i] is a character not allowed within keywords, so this must
        ** be an identifier instead *//* If the next character is a digit, this is a floating point
      ** number that begins with ".".  Fall thru into the next case *//* Switch on the character-class of the first byte
                          ** of the token. See the comment on the CC_ defines
                          ** above. *//*
** Return the length (in bytes) of the token that begins at z[0].
** Store the token type in *tokenType before returning.
*//*
** The following three functions are called immediately after the tokenizer
** reads the keywords WINDOW, OVER and FILTER, respectively, to determine
** whether the token should be treated as a keyword or an SQL identifier.
** This cannot be handled by the usual lemon %fallback method, due to
** the ambiguity in some constructions. e.g.
**
**   SELECT sum(x) OVER ...
**
** In the above, "OVER" might be a keyword, or it might be an alias for the
** sum(x) expression. If a "%fallback ID OVER" directive were added to
** grammar, then SQLite would always treat "OVER" as an alias, making it
** impossible to call a window-function without a FILTER clause.
**
** WINDOW is treated as a keyword if:
**
**   * the following token is an identifier, or a keyword that can fallback
**     to being an identifier, and
**   * the token after than one is TK_AS.
**
** OVER is a keyword if:
**
**   * the previous token was TK_RP, and
**   * the next token is either TK_LP or an identifier.
**
** FILTER is a keyword if:
**
**   * the previous token was TK_RP, and
**   * the next token is TK_LP.
*//* Token type to return *//*
** Return the id of the next token in string (*pz). Before returning, set
** (*pz) to point to the byte following the parsed token.
*//* Make the IdChar function accessible from ctime.c and alter.c *//* Fx *//* Ex *//* Dx *//* Cx *//* Bx *//* Ax *//* 9x *//* 8x *//*
** If X is a character that can be used in an identifier then
** IdChar(X) will be true.  Otherwise it is false.
**
** For ASCII, any character with the high-order bit set is
** allowed in an identifier.  For 7-bit characters,
** sqlite3IsIdChar[X] must be 1.
**
** For EBCDIC, the rules are more complex but have the same
** end result.
**
** Ticket #1066.  the SQL standard does not allow '$' in the
** middle of identifiers.  But many SQL implementations do.
** SQLite will allow '$' in identifiers for compatibility.
** But the feature is undocumented.
*//************** Continuing where we left off in tokenize.c *******************//************** End of keywordhash.h *****************************************//* PRIMARY *//* ALL *//* INITIALLY *//* BY *//* DO *//* WINDOW *//* VIEW *//* VACUUM *//* USING *//* UNION *//* UNBOUNDED *//* ROW *//* ROWS *//* ROLLBACK *//* RIGHT *//* RETURNING *//* OVER *//* OTHERS *//* RESTRICT *//* IF *//* LIMIT *//* FULL *//* FROM *//* FOLLOWING *//* FIRST *//* REPLACE *//* FILTER *//* LAST *//* FAIL *//* PRECEDING *//* CURRENT *//* CURRENT_TIME *//* CURRENT_TIMESTAMP *//* CROSS *//* CONFLICT *//* COMMIT *//* COLUMN *//* CAST *//* IN *//* TO *//* AUTOINCREMENT *//* PARTITION *//* DROP *//* AND *//* RENAME *//* AFTER *//* ABORT *//* RECURSIVE *//* WHERE *//* WHEN *//* ALWAYS *//* VIRTUAL *//* VALUES *//* IS *//* DISTINCT *//* DEFERRED *//* MATERIALIZED *//* PRAGMA *//* ANALYZE *//* PLAN *//* MATCH *//* JOIN *//* IMMEDIATE *//* CURRENT_DATE *//* CREATE *//* COLLATE *//* CASE *//* DEFAULT *//* ASC *//* CASCADE *//* GROUP *//* GROUPS *//* NOTHING *//* BETWEEN *//* ATTACH *//* RELEASE *//* OUTER *//* WITH *//* WITHOUT *//* QUERY *//* UNIQUE *//* REFERENCES *//* INNER *//* BEGIN *//* GLOB *//* HAVING *//* DETACH *//* GENERATED *//* RANGE *//* TRIGGER *//* SET *//* OF *//* OFFSET *//* INTO *//* CONSTRAINT *//* EXISTS *//* EXCLUSIVE *//* RAISE *//* ALTER *//* NATURAL *//* ON *//* ACTION *//* TRANSACTION *//* EXCEPT *//* LIKE *//* NULL *//* NO *//* NOT *//* NOTNULL *//* TIES *//* INTERSECT *//* SAVEPOINT *//* NULLS *//* ISNULL *//* OR *//* TEMP *//* TEMPORARY *//* EXCLUDE *//* ELSE *//* DEFERRABLE *//* END *//* THEN *//* LEFT *//* TABLE *//* SELECT *//* AS *//* DATABASE *//* ADD *//* INSTEAD *//* EXPLAIN *//* REGEXP *//* IGNORE *//* FOR *//* FOREIGN *//* BEFORE *//* KEY *//* CHECK *//* EACH *//* ESCAPE *//* DESC *//* INDEX *//* INDEXED *//* REINDEX *//* Check to see if z[0..n-1] is a keyword. If it is, write the
** parser symbol code for that keyword into *pType.  Always
** return the integer n (the length of the token). *//* Hash table decoded:
**   0: INSERT
**   1: IS
**   2: ROLLBACK TRIGGER
**   3: IMMEDIATE
**   4: PARTITION
**   5: TEMP
**   6:
**   7:
**   8: VALUES WITHOUT
**   9:
**  10: MATCH
**  11: NOTHING
**  12:
**  13: OF
**  14: TIES IGNORE
**  15: PLAN
**  16: INSTEAD INDEXED
**  17:
**  18: TRANSACTION RIGHT
**  19: WHEN
**  20: SET HAVING
**  21: MATERIALIZED IF
**  22: ROWS
**  23: SELECT
**  24:
**  25:
**  26: VACUUM SAVEPOINT
**  27:
**  28: LIKE UNION VIRTUAL REFERENCES
**  29: RESTRICT
**  30:
**  31: THEN REGEXP
**  32: TO
**  33:
**  34: BEFORE
**  35:
**  36:
**  37: FOLLOWING COLLATE CASCADE
**  38: CREATE
**  39:
**  40: CASE REINDEX
**  41: EACH
**  42:
**  43: QUERY
**  44: AND ADD
**  45: PRIMARY ANALYZE
**  46:
**  47: ROW ASC DETACH
**  48: CURRENT_TIME CURRENT_DATE
**  49:
**  50:
**  51: EXCLUSIVE TEMPORARY
**  52:
**  53: DEFERRED
**  54: DEFERRABLE
**  55:
**  56: DATABASE
**  57:
**  58: DELETE VIEW GENERATED
**  59: ATTACH
**  60: END
**  61: EXCLUDE
**  62: ESCAPE DESC
**  63: GLOB
**  64: WINDOW ELSE
**  65: COLUMN
**  66: FIRST
**  67:
**  68: GROUPS ALL
**  69: DISTINCT DROP KEY
**  70: BETWEEN
**  71: INITIALLY
**  72: BEGIN
**  73: FILTER CHECK ACTION
**  74: GROUP INDEX
**  75:
**  76: EXISTS DEFAULT
**  77:
**  78: FOR CURRENT_TIMESTAMP
**  79: EXCEPT
**  80:
**  81: CROSS
**  82:
**  83:
**  84:
**  85: CAST
**  86: FOREIGN AUTOINCREMENT
**  87: COMMIT
**  88: CURRENT AFTER ALTER
**  89: FULL FAIL CONFLICT
**  90: EXPLAIN
**  91: CONSTRAINT
**  92: FROM ALWAYS
**  93:
**  94: ABORT
**  95:
**  96: AS DO
**  97: REPLACE WITH RELEASE
**  98: BY RENAME
**  99: RANGE RAISE
** 100: OTHERS
** 101: USING NULLS
** 102: PRAGMA
** 103: JOIN ISNULL OFFSET
** 104: NOT
** 105: OR LAST LEFT
** 106: LIMIT
** 107:
** 108:
** 109: IN
** 110: INTO
** 111: OVER RECURSIVE
** 112: ORDER OUTER
** 113:
** 114: INTERSECT UNBOUNDED
** 115:
** 116:
** 117: RETURNING ON
** 118:
** 119: WHERE
** 120: NO INNER
** 121: NULL
** 122:
** 123: TABLE
** 124: NATURAL NOTNULL
** 125: PRECEDING
** 126: UPDATE UNIQUE
*//* aKWCode[i] is the parser symbol code for the i-th keyword *//* aKWOffset[i] is the index into zKWText[] of the start of
** the text for the i-th keyword. *//* aKWLen[i] is the length (in bytes) of the i-th keyword *//* aKWNext[] forms the hash collision chain.  If aKWHash[i]==0
** then the i-th keyword has no more hash collisions.  Otherwise,
** the next keyword with the same hash is aKWHash[i]-1. *//* aKWHash[i] is the hash value for the i-th keyword *//*   INITIALLYPRIMARY                                                   *//*   ETURNINGRIGHTROLLBACKROWSUNBOUNDEDUNIONUSINGVACUUMVIEWINDOWBY      *//*   EPLACEFIRSTFOLLOWINGFROMFULLIMITIFORDERESTRICTOTHERSOVER           *//*   COMMITCONFLICTCROSSCURRENT_TIMESTAMPRECEDINGFAILASTFILTER          *//*   CURSIVEABORTAFTERENAMEANDROPARTITIONAUTOINCREMENTCASTCOLUMN        *//*   PRAGMATERIALIZEDEFERREDISTINCTUPDATEVALUESVIRTUALWAYSWHENWHERE     *//*   CASECOLLATECREATECURRENT_DATEIMMEDIATEJOINSERTMATCHPLANALYZE       *//*   UNIQUERYWITHOUTERELEASEATTACHBETWEENOTHINGROUPSCASCADEFAULT        *//*   CONSTRAINTOFFSETRIGGERANGENERATEDETACHAVINGLOBEGINNEREFERENCES     *//*   IESNOTNULLIKEXCEPTRANSACTIONATURALTERAISEXCLUSIVEXISTS             *//*   ABLEFTHENDEFERRABLELSEXCLUDELETEMPORARYISNULLSAVEPOINTERSECT       *//*   REINDEXEDESCAPEACHECKEYBEFOREIGNOREGEXPLAINSTEADDATABASELECT       *//* zKWText[] encodes 1007 bytes of keyword text in 667 bytes *//* Hash score: 231 *//***** This file contains automatically generated code ******
**
** The code in this file has been automatically generated by
**
**   sqlite/tool/mkkeywordhash.c
**
** The code in this file implements a function that determines whether
** or not a given identifier is really an SQL keyword.  The same thing
** might be implemented more directly using a hand-written hash table.
** But by using this automatically generated code, the size of the code
** is substantially reduced.  This is important for embedded applications
** on platforms with limited memory.
*//************** Begin file keywordhash.h *************************************//************** Include keywordhash.h in the middle of tokenize.c ************//*
** The sqlite3KeywordCode function looks up an identifier to determine if
** it is a keyword.  If it is a keyword, the token code of that keyword is
** returned.  If the input is not a keyword, TK_ID is returned.
**
** The implementation of this routine was generated by a program,
** mkkeywordhash.c, located in the tool subdirectory of the distribution.
** The output of the mkkeywordhash.c program is written into a file
** named keywordhash.h and then included into this source file by
** the #include below.
*//* 0   1   2   3   4   5   6   7   8   9   A   B   C   D   E   F *//*
** The charMap() macro maps alphabetic characters (only) into their
** lower-case ASCII equivalent.  On ASCII machines, this is just
** an upper-to-lower case map.  On EBCDIC machines we also need
** to adjust the encoding.  The mapping is only valid for alphabetics
** which are the only characters for which this feature is used.
**
** Used by keywordhash.h
*//*         x0  x1  x2  x3  x4  x5  x6  x7  x8  x9  xa  xb  xc  xd  xe  xf *//* First byte of UTF8 BOM:  0xEF 0xBB 0xBF *//* 0x00 *//* Illegal character *//* unicode characters usable in IDs *//* '.' *//* '~' *//* '&' *//* ',' *//* '%' *//* '*' *//* '+' *//* ';' *//* ')' *//* '(' *//* '/'.  / or c-style comment *//* '!'.  Part of != *//* '='.  Part of = or == *//* '>'.  Part of > or >= *//* '<'.  Part of < or <= or <> *//* '-'.  Minus or SQL-style comment *//* '|'.   Bitwise OR or concatenate *//* '['.   [...] style quoted ids *//* '"', '\'', or '`'.  String literals, quoted ids *//* Space characters *//* '?'.  Numeric SQL variables *//* '@', '#', ':'.  Alphabetic SQL variables *//* '$' *//* Digits *//* Alphabetics or '_'.  Usable in a keyword *//* First letter of a keyword *//* The letter 'x', or start of BLOB literal *//* Character classes for tokenizing
**
** In the sqlite3GetToken() function, a switch() on aiClass[c] is implemented
** using a lookup table, whereas a switch() directly on c uses a binary search.
** The lookup table is much faster.  To maximize speed, and to ensure that
** a lookup table is used, all of the classes need to be small integers and
** all of them need to be used within the switch.
*//*
** 2001 September 15
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** An tokenizer for SQL
**
** This file contains C code that splits an SQL input string up into
** individual tokens and sends those tokens one-by-one over to the
** parser for analysis.
*//************** Begin file tokenize.c ****************************************//************** End of parse.c ***********************************************//* YYERRORSYMBOL is not defined *//* If the YYNOERRORRECOVERY macro is defined, then do not attempt to
      ** do any kind of error recovery.  Instead, simply invoke the syntax
      ** error routine and continue going as if nothing had happened.
      **
      ** Applications can set this macro (for example inside %include) if
      ** they intend to abandon the parse upon the first syntax error seen.
      *//* True if yymajor has invoked an error *//* The main parser program.
** The first argument is a pointer to a structure obtained from
** "sqlite3ParserAlloc" which describes the current state of the parser.
** The second argument is the major token number.  The third is
** the minor token.  The fourth optional argument is whatever the
** user wants (and specified in the grammar) and is available for
** use by the action routines.
**
** Inputs:
** <ul>
** <li> A pointer to the parser (an opaque structure.)
** <li> The major token number.
** <li> The minor token number.
** <li> An option argument of a grammar-specified type.
** </ul>
**
** Outputs:
** None.
*//* Silence some compiler warnings *//* YYNOERRORRECOVERY *//* (408) window ::= frame_opt (OPTIMIZED OUT) *//* (407) windowdefn_list ::= windowdefn (OPTIMIZED OUT) *//* (406) with ::= *//* (405) anylist ::= anylist ANY *//* (404) anylist ::= anylist LP anylist RP *//* (403) anylist ::= *//* (402) vtabarg ::= vtabarg vtabargtoken *//* (401) vtabarglist ::= vtabarglist COMMA vtabarg *//* (400) vtabarglist ::= vtabarg *//* (399) kwcolumn_opt ::= COLUMNKW *//* (398) kwcolumn_opt ::= *//* (397) database_kw_opt ::= *//* (396) database_kw_opt ::= DATABASE *//* (395) tridxby ::= *//* (394) trnm ::= nm *//* (393) foreach_clause ::= FOR EACH ROW *//* (392) foreach_clause ::= *//* (391) plus_num ::= INTEGER|FLOAT *//* (390) nmnum ::= DEFAULT *//* (389) nmnum ::= DELETE *//* (388) nmnum ::= ON *//* (387) nmnum ::= nm (OPTIMIZED OUT) *//* (386) nmnum ::= plus_num (OPTIMIZED OUT) *//* (385) exprlist ::= nexprlist *//* (384) case_operand ::= expr *//* (383) likeop ::= LIKE_KW|MATCH *//* (382) expr ::= term (OPTIMIZED OUT) *//* (381) returning ::= *//* (380) indexed_opt ::= indexed_by (OPTIMIZED OUT) *//* (379) as ::= ID|STRING *//* (378) sclp ::= selcollist COMMA *//* (377) oneselect ::= values *//* (376) selectnowith ::= oneselect (OPTIMIZED OUT) *//* (375) resolvetype ::= raisetype (OPTIMIZED OUT) *//* (374) defer_subclause_opt ::= defer_subclause (OPTIMIZED OUT) *//* (373) tconscomma ::= *//* (372) conslist ::= tcons (OPTIMIZED OUT) *//* (371) conslist ::= conslist tconscomma tcons *//* (370) conslist_opt ::= COMMA conslist *//* (369) ccons ::= AS generated *//* (368) ccons ::= GENERATED ALWAYS AS generated *//* (367) ccons ::= NULL onconf *//* (366) carglist ::= *//* (365) carglist ::= carglist ccons *//* (364) signed ::= minus_num (OPTIMIZED OUT) *//* (363) signed ::= plus_num (OPTIMIZED OUT) *//* (362) typename ::= ID|STRING *//* (361) typetoken ::= typename *//* (360) nm ::= STRING *//* (359) nm ::= ID|INDEXED|JOIN_KW *//* (358) columnlist ::= columnname carglist *//* (357) columnlist ::= columnlist COMMA columnname carglist *//* (356) table_option_set ::= table_option (OPTIMIZED OUT) *//* (355) cmd ::= create_table create_table_args *//* (354) savepoint_opt ::= *//* (353) savepoint_opt ::= SAVEPOINT *//* (352) trans_opt ::= TRANSACTION nm *//* (351) trans_opt ::= TRANSACTION *//* (350) trans_opt ::= *//* (349) ecmd ::= explain cmdx SEMI (NEVER REDUCES) *//* (348) ecmd ::= cmdx SEMI *//* (347) ecmd ::= SEMI *//* (346) cmdlist ::= ecmd (OPTIMIZED OUT) *//* (345) cmdlist ::= cmdlist ecmd *//* (344) input ::= cmdlist *//* term ::= QNUMBER *//* filter_clause ::= FILTER LP WHERE expr RP *//* over_clause ::= OVER nm *//* over_clause ::= OVER LP window RP *//* filter_over ::= filter_clause *//* filter_over ::= over_clause *//* filter_over ::= filter_clause over_clause *//* window_clause ::= WINDOW windowdefn_list *//*A-overwrites-X*//* frame_exclude ::= GROUP|TIES *//* frame_exclude ::= CURRENT ROW *//* frame_exclude ::= NO OTHERS *//* frame_exclude_opt ::= EXCLUDE frame_exclude *//* frame_exclude_opt ::= *//* frame_bound ::= expr PRECEDING|FOLLOWING *//* frame_bound ::= CURRENT ROW *//* frame_bound_e ::= UNBOUNDED FOLLOWING *//* frame_bound_s ::= UNBOUNDED PRECEDING *//* frame_bound_e ::= frame_bound *//* frame_bound_s ::= frame_bound *//* frame_opt ::= range_or_rows BETWEEN frame_bound_s AND frame_bound_e frame_exclude_opt *//* frame_opt ::= range_or_rows frame_bound_s frame_exclude_opt *//* frame_opt ::= *//* window ::= nm frame_opt *//* window ::= nm ORDER BY sortlist frame_opt *//* window ::= ORDER BY sortlist frame_opt *//* window ::= nm PARTITION BY nexprlist orderby_opt frame_opt *//* window ::= PARTITION BY nexprlist orderby_opt frame_opt *//* windowdefn ::= nm AS LP window RP *//* windowdefn_list ::= windowdefn_list COMMA windowdefn *//* wqlist ::= wqlist COMMA wqitem *//* wqlist ::= wqitem *//* withnm ::= nm *//* wqitem ::= withnm eidlist_opt wqas LP select RP *//* wqas ::= AS NOT MATERIALIZED *//* wqas ::= AS MATERIALIZED *//* wqas ::= AS *//* with ::= WITH RECURSIVE wqlist *//* with ::= WITH wqlist *//* lp ::= LP *//* vtabargtoken ::= lp anylist RP *//* vtabargtoken ::= ANY *//* vtabarg ::= *//* create_vtab ::= createkw VIRTUAL TABLE ifnotexists nm dbnm USING nm *//* cmd ::= create_vtab LP vtabarglist RP *//* cmd ::= create_vtab *//* cmd ::= ALTER TABLE fullname RENAME kwcolumn_opt nm TO nm *//* add_column_fullname ::= fullname *//* cmd ::= ALTER TABLE fullname DROP kwcolumn_opt nm *//* cmd ::= ALTER TABLE add_column_fullname ADD kwcolumn_opt columnname carglist *//* cmd ::= ALTER TABLE fullname RENAME TO nm *//* cmd ::= ANALYZE nm dbnm *//* cmd ::= ANALYZE *//* cmd ::= REINDEX nm dbnm *//* cmd ::= REINDEX *//* cmd ::= DETACH database_kw_opt expr *//* cmd ::= ATTACH database_kw_opt expr AS expr key_opt *//* cmd ::= DROP TRIGGER ifexists fullname *//* raisetype ::= FAIL *//* raisetype ::= ROLLBACK *//* expr ::= RAISE LP raisetype COMMA expr RP *//* expr ::= RAISE LP IGNORE RP *//*yylhsminor.yy319-overwrites-yymsp[-1].minor.yy637*//* trigger_cmd ::= scanpt select scanpt *//* trigger_cmd ::= DELETE FROM trnm tridxby where_opt scanpt *//*yylhsminor.yy319-overwrites-yymsp[-6].minor.yy502*//* trigger_cmd ::= scanpt insert_cmd INTO trnm idlist_opt select upsert scanpt *//* trigger_cmd ::= UPDATE orconf trnm tridxby SET setlist from where_opt scanpt *//* tridxby ::= NOT INDEXED *//* tridxby ::= INDEXED BY nm *//* trnm ::= nm DOT nm *//* trigger_cmd_list ::= trigger_cmd SEMI *//* trigger_cmd_list ::= trigger_cmd_list trigger_cmd SEMI *//* key_opt ::= KEY expr *//* when_clause ::= WHEN expr *//* key_opt ::= *//* when_clause ::= *//* trigger_event ::= UPDATE OF idlist *//* trigger_event ::= UPDATE *//* trigger_event ::= DELETE|INSERT *//* trigger_time ::= *//* trigger_time ::= INSTEAD OF *//* trigger_time ::= BEFORE|AFTER *//* But, should not be set for CREATE TRIGGER *//* Set by createkw reduce action *//*A-overwrites-T*//* trigger_decl ::= temp TRIGGER ifnotexists nm dbnm trigger_time trigger_event ON fullname foreach_clause when_clause *//* cmd ::= createkw trigger_decl BEGIN trigger_cmd_list END *//* cmd ::= PRAGMA nm dbnm LP minus_num RP *//* cmd ::= PRAGMA nm dbnm EQ minus_num *//* cmd ::= PRAGMA nm dbnm LP nmnum RP *//* cmd ::= PRAGMA nm dbnm EQ nmnum *//* cmd ::= PRAGMA nm dbnm *//* cmd ::= VACUUM nm vinto *//* cmd ::= VACUUM vinto *//* cmd ::= DROP INDEX ifexists fullname *//*A-overwrites-Y*//* eidlist ::= nm collate sortorder *//* eidlist ::= eidlist COMMA nm collate sortorder *//* uniqueflag ::= *//* raisetype ::= ABORT *//* uniqueflag ::= UNIQUE *//* cmd ::= createkw uniqueflag INDEX ifnotexists nm dbnm ON nm LP sortlist RP where_opt *//* eidlist_opt ::= LP eidlist RP *//* paren_exprlist ::= LP exprlist RP *//* nexprlist ::= expr *//* nexprlist ::= nexprlist COMMA expr *//* case_exprlist ::= WHEN expr THEN expr *//* case_exprlist ::= case_exprlist WHEN expr THEN expr *//* expr ::= CASE case_operand case_exprlist case_else END *//* expr ::= EXISTS LP select RP *//* expr ::= expr in_op nm dbnm paren_exprlist *//* expr ::= expr in_op LP select RP *//* expr ::= LP select RP *//* Expressions of the form
      **
      **      expr1 IN ()
      **      expr1 NOT IN ()
      **
      ** simplify to constants 0 (false) and 1 (true), respectively,
      ** regardless of the value of expr1.
      *//* expr ::= expr in_op LP exprlist RP *//* expr ::= expr between_op expr AND expr *//* in_op ::= IN *//* between_op ::= BETWEEN *//* expr ::= expr PTR expr *//*A-overwrites-B*//* expr ::= PLUS|MINUS expr *//* expr ::= BITNOT expr *//* expr ::= NOT expr *//* expr ::= expr IS DISTINCT FROM expr *//* expr ::= expr IS NOT DISTINCT FROM expr *//* expr ::= expr IS NOT expr *//* expr ::= expr IS expr *//* expr ::= expr NOT NULL *//* expr ::= expr ISNULL|NOTNULL *//* expr ::= expr likeop expr ESCAPE expr *//* expr ::= expr likeop expr *//*yymsp[-1].minor.yy0-overwrite-yymsp[0].minor.yy0*//* likeop ::= NOT LIKE_KW|MATCH *//* expr ::= expr CONCAT expr *//* expr ::= expr STAR|SLASH|REM expr *//* expr ::= expr PLUS|MINUS expr *//* expr ::= expr BITAND|BITOR|LSHIFT|RSHIFT expr *//* expr ::= expr EQ|NE expr *//* expr ::= expr LT|GT|GE|LE expr *//* expr ::= LP nexprlist COMMA expr RP *//* term ::= CTIME_KW *//* expr ::= ID|INDEXED|JOIN_KW LP STAR RP filter_over *//* expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist ORDER BY sortlist RP filter_over *//* expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist RP filter_over *//* expr ::= ID|INDEXED|JOIN_KW LP STAR RP *//* expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist ORDER BY sortlist RP *//* expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist RP *//* expr ::= CAST LP expr AS typetoken RP *//* expr ::= expr COLLATE ID|STRING *//* When doing a nested parse, one can include terms in an expression
    ** that look like this:   #1 #2 ...  These terms refer to registers
    ** in the virtual machine.  #N is the N-th register. *//* expr ::= VARIABLE *//* term ::= INTEGER *//* term ::= STRING *//* term ::= NULL|FLOAT|BLOB *//* expr ::= nm DOT nm DOT nm *//* expr ::= nm DOT nm *//* expr ::= ID|INDEXED|JOIN_KW *//* idlist ::= nm *//* idlist ::= idlist COMMA nm *//* idlist_opt ::= LP idlist RP *//* idlist_opt ::= *//* returning ::= RETURNING selcollist *//* upsert ::= ON CONFLICT DO UPDATE SET setlist where_opt returning *//* upsert ::= ON CONFLICT DO NOTHING returning *//* upsert ::= ON CONFLICT LP sortlist RP where_opt DO NOTHING upsert *//* upsert ::= ON CONFLICT LP sortlist RP where_opt DO UPDATE SET setlist where_opt upsert *//* upsert ::= RETURNING selcollist *//* upsert ::= *//* cmd ::= with insert_cmd INTO xfullname idlist_opt DEFAULT VALUES returning *//* cmd ::= with insert_cmd INTO xfullname idlist_opt select upsert *//* setlist ::= LP idlist RP EQ expr *//* setlist ::= nm EQ expr *//* setlist ::= setlist COMMA LP idlist RP EQ expr *//* setlist ::= setlist COMMA nm EQ expr *//* cmd ::= with UPDATE orconf xfullname indexed_opt SET setlist from where_opt_ret *//* where_opt_ret ::= WHERE expr RETURNING selcollist *//* where_opt_ret ::= RETURNING selcollist *//* cmd ::= with DELETE FROM xfullname indexed_opt where_opt_ret *//* limit_opt ::= LIMIT expr COMMA expr *//* limit_opt ::= LIMIT expr OFFSET expr *//* limit_opt ::= LIMIT expr *//* vinto ::= INTO expr *//* case_else ::= ELSE expr *//* where_opt_ret ::= WHERE expr *//* where_opt ::= WHERE expr *//* having_opt ::= HAVING expr *//* vinto ::= *//* case_operand ::= *//* case_else ::= *//* where_opt_ret ::= *//* where_opt ::= *//* limit_opt ::= *//* having_opt ::= *//* nulls ::= NULLS LAST *//* nulls ::= NULLS FIRST *//* nulls ::= *//* sortorder ::= *//* sortorder ::= DESC *//* sortorder ::= ASC *//* sortlist ::= expr sortorder nulls *//* sortlist ::= sortlist COMMA expr sortorder nulls *//* groupby_opt ::= GROUP BY nexprlist *//* orderby_opt ::= ORDER BY sortlist *//* indexed_by ::= NOT INDEXED *//* indexed_by ::= INDEXED BY nm *//* on_using ::= *//* on_using ::= USING LP idlist RP *//* on_using ::= ON expr *//*X-overwrites-A*//* joinop ::= JOIN_KW nm nm JOIN *//* joinop ::= JOIN_KW nm JOIN *//* joinop ::= JOIN_KW JOIN *//* joinop ::= COMMA|JOIN *//* xfullname ::= nm AS nm *//* xfullname ::= nm DOT nm AS nm *//* xfullname ::= nm DOT nm *//* xfullname ::= nm *//* fullname ::= nm DOT nm *//* fullname ::= nm *//* indexed_opt ::= *//* dbnm ::= *//* seltablist ::= stl_prefix LP seltablist RP as on_using *//* seltablist ::= stl_prefix LP select RP as on_using *//* seltablist ::= stl_prefix nm dbnm LP exprlist RP as on_using *//* seltablist ::= stl_prefix nm dbnm as indexed_by on_using *//* seltablist ::= stl_prefix nm dbnm as on_using *//* stl_prefix ::= seltablist joinop *//* from ::= FROM seltablist *//* stl_prefix ::= *//* from ::= *//* minus_num ::= MINUS INTEGER|FLOAT *//* plus_num ::= PLUS INTEGER|FLOAT *//* dbnm ::= DOT nm *//* as ::= AS nm *//* selcollist ::= sclp scanpt nm DOT STAR *//* selcollist ::= sclp scanpt STAR *//* selcollist ::= sclp scanpt expr scanpt as *//* eidlist_opt ::= *//* paren_exprlist ::= *//* exprlist ::= *//* groupby_opt ::= *//* orderby_opt ::= *//* sclp ::= *//* distinct ::= ALL *//* distinct ::= DISTINCT *//* mvalues ::= mvalues COMMA LP nexprlist RP *//* mvalues ::= values COMMA LP nexprlist RP *//* oneselect ::= mvalues *//* values ::= VALUES LP nexprlist RP *//* oneselect ::= SELECT distinct selcollist from where_opt groupby_opt having_opt window_clause orderby_opt limit_opt *//* oneselect ::= SELECT distinct selcollist from where_opt groupby_opt having_opt orderby_opt limit_opt *//* multiselect_op ::= UNION ALL *//*A-overwrites-OP*//* multiselect_op ::= EXCEPT|INTERSECT *//* multiselect_op ::= UNION *//* selectnowith ::= selectnowith multiselect_op oneselect *//* select ::= selectnowith *//* select ::= WITH RECURSIVE wqlist selectnowith *//* select ::= WITH wqlist selectnowith *//* cmd ::= select *//* cmd ::= DROP VIEW ifexists fullname *//* cmd ::= createkw temp VIEW ifnotexists nm dbnm eidlist_opt AS select *//* cmd ::= DROP TABLE ifexists fullname *//* insert_cmd ::= REPLACE *//* resolvetype ::= REPLACE *//* resolvetype ::= IGNORE *//* onconf ::= ON CONFLICT resolvetype *//* orconf ::= *//* onconf ::= *//* tcons ::= FOREIGN KEY LP eidlist RP REFERENCES nm eidlist_opt refargs defer_subclause_opt *//* tcons ::= CHECK LP expr RP onconf *//* tcons ::= UNIQUE LP sortlist RP onconf *//* tcons ::= PRIMARY KEY LP sortlist autoinc RP onconf *//* tconscomma ::= COMMA *//* init_deferred_pred_opt ::= INITIALLY IMMEDIATE *//* collate ::= COLLATE ID|STRING *//* in_op ::= NOT IN *//* between_op ::= NOT BETWEEN *//* ifexists ::= IF EXISTS *//* init_deferred_pred_opt ::= INITIALLY DEFERRED *//* insert_cmd ::= INSERT orconf *//* orconf ::= OR resolvetype *//* defer_subclause ::= DEFERRABLE init_deferred_pred_opt *//* defer_subclause ::= NOT DEFERRABLE init_deferred_pred_opt *//* EV: R-33326-45252 *//* refact ::= NO ACTION *//* refact ::= RESTRICT *//* refact ::= CASCADE *//* refact ::= SET DEFAULT *//* refact ::= SET NULL *//* refarg ::= ON UPDATE refact *//* refarg ::= ON DELETE refact *//* refarg ::= ON INSERT refact *//* refarg ::= MATCH nm *//* refargs ::= refargs refarg *//* EV: R-19803-45884 *//* refargs ::= *//* autoinc ::= AUTOINCR *//* generated ::= LP expr RP ID *//* generated ::= LP expr RP *//* ccons ::= COLLATE ID|STRING *//* ccons ::= defer_subclause *//* ccons ::= REFERENCES nm eidlist_opt refargs *//* ccons ::= CHECK LP expr RP *//* ccons ::= UNIQUE onconf *//* ccons ::= PRIMARY KEY sortorder onconf autoinc *//* ccons ::= NOT NULL onconf *//* ccons ::= DEFAULT scantok ID|INDEXED *//* ccons ::= DEFAULT MINUS scantok term *//* ccons ::= DEFAULT PLUS scantok term *//* ccons ::= DEFAULT LP expr RP *//* ccons ::= DEFAULT scantok term *//* tcons ::= CONSTRAINT nm *//* ccons ::= CONSTRAINT nm *//* scantok ::= *//* scanpt ::= *//* typename ::= typename ID|STRING *//* typetoken ::= typename LP signed COMMA signed RP *//* typetoken ::= typename LP signed RP *//* as ::= *//* conslist_opt ::= *//* typetoken ::= *//* columnname ::= nm typetoken *//* table_option ::= nm *//* table_option ::= WITHOUT nm *//* table_option_set ::= table_option_set COMMA table_option *//* table_option_set ::= *//* create_table_args ::= AS select *//* create_table_args ::= LP columnlist conslist_opt RP table_option_set *//* temp ::= TEMP *//* ifnotexists ::= IF NOT EXISTS *//* collate ::= *//* distinct ::= *//* ifexists ::= *//* defer_subclause_opt ::= *//* init_deferred_pred_opt ::= *//* autoinc ::= *//* temp ::= *//* ifnotexists ::= *//* createkw ::= CREATE *//* create_table ::= createkw temp TABLE ifnotexists nm dbnm *//* cmd ::= ROLLBACK trans_opt TO savepoint_opt nm *//* cmd ::= RELEASE savepoint_opt nm *//* cmd ::= SAVEPOINT nm *//* cmd ::= ROLLBACK trans_opt *//* cmd ::= COMMIT|END trans_opt *//* range_or_rows ::= RANGE|ROWS|GROUPS *//* transtype ::= EXCLUSIVE *//* transtype ::= IMMEDIATE *//* transtype ::= DEFERRED *//* transtype ::= *//* cmd ::= BEGIN transtype trans_opt *//* cmdx ::= cmd *//* explain ::= EXPLAIN QUERY PLAN *//* explain ::= EXPLAIN *//* Lookahead token, or YYNOCODE if none *//*
** Perform a reduce action and the shift that must immediately
** follow the reduce.
**
** The yyLookahead and yyLookaheadToken parameters provide reduce actions
** access to the lookahead token (if any).  The yyLookahead will be YYNOCODE
** if the lookahead token has already been consumed.  As this procedure is
** only called from one place, optimizing compilers will in-line it, which
** means that the extra parameters have no performance impact.
*//* (408) window ::= frame_opt *//* (407) windowdefn_list ::= windowdefn *//* (387) nmnum ::= nm *//* (386) nmnum ::= plus_num *//* (382) expr ::= term *//* (380) indexed_opt ::= indexed_by *//* (376) selectnowith ::= oneselect *//* (375) resolvetype ::= raisetype *//* (374) defer_subclause_opt ::= defer_subclause *//* (372) conslist ::= tcons *//* (364) signed ::= minus_num *//* (363) signed ::= plus_num *//* (356) table_option_set ::= table_option *//* (349) ecmd ::= explain cmdx SEMI *//* (346) cmdlist ::= ecmd *//* (343) term ::= QNUMBER *//* (342) filter_clause ::= FILTER LP WHERE expr RP *//* (341) over_clause ::= OVER nm *//* (340) over_clause ::= OVER LP window RP *//* (339) filter_over ::= filter_clause *//* (338) filter_over ::= over_clause *//* (337) filter_over ::= filter_clause over_clause *//* (336) window_clause ::= WINDOW windowdefn_list *//* (335) frame_exclude ::= GROUP|TIES *//* (334) frame_exclude ::= CURRENT ROW *//* (333) frame_exclude ::= NO OTHERS *//* (332) frame_exclude_opt ::= EXCLUDE frame_exclude *//* (331) frame_exclude_opt ::= *//* (330) frame_bound ::= CURRENT ROW *//* (329) frame_bound ::= expr PRECEDING|FOLLOWING *//* (328) frame_bound_e ::= UNBOUNDED FOLLOWING *//* (327) frame_bound_e ::= frame_bound *//* (326) frame_bound_s ::= UNBOUNDED PRECEDING *//* (325) frame_bound_s ::= frame_bound *//* (324) range_or_rows ::= RANGE|ROWS|GROUPS *//* (323) frame_opt ::= range_or_rows BETWEEN frame_bound_s AND frame_bound_e frame_exclude_opt *//* (322) frame_opt ::= range_or_rows frame_bound_s frame_exclude_opt *//* (321) frame_opt ::= *//* (320) window ::= nm frame_opt *//* (319) window ::= nm ORDER BY sortlist frame_opt *//* (318) window ::= ORDER BY sortlist frame_opt *//* (317) window ::= nm PARTITION BY nexprlist orderby_opt frame_opt *//* (316) window ::= PARTITION BY nexprlist orderby_opt frame_opt *//* (315) windowdefn ::= nm AS LP window RP *//* (314) windowdefn_list ::= windowdefn_list COMMA windowdefn *//* (313) wqlist ::= wqlist COMMA wqitem *//* (312) wqlist ::= wqitem *//* (311) withnm ::= nm *//* (310) wqitem ::= withnm eidlist_opt wqas LP select RP *//* (309) wqas ::= AS NOT MATERIALIZED *//* (308) wqas ::= AS MATERIALIZED *//* (307) wqas ::= AS *//* (306) with ::= WITH RECURSIVE wqlist *//* (305) with ::= WITH wqlist *//* (304) lp ::= LP *//* (303) vtabargtoken ::= lp anylist RP *//* (302) vtabargtoken ::= ANY *//* (301) vtabarg ::= *//* (300) create_vtab ::= createkw VIRTUAL TABLE ifnotexists nm dbnm USING nm *//* (299) cmd ::= create_vtab LP vtabarglist RP *//* (298) cmd ::= create_vtab *//* (297) cmd ::= ALTER TABLE fullname RENAME kwcolumn_opt nm TO nm *//* (296) add_column_fullname ::= fullname *//* (295) cmd ::= ALTER TABLE fullname DROP kwcolumn_opt nm *//* (294) cmd ::= ALTER TABLE add_column_fullname ADD kwcolumn_opt columnname carglist *//* (293) cmd ::= ALTER TABLE fullname RENAME TO nm *//* (292) cmd ::= ANALYZE nm dbnm *//* (291) cmd ::= ANALYZE *//* (290) cmd ::= REINDEX nm dbnm *//* (289) cmd ::= REINDEX *//* (288) key_opt ::= KEY expr *//* (287) key_opt ::= *//* (286) cmd ::= DETACH database_kw_opt expr *//* (285) cmd ::= ATTACH database_kw_opt expr AS expr key_opt *//* (284) cmd ::= DROP TRIGGER ifexists fullname *//* (283) raisetype ::= FAIL *//* (282) raisetype ::= ABORT *//* (281) raisetype ::= ROLLBACK *//* (280) expr ::= RAISE LP raisetype COMMA expr RP *//* (279) expr ::= RAISE LP IGNORE RP *//* (278) trigger_cmd ::= scanpt select scanpt *//* (277) trigger_cmd ::= DELETE FROM trnm tridxby where_opt scanpt *//* (276) trigger_cmd ::= scanpt insert_cmd INTO trnm idlist_opt select upsert scanpt *//* (275) trigger_cmd ::= UPDATE orconf trnm tridxby SET setlist from where_opt scanpt *//* (274) tridxby ::= NOT INDEXED *//* (273) tridxby ::= INDEXED BY nm *//* (272) trnm ::= nm DOT nm *//* (271) trigger_cmd_list ::= trigger_cmd SEMI *//* (270) trigger_cmd_list ::= trigger_cmd_list trigger_cmd SEMI *//* (269) when_clause ::= WHEN expr *//* (268) when_clause ::= *//* (267) trigger_event ::= UPDATE OF idlist *//* (266) trigger_event ::= UPDATE *//* (265) trigger_event ::= DELETE|INSERT *//* (264) trigger_time ::= *//* (263) trigger_time ::= INSTEAD OF *//* (262) trigger_time ::= BEFORE|AFTER *//* (261) trigger_decl ::= temp TRIGGER ifnotexists nm dbnm trigger_time trigger_event ON fullname foreach_clause when_clause *//* (260) cmd ::= createkw trigger_decl BEGIN trigger_cmd_list END *//* (259) minus_num ::= MINUS INTEGER|FLOAT *//* (258) plus_num ::= PLUS INTEGER|FLOAT *//* (257) cmd ::= PRAGMA nm dbnm LP minus_num RP *//* (256) cmd ::= PRAGMA nm dbnm EQ minus_num *//* (255) cmd ::= PRAGMA nm dbnm LP nmnum RP *//* (254) cmd ::= PRAGMA nm dbnm EQ nmnum *//* (253) cmd ::= PRAGMA nm dbnm *//* (252) vinto ::= *//* (251) vinto ::= INTO expr *//* (250) cmd ::= VACUUM nm vinto *//* (249) cmd ::= VACUUM vinto *//* (248) cmd ::= DROP INDEX ifexists fullname *//* (247) collate ::= COLLATE ID|STRING *//* (246) collate ::= *//* (245) eidlist ::= nm collate sortorder *//* (244) eidlist ::= eidlist COMMA nm collate sortorder *//* (243) eidlist_opt ::= LP eidlist RP *//* (242) eidlist_opt ::= *//* (241) uniqueflag ::= *//* (240) uniqueflag ::= UNIQUE *//* (239) cmd ::= createkw uniqueflag INDEX ifnotexists nm dbnm ON nm LP sortlist RP where_opt *//* (238) paren_exprlist ::= LP exprlist RP *//* (237) paren_exprlist ::= *//* (236) nexprlist ::= expr *//* (235) nexprlist ::= nexprlist COMMA expr *//* (234) exprlist ::= *//* (233) case_operand ::= *//* (232) case_else ::= *//* (231) case_else ::= ELSE expr *//* (230) case_exprlist ::= WHEN expr THEN expr *//* (229) case_exprlist ::= case_exprlist WHEN expr THEN expr *//* (228) expr ::= CASE case_operand case_exprlist case_else END *//* (227) expr ::= EXISTS LP select RP *//* (226) expr ::= expr in_op nm dbnm paren_exprlist *//* (225) expr ::= expr in_op LP select RP *//* (224) expr ::= LP select RP *//* (223) expr ::= expr in_op LP exprlist RP *//* (222) in_op ::= NOT IN *//* (221) in_op ::= IN *//* (220) expr ::= expr between_op expr AND expr *//* (219) between_op ::= NOT BETWEEN *//* (218) between_op ::= BETWEEN *//* (217) expr ::= expr PTR expr *//* (216) expr ::= PLUS|MINUS expr *//* (215) expr ::= BITNOT expr *//* (214) expr ::= NOT expr *//* (213) expr ::= expr IS DISTINCT FROM expr *//* (212) expr ::= expr IS NOT DISTINCT FROM expr *//* (211) expr ::= expr IS NOT expr *//* (210) expr ::= expr IS expr *//* (209) expr ::= expr NOT NULL *//* (208) expr ::= expr ISNULL|NOTNULL *//* (207) expr ::= expr likeop expr ESCAPE expr *//* (206) expr ::= expr likeop expr *//* (205) likeop ::= NOT LIKE_KW|MATCH *//* (204) expr ::= expr CONCAT expr *//* (203) expr ::= expr STAR|SLASH|REM expr *//* (202) expr ::= expr PLUS|MINUS expr *//* (201) expr ::= expr BITAND|BITOR|LSHIFT|RSHIFT expr *//* (200) expr ::= expr EQ|NE expr *//* (199) expr ::= expr LT|GT|GE|LE expr *//* (198) expr ::= expr OR expr *//* (197) expr ::= expr AND expr *//* (196) expr ::= LP nexprlist COMMA expr RP *//* (195) term ::= CTIME_KW *//* (194) expr ::= ID|INDEXED|JOIN_KW LP STAR RP filter_over *//* (193) expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist ORDER BY sortlist RP filter_over *//* (192) expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist RP filter_over *//* (191) expr ::= ID|INDEXED|JOIN_KW LP STAR RP *//* (190) expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist ORDER BY sortlist RP *//* (189) expr ::= ID|INDEXED|JOIN_KW LP distinct exprlist RP *//* (188) expr ::= CAST LP expr AS typetoken RP *//* (187) expr ::= expr COLLATE ID|STRING *//* (186) expr ::= VARIABLE *//* (185) term ::= INTEGER *//* (184) term ::= STRING *//* (183) term ::= NULL|FLOAT|BLOB *//* (182) expr ::= nm DOT nm DOT nm *//* (181) expr ::= nm DOT nm *//* (180) expr ::= ID|INDEXED|JOIN_KW *//* (179) expr ::= LP expr RP *//* (178) idlist ::= nm *//* (177) idlist ::= idlist COMMA nm *//* (176) idlist_opt ::= LP idlist RP *//* (175) idlist_opt ::= *//* (174) insert_cmd ::= REPLACE *//* (173) insert_cmd ::= INSERT orconf *//* (172) returning ::= RETURNING selcollist *//* (171) upsert ::= ON CONFLICT DO UPDATE SET setlist where_opt returning *//* (170) upsert ::= ON CONFLICT DO NOTHING returning *//* (169) upsert ::= ON CONFLICT LP sortlist RP where_opt DO NOTHING upsert *//* (168) upsert ::= ON CONFLICT LP sortlist RP where_opt DO UPDATE SET setlist where_opt upsert *//* (167) upsert ::= RETURNING selcollist *//* (166) upsert ::= *//* (165) cmd ::= with insert_cmd INTO xfullname idlist_opt DEFAULT VALUES returning *//* (164) cmd ::= with insert_cmd INTO xfullname idlist_opt select upsert *//* (163) setlist ::= LP idlist RP EQ expr *//* (162) setlist ::= nm EQ expr *//* (161) setlist ::= setlist COMMA LP idlist RP EQ expr *//* (160) setlist ::= setlist COMMA nm EQ expr *//* (159) cmd ::= with UPDATE orconf xfullname indexed_opt SET setlist from where_opt_ret *//* (158) where_opt_ret ::= WHERE expr RETURNING selcollist *//* (157) where_opt_ret ::= RETURNING selcollist *//* (156) where_opt_ret ::= WHERE expr *//* (155) where_opt_ret ::= *//* (154) where_opt ::= WHERE expr *//* (153) where_opt ::= *//* (152) cmd ::= with DELETE FROM xfullname indexed_opt where_opt_ret *//* (151) limit_opt ::= LIMIT expr COMMA expr *//* (150) limit_opt ::= LIMIT expr OFFSET expr *//* (149) limit_opt ::= LIMIT expr *//* (148) limit_opt ::= *//* (147) having_opt ::= HAVING expr *//* (146) having_opt ::= *//* (145) groupby_opt ::= GROUP BY nexprlist *//* (144) groupby_opt ::= *//* (143) nulls ::= *//* (142) nulls ::= NULLS LAST *//* (141) nulls ::= NULLS FIRST *//* (140) sortorder ::= *//* (139) sortorder ::= DESC *//* (138) sortorder ::= ASC *//* (137) sortlist ::= expr sortorder nulls *//* (136) sortlist ::= sortlist COMMA expr sortorder nulls *//* (135) orderby_opt ::= ORDER BY sortlist *//* (134) orderby_opt ::= *//* (133) indexed_by ::= NOT INDEXED *//* (132) indexed_by ::= INDEXED BY nm *//* (131) indexed_opt ::= *//* (130) on_using ::= *//* (129) on_using ::= USING LP idlist RP *//* (128) on_using ::= ON expr *//* (127) joinop ::= JOIN_KW nm nm JOIN *//* (126) joinop ::= JOIN_KW nm JOIN *//* (125) joinop ::= JOIN_KW JOIN *//* (124) joinop ::= COMMA|JOIN *//* (123) xfullname ::= nm AS nm *//* (122) xfullname ::= nm DOT nm AS nm *//* (121) xfullname ::= nm DOT nm *//* (120) xfullname ::= nm *//* (119) fullname ::= nm DOT nm *//* (118) fullname ::= nm *//* (117) dbnm ::= DOT nm *//* (116) dbnm ::= *//* (115) seltablist ::= stl_prefix LP seltablist RP as on_using *//* (114) seltablist ::= stl_prefix LP select RP as on_using *//* (113) seltablist ::= stl_prefix nm dbnm LP exprlist RP as on_using *//* (112) seltablist ::= stl_prefix nm dbnm as indexed_by on_using *//* (111) seltablist ::= stl_prefix nm dbnm as on_using *//* (110) stl_prefix ::= *//* (109) stl_prefix ::= seltablist joinop *//* (108) from ::= FROM seltablist *//* (107) from ::= *//* (106) as ::= *//* (105) as ::= AS nm *//* (104) selcollist ::= sclp scanpt nm DOT STAR *//* (103) selcollist ::= sclp scanpt STAR *//* (102) selcollist ::= sclp scanpt expr scanpt as *//* (101) sclp ::= *//* (100) distinct ::= *//* (99) distinct ::= ALL *//* (98) distinct ::= DISTINCT *//* (97) mvalues ::= mvalues COMMA LP nexprlist RP *//* (96) mvalues ::= values COMMA LP nexprlist RP *//* (95) oneselect ::= mvalues *//* (94) values ::= VALUES LP nexprlist RP *//* (93) oneselect ::= SELECT distinct selcollist from where_opt groupby_opt having_opt window_clause orderby_opt limit_opt *//* (92) oneselect ::= SELECT distinct selcollist from where_opt groupby_opt having_opt orderby_opt limit_opt *//* (91) multiselect_op ::= EXCEPT|INTERSECT *//* (90) multiselect_op ::= UNION ALL *//* (89) multiselect_op ::= UNION *//* (88) selectnowith ::= selectnowith multiselect_op oneselect *//* (87) select ::= selectnowith *//* (86) select ::= WITH RECURSIVE wqlist selectnowith *//* (85) select ::= WITH wqlist selectnowith *//* (84) cmd ::= select *//* (83) cmd ::= DROP VIEW ifexists fullname *//* (82) cmd ::= createkw temp VIEW ifnotexists nm dbnm eidlist_opt AS select *//* (81) ifexists ::= *//* (80) ifexists ::= IF EXISTS *//* (79) cmd ::= DROP TABLE ifexists fullname *//* (78) resolvetype ::= REPLACE *//* (77) resolvetype ::= IGNORE *//* (76) orconf ::= OR resolvetype *//* (75) orconf ::= *//* (74) onconf ::= ON CONFLICT resolvetype *//* (73) onconf ::= *//* (72) defer_subclause_opt ::= *//* (71) tcons ::= FOREIGN KEY LP eidlist RP REFERENCES nm eidlist_opt refargs defer_subclause_opt *//* (70) tcons ::= CHECK LP expr RP onconf *//* (69) tcons ::= UNIQUE LP sortlist RP onconf *//* (68) tcons ::= PRIMARY KEY LP sortlist autoinc RP onconf *//* (67) tcons ::= CONSTRAINT nm *//* (66) tconscomma ::= COMMA *//* (65) conslist_opt ::= *//* (64) init_deferred_pred_opt ::= INITIALLY IMMEDIATE *//* (63) init_deferred_pred_opt ::= INITIALLY DEFERRED *//* (62) init_deferred_pred_opt ::= *//* (61) defer_subclause ::= DEFERRABLE init_deferred_pred_opt *//* (60) defer_subclause ::= NOT DEFERRABLE init_deferred_pred_opt *//* (59) refact ::= NO ACTION *//* (58) refact ::= RESTRICT *//* (57) refact ::= CASCADE *//* (56) refact ::= SET DEFAULT *//* (55) refact ::= SET NULL *//* (54) refarg ::= ON UPDATE refact *//* (53) refarg ::= ON DELETE refact *//* (52) refarg ::= ON INSERT refact *//* (51) refarg ::= MATCH nm *//* (50) refargs ::= refargs refarg *//* (49) refargs ::= *//* (48) autoinc ::= AUTOINCR *//* (47) autoinc ::= *//* (46) generated ::= LP expr RP ID *//* (45) generated ::= LP expr RP *//* (44) ccons ::= COLLATE ID|STRING *//* (43) ccons ::= defer_subclause *//* (42) ccons ::= REFERENCES nm eidlist_opt refargs *//* (41) ccons ::= CHECK LP expr RP *//* (40) ccons ::= UNIQUE onconf *//* (39) ccons ::= PRIMARY KEY sortorder onconf autoinc *//* (38) ccons ::= NOT NULL onconf *//* (37) ccons ::= DEFAULT scantok ID|INDEXED *//* (36) ccons ::= DEFAULT MINUS scantok term *//* (35) ccons ::= DEFAULT PLUS scantok term *//* (34) ccons ::= DEFAULT LP expr RP *//* (33) ccons ::= DEFAULT scantok term *//* (32) ccons ::= CONSTRAINT nm *//* (31) scantok ::= *//* (30) scanpt ::= *//* (29) typename ::= typename ID|STRING *//* (28) typetoken ::= typename LP signed COMMA signed RP *//* (27) typetoken ::= typename LP signed RP *//* (26) typetoken ::= *//* (25) columnname ::= nm typetoken *//* (24) table_option ::= nm *//* (23) table_option ::= WITHOUT nm *//* (22) table_option_set ::= table_option_set COMMA table_option *//* (21) table_option_set ::= *//* (20) create_table_args ::= AS select *//* (19) create_table_args ::= LP columnlist conslist_opt RP table_option_set *//* (18) temp ::= *//* (17) temp ::= TEMP *//* (16) ifnotexists ::= IF NOT EXISTS *//* (15) ifnotexists ::= *//* (14) createkw ::= CREATE *//* (13) create_table ::= createkw temp TABLE ifnotexists nm dbnm *//* (12) cmd ::= ROLLBACK trans_opt TO savepoint_opt nm *//* (11) cmd ::= RELEASE savepoint_opt nm *//* (10) cmd ::= SAVEPOINT nm *//* (9) cmd ::= ROLLBACK trans_opt *//* (8) cmd ::= COMMIT|END trans_opt *//* (7) transtype ::= EXCLUSIVE *//* (6) transtype ::= IMMEDIATE *//* (5) transtype ::= DEFERRED *//* (4) transtype ::= *//* (3) cmd ::= BEGIN transtype trans_opt *//* (2) cmdx ::= cmd *//* (1) explain ::= EXPLAIN QUERY PLAN *//* (0) explain ::= EXPLAIN *//* For rule J, yyRuleInfoNRhs[J] contains the negative of the number
** of symbols on the right-hand side of that rule. *//* For rule J, yyRuleInfoLhs[J] contains the symbol on the left-hand side
** of that rule *//* YYWILDCARD *//* This array of booleans keeps track of the parser statement
** coverage.  The element yycoverage[X][Y] is set when the parser
** is in state X and has a lookahead token Y.  In a well-tested
** systems, every element of this matrix should end up being set.
*//* sqlite3Parser_ENGINEALWAYSONSTACK *//*
** Deallocate and destroy a parser.  Destructors are called for
** all stack elements before shutting the parser down.
**
** If the YYPARSEFREENEVERNULL macro exists (for example because it
** is defined in a %include section of the input grammar) then it is
** assumed that the input pointer is never NULL.
*//* In-lined version of calling yy_pop_parser_stack() for each
  ** element left in the stack *//* frame_bound_e *//* frame_bound_s *//* frame_bound *//* trigger_event *//* trigger_cmd *//* trigger_cmd_list *//* over_clause *//* frame_opt *//* window *//* windowdefn *//* filter_over *//* idlist_opt *//* idlist *//* windowdefn_list *//* window_clause *//* wqlist *//* xfullname *//* stl_prefix *//* seltablist *//* from *//* fullname *//* part_opt *//* case_exprlist *//* paren_exprlist *//* setlist *//* sclp *//* nexprlist *//* orderby_opt *//* groupby_opt *//* selcollist *//* eidlist *//* sortlist *//* eidlist_opt *//* filter_clause *//* key_opt *//* when_clause *//* vinto *//* case_else *//* case_operand *//* where_opt_ret *//* having_opt *//* where_opt *//* mvalues *//* values *//* oneselect *//* selectnowith *//* select *//* The following function deletes the "minor type" or semantic value
** associated with a symbol.  The symbol can be either a terminal
** or nonterminal. "yymajor" is the symbol code, and "yypminor" is
** a pointer to the value to be deleted.  The code used to do the
** deletions is derived from the %destructor and/or %token_destructor
** directives of the input grammar.
*//*
** This function allocates a new parser.
** The only argument is a pointer to a function which works like
** malloc.
**
** Inputs:
** A pointer to the function used to allocate memory.
**
** Outputs:
** A pointer to a parser.  This pointer is used in subsequent calls
** to sqlite3Parser and sqlite3ParserFree.
*//* Datatype of the argument to the memory allocated passed as the
** second argument to sqlite3ParserAlloc() below.  This can be changed by
** putting an appropriate #define in the %include section of the input
** grammar.
*//* For builds that do no have a growable stack, yyGrowStack always
** returns an error.
*//* YYGROWABLESTACK *//* 408 *//* 407 *//* 406 *//* 405 *//* 404 *//* 403 *//* 402 *//* 401 *//* 400 *//* 399 *//* 398 *//* 397 *//* 396 *//* 395 *//* 394 *//* 393 *//* 392 *//* 391 *//* 390 *//* 389 *//* 388 *//* 387 *//* 386 *//* 385 *//* 384 *//* 383 *//* 382 *//* 381 *//* 380 *//* 379 *//* 378 *//* 377 *//* 376 *//* 375 *//* 374 *//* 373 *//* 372 *//* 371 *//* 370 *//* 369 *//* 368 *//* 367 *//* 366 *//* 365 *//* 364 *//* 363 *//* 362 *//* 361 *//* 360 *//* 359 *//* 358 *//* 357 *//* 356 *//* 355 *//* 354 *//* 353 *//* 352 *//* 351 *//* 350 *//* 349 *//* 348 *//* 347 *//* 346 *//* 345 *//* 344 *//* 343 *//* 342 *//* 341 *//* 340 *//* 339 *//* 338 *//* 337 *//* 336 *//* 335 *//* 334 *//* 333 *//* 332 *//* 331 *//* 330 *//* 329 *//* 328 *//* 327 *//* 326 *//* 325 *//* 324 *//* 323 *//* 322 *//* 321 *//* 320 *//* 319 *//* 318 *//* 317 *//* 316 *//* 315 *//* 314 *//* 313 *//* 312 *//* 311 *//* 310 *//* 309 *//* 308 *//* 307 *//* 306 *//* 305 *//* 304 *//* 303 *//* 302 *//* 301 *//* 300 *//* 299 *//* 298 *//* 297 *//* 296 *//* 295 *//* 294 *//* 293 *//* 292 *//* 291 *//* 290 *//* 289 *//* 288 *//* 287 *//* 286 *//* 285 *//* 284 *//* 283 *//* 282 *//* 281 *//* 280 *//* 279 *//* 278 *//* 277 *//* 276 *//* 275 *//* 274 *//* 273 *//* 272 *//* 271 *//* 270 *//* 269 *//* 268 *//* 267 *//* 266 *//* 265 *//* 264 *//* 263 *//* 262 *//* 261 *//* 260 *//* 259 *//* 258 *//* 257 *//* 256 *//* 255 *//* 254 *//* 253 *//* 252 *//* 251 *//* 250 *//* 249 *//* 248 *//* 247 *//* 246 *//* 245 *//* 244 *//* 243 *//* 242 *//* 241 *//* 240 *//* 239 *//* 238 *//* 237 *//* 236 *//* 235 *//* 234 *//* 233 *//* 232 *//* 231 *//* 230 *//* 229 *//* 228 *//* 227 *//* 226 *//* 225 *//* 224 *//* 223 *//* 222 *//* 221 *//* 220 *//* 219 *//* 218 *//* 217 *//* 216 *//* 215 *//* 214 *//* 213 *//* 212 *//* 211 *//* 210 *//* 209 *//* 208 *//* 207 *//* 206 *//* 205 *//* 204 *//* 203 *//* 202 *//* 201 *//* 200 *//* 199 *//* 198 *//* 197 *//* 196 *//* 195 *//* 194 *//* 193 *//* 192 *//* 191 *//* 190 *//* 189 *//* 188 *//* 187 *//* 186 *//* 185 *//* 184 *//* 183 *//* 182 *//* 181 *//* 180 *//* 179 *//* 178 *//* 177 *//* 176 *//* 175 *//* 174 *//* 173 *//* 172 *//* 171 *//* 170 *//* 169 *//* 168 *//* 167 *//* 166 *//* 165 *//* 164 *//* 163 *//* 162 *//* 161 *//* 160 *//* 159 *//* 158 *//* 157 *//* 156 *//* 155 *//* 154 *//* 153 *//* 152 *//* 151 *//* 150 *//* 149 *//* 148 *//* 147 *//* 146 *//* 145 *//* 144 *//* 143 *//* 142 *//* 141 *//* 140 *//* 139 *//* 138 *//* 137 *//* 136 *//* 135 *//* 134 *//* 133 *//* 132 *//* 131 *//* 130 *//* 129 *//* 128 *//* 127 *//* 126 *//* 125 *//* 124 *//* 123 *//* 122 *//* 121 *//* 120 *//* 119 *//* 118 *//* 117 *//* 116 *//* 115 *//* 114 *//* 113 *//* 112 *//* 111 *//* 110 *//* 109 *//* 108 *//* 107 *//* 106 *//* 105 *//* 104 *//* 103 *//* 102 *//* 101 *//* 100 *//*  99 *//*  98 *//*  97 *//*  96 *//*  95 *//*  94 *//*  93 *//*  92 *//*  91 *//*  90 *//*  89 *//*  88 *//*  87 *//*  86 *//*  85 *//*  84 *//*  83 *//*  82 *//*  81 *//*  80 *//*  79 *//*  78 *//*  77 *//*  76 *//*  75 *//*  74 *//*  73 *//*  72 *//*  71 *//*  70 *//*  69 *//*  68 *//*  67 *//*  66 *//*  65 *//*  64 *//*  63 *//*  62 *//*  61 *//*  60 *//*  59 *//*  58 *//*  57 *//*  56 *//*  55 *//*  54 *//*  53 *//*  52 *//*  51 *//*  50 *//*  49 *//*  48 *//*  47 *//*  46 *//*  45 *//*  44 *//*  43 *//*  42 *//*  41 *//*  40 *//*  39 *//*  38 *//*  37 *//*  36 *//*  35 *//*  34 *//*  33 *//*  32 *//*  31 *//*  30 *//*  29 *//*  28 *//* defined(YYCOVERAGE) || !defined(NDEBUG) *//*  322 *//*  321 *//*  320 *//*  319 *//*  318 *//*  317 *//*  316 *//*  315 *//*  314 *//*  313 *//*  312 *//*  311 *//*  310 *//*  309 *//*  308 *//*  307 *//*  306 *//*  305 *//*  304 *//*  303 *//*  302 *//*  301 *//*  300 *//*  299 *//*  298 *//*  297 *//*  296 *//*  295 *//*  294 *//*  293 *//*  292 *//*  291 *//*  290 *//*  289 *//*  288 *//*  287 *//*  286 *//*  285 *//*  284 *//*  283 *//*  282 *//*  281 *//*  280 *//*  279 *//*  278 *//*  277 *//*  276 *//*  275 *//*  274 *//*  273 *//*  272 *//*  271 *//*  270 *//*  269 *//*  268 *//*  267 *//*  266 *//*  265 *//*  264 *//*  263 *//*  262 *//*  261 *//*  260 *//*  259 *//*  258 *//*  257 *//*  256 *//*  255 *//*  254 *//*  253 *//*  252 *//*  251 *//*  250 *//*  249 *//*  248 *//*  247 *//*  246 *//*  245 *//*  244 *//*  243 *//*  242 *//*  241 *//*  240 *//*  239 *//*  238 *//*  237 *//*  236 *//*  235 *//*  234 *//*  233 *//*  232 *//*  231 *//*  230 *//*  229 *//*  228 *//*  227 *//*  226 *//*  225 *//*  224 *//*  223 *//*  222 *//*  221 *//*  220 *//*  219 *//*  218 *//*  217 *//*  216 *//*  215 *//*  214 *//*  213 *//*  212 *//*  211 *//*  210 *//*  209 *//*  208 *//*  207 *//*  206 *//*  205 *//*  204 *//*  203 *//*  202 *//*  201 *//*  200 *//*  199 *//*  198 *//*  197 *//*  196 *//*  195 *//*  194 *//*  193 *//*  192 *//*  191 *//*  190 *//*  189 *//*  188 *//*  187 *//*  186 *//*  185 *//*  184 *//*  183 *//*  182 *//*  181 *//*  180 *//*  179 *//*  178 *//*  177 *//*  176 *//*  175 *//*  174 *//*  173 *//*  172 *//*  171 *//*  170 *//*  169 *//*  168 *//*  167 *//*  166 *//*  165 *//*  164 *//*  163 *//*  162 *//*  161 *//*  160 *//*  159 *//*  158 *//*  157 *//*  156 *//*  155 *//*  154 *//*  153 *//*  152 *//*  151 *//*  150 *//*  149 *//*  148 *//*  147 *//*  146 *//*  145 *//*  144 *//*  143 *//*  142 *//*  141 *//*  140 *//*  139 *//*  138 *//*  137 *//*  136 *//*  135 *//*  134 *//*  133 *//*  132 *//*  131 *//*  130 *//*  129 *//*  128 *//*  127 *//*  126 *//*  125 *//*  124 *//*  123 *//*  122 *//*  121 *//*  120 *//*  119 *//*  118 *//*  117 *//*  116 *//*  115 *//*  114 *//*  113 *//*  112 *//*  111 *//*  110 *//*  109 *//*  108 *//*  107 *//*  106 *//*  105 *//*  104 *//*  103 *//*  102 *//*  101 *//*  100 *//*   99 *//*   98 *//*   97 *//*   96 *//*   95 *//*   94 *//*   93 *//*   92 *//*   91 *//*   90 *//*   89 *//*   88 *//*   87 *//*   86 *//*   85 *//*   84 *//*   83 *//*   82 *//*   81 *//*   80 *//*   79 *//*   78 *//*   77 *//*   76 *//*   75 *//*   74 *//*   73 *//*   72 *//*   71 *//*   70 *//*   69 *//*   68 *//*   67 *//*   66 *//*   65 *//*   64 *//*   63 *//*   62 *//*   61 *//*   60 *//*   59 *//*   58 *//*   57 *//*   56 *//*   55 *//*   54 *//*   53 *//*   52 *//*   51 *//*   50 *//*   49 *//*   48 *//*   47 *//*   46 *//*   45 *//*   44 *//*   43 *//*   42 *//*   41 *//*   40 *//*   39 *//*   38 *//*   37 *//*   36 *//*   35 *//*   34 *//*   33 *//*   32 *//*   31 *//*   30 *//*   29 *//*   28 *//*   27 *//* YYFALLBACK *//*    ILLEGAL => nothing *//*    COMMENT => nothing *//*      SPACE => nothing *//*    QNUMBER => nothing *//*      ERROR => nothing *//*       SPAN => nothing *//*   ASTERISK => nothing *//* IF_NULL_ROW => nothing *//* SELECT_COLUMN => nothing *//*     VECTOR => nothing *//*   REGISTER => nothing *//*      TRUTH => nothing *//*     UMINUS => nothing *//*      UPLUS => nothing *//*   FUNCTION => nothing *//*  TRUEFALSE => nothing *//* AGG_COLUMN => nothing *//* AGG_FUNCTION => nothing *//*     COLUMN => nothing *//*     FILTER => nothing *//*       OVER => nothing *//*     WINDOW => nothing *//*        ADD => nothing *//*      ALTER => nothing *//*      INDEX => nothing *//*       ELSE => nothing *//*       THEN => nothing *//*       WHEN => nothing *//*       CASE => nothing *//*   VARIABLE => nothing *//*    INTEGER => nothing *//*       BLOB => nothing *//*      FLOAT => nothing *//*    NOTHING => nothing *//*       INTO => nothing *//*  RETURNING => nothing *//*      WHERE => nothing *//*      LIMIT => nothing *//*     HAVING => nothing *//*      GROUP => nothing *//*      ORDER => nothing *//*      USING => nothing *//*       JOIN => nothing *//*       FROM => nothing *//*        DOT => nothing *//*   DISTINCT => nothing *//*     VALUES => nothing *//*     SELECT => nothing *//*  INTERSECT => nothing *//*     EXCEPT => nothing *//*        ALL => nothing *//*      UNION => nothing *//*       DROP => nothing *//*    FOREIGN => nothing *//* DEFERRABLE => nothing *//*        SET => nothing *//*     UPDATE => nothing *//*     DELETE => nothing *//*     INSERT => nothing *//*   AUTOINCR => nothing *//* REFERENCES => nothing *//*      CHECK => nothing *//*     UNIQUE => nothing *//*    PRIMARY => nothing *//*       NULL => nothing *//*    DEFAULT => nothing *//* CONSTRAINT => nothing *//*    JOIN_KW => nothing *//*     STRING => nothing *//*    INDEXED => nothing *//*         ON => nothing *//*     BITNOT => nothing *//*    COLLATE => nothing *//*        PTR => nothing *//*     CONCAT => nothing *//*        REM => nothing *//*      SLASH => nothing *//*       STAR => nothing *//*      MINUS => nothing *//*       PLUS => nothing *//*     RSHIFT => nothing *//*     LSHIFT => nothing *//*      BITOR => nothing *//*     BITAND => nothing *//*        ANY => nothing *//*   CTIME_KW => ID *//*     RENAME => ID *//*    REINDEX => ID *//* MATERIALIZED => ID *//*     ALWAYS => ID *//*  GENERATED => ID *//*       TIES => ID *//*     OTHERS => ID *//*     GROUPS => ID *//*    EXCLUDE => ID *//*  UNBOUNDED => ID *//*      RANGE => ID *//*  PRECEDING => ID *//*  PARTITION => ID *//*  FOLLOWING => ID *//*    CURRENT => ID *//*       LAST => ID *//*      FIRST => ID *//*      NULLS => ID *//*       WITH => ID *//*    VIRTUAL => ID *//*       VIEW => ID *//*     VACUUM => ID *//*    TRIGGER => ID *//*       ROWS => ID *//*        ROW => ID *//*   RESTRICT => ID *//*    REPLACE => ID *//*  RECURSIVE => ID *//*      RAISE => ID *//*     PRAGMA => ID *//*     OFFSET => ID *//*         OF => ID *//*        KEY => ID *//*         NO => ID *//*    INSTEAD => ID *//*  INITIALLY => ID *//*     IGNORE => ID *//*        FOR => ID *//*         DO => ID *//*   COLUMNKW => ID *//*         ID => nothing *//*     ESCAPE => nothing *//*         GE => nothing *//*         LT => nothing *//*         LE => nothing *//*         GT => nothing *//*         EQ => nothing *//*         NE => nothing *//*    NOTNULL => nothing *//*     ISNULL => nothing *//*         IN => nothing *//*    BETWEEN => nothing *//*    LIKE_KW => ID *//*      MATCH => ID *//*      ISNOT => nothing *//*         IS => nothing *//*        AND => nothing *//*         OR => nothing *//*       FAIL => ID *//*       EACH => ID *//*     DETACH => ID *//*       DESC => ID *//*   DATABASE => ID *//*   CONFLICT => ID *//*       CAST => ID *//*    CASCADE => ID *//*         BY => ID *//*     BEFORE => ID *//*     ATTACH => ID *//*        ASC => ID *//*    ANALYZE => ID *//*      AFTER => ID *//*     ACTION => ID *//*      ABORT => ID *//*    WITHOUT => ID *//*      COMMA => nothing *//*         AS => nothing *//*         RP => nothing *//*         LP => nothing *//*       TEMP => ID *//*     EXISTS => nothing *//*        NOT => nothing *//*         IF => ID *//*     CREATE => nothing *//*      TABLE => nothing *//*         TO => nothing *//*    RELEASE => ID *//*  SAVEPOINT => ID *//*   ROLLBACK => ID *//*        END => ID *//*     COMMIT => nothing *//*  EXCLUSIVE => ID *//*  IMMEDIATE => ID *//*   DEFERRED => ID *//* TRANSACTION => nothing *//*      BEGIN => ID *//*       PLAN => ID *//*      QUERY => ID *//*    EXPLAIN => ID *//*       SEMI => nothing *//*          $ => nothing *//*   580 *//*   570 *//*   560 *//*   550 *//*   540 *//*   530 *//*   520 *//*   510 *//*   500 *//*   490 *//*   480 *//*   470 *//*   460 *//*   450 *//*   440 *//*   430 *//*   420 *//*   410 *//*   400 *//*   390 *//*   380 *//*   370 *//*   360 *//*   350 *//*   340 *//*   330 *//*   320 *//*   310 *//*   300 *//*   290 *//*   280 *//*   270 *//*   260 *//*   250 *//*   240 *//*   230 *//*   220 *//*   210 *//*   200 *//*   190 *//*   180 *//*   170 *//*   160 *//*   150 *//*   140 *//*   130 *//*  2390 *//*  2380 *//*  2370 *//*  2360 *//*  2350 *//*  2340 *//*  2330 *//*  2320 *//*  2310 *//*  2300 *//*  2290 *//*  2280 *//*  2270 *//*  2260 *//*  2250 *//*  2240 *//*  2230 *//*  2220 *//*  2210 *//*  2200 *//*  2190 *//*  2180 *//*  2170 *//*  2160 *//*  2150 *//*  2140 *//*  2130 *//*  2120 *//*  2110 *//*  2100 *//*  2090 *//*  2080 *//*  2070 *//*  2060 *//*  2050 *//*  2040 *//*  2030 *//*  2020 *//*  2010 *//*  2000 *//*  1990 *//*  1980 *//*  1970 *//*  1960 *//*  1950 *//*  1940 *//*  1930 *//*  1920 *//*  1910 *//*  1900 *//*  1890 *//*  1880 *//*  1870 *//*  1860 *//*  1850 *//*  1840 *//*  1830 *//*  1820 *//*  1810 *//*  1800 *//*  1790 *//*  1780 *//*  1770 *//*  1760 *//*  1750 *//*  1740 *//*  1730 *//*  1720 *//*  1710 *//*  1700 *//*  1690 *//*  1680 *//*  1670 *//*  1660 *//*  1650 *//*  1640 *//*  1630 *//*  1620 *//*  1610 *//*  1600 *//*  1590 *//*  1580 *//*  1570 *//*  1560 *//*  1550 *//*  1540 *//*  1530 *//*  1520 *//*  1510 *//*  1500 *//*  1490 *//*  1480 *//*  1470 *//*  1460 *//*  1450 *//*  1440 *//*  1430 *//*  1420 *//*  1410 *//*  1400 *//*  1390 *//*  1380 *//*  1370 *//*  1360 *//*  1350 *//*  1340 *//*  1330 *//*  1320 *//*  1310 *//*  1300 *//*  1290 *//*  1280 *//*  1270 *//*  1260 *//*  1250 *//*  1240 *//*  1230 *//*  1220 *//*  1210 *//*  1200 *//*  1190 *//*  1180 *//*  1170 *//*  1160 *//*  1150 *//*  1140 *//*  1130 *//*  1120 *//*  1110 *//*  1100 *//*  1090 *//*  1080 *//*  1070 *//*  1060 *//*  1050 *//*  1040 *//*  1030 *//*  1020 *//*  1010 *//*  1000 *//*   990 *//*   980 *//*   970 *//*   960 *//*   950 *//*   940 *//*   930 *//*   920 *//*   910 *//*   900 *//*   890 *//*   880 *//*   870 *//*   860 *//*   850 *//*   840 *//*   830 *//*   820 *//*   810 *//*   800 *//*   790 *//*   780 *//*   770 *//*   760 *//*   750 *//*   740 *//*   730 *//*   720 *//*   710 *//*   700 *//*   690 *//*   680 *//*   670 *//*   660 *//*   650 *//*   640 *//*   630 *//*   620 *//*   610 *//*   600 *//*   590 *//* Next are the tables used to determine what action to take based on the
** current state and lookahead token.  These tables are used to implement
** functions that take a state number and lookahead value and return an
** action integer.
**
** Suppose the action integer is N.  Then the action is determined as
** follows
**
**   0 <= N <= YY_MAX_SHIFT             Shift N.  That is, push the lookahead
**                                      token onto the stack and goto state N.
**
**   N between YY_MIN_SHIFTREDUCE       Shift to an arbitrary state then
**     and YY_MAX_SHIFTREDUCE           reduce by rule N-YY_MIN_SHIFTREDUCE.
**
**   N == YY_ERROR_ACTION               A syntax error has occurred.
**
**   N == YY_ACCEPT_ACTION              The parser accepts its input.
**
**   N == YY_NO_ACTION                  No such action.  Denotes unused
**                                      slots in the yy_action[] table.
**
**   N between YY_MIN_REDUCE            Reduce by rule N-YY_MIN_REDUCE
**     and YY_MAX_REDUCE
**
** The action table is constructed as a single large table named yy_action[].
** Given state S and lookahead X, the action is computed as either:
**
**    (A)   N = yy_action[ yy_shift_ofst[S] + X ]
**    (B)   N = yy_default[S]
**
** The (A) formula is preferred.  The B formula is used instead if
** yy_lookahead[yy_shift_ofst[S]+X] is not equal to X.
**
** The formulas above are for computing the action when the lookahead is
** a terminal symbol.  If the lookahead is a non-terminal (as occurs after
** a reduce action) then the yy_reduce_ofst[] array is used in place of
** the yy_shift_ofst[] array.
**
** The following are the tables generated in this section:
**
**  yy_action[]        A single table containing all actions.
**  yy_lookahead[]     A table containing the lookahead for each entry in
**                     yy_action.  Used to detect hash collisions.
**  yy_shift_ofst[]    For each state, the offset into yy_action for
**                     shifting terminals.
**  yy_reduce_ofst[]   For each state, the offset into yy_action for
**                     shifting non-terminals after a reduce.
**  yy_default[]       Default action for each state.
**
*********** Begin parsing tables **********************************************//* Define the yytestcase() macro to be a no-op if is not already defined
** otherwise.
**
** Applications can choose to define yytestcase() in the %include section
** to a macro that can assist in verifying code coverage.  For production
** code the yytestcase() macro should be turned off.  But it is useful
** for testing.
*//* The next sections is a series of control #defines.
** various aspects of the generated parser.
**    YYCODETYPE         is the data type used to store the integer codes
**                       that represent terminal and non-terminal symbols.
**                       "unsigned char" is used if there are fewer than
**                       256 symbols.  Larger types otherwise.
**    YYNOCODE           is a number of type YYCODETYPE that is not used for
**                       any terminal or nonterminal symbol.
**    YYFALLBACK         If defined, this indicates that one or more tokens
**                       (also known as: "terminal symbols") have fall-back
**                       values which should be used if the original symbol
**                       would not parse.  This permits keywords to sometimes
**                       be used as identifiers, for example.
**    YYACTIONTYPE       is the data type used for "action codes" - numbers
**                       that indicate what to do in response to the next
**                       token.
**    sqlite3ParserTOKENTYPE     is the data type used for minor type for terminal
**                       symbols.  Background: A "minor type" is a semantic
**                       value associated with a terminal or non-terminal
**                       symbols.  For example, for an "ID" terminal symbol,
**                       the minor type might be the name of the identifier.
**                       Each non-terminal can have a different minor type.
**                       Terminal symbols all have the same minor type, though.
**                       This macros defines the minor type for terminal
**                       symbols.
**    YYMINORTYPE        is the data type used for all minor types.
**                       This is typically a union of many types, one of
**                       which is sqlite3ParserTOKENTYPE.  The entry in the union
**                       for terminal symbols is called "yy0".
**    YYSTACKDEPTH       is the maximum depth of the parser's stack.  If
**                       zero the stack is dynamically sized using realloc()
**    sqlite3ParserARG_SDECL     A static variable declaration for the %extra_argument
**    sqlite3ParserARG_PDECL     A parameter declaration for the %extra_argument
**    sqlite3ParserARG_PARAM     Code to pass %extra_argument as a subroutine parameter
**    sqlite3ParserARG_STORE     Code to store %extra_argument into yypParser
**    sqlite3ParserARG_FETCH     Code to extract %extra_argument from yypParser
**    sqlite3ParserCTX_*         As sqlite3ParserARG_ except for %extra_context
**    YYREALLOC          Name of the realloc() function to use
**    YYFREE             Name of the free() function to use
**    YYDYNSTACK         True if stack space should be extended on heap
**    YYERRORSYMBOL      is the code number of the error symbol.  If not
**                       defined, then do no error processing.
**    YYNSTATE           the combined number of states.
**    YYNRULE            the number of rules in the grammar
**    YYNTOKEN           Number of terminal symbols
**    YY_MAX_SHIFT       Maximum value for shift actions
**    YY_MIN_SHIFTREDUCE Minimum value for shift-reduce actions
**    YY_MAX_SHIFTREDUCE Maximum value for shift-reduce actions
**    YY_ERROR_ACTION    The yy_action[] code for syntax error
**    YY_ACCEPT_ACTION   The yy_action[] code for accept
**    YY_NO_ACTION       The yy_action[] code for no-op
**    YY_MIN_REDUCE      Minimum value for reduce actions
**    YY_MAX_REDUCE      Maximum value for reduce actions
**    YY_MIN_DSTRCTR     Minimum symbol value that has a destructor
**    YY_MAX_DSTRCTR     Maximum symbol value that has a destructor
*//* Add a single new term to an ExprList that is used to store a
  ** list of identifiers.  Report an error if the ID list contains
  ** a COLLATE clause or an ASC or DESC keyword, except ignore the
  ** error while parsing a legacy schema.
  *//* A routine to convert a binary TK_IS or TK_ISNOT expression into a
  ** unary TK_ISNULL or TK_NOTNULL expression. *//* p->iAgg = -1; // Not required *//* memset(p, 0, sizeof(Expr)); *//* Construct a new Expr object from a single token *//* Memory allocator for parser stack resizing.  This is a thin wrapper around
  ** sqlite3_realloc() that includes a call to sqlite3FaultSim() to facilitate
  ** testing.
  *//* Attach a With object describing the WITH clause to a Select
  ** object describing the query for which the WITH clause is a prefix.
  *//*
  ** For a compound SELECT statement, make sure p->pPrior->pNext==p for
  ** all elements in the list.  And make sure list length does not exceed
  ** SQLITE_LIMIT_COMPOUND_SELECT.
  *//* SQLITE_ENABLE_UPDATE_DELETE_LIMIT *//*
** Issue an error message if an ORDER BY or LIMIT clause occurs on an
** UPDATE or DELETE statement.
*//*
** Disable lookaside memory allocation for objects that might be
** shared across database connections.
*//*
** Generate a syntax error
*//*
** An instance of the following structure describes the event of a
** TRIGGER.  "a" is the event type, one of TK_UPDATE, TK_INSERT,
** TK_DELETE, or TK_INSTEAD.  If the event is of the form
**
**      UPDATE ON (a,b,c)
**
** Then the "b" IdList records the list "a,b,c".
*//*
** In the amalgamation, the parse.c file generated by lemon and the
** tokenize.c file are concatenated.  In that case, sqlite3RunParser()
** has access to the the size of the yyParser object and so the parser
** engine can be allocated from stack.  In that case, only the
** sqlite3ParserInit() and sqlite3ParserFinalize() routines are invoked
** and the sqlite3ParserAlloc() and sqlite3ParserFree() routines can be
** omitted.
*//*
** Make yytestcase() the same as testcase()
*//*
** Verify that the pParse->isCreate field is set
*//*
** 2001-09-15
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains SQLite's SQL parser.
**
** The canonical source code to this file ("parse.y") is a Lemon grammar
** file that specifies the input grammar and actions to take while parsing.
** That input file is processed by Lemon to generate a C-language
** implementation of a parser for the given grammar.  You might be reading
** this comment as part of the translated C-code.  Edits should be made
** to the original parse.y sources.
*//* This file is automatically generated by Lemon from input grammar
** source file "parse.y".
*//************** Begin file parse.c *******************************************//************** End of window.c **********************************************//* End of the main input loop *//* Beginning of the block executed for the second and subsequent rows. *//*   values previously checked *//* NeverNull because bound <expr> *//* This block is run for the first row of each partition *//* Insert the new row into the ephemeral table *//* An input row has just been read into an array of registers starting
  ** at regNew. If the window has a PARTITION clause, this block generates
  ** VM code to check if the input row is the start of a new partition.
  ** If so, it does an OP_Gosub to an address to be filled in later. The
  ** address of the OP_Gosub is stored in local variable addrGosubFlush. *//* Load the column values for the row returned by the sub-select
  ** into an array of registers starting at regNew. Assemble them into
  ** a record in register regRecord. *//* If this is not a "ROWS BETWEEN ..." frame, then allocate arrays of
  ** registers to store copies of the ORDER BY expressions (peer values)
  ** for the main loop, and for each cursor (start, current and end). *//* If the window frame contains an "<expr> PRECEDING" or "<expr> FOLLOWING"
  ** clause, allocate registers to store the results of evaluating each
  ** <expr>.  *//* Allocate registers for the array of values from the sub-query, the
  ** same values in record form, and the rowid used to insert said record
  ** into the ephemeral table.  *//* Figure out when rows may be deleted from the ephemeral table. There
  ** are four options - they may never be deleted (eDelete==0), they may
  ** be deleted as soon as they are no longer part of the window frame
  ** (eDelete==WINDOW_AGGINVERSE), they may be deleted as after the row
  ** has been returned to the caller (WINDOW_RETURN_ROW), or they may
  ** be deleted after they enter the frame (WINDOW_AGGSTEP). *//* Fill in the context object *//* Value of <expr> FOLLOWING *//* Value of <expr> PRECEDING *//* Label just before sqlite3WhereEnd() code *//* Context object for sub-routines *//* Register for "Gosub flush_partition" *//* Peer values for current row *//* Peer values for new row (part of regNew) *//* regNew array in record form *//* Array of registers holding new input row *//* Address of OP_Rewind in flush: *//* Address of OP_Integer *//* Address of OP_Gosub to flush: *//* Address of OP_Ne *//* To iterate through sub cols *//* Number of cols returned by sub *//* Cursor of sub-select *//* Cursor used to write to eph. table *//* OP_Gosub here to return each row *//* Register for OP_Gosub *//* Context returned by sqlite3WhereBegin() *//* Rewritten SELECT statement *//*
** sqlite3WhereBegin() has already been called for the SELECT statement
** passed as the second argument when this function is invoked. It generates
** code to populate the Window.regResult register for each window function
** and invoke the sub-routine at instruction addrGosub once for each row.
** sqlite3WhereEnd() is always called before returning.
**
** This function handles several different types of window frames, which
** require slightly different processing. The following pseudo code is
** used to implement window frames of the form:
**
**   ROWS BETWEEN <expr1> PRECEDING AND <expr2> FOLLOWING
**
** Other window frame types use variants of the following:
**
**     ... loop started by sqlite3WhereBegin() ...
**       if( new partition ){
**         Gosub flush
**       }
**       Insert new row into eph table.
**
**       if( first row of partition ){
**         // Rewind three cursors, all open on the eph table.
**         Rewind(csrEnd);
**         Rewind(csrStart);
**         Rewind(csrCurrent);
**
**         regEnd = <expr2>          // FOLLOWING expression
**         regStart = <expr1>        // PRECEDING expression
**       }else{
**         // First time this branch is taken, the eph table contains two
**         // rows. The first row in the partition, which all three cursors
**         // currently point to, and the following row.
**         AGGSTEP
**         if( (regEnd--)<=0 ){
**           RETURN_ROW
**           if( (regStart--)<=0 ){
**             AGGINVERSE
**           }
**         }
**       }
**     }
**     flush:
**       AGGSTEP
**       while( 1 ){
**         RETURN ROW
**         if( csrCurrent is EOF ) break;
**         if( (regStart--)<=0 ){
**           AggInverse(csrStart)
**           Next(csrStart)
**         }
**       }
**
** The pseudo-code above uses the following shorthand:
**
**   AGGSTEP:    invoke the aggregate xStep() function for each window function
**               with arguments read from the current row of cursor csrEnd, then
**               step cursor csrEnd forward one row (i.e. sqlite3BtreeNext()).
**
**   RETURN_ROW: return a row to the caller based on the contents of the
**               current row of csrCurrent and the current state of all
**               aggregates. Then step cursor csrCurrent forward one row.
**
**   AGGINVERSE: invoke the aggregate xInverse() function for each window
**               functions with arguments read from the current row of cursor
**               csrStart. Then step csrStart forward one row.
**
** There are two other ROWS window frames that are handled significantly
** differently from the above - "BETWEEN <expr> PRECEDING AND <expr> PRECEDING"
** and "BETWEEN <expr> FOLLOWING AND <expr> FOLLOWING". These are special
** cases because they change the order in which the three cursors (csrStart,
** csrCurrent and csrEnd) iterate through the ephemeral table. Cases that
** use UNBOUNDED or CURRENT ROW are much simpler variations on one of these
** three.
**
**   ROWS BETWEEN <expr1> PRECEDING AND <expr2> PRECEDING
**
**     ... loop started by sqlite3WhereBegin() ...
**       if( new partition ){
**         Gosub flush
**       }
**       Insert new row into eph table.
**       if( first row of partition ){
**         Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**         regEnd = <expr2>
**         regStart = <expr1>
**       }else{
**         if( (regEnd--)<=0 ){
**           AGGSTEP
**         }
**         RETURN_ROW
**         if( (regStart--)<=0 ){
**           AGGINVERSE
**         }
**       }
**     }
**     flush:
**       if( (regEnd--)<=0 ){
**         AGGSTEP
**       }
**       RETURN_ROW
**
**
**   ROWS BETWEEN <expr1> FOLLOWING AND <expr2> FOLLOWING
**
**     ... loop started by sqlite3WhereBegin() ...
**     if( new partition ){
**       Gosub flush
**     }
**     Insert new row into eph table.
**     if( first row of partition ){
**       Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**       regEnd = <expr2>
**       regStart = regEnd - <expr1>
**     }else{
**       AGGSTEP
**       if( (regEnd--)<=0 ){
**         RETURN_ROW
**       }
**       if( (regStart--)<=0 ){
**         AGGINVERSE
**       }
**     }
**   }
**   flush:
**     AGGSTEP
**     while( 1 ){
**       if( (regEnd--)<=0 ){
**         RETURN_ROW
**         if( eof ) break;
**       }
**       if( (regStart--)<=0 ){
**         AGGINVERSE
**         if( eof ) break
**       }
**     }
**     while( !eof csrCurrent ){
**       RETURN_ROW
**     }
**
** For the most part, the patterns above are adapted to support UNBOUNDED by
** assuming that it is equivalent to "infinity PRECEDING/FOLLOWING" and
** CURRENT ROW by assuming that it is equivalent to "0 PRECEDING/FOLLOWING".
** This is optimized of course - branches that will never be taken and
** conditions that are always true are omitted from the VM code. The only
** exceptional case is:
**
**   ROWS BETWEEN <expr1> FOLLOWING AND UNBOUNDED FOLLOWING
**
**     ... loop started by sqlite3WhereBegin() ...
**     if( new partition ){
**       Gosub flush
**     }
**     Insert new row into eph table.
**     if( first row of partition ){
**       Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**       regStart = <expr1>
**     }else{
**       AGGSTEP
**     }
**   }
**   flush:
**     AGGSTEP
**     while( 1 ){
**       if( (regStart--)<=0 ){
**         AGGINVERSE
**         if( eof ) break
**       }
**       RETURN_ROW
**     }
**     while( !eof csrCurrent ){
**       RETURN_ROW
**     }
**
** Also requiring special handling are the cases:
**
**   ROWS BETWEEN <expr1> PRECEDING AND <expr2> PRECEDING
**   ROWS BETWEEN <expr1> FOLLOWING AND <expr2> FOLLOWING
**
** when (expr1 < expr2). This is detected at runtime, not by this function.
** To handle this case, the pseudo-code programs depicted above are modified
** slightly to be:
**
**     ... loop started by sqlite3WhereBegin() ...
**     if( new partition ){
**       Gosub flush
**     }
**     Insert new row into eph table.
**     if( first row of partition ){
**       Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**       regEnd = <expr2>
**       regStart = <expr1>
**       if( regEnd < regStart ){
**         RETURN_ROW
**         delete eph table contents
**         continue
**       }
**     ...
**
** The new "continue" statement in the above jumps to the next iteration
** of the outer loop - the one started by sqlite3WhereBegin().
**
** The various GROUPS cases are implemented using the same patterns as
** ROWS. The VM code is modified slightly so that:
**
**   1. The else branch in the main loop is only taken if the row just
**      added to the ephemeral table is the start of a new group. In
**      other words, it becomes:
**
**         ... loop started by sqlite3WhereBegin() ...
**         if( new partition ){
**           Gosub flush
**         }
**         Insert new row into eph table.
**         if( first row of partition ){
**           Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**           regEnd = <expr2>
**           regStart = <expr1>
**         }else if( new group ){
**           ...
**         }
**       }
**
**   2. Instead of processing a single row, each RETURN_ROW, AGGSTEP or
**      AGGINVERSE step processes the current row of the relevant cursor and
**      all subsequent rows belonging to the same group.
**
** RANGE window frames are a little different again. As for GROUPS, the
** main loop runs once per group only. And RETURN_ROW, AGGSTEP and AGGINVERSE
** deal in groups instead of rows. As for ROWS and GROUPS, there are three
** basic cases:
**
**   RANGE BETWEEN <expr1> PRECEDING AND <expr2> FOLLOWING
**
**     ... loop started by sqlite3WhereBegin() ...
**       if( new partition ){
**         Gosub flush
**       }
**       Insert new row into eph table.
**       if( first row of partition ){
**         Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**         regEnd = <expr2>
**         regStart = <expr1>
**       }else{
**         AGGSTEP
**         while( (csrCurrent.key + regEnd) < csrEnd.key ){
**           RETURN_ROW
**           while( csrStart.key + regStart) < csrCurrent.key ){
**             AGGINVERSE
**           }
**         }
**       }
**     }
**     flush:
**       AGGSTEP
**       while( 1 ){
**         RETURN ROW
**         if( csrCurrent is EOF ) break;
**           while( csrStart.key + regStart) < csrCurrent.key ){
**             AGGINVERSE
**           }
**         }
**       }
**
** In the above notation, "csr.key" means the current value of the ORDER BY
** expression (there is only ever 1 for a RANGE that uses an <expr> FOLLOWING
** or <expr PRECEDING) read from cursor csr.
**
**   RANGE BETWEEN <expr1> PRECEDING AND <expr2> PRECEDING
**
**     ... loop started by sqlite3WhereBegin() ...
**       if( new partition ){
**         Gosub flush
**       }
**       Insert new row into eph table.
**       if( first row of partition ){
**         Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**         regEnd = <expr2>
**         regStart = <expr1>
**       }else{
**         while( (csrEnd.key + regEnd) <= csrCurrent.key ){
**           AGGSTEP
**         }
**         while( (csrStart.key + regStart) < csrCurrent.key ){
**           AGGINVERSE
**         }
**         RETURN_ROW
**       }
**     }
**     flush:
**       while( (csrEnd.key + regEnd) <= csrCurrent.key ){
**         AGGSTEP
**       }
**       while( (csrStart.key + regStart) < csrCurrent.key ){
**         AGGINVERSE
**       }
**       RETURN_ROW
**
**   RANGE BETWEEN <expr1> FOLLOWING AND <expr2> FOLLOWING
**
**     ... loop started by sqlite3WhereBegin() ...
**       if( new partition ){
**         Gosub flush
**       }
**       Insert new row into eph table.
**       if( first row of partition ){
**         Rewind(csrEnd) ; Rewind(csrStart) ; Rewind(csrCurrent)
**         regEnd = <expr2>
**         regStart = <expr1>
**       }else{
**         AGGSTEP
**         while( (csrCurrent.key + regEnd) < csrEnd.key ){
**           while( (csrCurrent.key + regStart) > csrStart.key ){
**             AGGINVERSE
**           }
**           RETURN_ROW
**         }
**       }
**     }
**     flush:
**       AGGSTEP
**       while( 1 ){
**         while( (csrCurrent.key + regStart) > csrStart.key ){
**           AGGINVERSE
**           if( eof ) break "while( 1 )" loop.
**         }
**         RETURN_ROW
**       }
**       while( !eof csrCurrent ){
**         RETURN_ROW
**       }
**
** The text above leaves out many details. Refer to the code and comments
** below for a more complete picture.
*//*
** Return true if it can be determined at compile time that expression
** pExpr evaluates to a value that, when cast to an integer, is greater
** than zero. False otherwise.
**
** If an OOM error occurs, this function sets the Parse.db.mallocFailed
** flag and returns zero.
*//*
** Return a copy of the linked list of Window objects passed as the
** second argument.
*//*
** Allocate and return a duplicate of the Window object indicated by the
** third argument. Set the Window.pOwner field of the new object to
** pOwner.
*//* If this is a (RANGE BETWEEN a FOLLOWING AND b FOLLOWING) or
  ** (RANGE BETWEEN b PRECEDING AND a PRECEDING) frame, ensure the
  ** start cursor does not advance past the end cursor within the
  ** temporary table. It otherwise might, if (a>b). Also ensure that,
  ** if the input cursor is still finding new rows, that the end
  ** cursor does not go past it to EOF. *//* Special case - WINDOW_AGGINVERSE is always a no-op if the frame
  ** starts with UNBOUNDED PRECEDING. *//* Jump here if stepped cursor reaches EOF *//* Register for OP_IfPos countdown *//* WINDOW_RETURN_ROW, AGGSTEP or AGGINVERSE *//* Context object *//*
** Helper function for sqlite3WindowCodeStep(). Each call to this function
** generates VM code for a single RETURN_ROW, AGGSTEP or AGGINVERSE
** operation. Refer to the header comment for sqlite3WindowCodeStep() for
** details.
*//* Compare registers reg2 and reg1, taking the jump if required. Note that
  ** control skips over this test if the BIGNULL flag is set and either
  ** reg1 or reg2 contain a NULL value.  *//* Register reg1 currently contains csr1.peerVal (the peer-value from csr1).
  ** This block adds (or subtracts for DESC) the numeric value in regVal
  ** from it. Or, if reg1 is not numeric (it is a NULL, a text value or a blob),
  ** then leave reg1 as it is. In pseudo-code, this is implemented as:
  **
  **   if( reg1>='' ) goto addrGe;
  **   reg1 = reg1 +/- regVal
  **   addrGe:
  **
  ** Since all strings and blobs are greater-than-or-equal-to an empty string,
  ** the add/subtract is skipped for these, as required. If reg1 is a NULL,
  ** then the arithmetic is performed, but since adding or subtracting from
  ** NULL is always NULL anyway, this case is handled as required too.  *//* This block runs if reg1 is not NULL, but reg2 is. *//* This block runs if reg1 contains a NULL. *//* If the BIGNULL flag is set for the ORDER BY, then it is required to
  ** consider NULL values to be larger than all other values, instead of
  ** the usual smaller. The VDBE opcodes OP_Ge and so on do not handle this
  ** (and adding that capability causes a performance regression), so
  ** instead if the BIGNULL flag is set then cases where either reg1 or
  ** reg2 are NULL are handled separately in the following block. The code
  ** generated is equivalent to:
  **
  **   if( reg1 IS NULL ){
  **     if( op==OP_Ge ) goto lbl;
  **     if( op==OP_Gt && reg2 IS NOT NULL ) goto lbl;
  **     if( op==OP_Le && reg2 IS NULL ) goto lbl;
  **   }else if( reg2 IS NULL ){
  **     if( op==OP_Le ) goto lbl;
  **   }
  **
  ** Additionally, if either reg1 or reg2 are NULL but the jump to lbl is
  ** not taken, control jumps over the comparison operator coded below this
  ** block.  *//* Read the peer-value from each cursor into a register *//* Address past OP_Ge *//* Jump destination *//* OP_Add or OP_Subtract *//* Reg. for constant value '' *//* Reg. for csr2.peerVal *//* Reg. for csr1.peerVal+regVal *//* ORDER BY clause for window *//* Jump destination if condition is true *//* Cursor number for cursor 2 *//* Register containing non-negative number *//* Cursor number for cursor 1 *//* OP_Ge, OP_Gt, or OP_Le *//*
** This function is called as part of generating VM programs for RANGE
** offset PRECEDING/FOLLOWING frame boundaries. Assuming "ASC" order for
** the ORDER BY term in the window, and that argument op is OP_Ge, it generates
** code equivalent to:
**
**   if( csr1.peerVal + regVal >= csr2.peerVal ) goto lbl;
**
** The value of parameter op may also be OP_Gt or OP_Le. In these cases the
** operator in the above pseudo-code is replaced with ">" or "<=", respectively.
**
** If the sort-order for the ORDER BY term in the window is DESC, then the
** comparison is reversed. Instead of adding regVal to csr1.peerVal, it is
** subtracted. And the comparison operator is inverted to - ">=" becomes "<=",
** ">" becomes "<", and so on. So, with DESC sort order, if the argument op
** is OP_Ge, the generated code is equivalent to:
**
**   if( csr1.peerVal - regVal <= csr2.peerVal ) goto lbl;
**
** A special type of arithmetic is used such that if csr1.peerVal is not
** a numeric type (real or integer), then the result of the addition
** or subtraction is a a copy of csr1.peerVal.
*//* Jump here *//* First in array of old values *//* First in array of new values *//*
** regOld and regNew are each the first register in an array of size
** pOrderBy->nExpr. This function generates code to compare the two
** arrays of registers using the collation sequences and other comparison
** parameters specified by pOrderBy.
**
** If the two arrays are not equal, the contents of regNew is copied to
** regOld and control falls through. Otherwise, if the contents of the arrays
** are equal, an OP_Goto is executed. The address of the OP_Goto is returned.
*//*
** Return true if the current frame should be cached in the ephemeral table,
** even if there are no xInverse() calls required.
*//*
** Generate code to set the accumulator register for each window function
** in the linked list passed as the second argument to NULL. And perform
** any equivalent initialization required by any built-in window functions
** in the list.
*//*
** Invoke the sub-routine at regGosub (generated by code in select.c) to
** return the current row of Window.iEphCsr. If all window functions are
** aggregate window functions that use the standard API, a single
** OP_Gosub instruction is all that this routine generates. Extra VM code
** for per-row processing is only generated for the following built-in window
** functions:
**
**   nth_value()
**   first_value()
**   lag()
**   lead()
*//* AggStep peer values *//* AggStep rowid value *//* Current peer values *//* Current rowid value *//*
** Generate code to calculate the current values of all window functions in the
** p->pMWin list by doing a full scan of the current window frame. Store the
** results in the Window.regResult registers, ready to return the upper
** layer.
*//*
** Generate VM code to invoke either xValue() (bFin==0) or xFinalize()
** (bFin==1) for each window function in the linked list starting at
** pMWin. Or, for built-in window-functions that do not use the standard
** API, generate the equivalent VM code.
*//*
** Values that may be passed as the second argument to windowCodeOp().
*//* All OVER clauses in the same window function aggregate step must
    ** be the same. *//* Array of registers *//* True to invoke xInverse instead of xStep *//* Read arguments from this cursor *//* Linked list of window functions *//*
** Generate VM code to invoke either xStep() (if bInverse is 0) or
** xInverse (if bInverse is non-zero) for each window function in the
** linked list starting at pMWin. Or, for built-in window functions
** that do not use the standard function API, generate the required
** inline VM code.
**
** If argument csr is greater than or equal to 0, then argument reg is
** the first register in an array of registers guaranteed to be large
** enough to hold the array of arguments for each function. In this case
** the arguments are extracted from the current row of csr into the
** array of registers before invoking OP_AggStep or OP_AggInverse
**
** Or, if csr is less than zero, then the array of registers at reg is
** already populated with all columns from the current row of the sub-query.
**
** If argument regPartSize is non-zero, then it is a register containing the
** number of rows in the current partition.
*//*
** Generate VM code to read the window frames peer values from cursor csr into
** an array of registers starting at reg.
*//* First in array of accumulator registers *//* Register used with OP_Gosub(addrGosub) *//* OP_Gosub to this address to return one row *//* VDBE object *//* First in list of functions being processed *//*
** A single instance of this structure is allocated on the stack by
** sqlite3WindowCodeStep() and a pointer to it passed to the various helper
** routines. This is to reduce the number of arguments required by each
** helper function.
**
** regArg:
**   Each window function requires an accumulator register (just as an
**   ordinary aggregate function does). This variable is set to the first
**   in an array of accumulator registers - one for each window function
**   in the WindowCodeArg.pMWin list.
**
** eDelete:
**   The window functions implementation sometimes caches the input rows
**   that it processes in a temporary table. If it is not zero, this
**   variable indicates when rows may be removed from the temp table (in
**   order to reduce memory requirements - it would always be safe just
**   to leave them there). Possible values for eDelete are:
**
**      WINDOW_RETURN_ROW:
**        An input row can be discarded after it is returned to the caller.
**
**      WINDOW_AGGINVERSE:
**        An input row can be discarded after the window functions xInverse()
**        callbacks have been invoked in it.
**
**      WINDOW_AGGSTEP:
**        An input row can be discarded after the window functions xStep()
**        callbacks have been invoked in it.
**
** start,current,end
**   Consider a window-frame similar to the following:
**
**     (ORDER BY a, b GROUPS BETWEEN 2 PRECEDING AND 2 FOLLOWING)
**
**   The windows functions implementation caches the input rows in a temp
**   table, sorted by "a, b" (it actually populates the cache lazily, and
**   aggressively removes rows once they are no longer required, but that's
**   a mere detail). It keeps three cursors open on the temp table. One
**   (current) that points to the next row to return to the query engine
**   once its window function values have been calculated. Another (end)
**   points to the next row to call the xStep() method of each window function
**   on (so that it is 2 groups ahead of current). And a third (start) that
**   points to the next row to call the xInverse() method of each window
**   function on.
**
**   Each cursor (start, current and end) consists of a VDBE cursor
**   (WindowCsrAndReg.csr) and an array of registers (starting at
**   WindowCodeArg.reg) that always contains a copy of the peer values
**   read from the corresponding cursor.
**
**   Depending on the window-frame in question, all three cursors may not
**   be required. In this case both WindowCodeArg.csr and reg are set to
**   0.
*//* First in array of peer values *//* Cursor number *//*
** See comments above struct WindowCodeArg.
*//*
** Return the number of arguments passed to the window-function associated
** with the object passed as the only argument to this function.
*//*   the OP_Ge *//* NULL case caught by *//*   the OP_MustBeInt *//* NULL case captured by *//*
** A "PRECEDING <expr>" (eCond==0) or "FOLLOWING <expr>" (eCond==1) or the
** value of the second argument to nth_value() (eCond==2) has just been
** evaluated and the result left in register reg. This function generates VM
** code to check that the value is a non-negative integer and throws an
** exception if it is not.
*//* Allocate two registers at pWin->regApp. These will be used to
      ** store the start and end index of the current frame.  *//* The inline versions of min() and max() require a single ephemeral
      ** table and 3 registers. The registers are used as follows:
      **
      **   regApp+0: slot to copy min()/max() argument to for MakeRecord
      **   regApp+1: integer value used to ensure keys are unique
      **   regApp+2: output of MakeRecord
      *//* Allocate registers to use for PARTITION BY values, if any. Initialize
  ** said registers to NULL.  *//*
** This is called by code in select.c before it calls sqlite3WhereBegin()
** to begin iterating through the sub-query results. It is used to allocate
** and initialize registers and cursors used by sqlite3WindowCodeStep().
*//*
** Return 0 if the two window objects are identical, 1 if they are
** different, or 2 if it cannot be determined if the objects are identical
** or not. Identical window objects can be processed in a single scan.
*//*
** Possibly link window pWin into the list at pSel->pWin (window functions
** to be processed as part of SELECT statement pSel). The window is linked
** in if either (a) there are no other windows already linked to this
** SELECT, or (b) the windows already linked use a compatible window frame.
*//*
** Attach window object pWin to expression p.
*//* Check for errors *//*
** Window *pWin has just been created from a WINDOW clause. Token pBase
** is the base window. Earlier windows from the same WINDOW clause are
** stored in the linked list starting at pWin->pNextWin. This function
** either updates *pWin according to the base specification, or else
** leaves an error in pParse.
*//*
** Attach PARTITION and ORDER BY clauses pPartition and pOrderBy to window
** pWin. Also, if parameter pBase is not NULL, set pWin->zBase to the
** equivalent nul-terminated string.
*//* Additionally, the
  ** starting boundary type may not occur earlier in the following list than
  ** the ending boundary type:
  **
  **   UNBOUNDED PRECEDING
  **   <expr> PRECEDING
  **   CURRENT ROW
  **   <expr> FOLLOWING
  **   UNBOUNDED FOLLOWING
  **
  ** The parser ensures that "UNBOUNDED PRECEDING" cannot be used as an ending
  ** boundary, and than "UNBOUNDED FOLLOWING" cannot be used as a starting
  ** frame boundary.
  *//* Parser assures the following: *//* EXCLUDE clause *//* End window size if TK_FOLLOWING or PRECEDING *//* End type: CURRENT, FOLLOWING, TK_UNBOUNDED, PRECEDING *//* Start window size if TK_PRECEDING or FOLLOWING *//* Start type: CURRENT, PRECEDING, FOLLOWING, UNBOUNDED *//* Frame type. TK_RANGE, TK_ROWS, TK_GROUPS, or 0 *//* Parsing context *//*
** Allocate and return a new Window object describing a Window Definition.
*//*
** The argument expression is an PRECEDING or FOLLOWING offset.  The
** value should be a non-negative integer.  If the value is not a
** constant, change it to NULL.  The fact that it is then a non-negative
** integer will be caught later.  But it is important not to leave
** variable values in the expression tree.
*//*
** Free the linked list of Window objects starting at the second argument.
*//*
** Free the Window object passed as the second argument.
*//*
** Unlink the Window object from the Select to which it is attached,
** if it is attached.
*//* Defer deleting the temporary table pTab because if an error occurred,
    ** there could still be references to that table embedded in the
    ** result-set or ORDER BY clause of the SELECT statement p.  *//* Might actually be some other kind of error, but in that case
        ** pParse->nErr will be set, so if SQLITE_NOMEM is set, we will get
        ** the correct error message regardless. *//* Due to db->mallocFailed test inside
                                     ** of sqlite3DbMallocRawNN() called from
                                     ** sqlite3SrcListAppend() *//* If there is no ORDER BY or PARTITION BY clause, and the window
    ** function accepts zero arguments, and there are no other columns
    ** selected (e.g. "SELECT row_number() OVER () FROM t1"), it is possible
    ** that pSublist is still NULL here. Add a constant expression here to
    ** keep everything legal in this case.
    *//* Append the arguments passed to each window function to the
    ** sub-select expression list. Also allocate two registers for each
    ** window function - one for the accumulator, another for interim
    ** results.  *//* Append the PARTITION BY and ORDER BY expressions to the to the
    ** sub-select expression list. They are required to figure out where
    ** boundaries for partitions and sets of peer rows lie.  *//* Assign a cursor number for the ephemeral table used to buffer rows.
    ** The OpenEphemeral instruction is coded later, after it is known how
    ** many columns the table will have.  *//* Create the ORDER BY clause for the sub-select. This is the concatenation
    ** of the window PARTITION and ORDER BY clauses. Then, if this makes it
    ** redundant, remove the ORDER BY from the parent SELECT.  *//* Window object iterator *//* Main window object *//* Expression list for sub-query *//* The subquery *//*
** If the SELECT statement passed as the second argument does not invoke
** any SQL window functions, this function is a no-op. Otherwise, it
** rewrites the SELECT statement so that window function xStep functions
** are invoked in the correct order as described under "SELECT REWRITING"
** at the top of this file.
*//*
** When rewriting a query, if the new subquery in the FROM clause
** contains TK_AGG_FUNCTION nodes that refer to an outer query,
** then we have to increase the Expr->op2 values of those nodes
** due to the extra subquery layer that was added.
**
** See also the incrAggDepth() routine in resolve.c
*//* List of values to append. Might be NULL *//* List to which to append. Might be NULL *//*
** Append a copy of each expression in expression-list pAppend to
** expression list pList. Return a pointer to the result list.
*//* IN/OUT: Sub-select expression-list *//* Rewrite expressions in this list *//*
** Iterate through each expression in expression-list pEList. For each:
**
**   * TK_COLUMN,
**   * aggregate function, or
**   * window function with a Window object that is not a member of the
**     Window list passed as the second argument (pWin).
**
** Append the node to output expression-list (*ppSub). And replace it
** with a TK_COLUMN that reads the (N-1)th element of table
** pWin->iEphCsr, where N is the number of elements in (*ppSub) after
** appending the new one.
*//* If this function is being called from within a scalar sub-select
  ** that used by the SELECT statement being processed, only process
  ** TK_COLUMN expressions that refer to it (the outer SELECT). Do
  ** not process aggregates or window functions at all, as they belong
  ** to the scalar sub-select.  *//*
** Callback function used by selectWindowRewriteEList(). If necessary,
** this function appends to the output expression-list and updates
** expression (*ppExpr) in place.
*//* Current sub-select, if any *//*
** Context object passed through sqlite3WalkExprList() to
** selectWindowRewriteExprCb() by selectWindowRewriteEList().
*//* Window function definition *//* Window frame to update *//* List of named windows for this SELECT *//*
** This function is called immediately after resolving the function name
** for a window function within a SELECT statement. Argument pList is a
** linked list of WINDOW definitions for the current SELECT statement.
** Argument pFunc is the function definition just resolved and pWin
** is the Window object representing the associated OVER clause. This
** function updates the contents of pWin as follows:
**
**   * If the OVER clause referred to a named window (as in "max(x) OVER win"),
**     search list pList for a matching WINDOW definition, and update pWin
**     accordingly. If no such WINDOW clause can be found, leave an error
**     in pParse.
**
**   * If the function is a built-in window function that requires the
**     window to be coerced (see "BUILT-IN WINDOW FUNCTIONS" at the top
**     of this file), pWin is updated here.
*//*
** Register those built-in window functions that are not also aggregates.
*//* Window functions that use all window interfaces: xStep, the
** same routine for xFinalize and xValue and which never call
** xInverse. *//* Window functions that are implemented using bytecode and thus have
** no-op routines for their methods *//* Window functions that use all window interfaces: xStep, xFinal,
** xValue, and xInverse *//*NO_TEST*//*
** No-op implementations of xStep() and xFinalize().  Used as place-holders
** for built-in window functions that never call those interfaces.
**
** The noopValueFunc() is called but is expected to do nothing.  The
** noopStepFunc() is never called, and so it is marked with NO_TEST to
** let the test coverage routine know not to expect this function to be
** invoked.
*//*
** Static names for the built-in window function names.  These static
** names are used, rather than string literals, so that FuncDef objects
** can be associated with a particular window function by direct
** comparison of the zName pointer.  Example:
**
**       if( pFuncDef->zName==row_valueName ){ ... }
*//*
** Implementation of last_value().
*//*
** Context object for last_value() window function.
*//*
** Implementation of ntile(). This assumes that the window frame has
** been coerced to:
**
**   ROWS CURRENT ROW AND UNBOUNDED FOLLOWING
*//* Parameter passed to ntile(N) *//* Total rows in partition *//*
** Context object for ntile() window function.
*//*
** Implementation of built-in window function cume_dist(). Assumes that
** the window frame has been set to:
**
**   GROUPS BETWEEN 1 FOLLOWING AND UNBOUNDED FOLLOWING
*//*
** Implementation of built-in window function percent_rank(). Assumes that
** the window frame has been set to:
**
**   GROUPS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING
*//*
** Implementation of built-in window function rank(). Assumes that
** the window frame has been set to:
**
**   RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
*//*
** Implementation of built-in window function nth_value(). This
** implementation is used in "slow mode" only - when the EXCLUDE clause
** is not set to the default value "NO OTHERS".
*//*
** Implementation of built-in window function dense_rank(). Assumes that
** the window frame has been set to:
**
**   RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
*//*
** Context object type used by rank(), dense_rank(), percent_rank() and
** cume_dist().
*//*
** Implementation of built-in window function row_number(). Assumes that the
** window frame has been coerced to:
**
**   ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
*//*
** SELECT REWRITING
**
**   Any SELECT statement that contains one or more window functions in
**   either the select list or ORDER BY clause (the only two places window
**   functions may be used) is transformed by function sqlite3WindowRewrite()
**   in order to support window function processing. For example, with the
**   schema:
**
**     CREATE TABLE t1(a, b, c, d, e, f, g);
**
**   the statement:
**
**     SELECT a+1, max(b) OVER (PARTITION BY c ORDER BY d) FROM t1 ORDER BY e;
**
**   is transformed to:
**
**     SELECT a+1, max(b) OVER (PARTITION BY c ORDER BY d) FROM (
**         SELECT a, e, c, d, b FROM t1 ORDER BY c, d
**     ) ORDER BY e;
**
**   The flattening optimization is disabled when processing this transformed
**   SELECT statement. This allows the implementation of the window function
**   (in this case max()) to process rows sorted in order of (c, d), which
**   makes things easier for obvious reasons. More generally:
**
**     * FROM, WHERE, GROUP BY and HAVING clauses are all moved to
**       the sub-query.
**
**     * ORDER BY, LIMIT and OFFSET remain part of the parent query.
**
**     * Terminals from each of the expression trees that make up the
**       select-list and ORDER BY expressions in the parent query are
**       selected by the sub-query. For the purposes of the transformation,
**       terminals are column references and aggregate functions.
**
**   If there is more than one window function in the SELECT that uses
**   the same window declaration (the OVER bit), then a single scan may
**   be used to process more than one window function. For example:
**
**     SELECT max(b) OVER (PARTITION BY c ORDER BY d),
**            min(e) OVER (PARTITION BY c ORDER BY d)
**     FROM t1;
**
**   is transformed in the same way as the example above. However:
**
**     SELECT max(b) OVER (PARTITION BY c ORDER BY d),
**            min(e) OVER (PARTITION BY a ORDER BY b)
**     FROM t1;
**
**   Must be transformed to:
**
**     SELECT max(b) OVER (PARTITION BY c ORDER BY d) FROM (
**         SELECT e, min(e) OVER (PARTITION BY a ORDER BY b), c, d, b FROM
**           SELECT a, e, c, d, b FROM t1 ORDER BY a, b
**         ) ORDER BY c, d
**     ) ORDER BY e;
**
**   so that both min() and max() may process rows in the order defined by
**   their respective window declarations.
**
** INTERFACE WITH SELECT.C
**
**   When processing the rewritten SELECT statement, code in select.c calls
**   sqlite3WhereBegin() to begin iterating through the results of the
**   sub-query, which is always implemented as a co-routine. It then calls
**   sqlite3WindowCodeStep() to process rows and finish the scan by calling
**   sqlite3WhereEnd().
**
**   sqlite3WindowCodeStep() generates VM code so that, for each row returned
**   by the sub-query a sub-routine (OP_Gosub) coded by select.c is invoked.
**   When the sub-routine is invoked:
**
**     * The results of all window-functions for the row are stored
**       in the associated Window.regResult registers.
**
**     * The required terminal values are stored in the current row of
**       temp table Window.iEphCsr.
**
**   In some cases, depending on the window frame and the specific window
**   functions invoked, sqlite3WindowCodeStep() caches each entire partition
**   in a temp table before returning any rows. In other cases it does not.
**   This detail is encapsulated within this file, the code generated by
**   select.c is the same in either case.
**
** BUILT-IN WINDOW FUNCTIONS
**
**   This implementation features the following built-in window functions:
**
**     row_number()
**     rank()
**     dense_rank()
**     percent_rank()
**     cume_dist()
**     ntile(N)
**     lead(expr [, offset [, default]])
**     lag(expr [, offset [, default]])
**     first_value(expr)
**     last_value(expr)
**     nth_value(expr, N)
**
**   These are the same built-in window functions supported by Postgres.
**   Although the behaviour of aggregate window functions (functions that
**   can be used as either aggregates or window functions) allows them to
**   be implemented using an API, built-in window functions are much more
**   esoteric. Additionally, some window functions (e.g. nth_value())
**   may only be implemented by caching the entire partition in memory.
**   As such, some built-in window functions use the same API as aggregate
**   window functions and some are implemented directly using VDBE
**   instructions. Additionally, for those functions that use the API, the
**   window frame is sometimes modified before the SELECT statement is
**   rewritten. For example, regardless of the specified window frame, the
**   row_number() function always uses:
**
**     ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
**
**   See sqlite3WindowUpdate() for details.
**
**   As well as some of the built-in window functions, aggregate window
**   functions min() and max() are implemented using VDBE instructions if
**   the start of the window frame is declared as anything other than
**   UNBOUNDED PRECEDING.
*//*
** 2018 May 08
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
*//************** Begin file window.c ******************************************//************** End of where.c ***********************************************//* Final cleanup
  *//* The "break" point is here, just past the end of the outer loop.
  ** Set it.
  *//* The WHERE_EXPRIDX flag is set by the planner when it is likely
              ** that pLoop is a covering index loop, but it is not possible
              ** to be 100% sure. In this case, any OP_Explain opcode
              ** corresponding to this loop describes the index as a "COVERING
              ** INDEX". But, pOp proves that pLoop is not actually a covering
              ** index loop. So clear the WHERE_EXPRIDX flag and rewrite the
              ** text that accompanies the OP_Explain opcode, if any.  *//* An error. pLoop is supposed to be a covering index loop,
              ** and yet the VM code refers to a column of the table that
              ** is not part of the index.  *//* Do not need to translate the column number *//* Proof that the "+1" on the k value above is safe *//* If this scan uses an index, make VDBE code substitutions to read data
    ** from the index instead of from the table where possible.  In some cases
    ** this optimization prevents the table from ever being read, which can
    ** yield a significant performance boost.
    **
    ** Calls to the code generator in between sqlite3WhereBegin and
    ** sqlite3WhereEnd will have created code that references the table
    ** directly.  This loop scans all that code looking for opcodes
    ** that reference the table and converts them into opcodes that
    ** reference the index.
    *//* For a co-routine, change all OP_Column references to the table of
    ** the co-routine into OP_Copy of result contained in a register.
    ** OP_Rowid becomes OP_Null.
    *//* Do RIGHT JOIN processing.  Generate code that will output the
    ** unmatched rows of the right operand of the RIGHT JOIN with
    ** all of the columns of the left operand set to NULL.
    *//* Retarget the OP_IsNull against the left operand of IN so
              ** it jumps past the OP_IfNoHope.  This is because the
              ** OP_IsNull also bypasses the OP_Affinity opcode that is
              ** required by OP_IfNoHope. *//* For LEFT JOIN queries, cursor pIn->iCur may not have been
              ** opened yet. This occurs for WHERE clauses such as
              ** "a = ? AND b IN (...)", where the index is on (a, b). If
              ** the RHS of the (a=?) is NULL, then the "b IN (...)" may
              ** never have been coded, but the body of the loop run to
              ** return the null-row. So, if the cursor is not open yet,
              ** jump over the OP_Next or OP_Prev instruction about to
              ** be coded.  *//* The common case: Advance to the next row *//* SQLITE_DISABLE_SKIPAHEAD_DISTINCT *//* Ticket [ef9318757b152e3] 2017-10-21 *//* Terminate the subroutine that forms the interior of the loop of
      ** the RIGHT JOIN table *//* Generate loop termination code.
  *//*
** Generate the end of the WHERE loop.  See comments on
** sqlite3WhereBegin() for additional information.
*//* So compiler won't complain about unused func *//*
** Part of sqlite3WhereEnd() will rewrite opcodes to reference the
** index rather than the main table.  In SQLITE_DEBUG mode, we want
** to trace those changes if PRAGMA vdbe_addoptrace=on.  This routine
** does that.
*//* WHERETRACE_ENABLED *//* Prevent harmless compiler warnings about debugging routines
  ** being declared but never used *//* Jump here if malloc fails *//* Done. *//* Generate the code to do the search.  Each iteration of the for
  ** loop below generates code for a single nested loop of the VM
  ** program.
  *//* The nature of RIGHT JOIN processing is such that it messes up
      ** the output order.  So omit any ORDER BY/GROUP BY elimination
      ** optimizations.  We need to do an actual sort for RIGHT JOIN. *//* SQLITE_ENABLE_COLUMN_USED_MASK *//* This is one term of an OR-optimization using the PRIMARY KEY of a
        ** WITHOUT ROWID table.  No need for a separate index *//* iAuxArg is always set to a positive value if ONEPASS is possible *//* If we know that only a prefix of the record will be used,
        ** it is advantageous to reduce the "column count" field in
        ** the P4 operand of the OP_OpenRead/Write opcode. *//* Do nothing *//* Index of database containing table/index *//* Table to open *//* Open all tables in the pTabList and any indices selected for
  ** searching those tables.
  *//* If the caller is an UPDATE or DELETE statement that is requesting
  ** to use a one-pass algorithm, determine if this is appropriate.
  **
  ** A one-pass approach can be used if the caller has requested one
  ** and either (a) the scan visits at most one row or (b) each
  ** of the following are true:
  **
  **   * the caller has indicated that a one-pass approach can be used
  **     with multiple rows (by setting WHERE_ONEPASS_MULTIROW), and
  **   * the table is not a virtual table, and
  **   * either the scan does not use the OR optimization or the caller
  **     is a DELETE operation (WHERE_DUPLICATES_OK is only specified
  **     for DELETE).
  **
  ** The last qualification is because an UPDATE statement uses
  ** WhereInfo.aiCurOnePass[1] to determine whether or not it really can
  ** use a one-pass approach, and this is not set accurately for scans
  ** that use the OR optimization.
  *//* Display all terms of the WHERE clause *//* Check to see if there are any SEARCH loops that might benefit from
  ** using a Bloom filter.
  *//* (7) *//* (1),(6) *//* Condition (1) *//* Must be a join, or this opt8n is pointless *//* Attempt to omit tables from a join that do not affect the result.
  ** See the comment on whereOmitNoopJoin() for further information.
  **
  ** This query optimization is factored out into a separate "no-inline"
  ** procedure to keep the sqlite3WhereBegin() procedure from becoming
  ** too large.  If sqlite3WhereBegin() becomes too large, that prevents
  ** some C-compiler optimizers from in-lining the
  ** sqlite3WhereCodeOneLoopStart() procedure, and it is important to
  ** in-line sqlite3WhereCodeOneLoopStart() for performance reasons.
  *//* TUNING:  Assume that a DISTINCT clause on a subquery reduces
    ** the output size by a factor of 8 (LogEst -30).
    *//* If one or more WhereTerm.truthProb values were used in estimating
    ** loop parameters, but then those truthProb values were subsequently
    ** changed based on STAT4 information while computing subsequent loops,
    ** then we need to rerun the whole loop building process so that all
    ** loops will be built using the revised truthProb values. *//* Display all WHERE clause terms *//* Construct the WhereLoop objects *//* Try to ORDER BY the result set to make distinct processing easier *//* The DISTINCT marking is pointless.  Ignore it. *//* Disable the DISTINCT optimization if SQLITE_DistinctOpt is set via
      ** sqlite3_test_ctrl(SQLITE_TESTCTRL_OPTIMIZATIONS,...) *//* Condition (3) *//* Condition (4) *//* Conditions (1) and (2) *//* The expression of pT *//* A term of the WHERE clause *//* The False-WHERE-Term-Bypass optimization:
  **
  ** If there are WHERE terms that are false, then no rows will be output,
  ** so skip over all of the code generated here.
  **
  ** Conditions:
  **
  **   (1)  The WHERE term must not refer to any tables in the join.
  **   (2)  The term must not come from an ON clause on the
  **        right-hand side of a LEFT or FULL JOIN.
  **   (3)  The term must not come from an ON clause, or there must be
  **        no RIGHT or FULL OUTER joins in pTabList.
  **   (4)  If the expression contains non-deterministic functions
  **        that are not within a sub-select. This is not required
  **        for correctness but rather to preserves SQLite's legacy
  **        behaviour in the following two cases:
  **
  **          WHERE random()>0;           -- eval random() once per row
  **          WHERE (SELECT random())>0;  -- eval random() just once overall
  **
  ** Note that the Where term need not be a constant in order for this
  ** optimization to apply, though it does need to be constant relative to
  ** the current subquery (condition 1).  The term might include variables
  ** from outer queries so that the value of the term changes from one
  ** invocation of the current subquery to the next.
  *//* Analyze all of the subexpressions. *//* Assign a bit from the bitmask to every term in the FROM clause.
    **
    ** The N-th term of the FROM clause is assigned a bitmask of 1<<N.
    **
    ** The rule of the previous sentence ensures that if X is the bitmask for
    ** a table T, then X-1 is the bitmask for all other tables to the left of T.
    ** Knowing the bitmask for all tables to the left of a left join is
    ** important.  Ticket #3015.
    **
    ** Note that bitmasks are created for all pTabList->nSrc tables in
    ** pTabList, not just the first nTabList tables.  nTabList is normally
    ** equal to pTabList->nSrc but might be shortened to 1 if the
    ** WHERE_OR_SUBCLAUSE flag is set.
    *//* Special case: No FROM clause
  *//* Split the WHERE clause into separate subexpressions where each
  ** subexpression is separated by an AND operator.
  *//* Initialize ix[0] to a value that can never be
                         ** a valid cursor number, to avoid an initial
                         ** test for pMaskSet->n==0 in sqlite3WhereGetMask() *//* ONEPASS defaults to OFF *//* Allocate and initialize the WhereInfo structure that will become the
  ** return value. A single allocation is used to store the WhereInfo
  ** struct, the contents of WhereInfo.a[], the WhereClause structure
  ** and the WhereMaskSet structure. Since WhereClause contains an 8-byte
  ** field (type Bitmask) it must be aligned on an 8-byte boundary on
  ** some architectures. Hence the ROUND8() below.
  *//* This function normally generates a nested loop for all tables in
  ** pTabList.  But if the WHERE_OR_SUBCLAUSE flag is set, then we should
  ** only generate code for the first table in pTabList and assume that
  ** any cursors associated with subsequent tables are uninitialized.
  *//* The number of tables in the FROM clause is limited by the number of
  ** bits in a Bitmask
  *//* Disable omit-noop-join opt *//* An ORDER/GROUP BY clause of more than 63 terms cannot be optimized *//* Variable initialization *//* Only one of WHERE_OR_SUBCLAUSE or WHERE_USE_LIMIT *//* OPFLAG_FORDELETE or zero, as appropriate *//* Pointer to a single WhereLoop object *//* A single level in pWInfo->a[] *//* The expression mask set *//* The WhereLoop builder *//* Cursors that are not yet positioned *//* The virtual database engine *//* Will become the return value of this function *//* Number of elements in pTabList *//* Num. bytes allocated for WhereInfo struct *//* If WHERE_OR_SUBCLAUSE is set, index cursor number
                          ** If WHERE_USE_LIMIT, then the limit amount *//* The WHERE_* flags defined in sqliteInt.h *//* The entire SELECT statement *//* Query result set.  Req'd for DISTINCT *//* An ORDER BY (or GROUP BY) clause, or NULL *//* The WHERE clause *//* FROM clause: A list of all tables to be scanned *//* The parser context *//*
** Generate the beginning of the loop used for WHERE clause processing.
** The return value is a pointer to an opaque structure that contains
** information needed to terminate the loop.  Later, the calling routine
** should invoke sqlite3WhereEnd() with the return value of this function
** in order to complete the WHERE clause processing.
**
** If an error occurs, this routine returns NULL.
**
** The basic idea is to do a nested loop, one loop for each table in
** the FROM clause of a select.  (INSERT and UPDATE statements are the
** same as a SELECT with only a single table in the FROM clause.)  For
** example, if the SQL is this:
**
**       SELECT * FROM t1, t2, t3 WHERE ...;
**
** Then the code generated is conceptually like the following:
**
**      foreach row1 in t1 do       \    Code generated
**        foreach row2 in t2 do      |-- by sqlite3WhereBegin()
**          foreach row3 in t3 do   /
**            ...
**          end                     \    Code generated
**        end                        |-- by sqlite3WhereEnd()
**      end                         /
**
** Note that the loops might not be nested in the order in which they
** appear in the FROM clause if a different order is better able to make
** use of indices.  Note also that when the IN operator appears in
** the WHERE clause, it might result in additional nested loops for
** scanning through all values on the right-hand side of the IN.
**
** There are Btree cursors associated with each table.  t1 uses cursor
** number pTabList->a[0].iCursor.  t2 uses the cursor pTabList->a[1].iCursor.
** And so forth.  This routine generates code to open those VDBE cursors
** and sqlite3WhereEnd() generates the code to close them.
**
** The code that sqlite3WhereBegin() generates leaves the cursors named
** in pTabList pointing at their appropriate entries.  The [...] code
** can use OP_Column and OP_Rowid opcodes on these cursors to extract
** data from the various tables of the loop.
**
** If the WHERE clause is empty, the foreach loops must each scan their
** entire tables.  Thus a three-way join is an O(N^3) operation.  But if
** the tables have indices and there are terms in the WHERE clause that
** refer to those indices, a complete table scan can be avoided and the
** code will run much faster.  Most of the work of this routine is checking
** to see if there are indices that can be used to speed up the loop.
**
** Terms of the WHERE clause are also used to limit which rows actually
** make it to the "..." in the middle of the loop.  After each "foreach",
** terms of the WHERE clause that use only terms in that loop and outer
** loops are evaluated and if false a jump is made around all subsequent
** inner loops (or around the "..." if the test occurs within the inner-
** most loop)
**
** OUTER JOINS
**
** An outer join of tables t1 and t2 is conceptually coded as follows:
**
**    foreach row1 in t1 do
**      flag = 0
**      foreach row2 in t2 do
**        start:
**          ...
**          flag = 1
**      end
**      if flag==0 then
**        move the row2 cursor to a null row
**        goto start
**      fi
**    end
**
** ORDER BY CLAUSE PROCESSING
**
** pOrderBy is a pointer to the ORDER BY clause (or the GROUP BY clause
** if the WHERE_GROUPBY flag is set in wctrlFlags) of a SELECT statement
** if there is one.  If there is no ORDER BY clause or if this routine
** is called from an UPDATE or DELETE statement, then pOrderBy is NULL.
**
** The iIdxCur parameter is the cursor number of an index.  If
** WHERE_OR_SUBCLAUSE is set, iIdxCur is the cursor number of an index
** to use for OR clause processing.  The WHERE clause should use this
** specific cursor.  If WHERE_ONEPASS_DESIRED is set, then iIdxCur is
** the first cursor in an array of cursors for all indices.  iIdxCur should
** be used to compute the appropriate cursor depending on which index is
** used.
*//*
** Set the reverse-scan order mask to one for all tables in the query
** with the exception of MATERIALIZED common table expressions that have
** their own internal ORDER BY clauses.
**
** This implements the PRAGMA reverse_unordered_selects=ON setting.
** (Also SQLITE_DBCONFIG_REVERSE_SCANORDER).
*//* The FROM clause entry for the table *//* Cursor number for pIdx *//* The index-on-expression that contains the expressions *//* Add IndexedExpr entries to pParse->pIdxEpr *//*
** The index pIdx is used by a query and contains one or more expressions.
** In other words pIdx is an index on an expression.  iIdxCur is the cursor
** number for the index and iDataCur is the cursor number for the corresponding
** table.
**
** This routine adds IndexedExpr entries to the Parse->pIdxEpr field for
** each of the expressions in the index so that the expression code generator
** will know to replace occurrences of the indexed expression with
** references to the corresponding column of the index.
*//* vvvvvv--- Always the case if WHERE_COLUMN_EQ is defined *//*
** Check to see if there are any SEARCH loops that might benefit from
** using a Bloom filter.  Consider a Bloom filter if:
**
**   (1)  The SEARCH happens more than N times where N is the number
**        of rows in the table that is being considered for the Bloom
**        filter.
**   (2)  Some searches are expected to find zero rows.  (This is determined
**        by the WHERE_SELFCULL flag on the term.)
**   (3)  Bloom-filter processing is not disabled.  (Checked by the
**        caller.)
**   (4)  The size of the table being searched is known by ANALYZE.
**
** This block of code merely checks to see if a Bloom filter would be
** appropriate, and if so sets the WHERE_BLOOMFILTER flag on the
** WhereLoop.  The implementation of the Bloom filter comes further
** down where the code for each WhereLoop is generated.
*//* restriction (5) *//* These two preconditions checked by the caller combine to guarantee
  ** condition (1) of the header comment *//* Preconditions checked by the caller *//* Attempt to omit tables from a join that do not affect the result.
** For a table to not affect the result, the following must be true:
**
**   1) The query must not be an aggregate.
**   2) The table must be the RHS of a LEFT JOIN.
**   3) Either the query must be DISTINCT, or else the ON or USING clause
**      must contain a constraint that limits the scan of the table to
**      at most a single row.
**   4) The table must not be referenced by any part of the query apart
**      from its own USING or ON clause.
**   5) The table must not have an inner-join ON or USING clause if there is
**      a RIGHT JOIN anywhere in the query.  Otherwise the ON/USING clause
**      might move from the right side to the left side of the RIGHT JOIN.
**      Note: Due to (2), this condition can only arise if the table is
**      the right-most table of a subquery that was flattened into the
**      main query and that subquery was the right-hand operand of an
**      inner join that held an ON or USING clause.
**   6) The ORDER BY clause has 63 or fewer terms
**   7) The omit-noop-join optimization is enabled.
**
** Items (1), (6), and (7) are checked by the caller.
**
** For example, given:
**
**     CREATE TABLE t1(ipk INTEGER PRIMARY KEY, v1);
**     CREATE TABLE t2(ipk INTEGER PRIMARY KEY, v2);
**     CREATE TABLE t3(ipk INTEGER PRIMARY KEY, v3);
**
** then table t2 can be omitted from the following:
**
**     SELECT v1, v3 FROM t1
**       LEFT JOIN t2 ON (t1.ipk=t2.ipk)
**       LEFT JOIN t3 ON (t1.ipk=t3.ipk)
**
** or from:
**
**     SELECT DISTINCT v1, v3 FROM t1
**       LEFT JOIN t2
**       LEFT JOIN t3 ON (t1.ipk=t3.ipk)
*//* Display all of the WhereLoop objects *//*
** Display all WhereLoops in pWInfo
*//*
** Return true if the expression contains no non-deterministic SQL
** functions. Do not consider non-deterministic SQL functions that are
** part of sub-select statements.
*//*
** Helper function for exprIsDeterministic().
*//* sqlite3WhereGetMask(&pWInfo->sMaskSet, iCur); *//* 39==sqlite3LogEst(15) *//* TUNING: Cost of a unique index lookup is 15 *//* 33==sqlite3LogEst(10) *//* TUNING: Cost of a rowid lookup is 10 *//*
** Most queries use only a single table (they are not joins) and have
** simple == constraints against indexed fields.  This routine attempts
** to plan those simple cases using much less ceremony than the
** general-purpose query planner, and thereby yield faster sqlite3_prepare()
** times for the common case.
**
** Return non-zero on success, if this query can be handled by this
** no-frills query planner.  Return zero if this query needs the
** general-purpose query planner.
*//* Prevent 2nd solver() from using this one *//* Auto-index and index-constrained loops allowed to remain *//*
** This routine implements a heuristic designed to improve query planning.
** This routine is called in between the first and second call to
** wherePathSolver().  Hence the name "Interstage" "Heuristic".
**
** The first call to wherePathSolver() (hereafter just "solver()") computes
** the best path without regard to the order of the outputs.  The second call
** to the solver() builds upon the first call to try to find an alternative
** path that satisfies the ORDER BY clause.
**
** This routine looks at the results of the first solver() run, and for
** every FROM clause term in the resulting query plan that uses an equality
** constraint against an index, disable other WhereLoops for that same
** FROM clause term that would try to do a full-table scan.  This prevents
** an index search from being converted into a full-table scan in order to
** satisfy an ORDER BY clause, since even though we might get slightly better
** performance using the full-scan without sorting if the output size
** estimates are very precise, we might also get severe performance
** degradation using the full-scan if the output size estimate is too large.
** It is better to err on the side of caution.
**
** Except, if the first solver() call generated a full-table scan in an outer
** loop then stop this analysis at the first full-scan, since the second
** solver() run might try to swap that full-scan for another in order to
** get the output into the correct order.  In other words, we allow a
** rewrite like this:
**
**     First Solver()                      Second Solver()
**       |-- SCAN t1                         |-- SCAN t2
**       |-- SEARCH t2                       `-- SEARCH t1
**       `-- SORT USING B-TREE
**
** The purpose of this routine is to disallow rewrites such as:
**
**     First Solver()                      Second Solver()
**       |-- SEARCH t1                       |-- SCAN t2     <--- bad!
**       |-- SEARCH t2                       `-- SEARCH t1
**       `-- SORT USING B-TREE
**
** See test cases in test/whereN.test for the real-world query that
** originally provoked this heuristic.
*//* Free temporary memory and return success *//* vvv--- See check-in [12ad822d9b827777] on 2023-03-16 ---vvv *//* Load the lowest cost path into pWInfo *//* Find the lowest cost path.  pFrom will be left pointing to that path *//* Swap the roles of aFrom and aTo for the next generation *//* >=2 *//* pWLoop is a winner.  Add it to the set of best so far *//* 0x4 *//* Control reaches here if the candidate path is better than the
          ** pTo path.  Replace pTo with the candidate. *//* Discard the candidate path from further consideration *//* Control reaches here if best-so-far path pTo=aTo[jj] covers the
          ** same set of loops and has the same isOrdered setting as the
          ** candidate path.  Check to see if the candidate should replace
          ** pTo or if the candidate should be skipped.
          **
          ** The conditional is an expanded vector comparison equivalent to:
          **   (pTo->rCost,pTo->nRow,pTo->rUnsort) <= (rCost,nOut,rUnsort)
          *//* New path replaces the prior worst to keep count below mxChoice *//* Increase the size of the aTo set by one *//* If we reach this points it means that the new candidate path
          ** needs to be added to the set of best-so-far paths. *//* The current candidate is no better than any of the mxChoice
            ** paths currently in the best-so-far buffer.  So discard
            ** this candidate as not viable. *//* None of the existing best-so-far paths match the candidate. *//* Check to see if pWLoop should be added to the set of
        ** mxChoice best-so-far paths.
        **
        ** First look for an existing path among best-so-far paths
        ** that covers the same set of loops and has the same isOrdered
        ** setting as the current path candidate.
        **
        ** The term "((pTo->isOrdered^isOrdered)&0x80)==0" is equivalent
        ** to (pTo->isOrdered==(-1))==(isOrdered==(-1))" for the range
        ** of legal values for isOrdered, -1..64.
        *//* TUNING:  Slight bias in favor of no-sort plans *//* TUNING:  Add a small extra penalty (3) to sorting as an
          ** extra encouragement to the query planner to select a plan
          ** where the rows emerge in the correct order without any sorting
          ** required. *//* At this point, pWLoop is a candidate to be the next loop.
        ** Compute its cost *//* Do not use an automatic index if the this loop is expected
          ** to run less than 1.25 times.  It is tempting to also exclude
          ** automatic index usage on an outer loop, but sometimes an automatic
          ** index is useful in the outer loop of a correlated subquery. *//* Mask of rev-order loops for (..) *//* Mask of src visited by (..) *//* isOrdered for (pFrom+pWLoop) *//* Unsorted cost of (pFrom+pWLoop) *//* Cost of path (pFrom+pWLoop) *//* Rows visited by (pFrom+pWLoop) *//* Compute successively longer WherePaths using the previous generation
  ** of WherePaths as the basis for the next.  Keep track of the mxChoice
  ** best paths at each generation *//* If nLoop is zero, then there are no FROM terms in the query. Since
    ** in this case the query may return a maximum of one row, the results
    ** are already in the requested order. Set isOrdered to nOrderBy to
    ** indicate this. Or, if nLoop is greater than zero, set isOrdered to
    ** -1, indicating that the result set may or may not be ordered,
    ** depending on the loops added to the current plan.  *//* Seed the search with a single WherePath containing zero WhereLoops.
  **
  ** TUNING: Do not let the number of iterations go above 28.  If the cost
  ** of computing an automatic index is not paid back within the first 28
  ** rows, then do not use the automatic index. *//* If there is an ORDER BY clause and it is not being ignored, set up
    ** space for the aSortCost[] array. Each element of the aSortCost array
    ** is either zero - meaning it has not yet been initialized - or the
    ** cost of sorting nRowEst rows of data where the first X terms of
    ** the ORDER BY clause are already in order, where X is the array
    ** index.  *//* Allocate and initialize space for aTo, aFrom and aSortCost[] *//* If nRowEst is zero and there is an ORDER BY clause, ignore it. In this
  ** case the purpose of this call is to estimate the number of rows returned
  ** by the overall query. Once this estimate has been obtained, the caller
  ** will invoke this function a second time, passing the estimate as the
  ** nRowEst parameter.  *//* TUNING: mxChoice is the maximum number of possible paths to preserve
  ** at each step.  Based on the number of loops in the FROM clause:
  **
  **     nLoop      mxChoice
  **     -----      --------
  **       1            1            // the most common case
  **       2            5
  **       3+        12 or 18        // see computeMxChoice()
  *//* Bytes of space allocated at pSpace *//* Temporary memory used by this routine *//* Sorting and partial sorting costs *//* Used to divy up the pSpace memory *//* One of the WhereLoop objects *//* An element of aTo[] that we are working on *//* An element of aFrom[] that we are working on *//* The nTo best paths at the current level *//* All nFrom paths at the previous level *//* Number of valid entries in aTo[] and aFrom[] *//* Maximum unsorted cost of a set of path *//* Maximum cost of a set of paths *//* Number of ORDER BY clause terms *//* Index of next entry to replace *//* Loop counter over the terms of the join *//* Number of terms in the join *//* Maximum number of simultaneous paths tracked *//*
** Given the list of WhereLoop objects at pWInfo->pLoops, this routine
** attempts to find the lowest cost path that visits each WhereLoop
** once.  This path is then loaded into the pWInfo->a[].pWLoop fields.
**
** Assume that the total number of output rows that will need to be sorted
** will be nRowEst (in the 10*log2 representation).  Or, ignore sorting
** costs if nRowEst==0.
**
** Return SQLITE_OK on success or SQLITE_NOMEM of a memory allocation
** error occurs.
*//*
** Two WhereLoop objects, pCandidate and pBaseline, are known to have the
** same cost.  Look deep into each to see if pCandidate is even slightly
** better than pBaseline.  Return false if it is, if pCandidate is is preferred.
** Return true if pBaseline is preferred or if we cannot tell the difference.
**
**    Result       Meaning
**    --------     ----------------------------------------------------------
**    true         We cannot tell the difference in pCandidate and pBaseline
**    false        pCandidate seems like a better choice than pBaseline
*//* 0x80000 *//* Increase the cost of table scans for dimension tables to be
      ** slightly more than the maximum cost of the fact table *//* Compute the maximum cost of any WhereLoop for the
      ** fact table plus one epsilon *//* Make sure rStarDelta values are initialized *//* If we reach this point, it means that pFactTab is a fact table
      ** with four or more dimensions connected by inner joins.  Proceed
      ** to make cost adjustments. *//* Not a self-join *//* pWInfo not already a dependency *//* pWInfo depends on iFromIdx *//* Fact-tables and dimension-tables cannot be separated by an
          ** outer join (at least for the definition of fact- and dimension-
          ** used by this heuristic). *//* Impossible to reach nDep>=4 *//* If the candidate fact-table is the right table of an outer join
        ** restrict the search for dimension-tables to be tables to the right
        ** of the fact-table. *//* The candidate fact table *//* Mask of dimension tables *//* Maximum SCAN cost of a fact table *//* Number of dimension tables *//* Look for fact tables with four or more dimensions where the
    ** dimension tables are not separately from the fact tables by an outer
    ** or cross join.  Adjust cost weights if found.
    *//* Only do this computation once *//* Where to start searching for dimension-tables *//* Tables that cannot be dimension tables *//* Bitmask for candidate fact-table *//* Term of FROM clause is the candidate fact-table *//* All terms of the FROM clause *//* The star-query detection code below makes use of the following
  ** properties of the WhereLoop list, so verify them before
  ** continuing:
  **    (1)  .maskSelf is the bitmask corresponding to .iTab
  **    (2)  The WhereLoop list is in ascending .iTab order
  *//* For looping over WhereLoops *//*
** Compute the maximum number of paths in the solver algorithm, for
** queries that have three or more terms in the FROM clause.  Queries with
** two or fewer FROM clause terms are handled by the caller.
**
** Query planning is NP-hard.  We must limit the number of paths at
** each step of the solver search algorithm to avoid exponential behavior.
**
** The value returned is a tuning parameter.  Currently the value is:
**
**     18    for star queries
**     12    otherwise
**
** For the purposes of this heuristic, a star-query is defined as a query
** with a large central table that is joined using an INNER JOIN,
** not CROSS or OUTER JOINs, against four or more smaller tables.
** The central table is called the "fact" table.  The smaller tables
** that get joined are "dimension tables".  Also, any table that is
** self-joined cannot be a dimension table; we assume that dimension
** tables may only be joined against fact tables.
**
** SIDE EFFECT:  (and really the whole point of this subroutine)
**
** If pWInfo describes a star-query, then the cost for SCANs of dimension
** WhereLoops is increased to be slightly larger than the cost of a SCAN
** in the fact table.  Only SCAN costs are increased.  SEARCH costs are
** unchanged. This heuristic helps keep fact tables in outer loops. Without
** this heuristic, paths with fact tables in outer loops tend to get pruned
** by the mxChoice limit on the number of paths, resulting in poor query
** plans.  See the starschema1.test test module for examples of queries
** that need this heuristic to find good query plans.
**
** This heuristic can be completely disabled, so that no query is
** considered a star-query, using SQLITE_TESTCTRL_OPTIMIZATION to
** disable the SQLITE_StarQuery optimization.  In the CLI, the command
** to do that is:  ".testctrl opt -starquery".
**
** HISTORICAL NOTES:
**
** This optimization was first added on 2024-05-09 by check-in 38db9b5c83d.
** The original optimization reduced the cost and output size estimate for
** fact tables to help them move to outer loops.  But months later (as people
** started upgrading) performance regression reports started caming in,
** including:
**
**    forum post b18ef983e68d06d1 (2024-12-21)
**    forum post 0025389d0860af82 (2025-01-14)
**    forum post d87570a145599033 (2025-01-17)
**
** To address these, the criteria for a star-query was tightened to exclude
** cases where the fact and dimensions are separated by an outer join, and
** the affect of star-schema detection was changed to increase the rRun cost
** on just full table scans of dimension tables, rather than reducing costs
** in the all access methods of the fact table.
*//* TUNING: In the sort for a DISTINCT operator, assume that the DISTINCT
    ** reduces the number of output rows by a factor of 2 *//* TUNING: Extra 1.5x if also using partial sort *//* TUNING: Extra 2.0x if using LIMIT *//* Multiple by log(M) where M is the number of output rows.
  ** Use the LIMIT for M if it is smaller.  Or if this sort is for
  ** a DISTINCT operator, M will be the number of distinct output
  ** rows, so fudge it downwards a bit.
  *//* Scale the result by (Y/X) *//* TUNING: sorting cost proportional to the number of output columns: *//* Estimated cost of a full external sort, where N is
  ** the number of rows to sort is:
  **
  **   cost = (K * N * log(N)).
  **
  ** Or, if the order-by clause has X terms but only the last Y
  ** terms are out of order, then block-sorting will reduce the
  ** sorting cost to:
  **
  **   cost = (K * N * log(N)) * (Y/X)
  **
  ** The constant K is at least 2.0 but will be larger if there are a
  ** large number of columns to be sorted, as the sorting time is
  ** proportional to the amount of content to be sorted.  The algorithm
  ** does not currently distinguish between fat columns (BLOBs and TEXTs)
  ** and skinny columns (INTs).  It just uses the number of columns as
  ** an approximation for the row width.
  **
  ** And extra factor of 2.0 or 3.0 is added to the sorting cost if the sort
  ** is built using OP_IdxInsert and OP_Sort rather than with OP_SorterInsert.
  *//* Number of initial ORDER BY terms naturally in order *//* Estimated number of rows to sort *//* Query planning context *//*
** Return the cost of sorting nRow rows, assuming that the keys have
** nOrderby columns and that the first nSorted columns are already in
** order.
*//* For debugging use only: *//*
** If the WHERE_GROUPBY flag is set in the mask passed to sqlite3WhereBegin(),
** the planner assumes that the specified pOrderBy list is actually a GROUP
** BY clause - and so any order that groups rows as required satisfies the
** request.
**
** Normally, in this case it is not possible for the caller to determine
** whether or not the rows are really being delivered in sorted order, or
** just in some other order that provides the required grouping. However,
** if the WHERE_SORTBYGROUP flag is also passed to sqlite3WhereBegin(), then
** this function may be called on the returned WhereInfo object. It returns
** true if the rows really will be sorted in the specified order, or false
** otherwise.
**
** For example, assuming:
**
**   CREATE INDEX i1 ON t1(x, Y);
**
** then
**
**   SELECT * FROM t1 GROUP BY x,y ORDER BY x,y;   -- IsSorted()==1
**   SELECT * FROM t1 GROUP BY y,x ORDER BY y,x;   -- IsSorted()==0
*//* End the loop over all WhereLoops from outer-most down to inner-most *//* Mark off any other ORDER BY terms that reference pLoop *//* end-if not one-row *//* end Loop over all index columns *//* No match found *//* Make sure the sort order is compatible in an ORDER BY clause.
          ** Sort order is irrelevant for a GROUP BY clause. *//* Find the ORDER BY term that corresponds to the j-th column
        ** of the index and mark that ORDER BY term having been satisfied.
        *//* An unconstrained column that might be NULL means that this
        ** WhereLoop is not well-ordered.  tag-20210426-1
        *//* Get the column number in the table (iColumn) and sort order
        ** (revIdx) for the j-th column of the index.
        *//* ALWAYS() justification: eOp is an equality operator due to the
            ** j<pLoop->u.btree.nEq constraint above.  Any equality other
            ** than WO_IN is captured by the previous "if".  So this one
            ** always has to be WO_IN. *//* Skip over == and IS and ISNULL terms.  (Also skip IN terms when
          ** doing WHERE_ORDERBY_LIMIT processing).  Except, IS and ISNULL
          ** terms imply that the index is not UNIQUE NOT NULL in which case
          ** the loop need to be marked as not order-distinct because it can
          ** have repeated NULL rows.
          **
          ** If the current term is a column of an ((?,?) IN (SELECT...))
          ** expression for which the SELECT returns more than one column,
          ** check that it is the only column used by this loop. Otherwise,
          ** if it is one of two or more, none of the columns can be
          ** considered to match an ORDER BY term.
          *//* True to run the ORDER BY search loop *//* Loop through all columns of the index and deal with the ones
      ** that are not constrained by == or IN.
      *//* All relevant terms of the index must also be non-NULL in order
        ** for isOrderDistinct to be true.  So the isOrderDistinct value
        ** computed here might be a false positive.  Corrections will be
        ** made at tag-20210426-1 below *//* IN terms are only valid for sorting in the ORDER BY LIMIT
        ** optimization, and then only if they are actually used
        ** by the query plan *//* Mark off any ORDER BY term X that is a column in the table of
    ** the current loop for which there is term in the WHERE
    ** clause of the form X IS NULL or X=? that reference only outer
    ** loops.
    *//* Cannot optimize overly large ORDER BYs *//*
  ** We say the WhereLoop is "one-row" if it generates no more than one
  ** row of output.  A WhereLoop is one-row if all of the following are true:
  **  (a) All index columns match with WHERE_COLUMN_EQ.
  **  (b) The index is unique
  ** Any WhereLoop with an WHERE_COLUMN_EQ constraint on the rowid is one-row.
  ** Every one-row WhereLoop will have the WHERE_ONEROW bit set in wsFlags.
  **
  ** We say the WhereLoop is "order-distinct" if the set of columns from
  ** that WhereLoop that are in the ORDER BY clause are different for every
  ** row of the WhereLoop.  Every one-row WhereLoop is automatically
  ** order-distinct.   A WhereLoop that has no columns in the ORDER BY clause
  ** is not order-distinct. To be order-distinct is not quite the same as being
  ** UNIQUE since a UNIQUE column or index can have multiple rows that
  ** are NULL and NULL values are equivalent for the purpose of order-distinct.
  ** To be order-distinct, the columns must be UNIQUE and NOT NULL.
  **
  ** The rowid for a table is always UNIQUE and NOT NULL so whenever the
  ** rowid appears in the ORDER BY clause, the corresponding WhereLoop is
  ** automatically order-distinct.
  *//* Mask of inner loops *//* Mask of all well-ordered loops *//* Mask of all ORDER BY terms *//* Mask of ORDER BY terms satisfied so far *//* The index associated with pLoop *//* COLLATE function from an ORDER BY clause term *//* An expression from the ORDER BY clause *//* A single term of the WHERE clause *//* Current WhereLoop being processed. *//* A column number within table iCur *//* Cursor number for current WhereLoop *//* Index of WhereLoop in pPath being processed *//* Number terms in the ORDER BY clause *//* Total number of ordered columns in the index *//* Number of key columns in pIndex *//* Allowed equality operators *//* iColumn matches a term of the ORDER BY clause *//* True if the loop has UNIQUE NOT NULL columns *//* All prior WhereLoops are order-distinct *//* Index sort order *//* Composite sort order *//* True if rev is known *//* OUT: Mask of WhereLoops to run in reverse order *//* Add this WhereLoop to the end of pPath->aLoop[] *//* Number of entries in pPath->aLoop[] *//* WHERE_GROUPBY or _DISTINCTBY or _ORDERBY_LIMIT *//* The WherePath to check *//* ORDER BY or GROUP BY or DISTINCT clause to check *//*
** Examine a WherePath (with the addition of the extra WhereLoop of the 6th
** parameters) to see if it outputs rows in the requested ORDER BY
** (or GROUP BY) without requiring a separate sort operation.  Return N:
**
**   N>0:   N terms of the ORDER BY clause are satisfied
**   N==0:  No terms of the ORDER BY clause are satisfied
**   N<0:   Unknown yet how many terms of ORDER BY might be satisfied.
**
** Note that processing for WHERE_GROUPBY and WHERE_DISTINCTBY is not as
** strict.  With GROUP BY and DISTINCT the only requirement is that
** equivalent rows appear immediately adjacent to one another.  GROUP BY
** and DISTINCT do not require rows to appear in any particular order as long
** as equivalent rows are grouped together.  Thus for GROUP BY and DISTINCT
** the pOrderBy terms can be matched in any order.  With ORDER BY, the
** pOrderBy terms must be matched in strict left-to-right order.
*//* Cannot run a co-routine in reverse order *//* sortFlags for jSub *//* sortFlags for iOB *//* Complete ORDER BY on the subquery *//* Current term of outer ORDER BY *//* Sort direction for jSub *//* True if iOB and jSub sort in opposite directions *//* Index into pSubOB->a[] *//* Index into pOrderBy->a[] *//* Which terms of pOrderBy are satisfied so far *//* When loops need to go in reverse order *//* The ORDER BY clause on the whole query *//* Cursor used by the this loop *//* Which level of the nested loop.  0==outermost *//* The nested loop term that is a subquery *//* Implementation of the order-by-subquery optimization:
**
** WhereLoop pLoop, which the iLoop-th term of the nested loop, is really
** a subquery or CTE that has an ORDER BY clause.  See if any of the terms
** in the subquery ORDER BY clause will satisfy pOrderBy from the outer
** query.  Mark off all satisfied terms (by setting bits in *pOBSat) and
** return TRUE if they do.  If not, return false.
**
** Example:
**
**    CREATE TABLE t1(a,b,c, PRIMARY KEY(a,b));
**    CREATE TABLE t2(x,y);
**    WITH t3(p,q) AS MATERIALIZED (SELECT x+y, x-y FROM t2 ORDER BY x+y)
**       SELECT * FROM t3 JOIN t1 ON a=q ORDER BY p, b;
**
** The CTE named "t3" comes out in the natural order of "p", so the first
** first them of "ORDER BY p,b" is satisfied by a sequential scan of "t3"
** and sorting only needs to occur on the second term "b".
**
** Limitations:
**
** (1)  The optimization is not applied if the outer ORDER BY contains
**      a COLLATE clause.  The optimization might be applied if the
**      outer ORDER BY uses NULLS FIRST, NULLS LAST, ASC, and/or DESC as
**      long as the subquery ORDER BY does the same.  But if the
**      outer ORDER BY uses COLLATE, even a redundant COLLATE, the
**      optimization is bypassed.
**
** (2)  The subquery ORDER BY terms must exactly match subquery result
**      columns, including any COLLATE annotations.  This routine relies
**      on iOrderByCol to do matching between order by terms and result
**      columns, and iOrderByCol will not be set if the result column
**      and ORDER BY collations differ.
**
** (3)  The subquery and outer ORDER BY can be in opposite directions as
**      long as  the subquery is materialized.  If the subquery is
**      implemented as a co-routine, the sort orders must be in the same
**      direction because there is no way to run a co-routine backwards.
*//* We hit the query planner search limit set by iPlanLimit *//* Add prerequisites to prevent reordering of FROM clause terms
      ** across CROSS joins and outer joins.  The bFirstPastRJ boolean
      ** prevents the right operand of a RIGHT JOIN from being swapped with
      ** other elements even further to the right.
      **
      ** The JT_LTORJ case and the hasRightJoin flag work together to
      ** prevent FROM-clause terms from moving from the right side of
      ** a LEFT JOIN over to the left side of that join if the LEFT JOIN
      ** is itself on the left side of a RIGHT JOIN.
      *//* Verify that pNew has already been initialized *//* Loop over the tables in the join, from left to right *//*
** Add all WhereLoop objects for all tables
*//* TUNING: Currently sSum.a[i].rRun is set to the sum of the costs
        ** of all sub-scans required by the OR-scan. However, due to rounding
        ** errors, it may be that the cost of the OR-scan is equal to its
        ** most expensive sub-scan. Add the smallest possible penalty
        ** (equivalent to multiplying the cost by 1.07) to ensure that
        ** this does not happen. Otherwise, for WHERE clauses such as the
        ** following where there is an index on "y":
        **
        **     WHERE likelihood(x=?, 0.99) OR y=?
        **
        ** the planner may elect to "OR" together a full-table scan and an
        ** index lookup. And other similarly odd results.  *//* The multi-index OR optimization does not work for RIGHT and FULL JOIN *//*
** Add WhereLoop entries to handle OR terms.  This works for either
** btrees or virtual tables.
*//* If the calls to xBestIndex() have so far failed to find a plan
    ** that requires no source tables at all and does not use an IN(...)
    ** operator, make a final call to obtain one here.  *//* If the calls to xBestIndex() in the above loop did not find a plan
    ** that requires no source tables at all (i.e. one guaranteed to be
    ** usable), make a call here with all source tables disabled *//* Call xBestIndex once for each distinct value of (prereqRight & ~mPrereq)
    ** in the set of terms that apply to the current virtual table.  *//* If the plan produced by the earlier call uses an IN(...) term, call
    ** xBestIndex again, this time with IN(...) terms disabled. *//* Plan with no prereqs and no IN(...) seen *//* True if a plan with no prereqs seen *//* If the call to xBestIndex() with all terms enabled produced a plan
  ** that does not require any source tables (IOW: a plan with mBest==0)
  ** and does not use an IN(...) operator, then there is no point in making
  ** any further calls to xBestIndex() since they will all return the same
  ** result (if the xBestIndex() implementation is sane). *//* First call xBestIndex() with all constraints usable. *//* True to retry with LIMIT/OFFSET disabled *//* Tables used by best possible plan *//* True if plan uses IN(...) operator *//* Number of constraints in p *//* Object to pass to xBestIndex() *//* The FROM clause term to search *//* The parsing context *//* WHERE analysis context *//* Tables that must be scanned after this one *//* Tables that must be scanned before this one *//* WHERE clause information *//*
** Add all WhereLoop objects for a table of the join identified by
** pBuilder->pNew->iTab.  That table is guaranteed to be a virtual table.
**
** If there are no LEFT or CROSS JOIN joins in the query, both mPrereq and
** mUnusable are set to 0. Otherwise, mPrereq is a mask of all FROM clause
** entries that occur before the virtual table in the FROM clause and are
** separated from it by at least one LEFT or CROSS JOIN. Similarly, the
** mUnusable mask contains all FROM clause entries that occur after the
** virtual table and are separated from it by at least one LEFT or
** CROSS JOIN.
**
** For example, if the query were:
**
**   ... FROM t1, t2 LEFT JOIN t3, t4, vt CROSS JOIN t5, t6;
**
** then mPrereq corresponds to (t1, t2) and mUnusable to (t5, t6).
**
** All the tables in mPrereq must be scanned before the current virtual
** table. So any terms for which all prerequisites are satisfied by
** mPrereq may be specified as "usable" in all calls to xBestIndex.
** Conversely, all tables in mUnusable must be scanned after the current
** virtual table, so any terms for which the prerequisites overlap with
** mUnusable should always be configured as "not-usable" for xBestIndex.
*//*
** Cause the prepared statement that is associated with a call to
** xBestIndex to potentially use all schemas.  If the statement being
** prepared is read-only, then just start read transactions on all
** schemas.  But if this is a write operation, start writes on all
** schemas.
**
** This is used by the (built-in) sqlite_dbpage virtual table.
*//*
** Return true if ORDER BY clause may be handled as DISTINCT.
*//* IMP: R-36424-56542 *//* IMP: R-19933-32160 *//* EV: R-30545-25046 *//* Write value extracted here *//* Constraint for which RHS is wanted *//* Copy of first argument to xBestIndex *//*
** This interface is callable from within the xBestIndex callback only.
**
** If possible, set (*ppVal) to point to an object containing the value
** on the right-hand-side of constraint iCons.
*//*
** Return true if constraint iCons is really an IN(...) constraint, or
** false otherwise. If iCons is an IN(...) constraint, set (if bHandle!=0)
** or clear (if bHandle==0) the flag to handle it using an iterator.
*//*
** Return the collating sequence for a constraint passed into xBestIndex.
**
** pIdxInfo must be an sqlite3_index_info structure passed into xBestIndex.
** This routine depends on there being a HiddenIndexInfo structure immediately
** following the sqlite3_index_info structure.
**
** Return a pointer to the collation name:
**
**    1. If there is an explicit COLLATE operator on the constraint, return it.
**
**    2. Else, if the column has an alternative collation, return that.
**
**    3. Otherwise, return "BINARY".
*//* Set the WHERE_ONEROW flag if the xBestIndex() method indicated
  ** that the scan will visit at most one row. Clear it otherwise. *//* The non-zero argvIdx values must be contiguous.  Raise an
      ** error if they are not *//* If there is an IN(...) term handled as an == (separate call to
        ** xFilter for each value on the RHS of the IN) and a LIMIT or
        ** OFFSET term handled as well, the plan is unusable. Similarly,
        ** if there is a LIMIT/OFFSET and there are other unused terms,
        ** the plan cannot be used. In these cases set variable *pbRetryLimit
        ** to true to tell the caller to retry with LIMIT and OFFSET
        ** disabled. *//* Unless pbRetryLimit is non-NULL, there should be no LIMIT/OFFSET
      ** terms. And if there are any, they should follow all other terms. *//* A virtual table that is constrained by an IN clause may not
        ** consume the ORDER BY clause because (1) the order of IN terms
        ** is not necessarily related to the order of output terms and
        ** (2) Multiple outputs from a single IN value will not merge
        ** together.  *//* If the xBestIndex method returns SQLITE_CONSTRAINT, that means
      ** that the particular combination of parameters provided is unusable.
      ** Make no entries in the loop table.
      *//* Invoke the virtual table xBestIndex() method *//* Initialize the output fields of the sqlite3_index_info structure *//* Set the usable flag on the subset of constraints identified by
  ** arguments mUsable and mExclude. *//* OUT: Retry without LIMIT/OFFSET *//* OUT: True if plan uses an IN(...) op *//* Do not omit these constraints *//* Populated object for xBestIndex *//* Exclude terms using these operators *//* Mask of usable tables *//* Mask of tables that must be used. *//*
** Argument pIdxInfo is already populated with all constraints that may
** be used by the virtual table identified by pBuilder->pNew->iTab. This
** function marks a subset of those constraints usable, invokes the
** xBestIndex method and adds the returned plan to pBuilder.
**
** A constraint is marked usable if:
**
**   * Argument mUsable indicates that its prerequisites are available, and
**
**   * It is not one of the operators specified in the mExclude mask passed
**     as the fourth argument (which in practice is either WO_IN or 0).
**
** Argument mPrereq is a mask of tables that must be scanned before the
** virtual table in question. These are added to the plans prerequisites
** before it is added to pBuilder.
**
** Output parameter *pbIn is set to true if the plan added to pBuilder
** uses one or more WO_IN terms, or false otherwise.
*//*
** Return true if the first nCons constraints in the pUsage array are
** marked as in-use (have argvIndex>0). False otherwise.
*//*
** Return true if pTerm is a virtual table LIMIT or OFFSET term.
*//* If a non-unique index is used, or if a prefix of the key for
      ** unique index is used (making the index functionally non-unique)
      ** then the sqlite_stat1 data becomes important for scoring the
      ** plan *//* Do not do an SCAN of a index-on-expression in a RIGHT JOIN
          ** because the cursor used to access the index might not be
          ** positioned to the correct row during the right-join no-match
          ** loop. *//* pTerm can be evaluated using just the index.  So reduce
            ** the expected number of table lookups accordingly *//* Base cost:  N*3 *//* If this is a non-covering index scan, add in the cost of
          ** doing table lookups.  The cost will be 3x the number of
          ** lookups.  Take into account WHERE clause terms that can be
          ** satisfied using just the index, and that do not require a
          ** table lookup. *//* The cost of visiting the index rows is N*K, where K is
        ** between 1.1 and 3.0, depending on the relative sizes of the
        ** index and table rows. *//* Full scan via index *//* TUNING: Cost of full table scan is 3.0*N.  The 3.0 factor is an
      ** extra cost designed to discourage the use of full table scans,
      ** since index lookups have better worst-case performance if our
      ** stat guesses are wrong.  Reduce the 3.0 penalty slightly
      ** (to 2.75) if we have valid STAT4 information for the table.
      ** At 2.75, a full table scan is preferred over using an index on
      ** a column with just two distinct values where each value has about
      ** an equal number of appearances.  Without STAT4 data, we still want
      ** to use an index in that case, since the constraint might be for
      ** the scarcer of the two values, and in that case an index lookup is
      ** better.
      *//* Full table scan *//* Integer primary key index *//* The ONEPASS_DESIRED flags never occurs together with ORDER BY *//* Partial index inappropriate for this query *//* See ticket [98d973b8f5] *//* Loop over all indices. If there was an INDEXED BY clause, then only
  ** consider index pProbe.  *//* SQLITE_OMIT_AUTOMATIC_INDEX *//* TUNING: Each index lookup yields 20 rows in the table.  This
        ** is more than the usual guess of 10 rows, since we have no way
        ** of knowing how selective the index will ultimately be.  It would
        ** not be unreasonable to make this value much larger. *//* Greatly reduced setup cost for auto indexes
                               ** on ephemeral materializations of views *//* TUNING: One-time cost for computing the automatic index is
        ** estimated to be X*N*log2(N) where N is the number of rows in
        ** the table being indexed and where X is 7 (LogEst=28) for normal
        ** tables or 0.5 (LogEst=-10) for views and subqueries.  The value
        ** of X is smaller for views and subqueries so that the query planner
        ** will be more aggressive about generating automatic indexes for
        ** those objects, since there is no opportunity to add schema
        ** indexes on subqueries and views. *//* Logarithm of the number of rows in the table *//* Generate auto-index WhereLoops *//* Not the right tab of a RIGHT JOIN *//* Not a recursive common table expression. *//* Not a correlated subquery *//* Has no NOT INDEXED clause *//* Has no INDEXED BY clause *//* Not part of an OR optimization *//* Automatic indexes *//* The real indices of the table are only considered if the
      ** NOT INDEXED qualifier is omitted from the FROM clause *//* TUNING: Interior rows of IPK table are very small *//* First of real indices on the table *//* There is no INDEXED BY clause.  Create a fake Index object in local
    ** variable sPk to represent the rowid primary key index.  Make this
    ** fake index the first in a chain of Index objects with all of the real
    ** indices to follow *//* An INDEXED BY clause specifies a particular index to use *//* Table being queried *//* The parsed WHERE clause *//* number of rows in the table *//* A boolean value *//* Index number *//* Template WhereLoop object *//* The FROM clause btree term to add *//* The FROM clause *//* The aColumn[] value for the sPk index *//* The aiRowLogEst[] value for the sPk index *//* A fake index object for the primary key *//* An index we are evaluating *//* Extra prerequisites for using this table *//*
** Add all WhereLoop objects for a single table of the join where the table
** is identified by pBuilder->pNew->iTab.  That table is guaranteed to be
** a b-tree table, not a virtual table.
**
** The costs (WhereLoop.rRun) of the b-tree loops added by this function
** are calculated as follows:
**
** For a full scan, assuming the table (or index) contains nRow rows:
**
**     cost = nRow * 3.0                    // full-table scan
**     cost = nRow * K                      // scan of covering index
**     cost = nRow * (K+3.0)                // scan of non-covering index
**
** where K is a value between 1.1 and 3.0 set based on the relative
** estimated average size of the index and table records.
**
** For an index scan, where nVisit is the number of index rows visited
** by the scan, and nSeek is the number of seek operations required on
** the index b-tree:
**
**     cost = nSeek * (log(nRow) + K * nVisit)          // covering index
**     cost = nSeek * (log(nRow) + (K+3.0) * nVisit)    // non-covering index
**
** Normally, nSeek is 1. nSeek values greater than 1 come about if the
** WHERE clause includes "x IN (....)" terms used in place of "x=?". Or when
** implicit "x IN (SELECT x FROM tbl)" terms are added for skip-scans.
**
** The estimated values (nRow, nVisit, nSeek) often contain a large amount
** of uncertainty.  For this reason, scoring is designed to pick plans that
** "do the least harm" if the estimates are inaccurate.  For example, a
** log(nRow) factor is omitted from a non-covering index scan in order to
** bias the scoring in favor of using an index, since the worst-case
** performance of using an index is far better than the worst-case performance
** of a full table scan.
*//* Cursor number for index *//* Mask to clear bits in *//* WHERE clause being processed *//* Partial index being processed *//*
** This function is called for a partial index - one with a WHERE clause - in
** two scenarios. In both cases, it determines whether or not the WHERE
** clause on the index implies that a column of the table may be safely
** replaced by a constant expression. For example, in the following
** SELECT:
**
**   CREATE INDEX i1 ON t1(b, c) WHERE a=<expr>;
**   SELECT a, b, c FROM t1 WHERE a=<expr> AND b=?;
**
** The "a" in the select-list may be replaced by <expr>, iff:
**
**    (a) <expr> is a constant expression, and
**    (b) The (a=<expr>) comparison uses the BINARY collation sequence, and
**    (c) Column "a" has an affinity other than NONE or BLOB.
**
** If argument pItem is NULL, then pMask must not be NULL. In this case this
** function is being called as part of determining whether or not pIdx
** is a covering index. This function clears any bits in (*pMask)
** corresponding to columns that may be replaced by constants as described
** above.
**
** Otherwise, if pItem is not NULL, then this function is being called
** as part of coding a loop that uses index pIdx. In this case, add entries
** to the Parse.pIdxPartExpr list for each column that can be replaced
** by a constant.
*//*
** This is an sqlite3ParserAddCleanup() callback that is invoked to
** free the Parse->pIdxEpr list when the Parse object is destroyed.
*//* pIdx does not index any columns greater than 62, but we know from
      ** colMask that columns greater than 62 are used, so this is not a
      ** covering index *//* We don't have access to the full query, so we cannot check to see
    ** if pIdx is covering.  Assume it is not. *//* Cursor for the table being indexed *//* Index that is being tested *//* The WHERE clause context *//*
** pIdx is an index that covers all of the low-number columns used by
** pWInfo->pSelect (columns from 0 through 62) or an index that has
** expressions terms.  Hence, we cannot determine whether or not it is
** a covering index by using the colUsed bitmasks.  We have to do a search
** to see if the index is covering.  This routine does that search.
**
** The return value is one of these:
**
**      0                The index is definitely not a covering index
**
**      WHERE_IDX_ONLY   The index is definitely a covering index
**
**      WHERE_EXPRIDX    The index is likely a covering index, but it is
**                       difficult to determine precisely because of the
**                       expressions that are indexed.  Score it as a
**                       covering index, but still keep the main table open
**                       just in case we need it.
**
** This routine is an optimization.  It is always safe to return zero.
** But returning one of the other two values when zero should have been
** returned can lead to incorrect bytecode and assertion faults.
*//* if( pExpr->iColumn<(BMS-1) && pIdx->bHasExpr==0 ) return WRC_Continue;*//* Info about this search *//* Number of columns in the index *//* Columns contained in the index *//* The index of interest *//*
** Information passed in is pWalk->u.pCovIdxCk.  Call it pCk.
**
** If the Expr node references the table with cursor pCk->iTabCur, then
** make sure that column is covered by the index pCk->pIdx.  We know that
** all columns less than 63 (really BMS-1) are covered, so we don't need
** to check them.  But we do need to check any column at 63 or greater.
**
** If the index does not cover the column, then set pWalk->eCode to
** non-zero and return WRC_Abort to stop the search.
**
** If this node does not disprove that the index can be a covering index,
** then just return WRC_Continue, to continue the search.
**
** If pCk->pIdx contains indexed expressions and one of those expressions
** matches pExpr, then prune the search.
*//* Uses an unindexed column not within an indexed expr *//* Uses an indexed expression *//* Cursor number for the corresponding table *//* The index *//*
** Structure passed to the whereIsCoveringIndex Walker callback.
*//*
** pIdx is an index containing expressions.  Check it see if any of the
** expressions in the index match the pExpr expression.
*//* The WHERE clause from the partial index *//* The WHERE clause of the query *//* The JT_* flags on the join *//* The table for which we want an index *//* Check to see if a partial index with pPartIndexWhere can be used
** in the current query.  Return true if it can be and false if not.
*//*
** Return True if it is possible that pIndex might be useful in
** implementing the ORDER BY clause in pBuilder.
**
** Return False if pBuilder does not contain an ORDER BY clause or
** if there is no way for pIndex to be useful in implementing that
** ORDER BY clause.
*//* TUNING:  Because uncertainties in the estimates for skip-scan queries,
    ** add a 1.375 fudge factor to make skip-scan slightly less likely. *//* TUNING: Minimum for skip-scan *//* Consider using a skip-scan if there are no WHERE clause constraints
  ** available for the left-most terms of the index, and if the average
  ** number of repeats in the left-most terms is at least 18.
  **
  ** The magic number 18 is selected on the basis that scanning 17 rows
  ** is almost always quicker than an index seek (even though if the index
  ** contains fewer than 2^17 rows we assume otherwise in other parts of
  ** the code). And, even if it is not, it should not be too much slower.
  ** On the other hand, the extra seeks could end up being significantly
  ** more expensive.  *//* Estimate the cost of running the loop.  If all data is coming
    ** from the index, then this is just the cost of doing the index
    ** lookup and scan.  But if some data is coming out of the main table,
    ** we also have to add in the cost of doing pNew->nOut searches to
    ** locate the row in the main table that corresponds to the index entry.
    *//* The pProbe->szIdxRow is low for an IPK table since the interior
      ** pages are small.  Thus szIdxRow gives a good estimate of seek cost.
      ** But the leaf pages are full-size, so pProbe->szIdxRow would badly
      ** under-estimate the scanning cost. *//* Set rCostIdx to the estimated cost of visiting selected rows in the
    ** index.  The estimate is the sum of two values:
    **   1.  The cost of doing one search-by-key to find the first matching
    **       entry
    **   2.  Stepping forward in the index pNew->nOut times to find all
    **       additional matching entries.
    *//* TUNING: If there is no likelihood() value, assume that a
            ** "col IS NULL" expression matches twice as many rows
            ** as (col=?). *//* If the term has previously been used with an assumption of
                ** higher selectivity, then set the flag to rerun the
                ** loop computations. *//* 0x01 *//* TUNING: Mark terms as "low selectivity" if they seem likely
             ** to be true for half or more of the rows in the table.
             ** See tag-202002240-1 *//* Jump out of the pTerm loop *//* Adjust nOut using stat4 data. Or, if there is no stat4
      ** data, using some other estimate.  *//* At this point pNew->nOut is set to the number of rows expected to
    ** be visited by the index scan before considering term pTerm, or the
    ** values of nIn and nInMul. In other words, assuming that all
    ** "x IN(...)" terms are replaced with "x = ?". This block updates
    ** the value of pNew->nOut to account for pTerm (but not nIn/nInMul).  *//* OOM *//* Range constraints that come from the LIKE optimization are
          ** always used in pairs. *//* TUNING      v-----  10 to bias toward indexed IN *//* Let:
        **   N = the total number of rows in the table
        **   K = the number of entries on the RHS of the IN operator
        **   M = the number of rows in the table that match terms to the
        **       to the left in the same index.  If the IN operator is on
        **       the left-most index column, M==N.
        **
        ** Given the definitions above, it is better to omit the IN operator
        ** from the index lookup and instead do a scan of the M elements,
        ** testing each scanned row against the IN operator separately, if:
        **
        **        M*log(K) < K*log(N)
        **
        ** Our estimates for M, K, and N might be inaccurate, so we build in
        ** a safety margin of 2 (LogEst: 10) that favors using the IN operator
        ** with the index, as using an index has better worst-case behavior.
        ** If we do not have real sqlite_stat1 data, always prefer to use
        ** the index.  Do not bother with this optimization on very small
        ** tables (less than 2 rows) as it is pointless in that case.
        *//* "x IN (value, value, ...)" *//* The expression may actually be of the form (x, y) IN (SELECT...).
        ** In this case there is a separate term for each of (x) and (y).
        ** However, the nIn multiplier should only be applied once, not once
        ** for each such term. The following loop checks that pTerm is the
        ** first such term in use, and sets nIn back to 0 if it is not. *//* "x IN (SELECT ...)":  TUNING: the SELECT returns 25 rows *//* OOM while trying to enlarge the pNew->aLTerm array *//* Do not allow the upper bound of a LIKE optimization range constraint
    ** to mix with a lower range bound from some other source *//* ignore IS [NOT] NULL constraints on NOT NULL columns *//* nOut before IN() and WHERE adjustments *//* Shorthand for pTerm->eOperator *//* Top and bottom range constraints *//* Logarithm of table size *//* Number of rows in the table *//* Original value of pNew->nOut *//* Original value of pNew->wsFlags *//* Original value of pNew->nSkip *//* Original value of pNew->u.btree.nTop *//* Original value of pNew->u.btree.nBtm *//* Original value of pNew->u.btree.nEq *//* Original value of pNew->nLTerm *//* Original value of pNew->prereq *//* Iterator for WHERE terms *//* Valid operators for constraints *//* A WhereTerm under consideration *//* Template WhereLoop under construction *//* Database connection malloc context *//* WHERE analyze context *//* log(Number of iterations due to IN) *//* An index on pSrc *//* FROM clause term being analyzed *//* The WhereLoop factory *//*
** We have so far matched pBuilder->pNew->u.btree.nEq terms of the
** index pIndex. Try to match one more.
**
** When this function is called, pBuilder->pNew->nOut contains the
** number of rows expected to be visited by filtering using the nEq
** terms only. If it is modified, this value is restored before this
** function returns.
**
** If pProbe->idxType==SQLITE_IDXTYPE_IPK, that means pIndex is
** a fake index used for the INTEGER PRIMARY KEY.
*//*
** Adjust the cost C by the costMult factor T.  This only occurs if
** compiled with -DSQLITE_ENABLE_COSTMULT
*//* Check that the LHS of the comparison is a column reference to
    ** the right column of the right source table. And that the sort
    ** order of the index column is the same as the sort order of the
    ** leftmost index column.  *//* Comparison collation sequence *//* Indexed columns affinity *//* Comparison affinity *//* Test if comparison i of pTerm is compatible with column (i+nEq)
    ** of the index. If not, exit the loop.  *//* The vector inequality constraint *//* Number of prior equality constraints on same index *//* The index to be used for a inequality constraint *//* Cursor open on pIdx *//*
** Term pTerm is a vector range comparison operation. The first comparison
** in the vector can be optimized using column nEq of the index. This
** function returns the total number of vector elements that can be used
** as part of the range comparison.
**
** For example, if the query is:
**
**   WHERE a = ? AND (b, c, d) > (?, ?, ?)
**
** and the index:
**
**   CREATE INDEX ... ON (a, b, c, d, e)
**
** then this function would be invoked with nEq=1. The value returned in
** this case is 3.
*//* tag-20200224-1 *//* In the absence of explicit truth probabilities, use heuristics to
        ** guess a reasonable truth probability. *//* If a truth probability is specified using the likelihood() hints,
        ** then use the probability provided by the application. *//* If there are extra terms in the WHERE clause not used by an index
        ** that depend only on the table being scanned, and that will tend to
        ** cause many rows to be omitted, then mark that table as
        ** "self-culling".
        **
        ** 2022-03-24:  Self-culling only applies if either the extra terms
        ** are straight comparison operators that are non-true with NULL
        ** operand, or if the loop is not an OUTER JOIN.
        *//* pLoop->nOut should not exceed nRow-iReduce *//* Number of rows in the entire table *//* The loop to adjust downward *//*
** Adjust the WhereLoop.nOut value downward to account for terms of the
** WHERE clause that reference the loop but which are not used by an
** index.
*
** For every WHERE clause term that is not used by the index
** and which has a truth probability assigned by one of the likelihood(),
** likely(), or unlikely() SQL functions, reduce the estimated number
** of output rows by the probability specified.
**
** TUNING:  For every WHERE clause term that is not used by the index
** and which does not have an assigned truth probability, heuristics
** described below are used to try to estimate the truth probability.
** TODO --> Perhaps this is something that could be improved by better
** table statistics.
**
** Heuristic 1:  Estimate the truth probability as 93.75%.  The 93.75%
** value corresponds to -1 in LogEst notation, so this means decrement
** the WhereLoop.nOut field for every such WHERE clause term.
**
** Heuristic 2:  If there exists one or more WHERE clause terms of the
** form "x==EXPR" and EXPR is not a constant 0 or 1, then make sure the
** final output row estimate is no greater than 1/4 of the total number
** of rows in the table.  In other words, assume that x==EXPR will filter
** out at least 3 out of 4 rows.  If EXPR is -1 or 0 or 1, then maybe the
** "x" column is boolean or else -1 or 0 or 1 is a common default value
** on the "x" column and so in that case only cap the output row estimate
** at 1/2 instead of 1/4.
*//* 0x8 *//* We will be overwriting WhereLoop p[].  But before we do, first
    ** go through the rest of the list and delete any other entries besides
    ** p[] that are also supplanted by pTemplate *//* Allocate a new WhereLoop to add to the end of the list *//* If we reach this point it means that either p[] should be overwritten
  ** with pTemplate[] if p[] exists, or if p==NULL then allocate a new
  ** WhereLoop and insert it.
  *//* There already exists a WhereLoop on the list that is better
    ** than pTemplate, so just ignore pTemplate *//* Look for an existing WhereLoop to replace with pTemplate
  *//* If pBuilder->pOrSet is defined, then only keep track of the costs
  ** and prereqs.
  *//* Stop the search once we hit the query planner search limit *//*
** Insert or replace a WhereLoop entry using the template supplied.
**
** An existing WhereLoop entry might be overwritten if the new template
** is better and has fewer dependencies.  Or the template will be ignored
** and no insert will occur if an existing WhereLoop is faster and has
** fewer dependencies than the template.  Otherwise a new WhereLoop is
** added based on the template.
**
** If pBuilder->pOrSet is not NULL then we care about only the
** prerequisites and rRun and nOut costs of the N best loops.  That
** information is gathered in the pBuilder->pOrSet object.  This special
** processing mode is used only for OR clause processing.
**
** When accumulating multiple loops (when pBuilder->pOrSet is NULL) we
** still might overwrite similar loops with the new template if the
** new template is better.  Loops may be overwritten if the following
** conditions are met:
**
**    (1)  They have the same iTab.
**    (2)  They have the same iSortIdx.
**    (3)  The template has same or fewer dependencies than the current loop
**    (4)  The template has the same or lower cost than the current loop
*//* Cause p to be overwritten by pTemplate *//* SETUP-INVARIANT above *//* (2b) *//* (2a) *//* (1)  *//* If pTemplate is always better than p, then cause p to be overwritten
    ** with pTemplate.  pTemplate is better than p if:
    **   (1)  pTemplate has no more dependencies than p, and
    **   (2)  pTemplate has an equal or lower cost than p.
    *//* Discard pTemplate *//* (2c) *//* If existing WhereLoop p is better than pTemplate, pTemplate can be
    ** discarded.  WhereLoop p is better if:
    **   (1)  p has no more dependencies than pTemplate, and
    **   (2)  p has an equal or lower cost than pTemplate
    *//* Any loop using an application-defined index (or PRIMARY KEY or
    ** UNIQUE constraint) with one or more == constraints is better
    ** than an automatic index. Unless it is a skip-scan. *//* whereLoopAddBtree() always generates and inserts the automatic index
    ** case first.  Hence compatible candidate WhereLoops never have a larger
    ** rSetup. Call this SETUP-INVARIANT *//* In the current implementation, the rSetup value is either zero
    ** or the cost of building an automatic index (NlogN) and the NlogN
    ** is the same for compatible WhereLoops. *//* If either the iTab or iSortIdx values for two WhereLoop are different
      ** then those WhereLoops need to be considered separately.  Neither is
      ** a candidate to replace the other. *//*
** Search the list of WhereLoops in *ppPrev looking for one that can be
** replaced by pTemplate.
**
** Return NULL if pTemplate does not belong on the WhereLoop list.
** In other words if pTemplate ought to be dropped from further consideration.
**
** If pX is a WhereLoop that pTemplate can replace, then return the
** link that points to pX.
**
** If pTemplate cannot replace any existing element of the list but needs
** to be added to the list as a new entry, then return a pointer to the
** tail of the list.
*//* Adjust pTemplate cost upward so that it is costlier than p since
      ** pTemplate is a proper subset of p *//* Adjust pTemplate cost downward so that it is cheaper than its
      ** subset p. *//*
** Try to adjust the cost and number of output rows of WhereLoop pTemplate
** upwards or downwards so that:
**
**   (1) pTemplate costs less than any other WhereLoops that are a proper
**       subset of pTemplate
**
**   (2) pTemplate costs more than any other WhereLoops for which pTemplate
**       is a proper subset.
**
** To say "WhereLoop X is a proper subset of Y" means that X uses fewer
** WHERE clause terms than Y and that every WHERE clause term used by X is
** also used by Y.
*//* Case 2 is true *//* (2e) *//* (2d) *//* Case 1 is true *//* (1c) *//* (1a) *//* (1b) *//* (1d) and (2a) *//* Compare against this WhereLoop *//* First WhereLoop to compare *//*
** Return TRUE if X is a proper subset of Y but is of equal or less cost.
** In other words, return true if all constraints of X are also part of Y
** and Y has additional constraints that might speed the search that X lacks
** but the cost of running X is not more than the cost of running Y.
**
** In other words, return true if the cost relationship between X and Y
** is inverted and needs to be adjusted.
**
** Case 1:
**
**   (1a)  X and Y use the same index.
**   (1b)  X has fewer == terms than Y
**   (1c)  Neither X nor Y use skip-scan
**   (1d)  X does not have a a greater cost than Y
**
** Case 2:
**
**   (2a)  X has the same or lower cost, or returns the same or fewer rows,
**         than Y.
**   (2b)  X uses fewer WHERE clause terms than Y
**   (2c)  Every WHERE clause term used by X is also used by Y
**   (2d)  X skips at least as many columns as Y
**   (2e)  If X is a covering index, than Y is too
*//*
** Free a WhereInfo structure
*//*
** Delete a WhereLoop object
*//*
** Transfer content from the second pLoop into the first.
*//*
** Increase the memory allocation for pLoop->aLTerm[] to be at least n.
*//*
** Deallocate internal memory used by a WhereLoop object.  Leave the
** object in an initialized state, as if it had been newly allocated.
*//*
** Clear the WhereLoop.u union.  Leave WhereLoop.pLTerm intact.
*//*
** Convert bulk memory into a valid WhereLoop that can be passed
** to whereLoopClear harmlessly.
*//*
** Print a WhereLoop object for debugging purposes
**
** Format example:
**
**     .--- Position in WHERE clause           rSetup, rRun, nOut ---.
**     |                                                             |
**     |  .--- selfMask                       nTerm ------.          |
**     |  |                                               |          |
**     |  |   .-- prereq    Idx          wsFlags----.     |          |
**     |  |   |             Name                    |     |          |
**     |  |   |           __|__        nEq ---.  ___|__   |        __|__
**     | / \ / \         /     \              | /      \ / \      /     \
**     1.002.001         t2.t2xy              2 f 010241 N 2 cost 0,56,31
*//*
** Show the complete content of a WhereClause
*//* The 0x10000 .wheretrace flag causes extra information to be
    ** shown about each Term *//*
** Print the content of a WhereTerm object
*//* SQLITE_ENABLE_STAT4 *//* New estimate of the number of rows *//* Number of rows for a single term *//* Subfunction return code *//* Write the revised row estimate here *//* The value list on the RHS of "x IN (v1,v2,v3,...)" *//* Parsing & code generating context *//*
** Estimate the number of rows that will be returned based on
** an IN constraint where the right-hand side of the IN operator
** is a list of values.  Example:
**
**        WHERE x IN (1,2,3,4)
**
** Write the estimated row count into *pnRow and return SQLITE_OK.
** If unable to make an estimate, leave *pnRow unchanged and return
** non-zero.
**
** This routine can fail if it is unable to load a collating sequence
** required for string comparison, or if unable to allocate memory
** for a UTF conversion required for comparison.  The error is stored
** in the pParse structure.
*//* This is an optimization only. The call to sqlite3Stat4ProbeSetValue()
  ** below would return the same value.  *//* If values are not available for all fields of the index to the left
  ** of this one, no estimate can be made. Return SQLITE_NOTFOUND. *//* Statistics *//* Expression for VALUE in the x=VALUE constraint *//*
** Estimate the number of rows that will be returned based on
** an equality constraint x=VALUE and where that VALUE occurs in
** the histogram data.  This only works when x is the left-most
** column of an index and sqlite_stat4 histogram data is available
** for that index.  When pExpr==NULL that means the constraint is
** "x IS NULL" instead of "x=VALUE".
**
** Write the estimated row count into *pnRow and return SQLITE_OK.
** If unable to make an estimate, leave *pnRow unchanged and return
** non-zero.
**
** This routine can fail if it is unable to load a collating sequence
** required for string comparison, or if unable to allocate memory
** for a UTF conversion required for comparison.  The error is stored
** in the pParse structure.
*//* TUNING: If there is both an upper and lower limit and neither limit
  ** has an application-defined likelihood(), assume the range is
  ** reduced by an additional 75%. This means that, by default, an open-ended
  ** range query (e.g. col > ?) is assumed to match 1/4 of the rows in the
  ** index. While a closed range (e.g. col BETWEEN ? AND ?) is estimated to
  ** match 1/64 of the index. *//* TUNING:  If both iUpper and iLower are derived from the same
          ** sample, then assume they are 4x more selective.  This brings
          ** the estimated selectivity more in line with what it would be
          ** if estimated without the use of STAT4 tables. *//* Values extracted from pExpr *//* If possible, improve on the iUpper estimate using ($P:$U). *//* If possible, improve on the iLower estimate using ($P:$L). *//* The roles of pLower and pUpper are swapped for a DESC index *//* Note: this call could be optimized away - since the same values must
        ** have been requested when testing key $P in whereEqualScanEst().  *//* Determine iLower and iUpper using ($P) only. *//* aSample[] for the upper bound *//* aSample[] for the lower bound *//* Rows less than the upper bound *//* Rows less than the lower bound *//* Variable iLower will be set to the estimate of the number of rows in
      ** the index that are less than the lower bound of the range query. The
      ** lower bound being the concatenation of $P and $L, where $P is the
      ** key-prefix formed by the nEq values matched against the nEq left-most
      ** columns of the index, and $L is the value in pLower.
      **
      ** Or, if pLower is NULL or $L cannot be extracted from it (because it
      ** is not a simple variable or literal value), the lower bound of the
      ** range is $P. Due to a quirk in the way whereKeyStats() works, even
      ** if $L is available, whereKeyStats() is called for both ($P) and
      ** ($P:$L) and the larger of the two returned values is used.
      **
      ** Similarly, iUpper is to be set to the estimate of the number of rows
      ** less than the upper bound of the range query. Where the upper bound
      ** is either ($P) or ($P:$U). Again, even if $U is available, both values
      ** of iUpper are requested of whereKeyStats() and the smaller used.
      **
      ** The number of rows between the two bounds is then just iUpper-iLower.
      *//* Modify the .nOut and maybe .rRun fields *//* Upper bound on the range. ex: "x<455" Might be NULL *//* Lower bound on the range. ex: "x>123" Might be NULL *//*
** This function is used to estimate the number of rows that will be visited
** by scanning an index for a range of values. The range may have an upper
** bound, a lower bound, or both. The WHERE clause terms that set the upper
** and lower bounds are represented by pLower and pUpper respectively. For
** example, assuming that index p is on t1(a):
**
**   ... FROM t1 WHERE a > ? AND a < ? ...
**                    |_____|   |_____|
**                       |         |
**                     pLower    pUpper
**
** If either of the upper or lower bound is not present, then NULL is passed in
** place of the corresponding WhereTerm.
**
** The value in (pBuilder->pNew->u.btree.nEq) is the number of the index
** column subject to the range constraint. Or, equivalently, the number of
** equality constraints optimized by the proposed index scan. For example,
** assuming index p is on t1(a, b), and the SQL query is:
**
**   ... FROM t1 WHERE a = ? AND b > ? AND b < ? ...
**
** then nEq is set to 1 (as the range restricted column, b, is the second
** left-most column of the index). Or, if the query is:
**
**   ... FROM t1 WHERE a > ? AND a < ? ...
**
** then nEq is set to 0.
**
** When this function is called, *pnOut is set to the sqlite3LogEst() of the
** number of rows that the index scan is expected to visit without
** considering the range constraints. If nEq is 0, then *pnOut is the number of
** rows in the index. Assuming no error occurs, *pnOut is adjusted (reduced)
** to account for the range constraints pLower and pUpper.
**
** In the absence of sqlite_stat4 ANALYZE data, or if such data cannot be
** used, a single range inequality reduces the search space by a factor of 4.
** and a pair of constraints (x>? AND x<?) reduces the expected number of
** rows visited by a factor of 64.
*//* If there is both an upper and lower bound specified, and the
    ** comparisons indicate that they are close together, use the fallback
    ** method (assume that the scan visits 1/64 of the rows) for estimating
    ** the number of rows visited. Otherwise, estimate the number of rows
    ** using the method described in the header comment for this function. *//* Value extracted from record *//* Value extracted from pUpper *//* Value extracted from pLower *//* Set to true if at least one expr. value extracted *//* Update the .nOut value of this loop *//*
** This function is called to estimate the number of rows visited by a
** range-scan on a skip-scan index. For example:
**
**   CREATE INDEX i1 ON t1(a, b, c);
**   SELECT * FROM t1 WHERE a=? AND c BETWEEN ? AND ?;
**
** Value pLoop->nOut is currently set to the estimated number of rows
** visited for scanning (a=? AND b=?). This function reduces that estimate
** by some factor to account for the (c BETWEEN ? AND ?) expression based
** on the stat4 data for the index. this scan will be performed multiple
** times (once for each (a,b) combination that matches a=?) is dealt with
** by the caller.
**
** It does this by scanning through all stat4 samples, comparing values
** extracted from pLower and pUpper with the corresponding column in each
** sample. If L and U are the number of samples found to be less than or
** equal to the values extracted from pLower and pUpper respectively, and
** N is the total number of samples, the pLoop->nOut value is adjusted
** as follows:
**
**   nOut = nOut * ( min(U - L, 1) / N )
**
** If pLower is NULL, or a value cannot be extracted from the term, L is
** set to zero. If pUpper is NULL, or a value cannot be extracted from it,
** U is set to N.
**
** Normally, this function sets *pbDone to 1 before returning. However,
** if no value can be extracted from either pLower or pUpper (and so the
** estimate of the number of rows delivered remains unchanged), *pbDone
** is left as is.
**
** If an error occurs, an SQLite error code is returned. Otherwise,
** SQLITE_OK.
*//*
** Return the affinity for a single column of an index.
*//*
** If it is not NULL, pTerm is a term that provides an upper or lower
** bound on a range scan. Without considering pTerm, it is estimated
** that the scan will visit nNew rows. This function returns the number
** estimated to be visited after taking pTerm into account.
**
** If the user explicitly specified a likelihood() value for this term,
** then the return value is the likelihood multiplied by the number of
** input rows. Otherwise, this function assumes that an "IS NOT NULL" term
** has a likelihood of 0.50, and any other term a likelihood of 0.25.
*//* Restore the pRec->nField value before returning.  *//* At this point, the (iCol+1) field prefix of aSample[i] is the first
    ** sample that is greater than pRec. Or, if i==pIdx->nSample then pRec
    ** is larger than all samples in the array. *//* Record pRec is equal to sample i *//* ifdef SQLITE_DEBUG *//* if i==0 and iCol==0, then record pRec is smaller than all samples
      ** in the aSample[] array. Otherwise, if (iCol>0) then pRec must
      ** be greater than or equal to the (iCol) field prefix of sample i.
      ** If (i>0), then pRec must also be greater than sample (i-1).  *//* Unless i==pIdx->nSample, indicating that pRec is larger than
      ** all samples in the aSample[] array, pRec must be smaller than the
      ** (iCol+1) field prefix of sample i.  *//* If (res==0) is true, then pRec must be equal to sample i. *//* The following assert statements check that the binary search code
  ** above found the right answer. This block serves no purpose other
  ** than to invoke the asserts.  *//* The proposed effective sample is a prefix of sample aSample[iSamp].
      ** Specifically, the shortest prefix of at least (1 + iTest%nField)
      ** fields that is greater than the previous effective sample.  *//* Number of fields in test sample *//* Index in aSample[] of test sample *//* Do a binary search to find the first sample greater than or equal
  ** to pRec. If pRec contains a single field, the set of samples to search
  ** is simply the aSample[] array. If the samples in aSample[] contain more
  ** than one fields, all fields following the first are ignored.
  **
  ** If pRec contains N fields, where N is more than one, then as well as the
  ** samples in aSample[] (truncated to N fields), the search also has to
  ** consider prefixes of those samples. For example, if the set of samples
  ** in aSample is:
  **
  **     aSample[0] = (a, 5)
  **     aSample[1] = (a, 10)
  **     aSample[2] = (b, 5)
  **     aSample[3] = (c, 100)
  **     aSample[4] = (c, 105)
  **
  ** Then the search space should ideally be the samples above and the
  ** unique prefixes [a], [b] and [c]. But since that is hard to organize,
  ** the code actually searches this set:
  **
  **     0: (a)
  **     1: (a, 5)
  **     2: (a, 10)
  **     3: (a, 10)
  **     4: (b)
  **     5: (b, 5)
  **     6: (c)
  **     7: (c, 100)
  **     8: (c, 105)
  **     9: (c, 105)
  **
  ** For each sample in the aSample[] array, N samples are present in the
  ** effective sample array. In the above, samples 0 and 1 are based on
  ** sample aSample[0]. Samples 2 and 3 on aSample[1] etc.
  **
  ** Often, sample i of each block of N effective samples has (i+1) fields.
  ** Except, each sample may be extended to ensure that it is greater than or
  ** equal to the previous sample in the array. For example, in the above,
  ** sample 2 is the first sample of a block of N samples, so at first it
  ** appears that it should be 1 field in size. However, that would make it
  ** smaller than sample 1, so the binary search would not work. As a result,
  ** it is extended to two fields. The duplicates that this creates do not
  ** cause any problems.
  *//* anLt[] + anEq[] of largest sample pRec is > *//* Number of fields in pRec *//* Result of comparison operation *//* Next sample to test *//* Smallest sample not yet tested *//* Smallest sample larger than or equal to pRec *//* Index of first sample >= pRec *//* Index of required stats in anEq[] etc. *//* OUT: stats written here *//* Round up if true.  Round down if false *//* Vector of values to consider *//* Index to consider domain of *//*
** Estimate the location of a particular key among all keys in an
** index.  Store the results in aStat as follows:
**
**    aStat[0]      Est. number of rows less than pRec
**    aStat[1]      Est. number of rows equal to pRec
**
** Return the index of the sample that is the smallest sample that
** is greater than or equal to pRec. Note that this index is not an index
** into the aSample[] array - it is an index into a virtual set of samples
** based on the contents of aSample[] and the number of fields in record
** pRec.
*//* !defined(SQLITE_OMIT_VIRTUALTABLE) *//*
** The table object reference passed as the second argument to this function
** must represent a virtual table. This function invokes the xBestIndex()
** method of the virtual table with the sqlite3_index_info object that
** comes in as the 3rd argument to this function.
**
** If an error occurs, pParse is populated with an error message and an
** appropriate error code is returned.  A return of SQLITE_CONSTRAINT from
** xBestIndex is not considered an error.  SQLITE_CONSTRAINT indicates that
** the current configuration of "unusable" flags in sqlite3_index_info can
** not result in a valid plan.
**
** Whether or not an error is returned, it is the responsibility of the
** caller to eventually free p->idxStr if p->needToFreeIdxStr indicates
** that this is required.
*//* IMP: R-14553-25174 *//*
** Free an sqlite3_index_info structure allocated by allocateIndexInfo()
** and possibly modified by xBestIndex methods.
*//*
** Free and zero the sqlite3_index_info.idxStr value if needed.
*//* The direct assignment in the previous line is possible only because
        ** the WO_ and SQLITE_INDEX_CONSTRAINT_ codes are identical.  The
        ** following asserts verify this fact. *//* Ensure that all bits associated with PK columns are set. This is to
    ** ensure they are available for cases like RIGHT joins or OR loops. *//* Allocate the sqlite3_index_info structure
  *//* No matches cause a break out of the loop *//* Collseq does not matter for rowid *//* The collating sequence name *//* 2nd case - a column reference with a COLLATE operator.  Only match
      ** of the COLLATE operator matches the collation of the column. *//* First case - a direct column references without a COLLATE operator *//* Virtual tables are unable to deal with NULLS FIRST *//* Skip over constant terms in the ORDER BY clause *//* If the ORDER BY clause contains only columns in the current
  ** virtual table then allocate space for the aOrderBy part of
  ** the sqlite3_index_info structure.
  *//* Find all WHERE clause constraints referring to this virtual table.
  ** Mark each term with the TERM_OK flag.  Set nTerm to the number of
  ** terms found.
  *//* Mask of terms not to omit *//* The FROM clause term that is the vtab *//* Ignore terms with these prereqs *//* The WHERE clause being analyzed *//*
** Allocate and populate an sqlite3_index_info structure. It is the
** responsibility of the caller to eventually release the structure
** by passing the pointer returned by this function to freeIndexInfo().
*//*
** Return term iTerm of the WhereClause passed as the first argument. Terms
** are numbered from 0 upwards, starting with the terms in pWC->a[], then
** those in pWC->pOuter->a[] (if any), and so on.
*//* This is a candidate for bloom-filter pull-down (early evaluation).
        ** The test that WHERE_COLUMN_IN is omitted is important, as we are
        ** not able to do early evaluation of bloom filters that make use of
        ** the IN operator *//* The Bloom filter is a Blob held in a register.  Initialize it
    ** to zero-filled blob of at least 80K bits, but maybe more if the
    ** estimated size of the table is larger.  We could actually
    ** measure the size of the table at run-time using OP_Count with
    ** P3==1 and use that value to initialize the blob.  But that makes
    ** testing complicated.  By basing the blob size on the value in the
    ** sqlite_stat1 table, testing is much easier.
    *//* saved copy of Parse.pIdxPartExpr *//* saved copy of Parse.pIdxEpr *//* Cursor for table getting the filter *//* The loop being coded *//* VDBE under construction *//* Last WHERE clause term *//* For looping over WHERE clause terms *//* Jump here to skip a row *//* Address of OP_Rewind *//* Address of opening OP_Once *//* Loops that are not ready *//* Make a Bloom filter for this FROM term *//* Index in pWInfo->a[] that is pLevel *//*
** Generate bytecode that will initialize a Bloom filter that is appropriate
** for pLevel.
**
** If there are inner loops within pLevel that have the WHERE_BLOOMFILTER
** flag set, initialize a Bloomfilter for them as well.  Except don't do
** this recursive initialization if the SQLITE_BloomPulldown optimization has
** been turned off.
**
** When the Bloom filter is initialized, the WHERE_BLOOMFILTER flag is cleared
** from the loop, but the regFilter value is set to a register that implements
** the Bloom filter.  When regFilter is positive, the
** sqlite3WhereCodeOneLoopStart() will generate code to test the Bloom filter
** and skip the subsequence B-Tree seek if the Bloom filter indicates that
** no matching rows exist.
**
** This routine may only be called if it has previously been determined that
** the loop would benefit from a Bloom filter, and the WHERE_BLOOMFILTER bit
** is set.
*//* Jump here when skipping the initialization *//* Fill the automatic index with content *//* Create the automatic index *//* Add additional columns needed to make the automatic index into
  ** a covering index *//* TUNING: only use a Bloom filter on an automatic index
          ** if one or more key columns has the ability to hold numeric
          ** values, since strings all have the same hash in the Bloom
          ** filter implementation and hence a Bloom filter on a text column
          ** is not usually helpful. *//* TH3 collate01.800 *//* Construct the Index object to describe this index *//* For WITHOUT ROWID tables, ensure that all PRIMARY KEY columns are
    ** either in the idxCols mask or in the extraCols mask *//* Count the number of additional columns needed to create a
  ** covering index.  A "covering index" is an index that contains all
  ** columns that are needed by the query.  With a covering index, the
  ** original table never needs to be accessed.  Automatic indices must
  ** be a covering index because the index will not be updated if the
  ** original table changes and the index and table cannot both be used
  ** if they go out of sync.
  *//* Make the automatic index a partial index if there are terms in the
    ** WHERE clause (or the ON clause of a LEFT join) that constrain which
    ** rows of the target table (pSrc) that can be used. *//* Count the number of columns that will be added to the index
  ** and used to match WHERE clause constraints *//* Generate code to skip over the creation and initialization of the
  ** transient index on 2nd and subsequent iterations of the loop. *//* Address of OP_Explain *//* Array of registers where record is assembled *//* Address where integer counter is initialized *//* The FROM clause term to get the next index *//* The complete FROM clause *//* Jump here to skip excluded rows *//* Partial Index Expression *//* True to also add a Bloom filter *//* True if a warning has been issued *//* Bitmap of additional columns *//* Bitmap of columns used for indexing *//* Extra space on the end of pIdx *//* The Loop object *//* Collating sequence to on a column *//* Maximum column in pSrc->colUsed *//* Column counter *//* Register holding an index record *//* Top of the index fill loop *//* The table being indexed *//* Address of the initialization bypass jump *//* Prepared statement under construction *//* Object describing the transient index *//* End of pWC->a[] *//* Number of columns in the constructed index *//* Write new index here *//* Mask of cursors that are not available *//*
** Generate code to construct the Index object for an automatic index
** and to set up the WhereLevel object pLevel so that the code generator
** makes use of the automatic index.
*//* OUT: Address of OP_Explain *//* True if pIdx is a partial index *//* Automatic index to explain *//*
** Argument pIdx represents an automatic index that the current statement
** will create and populate. Add an OP_Explain with text of the form:
**
**     CREATE AUTOMATIC INDEX ON <table>(<cols>) [WHERE <expr>]
**
** This is only required if sqlite3_stmt_scanstatus() is enabled, to
** associate an SQLITE_SCANSTAT_NCYCLE and SQLITE_SCANSTAT_NLOOP
** values with. In order to avoid breaking legacy code and test cases,
** the OP_Explain is not added if this is an EXPLAIN QUERY PLAN command.
*//* See https://sqlite.org/forum/forumpost/51e6959f61 *//* Tables in outer loops of the join *//* Table we are trying to access *//* WHERE clause term to check *//*
** Return TRUE if the WHERE clause term pTerm is of a form where it
** could be used with an index to access pSrc, assuming an appropriate
** index existed.
*//*
** Return true if column iCol of table pTab seem like it might be a
** good column to use as part of a query-time index.
**
** Current algorithm (subject to improvement!):
**
**   1.   If iCol is already the left-most column of some other index,
**        then return false.
**
**   2.   If iCol is part of an existing index that has an aiRowLogEst of
**        more than 20, then return false.
**
**   3.   If no disqualifying conditions above are found, return true.
**
** 2025-01-03: I experimented with a new rule that returns false if the
** the datatype of the column is "BOOLEAN". This did not improve
** performance on any queries at hand, but it did burn CPU cycles, so the
** idea was not committed.
*//* By caller *//*
** We know that pSrc is an operand of an outer join.  Return true if
** pTerm is a constraint that is compatible with that join.
**
** pTerm must be EP_OuterON if pSrc is the right operand of an
** outer join.  pTerm can be either EP_OuterON or EP_InnerON if pSrc
** is the left operand of a RIGHT join.
**
** See https://sqlite.org/forum/forumpost/206d99a16dd9212f
** for an example of a WHERE clause constraints that may not be used on
** the right table of a RIGHT JOIN because the constraint implies a
** not-NULL condition on the left table of the RIGHT JOIN.
*//* The TABLE that is the virtual table *//* The IndexInfo object *//*
** Two routines for printing the content of an sqlite3_index_info
** structure.  Used for testing and debugging only.  If neither
** SQLITE_TEST or SQLITE_DEBUG are defined, then these routines
** are no-ops.
*//* Cause the MEM_Subtype flag to be cleared *//* If non-zero, cursor of autoindex being generated *//* The first column is in this register *//* OP_Column/OP_Rowid references to this table *//* Translate from this opcode to the end *//*
** Convert OP_Column opcodes to OP_Copy in previously generated code.
**
** This routine runs over generated VDBE code and translates OP_Column
** opcodes into OP_Copy when the table is being accessed via co-routine
** instead of via table lookup.
**
** If the iAutoidxCur is not zero, then any OP_Rowid instructions on
** cursor iTabCur are transformed into OP_Sequence opcode for the
** iAutoidxCur cursor, in order to generate unique rowids for the
** automatic index being generated.
*//*
** Estimate the logarithm of the input value to base 2.
*//* This index implies that the DISTINCT qualifier is redundant. *//* Loop through all indices on the table, checking each to see if it makes
  ** the DISTINCT qualifier redundant. It does so if:
  **
  **   1. The index is itself UNIQUE, and
  **
  **   2. All of the columns in the index are either part of the pDistinct
  **      list, or else the WHERE clause contains a term of the form "col=X",
  **      where X is a constant value. The collation sequences of the
  **      comparison and select-list expressions must match those of the index.
  **
  **   3. All of those index columns for which the WHERE clause does not
  **      contain a "col=X" term are subject to a NOT NULL constraint.
  *//* If any of the expressions is an IPK column on table iBase, then return
  ** true. Note: The (p->iTable==iBase) part of this test may be false if the
  ** current SELECT is a correlated sub-query.
  *//* If there is more than one table or sub-select in the FROM clause of
  ** this query, then it will not be possible to show that the DISTINCT
  ** clause is redundant. *//* The result set that needs to be DISTINCT *//*
** Return true if the DISTINCT expression-list passed as the third argument
** is redundant.
**
** A DISTINCT list is redundant if any subset of the columns in the
** DISTINCT list are collectively unique and individually non-null.
*//* Assume an indexed expression can always yield a NULL *//*
** Return TRUE if the iCol-th column of index pIdx is NOT NULL
*//* Column of index to match *//* Index to match column of *//* Cursor for table associated with pIdx *//* Expression list to search *//*
** This function searches pList for an entry that matches the iCol-th column
** of index pIdx.
**
** If such an expression is found, its index in pList->a[] is returned. If
** no expression is found, -1 is returned.
*//* Must be compatible with this index, if not NULL *//* Mask of WO_xx values describing operator *//* RHS must not overlap with this mask *//* Column number of LHS *//* Cursor number of LHS *//* The WHERE clause to be searched *//*
** Search for a term in the WHERE clause that is of the form "X <op> <expr>"
** where X is a reference to the iColumn of table iCur or of index pIdx
** if pIdx!=0 and <op> is one of the WO_xx operator codes specified by
** the op parameter.  Return a pointer to the term.  Return 0 if not found.
**
** If pIdx!=0 then it must be one of the indexes of table iCur.
** Search for terms matching the iColumn-th column of pIdx
** rather than the iColumn-th column of table iCur.
**
** The term returned might by Y=<expr> if there is another constraint in
** the WHERE clause that specifies that X=Y.  Any such constraints will be
** identified by the WO_EQUIV bit in the pTerm->eOperator field.  The
** aiCur[]/iaColumn[] arrays hold X and all its equivalents. There are 11
** slots in aiCur[]/aiColumn[] so that means we can look for X plus up to 10
** other equivalent values.  Hence a search for X will return <expr> if X=A1
** and A1=A2 and A2=A3 and ... and A9=A10 and A10=<expr>.
**
** If there are multiple terms in the WHERE clause of the form "X <op> <expr>"
** then try for the one with no dependencies on <expr> - in other words where
** <expr> is a constant expression of some kind.  Only return entries of
** the form "X <op> Y" where Y is a column in another table if no terms of
** the form "X <op> <const-expr>" exist.   If no terms with a constant RHS
** exist, try to return a term that does not use WO_EQUIV.
*//* Must be compatible with this index *//* Operator(s) to scan for *//* Column to scan for *//* Cursor to scan for *//* The WHERE clause to be scanned *//* The WhereScan object being initialized *//*
** Initialize a WHERE clause scanner object.  Return a pointer to the
** first match.  Return NULL if there are no matches.
**
** The scanner will be searching the WHERE clause pWC.  It will look
** for terms of the form "X <op> <expr>" where X is column iColumn of table
** iCur.   Or if pIdx!=0 then X is column iColumn of index pIdx.  pIdx
** must be one of the indexes of table iCur.
**
** The <op> must be one of the operators described by opMask.
**
** If the search is for X and the WHERE clause contains terms of the
** form X=Y then this routine might also return terms of the form
** "Y <op> <expr>".  The number of levels of transitivity is limited,
** but is enough to handle most commonly occurring SQL statements.
**
** If X is not the INTEGER PRIMARY KEY then X must be compatible with
** index pIdx.
*//*
** This is whereScanInit() for the case of an index on an expression.
** It is factored out into a separate tail-recursion subroutine so that
** the normal whereScanInit() routine, which is a high-runner, does not
** need to push registers onto the stack as part of its prologue.
*//* Verify the affinity and collating sequence match *//* Where to start scanning *//* The term being tested *//* Shorthand for pScan->pWC *//* An expression being tested *//* The column on the LHS of the term.  -1 for IPK *//* The cursor on the LHS of the term *//*
** Advance to the next WhereTerm that matches according to the criteria
** established when the pScan object was initialized by whereScanInit().
** Return NULL if there are no more matching WhereTerms.
*//*
** Term pTerm is guaranteed to be a WO_IN term. It may be a component term
** of a vector IN expression of the form "(x, y, ...) IN (SELECT ...)".
** This function checks to see if the term is compatible with an index
** column with affinity idxaff (one of the SQLITE_AFF_XYZ values). If so,
** it returns a pointer to the name of the collation sequence (e.g. "BINARY"
** or "NOCASE") used by the comparison in pTerm. If it is not compatible
** with affinity idxaff, NULL is returned.
*//*
** If the right-hand branch of the expression is a TK_COLUMN, then return
** a pointer to the right-hand branch.  Otherwise, return NULL.
*//*
** Create a new mask for cursor iCursor.
**
** There is one cursor per table in the FROM clause.  The number of
** tables in the FROM clause is limited by a test early in the
** sqlite3WhereBegin() routine.  So we know that the pMaskSet->ix[]
** array will never overflow.
*//* Allocate memory that is automatically freed when pWInfo is freed.
*//*
** Return the bitmask for the given cursor number.  Return 0 if
** iCursor is not in the set.
*//* Number of outputs for the new entry *//* Run-cost of the new entry *//* Prerequisites of the new entry *//* The WhereOrSet to be updated *//*
** Try to insert a new prerequisite/cost entry into the WhereOrSet pSet.
**
** The new entry might overwrite an existing entry, or it might be
** appended, or it might be discarded.  Do whatever is the right thing
** so that pSet keeps the N_OR_COST best entries seen so far.
*//*
** Move the content of pSrc into pDest
*//*
** Return TRUE if the WHERE loop uses the OP_DeferredSeek opcode to move
** the data cursor to the row selected by the index cursor.
*//*
** Return ONEPASS_OFF (0) if an UPDATE or DELETE statement is unable to
** operate directly on the rowids returned by a WHERE clause.  Return
** ONEPASS_SINGLE (1) if the statement can operation directly because only
** a single row is to be changed.  Return ONEPASS_MULTI (2) if the one-pass
** optimization can be used on multiple
**
** If the ONEPASS optimization is used (if this routine returns true)
** then also write the indices of open cursors used by ONEPASS
** into aiCur[0] and aiCur[1].  iaCur[0] gets the cursor of the data
** table and iaCur[1] gets the cursor used by an auxiliary index.
** Either value may be -1, indicating that cursor is not used.
** Any cursors returned will have been opened for writing.
**
** aiCur[0] and aiCur[1] both get -1 if the where-clause logic is
** unable to use the ONEPASS optimization.
*//*
** Return the VDBE address or label to jump to in order to break
** out of a WHERE loop.
*//*
** Return the VDBE address or label to jump to in order to continue
** immediately with the next row of a WHERE clause.
*//*
** While generating code for the min/max optimization, after handling
** the aggregate-step call to min() or max(), check to see if any
** additional looping is required.  If the output order is such that
** we are certain that the correct answer has already been found, then
** code an OP_Goto to by pass subsequent processing.
**
** Any extra OP_Goto that is coded here is an optimization.  The
** correct answer should be obtained regardless.  This OP_Goto just
** makes the answer appear faster.
*//* The ORDER BY LIMIT optimization does not apply.  Jump to the
    ** continuation of the inner-most loop. *//*
** In the ORDER BY LIMIT optimization, if the inner-most loop is known
** to emit rows in increasing order, and if the last row emitted by the
** inner-most loop did not fit within the sorter, then we can skip all
** subsequent rows for the current iteration of the inner loop (because they
** will not fit in the sorter either) and continue with the second inner
** loop - the loop immediately outside the inner-most.
**
** When a row does not fit in the sorter (because the sorter already
** holds LIMIT+OFFSET rows that are smaller), then a jump is made to the
** label returned by this function.
**
** If the ORDER BY LIMIT optimization applies, the jump destination should
** be the continuation for the second-inner-most loop.  If the ORDER BY
** LIMIT optimization does not apply, then the jump destination should
** be the continuation for the inner-most loop.
**
** It is always safe for this routine to return the continuation of the
** inner-most loop, in the sense that a correct answer will result.
** Returning the continuation the second inner loop is an optimization
** that might make the code run a little faster, but should not change
** the final answer.
*//*
** Return the number of ORDER BY terms that are satisfied by the
** WHERE clause.  A return of 0 means that the output must be
** completely sorted.  A return equal to the number of ORDER BY
** terms means that no sorting is needed at all.  A return that
** is positive but less than the number of ORDER BY terms means that
** block sorting is required.
*//*
** Return one of the WHERE_DISTINCT_xxxxx values to indicate how this
** WHERE clause returns outputs for DISTINCT processing.
*//*
** Return the estimated number of output rows from a WHERE clause
*//* Forward declaration of methods *//* RHS values for constraints. MUST BE LAST
                           ** because extra space is allocated to hold up
                           ** to nTerm such values *//* Terms that vtab will handle as <col> IN (...) *//* Mask of terms that are <col> IN (...) *//* Value to return from sqlite3_vtab_distinct() *//* The Where clause being analyzed *//*
** Extra information appended to the end of sqlite3_index_info but not
** visible to the xBestIndex function, at least not directly.  The
** sqlite3_vtab_collation() interface knows how to reach it, however.
**
** This object is not an API and can be changed from one release to the
** next.  As long as allocateIndexInfo() and sqlite3_vtab_collation()
** agree on the structure, all will be well.
*//* #include "whereInt.h" *//*
** 2001 September 15
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This module contains C code that generates VDBE code used to process
** the WHERE clause of SQL statements.  This module is responsible for
** generating the code that loops through a table looking for applicable
** rows.  Indices are selected and used to speed the search when doing
** so is applicable.  Because this module is responsible for selecting
** indices, you might also think of this module as the "query optimizer".
*//************** Begin file where.c *******************************************//************** End of whereexpr.c *******************************************//* testtag-20230227c *//* testtag-20230227b *//* testtag-20230227a *//* Xfer function arguments to here *//* The FROM clause term to process *//*
** For table-valued-functions, transform the function arguments into
** new WHERE clause terms.
**
** Each function argument translates into an equality constraint against
** a HIDDEN column in the table.
*//* the WHERE clause to be analyzed *//* the FROM clause *//*
** Call exprAnalyze on all terms in a WHERE clause.
**
** Note that exprAnalyze() might add new virtual terms onto the
** end of the WHERE clause.  We do not want to analyze these new
** virtual terms, so start analyzing at the end and work forward
** so that the added virtual terms are never processed.
*//*
** These routines walk (recursively) an expression tree and generate
** a bitmask indicating which tables are used in that expression
** tree.
**
** sqlite3WhereExprUsage(MaskSet, Expr) ->
**
**       Return a Bitmask of all tables referenced by Expr.  Expr can be
**       be NULL, in which case 0 is returned.
**
** sqlite3WhereExprUsageNN(MaskSet, Expr) ->
**
**       Same as sqlite3WhereExprUsage() except that Expr must not be
**       NULL.  The "NN" suffix on the name stands for "Not Null".
**
** sqlite3WhereExprListUsage(MaskSet, ExprList) ->
**
**       Return a Bitmask of all tables referenced by every expression
**       in the expression list ExprList.  ExprList can be NULL, in which
**       case 0 is returned.
**
** sqlite3WhereExprUsageFull(MaskSet, ExprList) ->
**
**       Internal use only.  Called only by sqlite3WhereExprUsageNN() for
**       complex expressions that require pushing register values onto
**       the stack.  Many calls to sqlite3WhereExprUsageNN() do not need
**       the more complex analysis done by this routine.  Hence, the
**       computations done by this routine are broken out into a separate
**       "no-inline" function to avoid the stack push overhead in the
**       common case where it is not needed.
*//* Verify that every term past pWC->nBase is virtual *//*
** Deallocate a WhereClause structure.  The WhereClause structure
** itself is not freed.  This routine is the inverse of
** sqlite3WhereClauseInit().
*//* The WHERE processing context *//* The WhereClause to be initialized *//*
** Initialize a preallocated WhereClause structure.
*//* All conditions are met. Add the terms to the where-clause object. *//* Check condition (5). Return early if it is not met. *//* If this term has child terms, then they are also part of the
        ** pWC->a[] array. So this term can be ignored, as a LIMIT clause
        ** will only be added if each of the child terms passes the
        ** (leftCursor==iCsr) test below.  *//* This term is a vector operation that has been decomposed into
        ** other, subsequent terms.  It can be ignored. See tag-20220128a *//* Check condition (4). Return early if it is not met. *//* 1 -- checked by caller *//*
** Possibly add terms corresponding to the LIMIT and OFFSET clauses of the
** SELECT statement passed as the second argument. These terms are only
** added if:
**
**   1. The SELECT statement has a LIMIT clause, and
**   2. The SELECT statement is not an aggregate or DISTINCT query, and
**   3. The SELECT statement has exactly one object in its from clause, and
**      that object is a virtual table, and
**   4. There are no terms in the WHERE clause that will not be passed
**      to the virtual table xBestIndex method.
**   5. The ORDER BY clause, if any, will be made available to the xBestIndex
**      method.
**
** LIMIT and OFFSET terms are ignored by most of the planner code. They
** exist only so that they may be passed to the xBestIndex method of the
** single virtual table in the FROM clause of the SELECT.
*//* SQLITE_INDEX_CONSTRAINT_LIMIT or _OFFSET *//* Cursor to which the constraint applies *//* Expression that defines the limit/offset *//* Register that will hold value of the limit/offset *//* Add the constraint to this WHERE clause *//*
** Add either a LIMIT (if eMatchOp==SQLITE_INDEX_CONSTRAINT_LIMIT) or
** OFFSET (if eMatchOp==SQLITE_INDEX_CONSTRAINT_OFFSET) term to the
** where-clause passed as the first argument. The value for the term
** is found in register iReg.
**
** In the common case where the value is a simple integer
** (example: "LIMIT 5 OFFSET 10") then the expression codes as a
** TK_INTEGER so that it will be available to sqlite3_vtab_rhs_value().
** If not, then it codes as a TK_REGISTER expression.
*//*
** This routine identifies subexpressions in the WHERE clause where
** each subexpression is separated by the AND operator or some other
** operator specified in the op parameter.  The WhereClause structure
** is filled with pointers to subexpressions.  For example:
**
**    WHERE  a=='hello' AND coalesce(b,11)<10 AND (c+12!=d OR c==22)
**           \________/     \_______________/     \________________/
**            slot[0]            slot[1]               slot[2]
**
** The original WHERE clause in pExpr is unaltered.  All this routine
** does is make slot[] entries point to substructure within pExpr.
**
** In the previous sentence and in the diagram, "slot[]" refers to
** the WhereClause.a[] array.  The slot[] array grows as needed to contain
** all terms of the WHERE clause.
*//***************************************************************************
** Routines with file scope above.  Interface to the rest of the where.c
** subsystem follows.
***************************************************************************//* Prevent ON clause terms of a LEFT JOIN from being used to drive
  ** an index for tables to the left of the join.
  *//* Add a WO_AUX auxiliary term to the constraint set if the
  ** current expression is of the form "column OP expr" where OP
  ** is an operator that gets passed into virtual tables but which is
  ** not normally optimized for ordinary tables.  In other words, OP
  ** is one of MATCH, LIKE, GLOB, REGEXP, !=, IS, IS NOT, or NOT NULL.
  ** This information is used by the xBestIndex methods of
  ** virtual tables.  The native query optimizer does not attempt
  ** to do anything with MATCH functions.
  *//* If there is a vector IN term - e.g. "(a, b) IN (SELECT ...)" - create
  ** a virtual term for each vector component. The expression object
  ** used by each such virtual term is pExpr (the full vector IN(...)
  ** expression). The WhereTerm.u.x.iField variable identifies the index within
  ** the vector on the LHS that the virtual term represents.
  **
  ** This only works if the RHS is a simple SELECT (not a compound) that does
  ** not use window functions.
  *//* Disable the original *//* If there is a vector == or IS term - e.g. "(a, b) == (?, ?)" - create
  ** new terms for each component comparison - "a = ?" and "b = ?".  The
  ** new terms completely replace the original vector comparison, which is
  ** no longer used.
  **
  ** This is only required if at least one side of the comparison operation
  ** is not a sub-select.
  **
  ** tag-20220128a
  *//* SQLITE_OMIT_LIKE_OPTIMIZATION *//* isLikeOrGlob() guarantees this *//* Increment the value of the last utf8 character in the prefix. *//* The point is to increment the last character before the first
        ** wildcard.  But if we increment '@', that will push it into the
        ** alphabetic range where case conversions will mess up the
        ** inequality.  To avoid this, make sure to also run the full
        ** LIKE on all candidate expressions by clearing the isComplete flag
        *//* Last character before the first wildcard *//* Convert the lower bound to upper-case and the upper bound to
    ** lower-case (upper-case is less than lower-case in ASCII) so that
    ** the range constraints also work for BLOBs
    *//* Name of collating sequence *//* Copy of pStr1 - RHS of LIKE/GLOB operator *//* LHS of LIKE/GLOB operator *//* Add constraints to reduce the search space on a LIKE or GLOB
  ** operator.
  **
  ** A like pattern of the form "x LIKE 'aBc%'" is changed into constraints
  **
  **          x>='ABC' AND x<'abd' AND x LIKE 'aBc%'
  **
  ** The last character of the prefix "abc" is incremented to form the
  ** termination condition "abd".  If case is not significant (the default
  ** for LIKE) then the lower-bound is made all uppercase and the upper-
  ** bound is made all lowercase so that the bounds also work when comparing
  ** BLOBs.
  *//* The form "x IS NOT NULL" can sometimes be evaluated more efficiently
  ** as "x>NULL" if x is not an INTEGER PRIMARY KEY.  So construct a
  ** virtual term of that form.
  **
  ** The virtual term must be tagged with TERM_VNULL.
  *//* SQLITE_OMIT_OR_OPTIMIZATION *//* Analyze a term that is composed of two or more subterms connected by
  ** an OR operator.
  *//* SQLITE_OMIT_BETWEEN_OPTIMIZATION *//* If a term is the BETWEEN operator, create two new virtual terms
  ** that define the range that the BETWEEN implements.  For example:
  **
  **      a BETWEEN b AND c
  **
  ** is converted into:
  **
  **      (a BETWEEN b AND c) AND (a>=b) AND (a<=c)
  **
  ** The two new terms are added onto the end of the WhereClause object.
  ** The new terms are "dynamic" and are children of the original BETWEEN
  ** term.  That means that if the BETWEEN term is coded, the children are
  ** skipped.  Or, if the children are satisfied by an index, the original
  ** BETWEEN term is skipped.
  *//* See tag-20230504-1 *//* Extra bits for pNew->eOperator *//* The ON clause of an INNER JOIN references a table to its right.
      ** Most other SQL database engines raise an error.  But SQLite versions
      ** 3.0 through 3.38 just put the ON clause constraint into the WHERE
      ** clause and carried on.   Beginning with 3.39, raise an error only
      ** if there is a RIGHT or FULL JOIN in the query.  This makes SQLite
      ** more like other systems, and also preserves legacy. *//* ON clause terms may not be used with an index
                         ** on left table of a LEFT JOIN.  Ticket #3015 *//* Because malloc() has not failed *//* Number of elements on left side vector *//* op2 value for LIKE/REGEXP/GLOB *//* Top-level operator.  pExpr->op *//* uppercase equivalent to lowercase *//* RHS of LIKE/GLOB ends with wildcard *//* RHS of LIKE/GLOB operator *//* Extra dependencies on LEFT JOIN *//* Prerequisites of pExpr *//* Prerequisites of the pExpr->pLeft *//* The expression to be analyzed *//* Set of table index masks *//* The term to be analyzed *//* WHERE clause processing context *//* Index of the term to be analyzed *//* the WHERE clause *//*
** The input to this routine is an WhereTerm structure with only the
** "pExpr" field filled in.  The job of this routine is to analyze the
** subexpression and populate all the other fields of the WhereTerm
** structure.
**
** If the expression is of the form "<expr> <op> X" it gets commuted
** to the standard form of "X <op> <expr>".
**
** If the expression is of the form "X <op> Y" where both X and Y are
** columns, then the original expression is unchanged and a new virtual
** term of the form "Y <op> X" is added to the WHERE clause and
** analyzed separately.  The original term is marked with TERM_COPIED
** and the new term is marked with TERM_DYNAMIC (because it's pExpr
** needs to be freed with the WhereClause) and TERM_VIRTUAL (because it
** is a commuted copy of a prior term.)  The original term has nChild=1
** and the copy has idxParent set to the index of the original term.
*//* If this expression is a vector to the left or right of a
  ** inequality constraint (>, <, >= or <=), perform the processing
  ** on the first element of the vector.  *//* The specific comparison operator *//* An operand of a comparison operator *//* Write the referenced table cursor & column here *//* Start looking with the j-th pFrom entry *//* Write the referenced table cursor and column here *//*
** Expression pExpr is one operand of a comparison operator that might
** be useful for indexing.  This routine checks to see if pExpr appears
** in any index.  Return TRUE (1) if pExpr is an indexed term and return
** FALSE (0) if not.  If TRUE is returned, also set aiCurCol[0] to the cursor
** number of the table that is indexed and aiCurCol[1] to the column number
** of the column that is indexed, or XN_EXPR (-2) if an expression is being
** indexed.
**
** If pExpr is a TK_COLUMN column reference, then this routine always returns
** true even if that particular column is not indexed, because the column
** might be added to an automatic index later.
*//*
** Recursively walk the expressions of a SELECT statement and generate
** a bitmask indicating which tables are used in that expression
** tree.
*//*
** We already know that pExpr is a binary operator where both operands are
** column references.  This routine checks to see if pExpr is an equivalence
** relation:
**   1.  The SQLITE_Transitive optimization must be enabled
**   2.  Must be either an == or an IS operator
**   3.  Not originating in the ON clause of an OUTER JOIN
**   4.  The affinities of A and B must be compatible
**   5a. Both operands use the same collating sequence OR
**   5b. The overall collating sequence is BINARY
** If this routine returns TRUE, that means that the RHS can be substituted
** for the LHS anyplace else in the WHERE clause where the LHS column occurs.
** This is an optimization.  No harm comes from returning 0.  But if 1 is
** returned when it should not be, then incorrect answers might result.
*//* !SQLITE_OMIT_OR_OPTIMIZATION && !SQLITE_OMIT_SUBQUERY *//* pTerm = &pWC->a[idxTerm]; // would be needed if pTerm where reused *//* The complete IN operator *//* The LHS of the IN operator *//* The RHS of the IN operator *//* A transient duplicate expression *//* At this point, okToChngToIN is true if original pTerm satisfies
    ** case 1.  In that case, construct a new virtual term that is
    ** pTerm converted into an IN operator.
    *//* If the right-hand side is also a column, then the affinities
          ** of both right and left sides must be such that no type
          ** conversions are required on the right.  (Ticket #2249)
          *//* We have found a candidate table and column.  Check to see if that
      ** table and column is common to every term in the OR clause *//* No candidate table+column was found.  This can only occur
        ** on the second iteration *//* This term must be of the form t1.a==t2.b where t2 is in the
          ** chngToIN set but t1 is not.  This term will be either preceded
          ** or followed by an inverted copy (t2.b==t1.a).  Skip this term
          ** and use its inversion. *//* This is the 2-bit case and we are on the second iteration and
          ** current term is from the first iteration.  So skip this term. *//* Search for a table and column that appears on one side or the
    ** other of the == operator in every subterm.  That table and column
    ** will be recorded in iCursor and iColumn.  There might not be any
    ** such table and column.  Set okToChngToIN if an appropriate table
    ** and column is found but leave okToChngToIN false if not found.
    *//* Table cursor common to all terms *//* Column index on lhs of IN operator *//* True if the conversion to IN is valid *//*
  ** chngToIN holds a set of tables that *might* satisfy case 1.  But
  ** we have to do some additional checking to see if case 1 really
  ** is satisfied.
  **
  ** chngToIN will hold either 0, 1, or 2 bits.  The 0-bit case means
  ** that there is no possibility of transforming the OR clause into an
  ** IN operator because one or more terms in the OR clause contain
  ** something other than == on a column in the single table.  The 1-bit
  ** case means that every term of the OR clause is of the form
  ** "table.column=expr" for some single table.  The one bit that is set
  ** will correspond to the common table.  We still need to check to make
  ** sure the same column is used on all terms.  The 2-bit case is when
  ** the all terms are of the form "table1.column=table2.column".  It
  ** might be possible to form an IN operator with either table1.column
  ** or table2.column as the LHS if either is common to every term of
  ** the OR clause.
  **
  ** Note that terms of the form "table.column1=table.column2" (the
  ** same table on both sizes of the ==) cannot be optimized.
  *//* For a two-way OR, attempt to implementation case 2.
  *//*
  ** Record the set of tables that satisfy case 3.  The set might be
  ** empty.
  *//* Skip this term for now.  We revisit it when we process the
      ** corresponding TERM_VIRTUAL term *//*
  ** Compute the set of tables that might satisfy cases 1 or 3.
  *//*
  ** Break the OR clause into its separate subterms.  The subterms are
  ** stored in a WhereClause structure containing within the WhereOrInfo
  ** object that is attached to the original OR clause term.
  *//* Tables that are indexable, satisfying case 2 *//* Tables that might satisfy case 1 *//* Additional information associated with pTerm *//* A Sub-term within the pOrWc *//* Breakup of pTerm into subterms *//* The expression of the term *//* Parser context *//* Index of the OR-term to be analyzed *//* the complete WHERE clause *//*
** Analyze a term that consists of two or more OR-connected
** subterms.  So in:
**
**     ... WHERE  (a=5) AND (b=7 OR c=9 OR d=13) AND (d=13)
**                          ^^^^^^^^^^^^^^^^^^^^
**
** This routine analyzes terms such as the middle term in the above example.
** A WhereOrTerm object is computed and attached to the term under
** analysis, regardless of the outcome of the analysis.  Hence:
**
**     WhereTerm.wtFlags   |=  TERM_ORINFO
**     WhereTerm.u.pOrInfo  =  a dynamically allocated WhereOrTerm object
**
** The term being analyzed must have two or more of OR-connected subterms.
** A single subterm might be a set of AND-connected sub-subterms.
** Examples of terms under analysis:
**
**     (A)     t1.x=t2.y OR t1.x=t2.z OR t1.y=15 OR t1.z=t3.a+5
**     (B)     x=expr1 OR expr2=x OR x=expr3
**     (C)     t1.x=t2.y OR (t1.x=t2.z AND t1.y=15)
**     (D)     x=expr1 OR (y>11 AND y<22 AND z LIKE '*hello*')
**     (E)     (p.a=1 AND q.b=2 AND r.c=3) OR (p.x=4 AND q.y=5 AND r.z=6)
**     (F)     x>A OR (x=A AND y>=B)
**
** CASE 1:
**
** If all subterms are of the form T.C=expr for some single column of C and
** a single table T (as shown in example B above) then create a new virtual
** term that is an equivalent IN expression.  In other words, if the term
** being analyzed is:
**
**      x = expr1  OR  expr2 = x  OR  x = expr3
**
** then create a new virtual term like this:
**
**      x IN (expr1,expr2,expr3)
**
** CASE 2:
**
** If there are exactly two disjuncts and one side has x>A and the other side
** has x=A (for the same x and A) then add a new virtual conjunct term to the
** WHERE clause of the form "x>=A".  Example:
**
**      x>A OR (x=A AND y>B)    adds:    x>=A
**
** The added conjunct can sometimes be helpful in query planning.
**
** CASE 3:
**
** If all subterms are indexable by a single table T, then set
**
**     WhereTerm.eOperator              =  WO_OR
**     WhereTerm.u.pOrInfo->indexable  |=  the cursor number for table T
**
** A subterm is "indexable" if it is of the form
** "T.C <op> <expr>" where C is any column of table T and
** <op> is one of "=", "<", "<=", ">", ">=", "IS NULL", or "IN".
** A subterm is also indexable if it is an AND of two or more
** subsubterms at least one of which is indexable.  Indexable AND
** subterms have their eOperator set to WO_AND and they have
** u.pAndInfo set to a dynamically allocated WhereAndTerm object.
**
** From another point of view, "indexable" means that the subterm could
** potentially be used with an index if an appropriate index exists.
** This analysis does not consider whether or not the index exists; that
** is decided elsewhere.  This analysis only looks at whether subterms
** appropriate for indexing exist.
**
** All examples A through E above satisfy case 3.  But if a term
** also satisfies case 1 (such as B) we know that the optimizer will
** always prefer case 1, so in that case we pretend that case 3 is not
** satisfied.
**
** It might be the case that multiple tables are indexable.  For example,
** (E) above is indexable on tables P, Q, and R.
**
** Terms that satisfy case 3 are candidates for lookup by using
** separate indices to find rowids for each subterm and composing
** the union of all rowids using a RowSet object.  This is similar
** to "bitmap indices" in other database engines.
**
** OTHERWISE:
**
** If none of cases 1, 2, or 3 apply, then leave the eOperator set to
** zero.  This term is not useful for search.
*//* If we reach this point, it means the two subterms can be combined *//* Index in pWC of the next virtual term *//* Operator for the combined expression *//* New virtual expression *//* Database connection (for malloc) *//* Second disjunct *//* First disjunct *//* The complete WHERE clause *//*
** Subterms pOne and pTwo are contained within WHERE clause pWC.  The
** two subterms are in disjunction - they are OR-ed together.
**
** If these two terms are both of the form:  "A op B" with the same
** A and B values but different operators and if the operators are
** compatible (if one is = and the other is <, for example) then
** add a new virtual AND term to pWC that is the combination of the
** two.
**
** Some examples:
**
**    x<y OR x=y    -->     x<=y
**    x=y OR x=y    -->     x=y
**    x<=y OR x<y   -->     x<=y
**
** The following is NOT generated:
**
**    x<y OR x>y    -->     x!=y
*//*
** Return the N-th AND-connected subterm of pTerm.  Or if pTerm is not
** a conjunction, then return just pTerm when N==0.  If N is exceeds
** the number of available subterms, return NULL.
*//*
** Mark term iChild as being a child of term iParent
*//*
** If the pBase expression originated in the ON or USING clause of
** a join, then transfer the appropriate markings over to derived.
*//* Comparison operators are a common case.  Save a few comparisons for
    ** that common case by terminating early. *//* We can also match against the first column of overloaded
    ** functions where xFindFunction returns a value of at least
    ** SQLITE_INDEX_CONSTRAINT_FUNCTION.
    **
    **      OVERLOADED(vtab_column,expression)
    **
    ** Historically, xFindFunction expected to see lower-case function
    ** names.  But for this use case, xFindFunction is expected to deal
    ** with function names in an arbitrary case.
    *//* Built-in operators MATCH, GLOB, LIKE, and REGEXP attach to a
    ** virtual table on their second argument, which is the same as
    ** the left-hand side operand in their in-fix form.
    **
    **       vtab_column MATCH expression
    **       MATCH(expression,vtab_column)
    *//* Column reference *//* Expression to left of MATCH/op2 *//* Column expression to left of MATCH/op2 *//* OUT: 0 for MATCH, or else an op2 value *//* Test this expression *//*
** Check to see if the pExpr expression is a form that needs to be passed
** to the xBestIndex method of virtual tables.  Forms of interest include:
**
**          Expression                   Virtual Table Operator
**          -----------------------      ---------------------------------
**      1.  column MATCH expr            SQLITE_INDEX_CONSTRAINT_MATCH
**      2.  column GLOB expr             SQLITE_INDEX_CONSTRAINT_GLOB
**      3.  column LIKE expr             SQLITE_INDEX_CONSTRAINT_LIKE
**      4.  column REGEXP expr           SQLITE_INDEX_CONSTRAINT_REGEXP
**      5.  column != expr               SQLITE_INDEX_CONSTRAINT_NE
**      6.  expr != column               SQLITE_INDEX_CONSTRAINT_NE
**      7.  column IS NOT expr           SQLITE_INDEX_CONSTRAINT_ISNOT
**      8.  expr IS NOT column           SQLITE_INDEX_CONSTRAINT_ISNOT
**      9.  column IS NOT NULL           SQLITE_INDEX_CONSTRAINT_ISNOTNULL
**
** In every case, "column" must be a column of a virtual table.  If there
** is a match, set *ppLeft to the "column" expression, set *ppRight to the
** "expr" expression (even though in forms (6) and (8) the column is on the
** right and the expression is on the left).  Also set *peOp2 to the
** appropriate virtual table operator.  The return value is 1 or 2 if there
** is a match.  The usual return is 1, but if the RHS is also a column
** of virtual table in forms (5) or (7) then return 2.
**
** If the expression matches none of the patterns above, return 0.
*//* If the rhs of the LIKE expression is a variable, and the current
          ** value of the variable means there is no need to invoke the LIKE
          ** function, then no OP_Variable will be added to the program.
          ** This causes problems for the sqlite3_bind_parameter_name()
          ** API. To work around them, add a dummy OP_Variable here.
          *//* If the RHS pattern is a bound parameter, make arrangements to
      ** reprepare the statement when that parameter is rebound *//* Might be numeric *//* If the LHS is not an ordinary column with TEXT affinity, then the
        ** pattern prefix boundaries (both the start and end boundaries) must
        ** not look like a number.  Otherwise the pattern might be treated as
        ** a number, which will invalidate the LIKE optimization.
        **
        ** Getting this right has been a persistent source of bugs in the
        ** LIKE optimization.  See, for example:
        **    2018-09-10 https://sqlite.org/src/info/c94369cae9b561b1
        **    2019-05-02 https://sqlite.org/src/info/b043a54c3de54b28
        **    2019-06-10 https://sqlite.org/src/info/fd76310a5e843e07
        **    2019-06-14 https://sqlite.org/src/info/ce8717f0885af975
        **    2019-09-03 https://sqlite.org/src/info/0f0428096f17252a
        *//* Get the pattern prefix.  Remove all escapes from the prefix. *//* A "complete" match if the pattern ends with "*" or "%" *//* The optimization is possible only if (1) the pattern does not begin
    ** with a wildcard and if (2) the non-wildcard prefix does not end with
    ** an (illegal 0xff) character, or (3) the pattern does not consist of
    ** a single escape character. The second condition is necessary so
    ** that we can increment the prefix key to find an upper bound for the
    ** range search. The third is because the caller assumes that the pattern
    ** consists of at least one character after all escapes have been
    ** removed.  *//* bad utf-8 *//* Count the number of prefix bytes prior to the first wildcard,
    ** U+fffd character, or malformed utf-8. If the underlying database
    ** has a UTF16LE encoding, then only consider ASCII characters.  Note that
    ** the encoding of z[] is UTF8 - we are dealing with only UTF8 here in this
    ** code, but the database engine itself might be processing content using a
    ** different encoding. *//* Result code to return *//* Opcode of pRight *//* Wildcard characters *//* Number of non-wildcard prefix characters *//* One character in z[] *//* List of operands to the LIKE operator *//* Right and left size of LIKE operator *//* String on RHS of LIKE operator *//* True if uppercase is equivalent to lowercase *//* True if the only wildcard is % in the last character *//* Pointer to TK_STRING expression with pattern prefix *//* Parsing and code generating context *//*
** Check to see if the given expression is a LIKE or GLOB operator that
** can be optimized using inequality constraints.  Return TRUE if it is
** so and false if not.
**
** In order for the operator to be optimizible, the RHS must be a string
** literal that does not begin with a wildcard.  The LHS must be a column
** that may only be NULL, a string, or a BLOB, never a number. (This means
** that virtual tables cannot participate in the LIKE optimization.)  The
** collating sequence for the column on the LHS must be appropriate for
** the operator.
*//*
** Translate from TK_xx operator to WO_xx bitmask.
*//*
** Commute a comparison operator.  Expressions of the form "X op Y"
** are converted into "Y op X".
*//*
** Return TRUE if the given operator is one of the operators that is
** allowed for an indexable WHERE clause term.  The allowed operators are
** "=", "<", ">", "<=", ">=", "IN", "IS", and "IS NULL"
*//*
** Add a single new WhereTerm entry to the WhereClause object pWC.
** The new WhereTerm object is constructed from Expr p and with wtFlags.
** The index in pWC->a[] of the new WhereTerm is returned on success.
** 0 is returned if the new WhereTerm could not be added due to a memory
** allocation error.  The memory allocation failure will be recorded in
** the db->mallocFailed flag so that higher-level functions can detect it.
**
** This routine will increase the size of the pWC->a[] array as necessary.
**
** If the wtFlags argument includes TERM_DYNAMIC, then responsibility
** for freeing the expression p is assumed by the WhereClause object pWC.
** This is true even if this routine fails to allocate a new WhereTerm.
**
** WARNING:  This routine might reallocate the space used to store
** WhereTerms.  All pointers to WhereTerms should be invalidated after
** calling this routine.  Such pointers may be reinitialized by referencing
** the pWC->a[] array.
*//*
** Deallocate all memory associated with a WhereAndInfo object.
*//*
** Deallocate all memory associated with a WhereOrInfo object.
*//* Forward declarations *//*
** 2015-06-08
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This module contains C code that generates VDBE code used to process
** the WHERE clause of SQL statements.
**
** This file was originally part of where.c but was split out to improve
** readability and editability.  This file contains utility routines for
** analyzing Expr objects in the WHERE clause.
*//************** Begin file whereexpr.c ***************************************//************** End of wherecode.c *******************************************//*
** Generate the code for the loop that finds all non-matched terms
** for a RIGHT JOIN.
*//* 0x4001 *//* WHERE clause constraints must be deferred until after outer join
    ** row elimination has completed, since WHERE clause constraints apply
    ** to the results of the OUTER JOIN.  The following loop generates the
    ** appropriate WHERE clause constraint checks.  tag-20220513a.
    *//* Create a subroutine used to process all interior loops and code
    ** of the RIGHT JOIN.  During normal operation, the subroutine will
    ** be in-line with the rest of the code.  But at the end, a separate
    ** loop will run that invokes this subroutine for unmatched rows
    ** of pTab, with all tables to left begin set to NULL.
    *//* WHERE clause constraints *//* For a LEFT OUTER JOIN, generate code that will record the fact that
  ** at least one row of the right table has matched the left table.
  *//* pTab is the right-hand table of the RIGHT JOIN.  Generate code that
    ** will record that the current row of that table has been matched at
    ** least once.  This is accomplished by storing the PK for the row in
    ** both the iMatch index and the regBloom Bloom filter.
    *//* For a RIGHT OUTER JOIN, record the fact that the current row has
  ** been matched at least once.
  *//* Insert code to test for implied constraints based on transitivity
  ** of the "==" operator.
  **
  ** Example: If the WHERE clause contains "t1.a=t2.b" and "t2.b=123"
  ** and we are coding the t1 loop and the t2 loop has not yet coded,
  ** then we cannot use the "t1.a=t2.b" constraint, but we can code
  ** the implied "t1.a=123" constraint.
  *//* 0xffffffff *//* If the TERM_LIKECOND flag is set, that means that the range search
        ** is sufficient to guarantee that the LIKE operator is true, so we
        ** can skip the call to the like(A,B) function.  But this only works
        ** for strings.  So do not skip the call to the function on the pass
        ** that compares BLOBs. *//* An ON clause that is not ripe *//* Defer processing WHERE clause constraints until after outer
          ** join processing.  tag-20220513a *//* Next value for iLoop *//* Insert code to test every subexpression that can be completely
  ** computed using the current set of tables.
  **
  ** This loop may run between one and three times, depending on the
  ** constraints to be generated. The value of stack variable iLoop
  ** determines the constraints coded by each iteration, as follows:
  **
  ** iLoop==1: Code only expressions that are entirely covered by pIdx.
  ** iLoop==2: Code remaining expressions that do not contain correlated
  **           sub-queries.
  ** iLoop==3: Code all remaining expressions.
  **
  ** An effort is made to skip unnecessary iterations of the loop.
  **
  ** This optimization of causing simple query restrictions to occur before
  ** more complex one is call the "push-down" optimization in MySQL.  Here
  ** in SQLite, the name is "MySQL push-down", since there is also another
  ** totally unrelated optimization called "WHERE-clause push-down".
  ** Sometimes the qualifier is omitted, resulting in an ambiguity, so beware.
  *//* Tables marked isRecursive have only a single row that is stored in
      ** a pseudo-cursor.  No need to Rewind or Next such cursors. *//* Case 6:  There is no usable index.  We must do a complete
    **          scan of the entire table.
    *//* Set the P2 operand of the OP_Return opcode that will end the current
    ** loop to point to this spot, which is the top of the next containing
    ** loop.  The byte-code formatter will use that P2 value as a hint to
    ** indent everything in between the this point and the final OP_Return.
    ** See tag-20220407a in vdbe.c and shell.c *//* Finish the loop through table entries that match term pOrTerm. *//* If all of the OR-connected terms are optimized using the same
          ** index, and the index is opened using the same cursor number
          ** by each call to sqlite3WhereBegin() made by this loop, it may
          ** be possible to use that index as a covering index.
          **
          ** If the call to sqlite3WhereBegin() above resulted in a scan that
          ** uses an index, and this is either the first OR-connected term
          ** processed or the index is the same as that used by all previous
          ** terms, set pCov to the candidate covering index. Otherwise, set
          ** pCov to NULL to indicate that no candidate covering index will
          ** be available.
          *//* The pSubWInfo->untestedTerms flag means that this OR term
          ** contained one or more AND term from a notReady table.  The
          ** terms from the notReady table could not be tested and will
          ** need to be tested later.
          *//* Jump here (skipping the main loop body subroutine) if the
          ** current sub-WHERE row is a duplicate from prior sub-WHEREs. *//* Invoke the main loop body as a subroutine *//* Release the array of temp registers *//* Check if the temp table already contains this key. If so,
              ** the row has already been included in the result set and
              ** can be ignored (by jumping past the Gosub below). Otherwise,
              ** insert the key into the temp table and proceed with processing
              ** the row.
              **
              ** Use some of the same optimizations as OP_RowSetTest: If iSet
              ** is zero, assume that the key cannot already be present in
              ** the temp table. And if iSet is -1, assume that there is no
              ** need to insert the key into the temp table, as it will never
              ** be tested for.  *//* Read the PK into an array of temp registers. *//* This is the sub-WHERE clause body.  First skip over
          ** duplicate rows from prior sub-WHERE clauses, and record the
          ** rowid (or PRIMARY KEY) for the current row so that the same
          ** row will be skipped in subsequent sub-WHERE clauses.
          *//* Loop through table entries that match term pOrTerm. *//* See TH3 vtab25.400 and ticket 614b25314c766238 *//* Address of jump operation *//* Local copy of OR clause term *//* Current OR clause term *//* Info for single OR-term scan *//* Run a separate WHERE clause for each term of the OR clause.  After
    ** eliminating duplicates from other WHERE clauses, the action for each
    ** sub-WHERE clause is to to invoke the main loop body as a subroutine.
    *//* The extra 0x10000 bit on the opcode is masked off and does not
        ** become part of the new Expr.op.  However, it does make the
        ** op==TK_AND comparison inside of sqlite3PExpr() false, and this
        ** prevents sqlite3PExpr() from applying the AND short-circuit
        ** optimization, which we do not want here. *//* tag-20220303a *//* If the original WHERE clause is z of the form:  (x1 OR x2 OR ...) AND y
    ** Then for every term xN, evaluate as the subexpression: xN AND y
    ** That way, terms in y that are factored into the disjunction will
    ** be picked up by the recursive calls to sqlite3WhereBegin() below.
    **
    ** Actually, each subexpression is converted to "xN AND w" where w is
    ** the "interesting" terms of z - terms that did not originate in the
    ** ON or USING clause of a LEFT JOIN, and terms that are usable as
    ** indices.
    **
    ** This optimization also only applies if the (x1 OR x2 OR ...) term
    ** is not contained in the ON clause of a LEFT JOIN.
    ** See ticket http://www.sqlite.org/src/info/f2369304e4
    **
    ** 2022-02-04:  Do not push down slices of a row-value comparison.
    ** In other words, "w" or "y" may not be a slice of a vector.  Otherwise,
    ** the initialization of the right-hand operand of the vector comparison
    ** might not occur, or might occur only in an OR branch that is not
    ** taken.  dbsqlfuzz 80a9fade844b4fb43564efc972bcb2c68270f5d1.
    **
    ** 2022-03-03:  Do not push down expressions that involve subqueries.
    ** The subquery might get coded as a subroutine.  Any table-references
    ** in the subquery might be resolved to index-references for the index on
    ** the OR branch in which the subroutine is coded.  But if the subroutine
    ** is invoked from a different OR branch that uses a different index, such
    ** index-references will not work.  tag-20220303a
    ** https://sqlite.org/forum/forumpost/36937b197273d403
    *//* Initialize the rowset register to contain NULL. An SQL NULL is
    ** equivalent to an empty rowset.  Or, create an ephemeral index
    ** capable of holding primary keys in the case of a WITHOUT ROWID.
    **
    ** Also initialize regReturn to contain the address of the instruction
    ** immediately following the OP_Return at the bottom of the loop. This
    ** is required in a few obscure LEFT JOIN cases where control jumps
    ** over the top of the loop into the body of it. In this case the
    ** correct response for the end-of-loop code (the OP_Return) is to
    ** fall through to the next instruction, just as an OP_Next does if
    ** called on an uninitialized cursor.
    *//* Original list of tables *//* The number of notReady tables *//* Set up a new SrcList in pOrTab containing the table being scanned
    ** by this loop in the a[0] slot and all notReady tables in a[1..] slots.
    ** This becomes the SrcList in the recursive call to sqlite3WhereBegin().
    *//* An ".. AND (...)" expression *//* Some terms not completely tested *//* Address of regReturn init *//* Start of loop body *//* Register holding rowid *//* Register for RowSet object *//* Register used with OP_Gosub *//* Cursor used for index scans (if any) *//* Potential covering index (or NULL) *//* Shortened table list or OR-clause generation *//* The OR-clause broken out into subterms *//* Case 5:  Two or more separately indexed terms connected by OR
    **
    ** Example:
    **
    **   CREATE TABLE t1(a,b,c,d);
    **   CREATE INDEX i1 ON t1(a);
    **   CREATE INDEX i2 ON t1(b);
    **   CREATE INDEX i3 ON t1(c);
    **
    **   SELECT * FROM t1 WHERE a=5 OR b=7 OR (c=11 AND d=13)
    **
    ** In the example, there are three indexed terms connected by OR.
    ** The top of the loop looks like this:
    **
    **          Null       1                # Zero the rowset in reg 1
    **
    ** Then, for each indexed term, the following. The arguments to
    ** RowSetTest are such that the rowid of the current row is inserted
    ** into the RowSet. If it is already present, control skips the
    ** Gosub opcode and jumps straight to the code generated by WhereEnd().
    **
    **        sqlite3WhereBegin(<term>)
    **          RowSetTest                  # Insert rowid into rowset
    **          Gosub      2 A
    **        sqlite3WhereEnd()
    **
    ** Following the above, code to terminate the loop. Label A, the target
    ** of the Gosub above, jumps to the instruction right after the Goto.
    **
    **          Null       1                # Zero the rowset in reg 1
    **          Goto       B                # The loop is finished.
    **
    **       A: <loop body>                 # Return data, whatever.
    **
    **          Return     2                # Jump back to the Gosub
    **
    **       B: <after the loop>
    **
    ** Added 2014-05-26: If the table is a WITHOUT ROWID table, then
    ** use an ephemeral index instead of a RowSet to record the primary
    ** keys of the rows we have already seen.
    **
    *//* Record the instruction used to terminate the loop. *//* The following assert() is not a requirement, merely an observation:
      ** The OR-optimization doesn't work for the right hand table of
      ** a LEFT JOIN: *//* If a partial index is driving the loop, try to eliminate WHERE clause
      ** terms from the query that must be true due to the WHERE clause of
      ** the partial index.
      **
      ** 2019-11-02 ticket 623eff57e76d45f6: This optimization does not work
      ** for a LEFT JOIN.
      *//* pIdx is a covering index.  No need to access the main table. *//* Seek the table cursor, if required *//* During a NULL-scan, check to see if we have reached the end of
      ** the NULLs *//* Except, skip the end-of-range check while doing the NULL-scan *//* Check if the index cursor is past the end of the range. *//* Top of the loop body *//* Load the value for the inequality constraint at the end of the
    ** range (if any).
    *//* TUNING:  The OP_SeekScan opcode seeks to reduce the number
        ** of expensive seek operations by replacing a single seek with
        ** 1 or more step operations.  The question is, how many steps
        ** should we try before giving up and going with a seek.  The cost
        ** of a seek is proportional to the logarithm of the of the number
        ** of entries in the tree, so basing the number of steps to try
        ** on the estimated number of rows in the btree seems like a good
        ** guess. *//* The skip-scan logic inside the call to codeAllEqualityConstraints()
      ** above has already left the cursor sitting on the correct row,
      ** so no further seeking is needed *//* Seek the index cursor to the start of the range. *//* Generate code to evaluate all constraint terms using == or IN
    ** and store the values of those terms in an array of registers
    ** starting at regBase.
    *//* In case OP_SeekScan is used, ensure that the index cursor does not
      ** point to a valid row for the first iteration of this loop. *//* If we are doing a reverse order scan on an ascending index, or
    ** a forward order scan on a descending index, interchange the
    ** start and end terms (pRangeStart and pRangeEnd).
    *//* If the WHERE_BIGNULL_SORT flag is set, then index column nEq uses
    ** a non-default "big-null" sort (either ASC NULLS LAST or DESC NULLS
    ** FIRST). In both cases separate ordered scans are made of those
    ** index entries for which the column is null and for those for which
    ** it is not. For an ASC sort, the non-NULL entries are scanned first.
    ** For DESC, NULL entries are scanned first.
    *//* iLikeRepCntr actually stores 2x the counter register number.  The
        ** bottom bit indicates whether the search order is ASC or DESC. *//* occur in pairs *//* LIKE opt constraints *//* Like optimization range constraints always occur in pairs *//* Find any inequality constraint terms for the start and end
    ** of the range.
    *//* Opcode of the OP_SeekScan, if any *//* big-null flag register *//* True if we use the index only *//* Add condition to terminate at NULLs *//* True to seek past initial nulls *//* Affinity for end of range constraint *//* Affinity for start of range constraint *//* Instruction opcode *//* Number of extra registers needed *//* The VDBE cursor for the index *//* Number of constraint terms *//* Start of range is constrained *//* True if range end uses ==, >= or <= *//* True if range start uses ==, >= or <= *//* Inequality constraint at range end *//* Inequality constraint at range start *//* Base register holding constraint values *//* Length of TOP vector *//* Length of BTM vector *//* Number of == or IN terms *//* 3: (end_constraints &&  bRev &&  endEq) *//* 2: (end_constraints &&  bRev && !endEq) *//* 1: (end_constraints && !bRev &&  endEq) *//* 0: (end_constraints && !bRev && !endEq) *//* 7: (start_constraints  &&  startEq &&  bRev) *//* 6: (start_constraints  &&  startEq && !bRev) *//* 5: (start_constraints  && !startEq &&  bRev) *//* 4: (start_constraints  && !startEq && !bRev) *//* 3: (!start_constraints && startEq &&   bRev) *//* 2: (!start_constraints && startEq &&  !bRev) *//* Case 4: A scan using an index.
    **
    **         The WHERE clause may contain zero or more equality
    **         terms ("==" or "IN" operators) that refer to the N
    **         left-most columns of the index. It may also contain
    **         inequality constraints (>, <, >= or <=) on the indexed
    **         column that immediately follows the N equalities. Only
    **         the right-most column can be an inequality - the rest must
    **         use the "==" and "IN" operators. For example, if the
    **         index is on (x,y,z), then the following clauses are all
    **         optimized:
    **
    **            x=5
    **            x=5 AND y=10
    **            x=5 AND y<10
    **            x=5 AND y>5 AND y<10
    **            x=5 AND y=5 AND z<=10
    **
    **         The z<10 term of the following cannot be used, only
    **         the x=5 term:
    **
    **            x=5 AND z<10
    **
    **         N may be zero if there are inequality constraints.
    **         If there are no inequality constraints, then N is at
    **         least one.
    **
    **         This case is also used when there are no WHERE clause
    **         constraints but an index is selected anyway, in order
    **         to force the output order to conform to an ORDER BY.
    *//* Transitive constraints *//* transitive constraints *//*  ... is correct. *//*  ... of the TK_xx values... *//* Make sure the ordering.. *//* TK_GE *//* TK_LT *//* TK_LE *//* TK_GT *//* The following constant maps TK_xx codes into corresponding
      ** seek opcodes.  It depends on a particular ordering of TK_xx
      *//* Cursor seek operation *//* Registers for holding the start boundary *//* The expression that defines the start bound *//* Case 3:  We have an inequality comparison against the ROWID field.
    *//* Case 2:  We can directly reference a single row using an
    **          equality comparison against the ROWID field.  Or
    **          we reference multiple rows using a "rowid IN (...)"
    **          construct.
    *//* These registers need to be preserved in case there is an IN operator
    ** loop.  So we could deallocate the registers here (and potentially
    ** reuse them later) if (pLoop->wsFlags & WHERE_IN_ABLE)==0.  But it seems
    ** simpler and safer to simply not reuse the registers.
    **
    **    sqlite3ReleaseTempRange(pParse, iReg, nConstraint+2);
    *//* Generate code that will continue to the next row if
        ** the IN constraint is not satisfied
        *//* Reload the constraint value into reg[iReg+j+2].  The same value
        ** was loaded into the same register prior to the OP_VFilter, but
        ** the xFilter implementation might have changed the datatype or
        ** encoding of the value in the register, so it *must* be reloaded.
        *//* IN loop corresponding to the j-th constraint *//* Opcode to access the value of the IN constraint *//* RHS of the comparison *//* The comparison operator *//* An OOM inside of AddOp4(OP_VFilter) instruction above might have freed
    ** the u.vtab.idxStr.  NULL it out to prevent a use-after-free *//* The instruction immediately prior to OP_VFilter must be an OP_Integer
    ** that sets the "argc" value for xVFilter.  This is necessary for
    ** resolveP2() to work correctly.  See tag-20250207a. *//* P3 Value for OP_VFilter *//* Case 1:  The table is a virtual-table.  Use the VFilter and VNext
    **          to access the data.
    *//* Special case of a FROM clause subquery implemented as a co-routine *//* Compute a safe address to jump to if we discover that the table for
  ** this loop is empty and can never contribute content. *//* If this is the right table of a LEFT OUTER JOIN, allocate and
  ** initialize a memory cell that records if this table matches any
  ** row of the left table of the join.
  *//* Create labels for the "break" and "continue" instructions
  ** for the current loop.  Jump to addrBrk to break out of a loop.
  ** Jump to cont to go immediately to the next iteration of the
  ** loop.
  **
  ** When there is an IN operator, we also have a "addrNxt" label that
  ** means to continue with the next IN value combination.  When
  ** there are no IN operators in the constraints, the "addrNxt" label
  ** is the same as "addrBrk".
  *//* Iteration of constraint generator loop *//* Index used by loop (if any) *//* Temp register to free before returning *//* Rowid is stored in this register, if not zero *//* Jump here to continue with next cycle *//* addrBrk for the outermost loop *//* Jump here to break out of the loop *//* FROM clause term being coded *//* A WHERE clause term *//* Decomposition of the entire WHERE clause *//* The WhereLoop object being coded *//* True if we need to scan in reverse order *//* Where to jump to continue with the next IN case *//* The VDBE cursor for the table *//* Which tables are currently available *//* The current level pointer *//* Which level of pWInfo->a[] should be coded *//* Complete information about the WHERE clause *//*
** Generate code for the start of the iLevel-th loop in the WHERE clause
** implementation described by pWInfo.
*//*
** Loop pLoop is a WHERE_INDEXED level that uses at least one IN(...)
** operator. Return true if level pLoop is guaranteed to visit only one
** row for each key generated for the index.
*//*         ,--- Because sqlite3ConstructBloomFilter() has will not have set
    **  vvvvv--'    pLevel->regFilter if this were true. *//* Jump here to bypass inner loops *//*
** This routine is called right after An OP_Filter has been generated and
** before the corresponding index search has been performed.  This routine
** checks to see if there are additional Bloom filters in inner loops that
** can be checked prior to doing the index lookup.  If there are available
** inner-loop Bloom filters, then evaluate those filters now, before the
** index lookup.  The idea is that a Bloom filter check is way faster than
** an index lookup, and the Bloom filter might return false, meaning that
** the index lookup can be skipped.
**
** We know that an inner loop uses a Bloom filter because it has the
** WhereLevel.regFilter set.  If an inner-loop Bloom filter is checked,
** then clear the WhereLevel.regFilter value to prevent the Bloom filter
** from being checked a second time when the inner loop is evaluated.
*//*
** The pTruth expression is always true because it is the WHERE clause
** a partial index that is driving a query loop.  Look through all of the
** WHERE clause terms on the query, and if any of those terms must be
** true because pTruth is true, then mark those WHERE clause terms as
** coded.
*//*
** If the expression passed as the second argument is a vector, generate
** code to write the first nReg elements of the vector into an array
** of registers starting with iReg.
**
** If the expression is not a vector, then nReg must be passed 1. In
** this case, generate code to evaluate the expression and leave the
** result in register iReg.
*//* Vdbe to generate code within *//* Index cursor *//* Cursor for IPK b-tree *//* Index scan is using *//* Where clause context *//*
** Cursor iCur is open on an intkey b-tree (a table). Register iRowid contains
** a rowid value just read from cursor iIdxCur, open on index pIdx. This
** function generates code to do a deferred seek of cursor iCur to the
** rowid stored in register iRowid.
**
** Normally, this is just:
**
**   OP_DeferredSeek $iCur $iRowid
**
** Which causes a seek on $iCur to the row with rowid $iRowid.
**
** However, if the scan currently being coded is a branch of an OR-loop and
** the statement currently being coded is a SELECT, then additional information
** is added that might allow OP_Column to omit the seek and instead do its
** lookup on the index, thus avoiding an expensive seek operation.  To
** enable this optimization, the P3 of OP_DeferredSeek is set to iIdxCur
** and P4 is set to an array of integers containing one entry for each column
** in the table.  For each table column, if the column is the i'th
** column of the index, then the corresponding array entry is set to (i+1).
** If the column does not appear in the index at all, the array entry is set
** to 0.  The OP_Column opcode can check this array to see if the column it
** wants is in the index and if it is, it will substitute the index cursor
** and column number and continue with those new values, rather than seeking
** the table cursor.
*//* SQLITE_ENABLE_CURSOR_HINTS *//* If we survive all prior tests, that means this term is worth hinting *//* For an index scan, make sure referenced columns are actually in
    ** the index. *//* No subqueries or non-deterministic functions allowed *//* All terms in pWLoop->aLTerm[] except pEndRange are used to initialize
    ** the cursor.  These terms are not needed as hints for a pure range
    ** scan (that has no == terms) so omit them. *//* Any terms specified as part of the ON(...) clause for any LEFT
    ** JOIN for which the current table is not the rhs are omitted
    ** from the cursor-hint.
    **
    ** If this table is the rhs of a LEFT JOIN, "IS" or "IS NULL" terms
    ** that were specified as part of the WHERE clause must be excluded.
    ** This is to address the following:
    **
    **   SELECT ... t1 LEFT JOIN t2 ON (t1.a=t2.b) WHERE t2.c IS NULL;
    **
    ** Say there is a single row in t2 that matches (t1.a=t2.b), but its
    ** t2.c values is not NULL. If the (t2.c IS NULL) constraint is
    ** pushed down to the cursor, this row is filtered out, causing
    ** SQLite to synthesize a row of NULL values. Which does match the
    ** WHERE clause, and so the query returns a row. Which is incorrect.
    **
    ** For the same reason, WHERE terms such as:
    **
    **   WHERE 1 = (t2.c IS NULL)
    **
    ** are also excluded. See codeCursorHintIsOrFunction() for details.
    *//* Hint this end-of-scan boundary term if not NULL *//* Which loop to provide hints for *//* The where clause *//* FROM clause item *//*
** Insert an OP_CursorHint instruction if it is appropriate to do so.
*//* Do not walk disabled expressions.  tag-20230504-1 *//* Register for column value *//*
** This function is called on every node of an expression tree used as an
** argument to the OP_CursorHint instruction. If the node is a TK_COLUMN
** that accesses any table other than the one identified by
** CCurHint.iTabCur, then do the following:
**
**   1) allocate a register and code an OP_Column instruction to read
**      the specified column into the new register, and
**
**   2) transform the expression node to a TK_REGISTER node that reads
**      from the newly populated register.
**
** Also, if the node is a TK_COLUMN that does access the table identified
** by pCCurHint.iTabCur, and an index is being used (which we will
** know because CCurHint.pIdx!=0) then transform the TK_COLUMN into
** an access of the index rather than the original table.
*//*
** Test whether or not expression pExpr, which was part of a WHERE clause,
** should be included in the cursor-hint for a table that is on the rhs
** of a LEFT JOIN. Set Walker.eCode to non-zero before returning if the
** expression is not suitable.
**
** An expression is unsuitable if it might evaluate to non NULL even if
** a TK_COLUMN node that does affect the value of the expression is set
** to NULL. For example:
**
**   col IS NULL
**   col IS NOT NULL
**   coalesce(col, 1)
**   CASE WHEN col THEN 0 ELSE 1 END
*//*
** This function is called for every node of an expression that is a candidate
** for a cursor hint on an index cursor.  For TK_COLUMN nodes that reference
** the table CCurHint.iTabCur, verify that the same column can be
** accessed through the index.  If it cannot, then set pWalker->eCode to 1.
*//* The index used to access the table *//* Cursor for the index, if pIdx!=0.  Unused otherwise *//* Cursor for the main table *//*
** Information is passed from codeCursorHint() down to individual nodes of
** the expression tree (by sqlite3WalkExpr()) using an instance of this
** structure.
*//* ASC or DESC *//* Register holding counter *//* The upper or lower bound just coded *//* The loop that contains the LIKE operator *//* prepared statement under construction *//*
** If the most recently coded instruction is a constant range constraint
** (a string literal) that originated from the LIKE optimization, then
** set P3 and P5 on the OP_String opcode so that the string will be cast
** to a BLOB at appropriate times.
**
** The LIKE optimization trys to evaluate "x LIKE 'abc%'" as a range
** expression: "x>='ABC' AND x<'abd'".  But this requires that the range
** scan loop run twice, once for strings and a second time for BLOBs.
** The OP_String opcodes on the second pass convert the upper and lower
** bound string constants to blobs.  This routine makes the necessary changes
** to the OP_String opcodes for that to happen.
**
** Except, of course, if SQLITE_LIKE_DOESNT_MATCH_BLOBS is defined, then
** only the one pass through the string space is required, so this routine
** becomes a no-op.
*//* No affinity ever needs to be (or should be) applied to a value
        ** from the RHS of an "? IN (SELECT ...)" expression. The
        ** sqlite3FindInIndex() routine has already ensured that the
        ** affinity of the comparison has been applied to the value.  *//* The following testcase is true for indices with redundant columns.
    ** Ex: CREATE INDEX i1 ON t1(a,b,a); SELECT * FROM t1 WHERE a=0 AND b=0; *//* Evaluate the equality constraints
  *//* Figure out how many memory cells we will need then allocate them.
  *//* This module is only called on query plans that use an index. *//* Affinity string to return *//* Number of registers to allocate *//* Base register *//* The WhereLoop object *//* A single constraint term *//* The index being used for this loop *//* The vm under construction *//* Number of left-most columns to skip *//* The number of == or IN constraints to code *//* OUT: Set to point to affinity string *//* Number of extra registers to allocate *//* Reverse the order of IN operators *//* Which nested loop of the FROM we are coding *//*
** Generate code that will evaluate all == and IN constraints for an
** index scan.
**
** For example, consider table t1(a,b,c,d,e,f) with index i1(a,b,c).
** Suppose the WHERE clause is this:  a==5 AND b IN (1,2,3) AND c>5 AND c<10
** The index has as many as three equality constraints, but in this
** example, the third "c" value is an inequality.  So only two
** constraints are coded.  This routine will generate code to evaluate
** a==5 and b IN (1,2,3).  The current values for a and b will be stored
** in consecutive registers and the index of the first register is returned.
**
** In the example above nEq==2.  But this subroutine works for any value
** of nEq including 0.  If nEq==0, this routine is nearly a no-op.
** The only thing it does is allocate the pLevel->iMem memory cell and
** compute the affinity string.
**
** The nExtraReg parameter is 0 or 1.  It is 0 if all WHERE clause constraints
** are == or IN and are covered by the nEq.  nExtraReg is 1 if there is
** an inequality constraint (such as the "c>=5 AND c<10" in the example) that
** occurs after the nEq quality constraints.
**
** This routine allocates a range of nEq+nExtraReg memory cells and returns
** the index of the first memory cell in that range. The code that
** calls this routine will use that memory range to store keys for
** start and termination conditions of the loop.
** key value of the loop.  If one or more IN operators appear, then
** this routine allocates an additional nEq memory cells for internal
** use.
**
** Before returning, *pzAff is set to point to a buffer containing a
** copy of the column affinity string of the index allocated using
** sqlite3DbMalloc(). Except, entries in the copy of the string associated
** with equality constraints that use BLOB or NONE affinity are set to
** SQLITE_AFF_BLOB. This is to deal with SQL such as the following:
**
**   CREATE TABLE t1(a TEXT PRIMARY KEY, b);
**   SELECT ... FROM t1 AS t2, t1 WHERE t1.a = t2.b;
**
** In the example above, the index on t1(a) has TEXT affinity. But since
** the right hand side of the equality constraint (t2.b) has BLOB/NONE affinity,
** no conversion should be attempted before using a t2.b value as part of
** a key to search the index. Hence the first byte in the returned affinity
** string in this example would be set to SQLITE_AFF_BLOB.
*//* As an optimization, try to disable the WHERE clause term that is
  ** driving the index as it will always be true.  The correct answer is
  ** obtained regardless, but we might get the answer with fewer CPU cycles
  ** by omitting the term.
  **
  ** But do not disable the term unless we are certain that the term is
  ** not a transitive constraint.  For an example of where that does not
  ** work, see https://sqlite.org/forum/forumpost/eb8613976a (2021-05-04)
  *//* Register holding results *//* Attempt to leave results in this register *//* True for reverse-order IN operations *//* Index of the equality term within this level *//* The level of the FROM clause we are working on *//* The term of the WHERE clause to be coded *//*
** Generate code for a single equality term of the WHERE clause.  An equality
** term can be either X=expr or X IN (...).   pTerm is the term to be
** coded.
**
** The current value for the constraint is left in a register, the index
** of which is returned.  An attempt is made store the result in iTarget but
** this is only guaranteed for TK_ISNULL and TK_IN constraints.  If the
** constraint is a TK_EQ or TK_IS, then the current value might be left in
** some other register and it is the caller's responsibility to compensate.
**
** For a constraint of the form X=expr, the expression is evaluated in
** straight-line code.  For constraints of the form X IN (...)
** this routine sets up a loop that will iterate over all values of X.
*//* Index in aiMap[] *//*
** Generate code for a single X IN (....) term of the WHERE clause.
**
** This is a special-case of codeEqualityTerm() that works for IN operators
** only.  It is broken out into a subroutine because this case is
** uncommon and by splitting it off into a subroutine, the common case
** runs faster.
**
** The current value for the constraint is left in  register iTarget.
** This routine sets up a loop that will iterate over all values of X.
*//* If either the ORDER BY clause or the GROUP BY clause contains
      ** references to result-set columns, those references might now be
      ** obsolete.  So fix them up.
      *//* Take care here not to generate a TK_VECTOR containing only a
        ** single value. Since the parser never creates such a vector, some
        ** of the subroutines do not handle this case.  *//* Req'd for SubrtnSig validity *//* Duplicate PK column *//* New LHS after mods *//* New RHS after modifications *//* Original unmodified LHS *//* Original unmodified RHS *//* Pointer to the SELECT on the RHS *//* The IN expression to be reduced *//* The current loop *//* Look at loop terms starting here *//*
** pX is an expression of the form:  (vector) IN (SELECT ...)
** In other words, it is a vector IN operator with a SELECT clause on the
** LHS.  But not all terms in the vector are indexable and the terms might
** not be in the correct order for indexing.
**
** This routine makes a copy of the input pX expression and then adjusts
** the vector on the LHS with corresponding changes to the SELECT so that
** the vector contains only index terms and those terms are in the correct
** order.  The modified IN expression is returned.  The caller is responsible
** for deleting the returned expression.
**
** Example:
**
**    CREATE TABLE t1(a,b,c,d,e,f);
**    CREATE INDEX t1x1 ON t1(e,c);
**    SELECT * FROM t1 WHERE (a,b,c,d,e) IN (SELECT v,w,x,y,z FROM t2)
**                           \_______________________________________/
**                                     The pX expression
**
** Since only columns e and c can be used with the index, in that order,
** the modified IN expression that is returned will be:
**
**        (e,c) IN (SELECT z,x FROM t2)
**
** The reduced pX is different from the original (obviously) and thus is
** only used for indexing, to improve performance.  The original unaltered
** IN expression must also be run on each output row for correctness.
*//*
** The pOrderBy->a[].u.x.iOrderByCol values might be incorrect because
** columns might have been rearranged in the result set.  This routine
** fixes them up.
**
** pEList is the new result set.  The pEList->a[].u.x.iOrderByCol values
** contain the *old* locations of each expression.  This is a temporary
** use of u.x.iOrderByCol, not its intended use.  The caller must reset
** u.x.iOrderByCol back to zero for all entries in pEList before the
** caller returns.
**
** This routine changes pOrderBy->a[].u.x.iOrderByCol values from
** pEList->a[N].u.x.iOrderByCol into N+1.  (The "+1" is because of the 1-based
** indexing used by iOrderByCol.)  Or if no match, iOrderByCol is set to zero.
*//* Affinity string to modify *//* Number of vector elements in comparison *//*
** Expression pRight, which is the RHS of a comparison operation, is
** either a vector of n elements or, if n==1, a scalar expression.
** Before the comparison operation, affinity zAff is to be applied
** to the pRight values. This function modifies characters within the
** affinity string to SQLITE_AFF_BLOB if either:
**
**   * the comparison will be performed with no affinity, or
**   * the affinity change in zAff is guaranteed not to change the value.
*//* Code the OP_Affinity opcode if there is anything left to do. *//* Adjust base and n to skip over SQLITE_AFF_BLOB and SQLITE_AFF_NONE
  ** entries at the beginning and end of the affinity string.
  *//*
** Code an OP_Affinity opcode to apply the column affinity string zAff
** to the n registers starting at base.
**
** As an optimization, SQLITE_AFF_BLOB and SQLITE_AFF_NONE entries (which
** are no-ops) at the beginning and end of zAff are ignored.  If all entries
** in zAff are SQLITE_AFF_BLOB or SQLITE_AFF_NONE, then no code gets generated.
**
** This routine makes its own copy of zAff so that the caller is free
** to modify zAff after this routine returns.
*//*
** Disable a term in the WHERE clause.  Except, do not disable the term
** if it controls a LEFT OUTER JOIN and it did not originate in the ON
** or USING clause of that join.
**
** Consider the term t2.z='ok' in the following queries:
**
**   (1)  SELECT * FROM t1 LEFT JOIN t2 ON t1.a=t2.x WHERE t2.z='ok'
**   (2)  SELECT * FROM t1 LEFT JOIN t2 ON t1.a=t2.x AND t2.z='ok'
**   (3)  SELECT * FROM t1, t2 WHERE t1.a=t2.x AND t2.z='ok'
**
** The t2.z='ok' is disabled in the in (2) because it originates
** in the ON clause.  The term is disabled in (3) because it is not part
** of a LEFT OUTER JOIN.  In (1), the term is not disabled.
**
** Disabling a term causes that term to not be tested in the inner loop
** of the join.  Disabling is an optimization.  When terms are satisfied
** by indices, we disable them to prevent redundant tests in the inner
** loop.  We would get the correct results if nothing were ever disabled,
** but joins might run a little slower.  The trick is to disable as much
** as we can without disabling too much.  If we disabled in (1), we'd get
** the wrong answer.  See ticket #813.
**
** If all the children of a term are disabled, then that term is also
** automatically disabled.  In this way, terms get disabled if derived
** virtual terms are tested first.  For example:
**
**      x GLOB 'abc*' AND x>='abc' AND x<'acd'
**      \___________/     \______/     \_____/
**         parent          child1       child2
**
** Only the parent term was in the original WHERE clause.  The child1
** and child2 terms were added by the LIKE optimization.  If both of
** the virtual child terms are valid, then testing of the parent can be
** skipped.
**
** Usually the parent term is marked as TERM_CODED.  But if the parent
** term was originally TERM_LIKE, then the parent gets TERM_LIKECOND instead.
** The TERM_LIKECOND marking indicates that the term should be coded inside
** a conditional such that is only evaluated on the second pass of a
** LIKE-optimization loop, when scanning BLOBs instead of strings.
*//* Address of OP_Explain (or 0) *//* Level to add scanstatus() entry for *//* FROM clause pLvl reads data from *//* Vdbe to add scanstatus entry to *//*
** Configure the VM passed as the first argument with an
** sqlite3_stmt_scanstatus() entry corresponding to the scan used to
** implement level pLvl. Argument pSrclist is a pointer to the FROM
** clause that the scan reads data from.
**
** If argument addrExplain is not 0, it must be the address of an
** OP_Explain instruction that describes the same loop.
*//* SQLITE_OMIT_EXPLAIN *//* Initial space for EQP output string *//* EQP output string *//* The where loop *//* Text to add to EQP output *//* VM being constructed *//* Bloom filter on this level *//* WHERE clause *//*
** Add a single OP_Explain opcode that describes a Bloom filter.
**
** Or if not processing EXPLAIN QUERY PLAN and not in a SQLITE_DEBUG and/or
** SQLITE_ENABLE_STMT_SCANSTATUS build, then OP_Explain opcodes are not
** required and this routine is a no-op.
**
** If an OP_Explain opcode is added to the VM, its address is returned.
** Otherwise, if no OP_Explain is coded, zero is returned.
*//* Flags passed to sqlite3WhereBegin() *//* Scan to write OP_Explain opcode for *//* Table list this loop refers to *//*
** This function is a no-op unless currently processing an EXPLAIN QUERY PLAN
** command, or if stmt_scanstatus_v2() stats are enabled, or if SQLITE_DEBUG
** was defined at compile-time. If it is not a no-op, a single OP_Explain
** opcode is added to the output to describe the table scan strategy in pLevel.
**
** If an OP_Explain opcode is added to the VM, its address is returned.
** Otherwise, if no OP_Explain is coded, zero is returned.
*//* Better output, but breaks many tests *//* Flags that describe this loop *//* The controlling WhereLoop object *//* True for a SEARCH. False for SCAN. *//* Address of OP_Explain opcode *//*
** This function sets the P4 value of an existing OP_Explain opcode to
** text describing the loop in pLevel. If the OP_Explain opcode already has
** a P4 value, it is freed before it is overwritten.
*//*
** Argument pLevel describes a strategy for scanning table pTab. This
** function appends text to pStr that describes the subset of table
** rows scanned by the strategy in the form of an SQL expression.
**
** For example, if the query:
**
**   SELECT * FROM t1 WHERE a=1 AND b>2;
**
** is run and there is an index on (a, b), then this function returns a
** string similar to:
**
**   "a=? AND b>?"
*//* Name of the operator *//* Non-zero to append " AND " *//* Zero-based index of first term. *//* Number of terms *//* Index to read column names from *//* The text expression being built *//*
** This routine is a helper for explainIndexRange() below
**
** pStr holds the text of an expression that we are building up one term
** at a time.  This routine adds a new term to the end of the expression.
** Terms are separated by AND so add the "AND" text for second and subsequent
** terms only.
*//*
** Return the name of the i-th column of the pIdx index.
*//************** Continuing where we left off in wherecode.c ******************//************** End of whereInt.h ********************************************//* !defined(SQLITE_WHEREINT_H) *//* Uses an index-on-expressions *//* Implemented by co-routine.
                                       ** NB: False-negatives are possible *//* Set offset counter to zero *//* nOut reduced by extra WHERE terms *//* Consider using a Bloom-filter *//* Uses a transitive constraint *//* Seek-scan optimization for IN *//* Column nEq of index is BIGNULL *//* Perhaps quit IN loops early *//* The automatic index is partial *//* WHERE_ONEROW would have been helpful*//* Uses the skip-scan algorithm *//* Uses an ephemeral index *//* OR using multiple indices *//* Selects no more than one row *//* Able to support an IN operator *//* WhereLoop.u.vtab is valid *//* WhereLoop.u.btree.pIndex is valid *//* x is the INTEGER PRIMARY KEY *//* Use index only - omit table *//* Both x>EXPR and x<EXPR *//* x>EXPR or x>=EXPR constraint *//* x<EXPR or x<=EXPR constraint *//* Any of the WHERE_COLUMN_xxx values *//* x IS NULL *//* x IN (...) *//* x<EXPR and/or x>EXPR *//* x=EXPR *//*
** These are definitions of bits in the WhereLoop.wsFlags field.
** The particular combination of bits in each WhereLoop help to
** determine the algorithm that WhereLoop represents.
*//* Mask of all non-compound WO_* values *//* Mask of all possible WO_* values *//* A row-value term *//* This term does not restrict search space *//* Of the form A==B, both columns *//* Two or more AND-connected terms *//* Two or more OR-connected terms *//* Op useful to virtual tables only *//*
** Bitmasks for the operators on WhereTerm objects.  These are all
** operators that are of interest to the query planner.  An
** OR-ed combination of these values can be used when searching for
** particular WhereTerms within a WhereClause.
**
** Value constraints:
**     WO_EQ    == SQLITE_INDEX_CONSTRAINT_EQ
**     WO_LT    == SQLITE_INDEX_CONSTRAINT_LT
**     WO_LE    == SQLITE_INDEX_CONSTRAINT_LE
**     WO_GT    == SQLITE_INDEX_CONSTRAINT_GT
**     WO_GE    == SQLITE_INDEX_CONSTRAINT_GE
*//* whereexpr.c: *//* wherecode.c: *//*
** Private interfaces - callable only by other where.c routines.
**
** where.c:
*//* Information about each nest loop in WHERE *//* Map cursor numbers to bitmasks *//* Decomposition of the WHERE clause *//* Mask of ORDER BY terms that need reversing *//* Memory to free when this object destroyed *//* List of all WhereLoop objects *//* End of the WHERE clause itself *//* The very beginning of the WHERE loop *//* Total cost of the solution *//* Estimated number of output rows *//* True if star-query heuristic is used *//* True if check for star-query is complete *//* True if really sorted (not just grouped) *//* True if only the inner-most loop is ordered *//* Not all WHERE terms resolved by outer loop *//* Uses OP_DeferredSeek *//* One of the WHERE_DISTINCT_* values *//* ONEPASS_OFF, or _SINGLE, or _MULTI *//* Number of ORDER BY terms satisfied by indices *//* Number of nested loop *//* LIMIT if wctrlFlags has WHERE_USE_LIMIT *//* Flags originally passed to sqlite3WhereBegin() *//* pParse->nQueryLoop outside the WHERE loop *//* Jump here to continue with next record *//* OP_OpenWrite cursors for the ONEPASS opt *//* The entire SELECT statement containing WHERE *//* Result set of the query *//* The ORDER BY clause or NULL *//* List of tables in the join *//*
** The WHERE clause processing routine has two halves.  The
** first part does the start of the WHERE loop and the second
** half does the tail of the WHERE loop.  An instance of
** this structure is returned by the first half and passed
** into the second half to give some continuity.
**
** An instance of this object holds the complete state of the query
** planner.
*//* The WhereLoopBuilder.iPlanLimit is used to limit the number of
** index+constraint combinations the query planner will consider for a
** particular query.  If this parameter is unlimited, then certain
** pathological queries can spend excess time in the sqlite3WhereBegin()
** routine.  The limit is high enough that is should not impact real-world
** queries.
**
** SQLITE_QUERY_PLANNER_LIMIT is the baseline limit.  The limit is
** increased by SQLITE_QUERY_PLANNER_LIMIT_INCR before each term of the FROM
** clause is processed, so that every table in a join is guaranteed to be
** able to propose a some index+constraint combinations even if the initial
** baseline limit was exhausted by prior tables of the join.
*//* Second builder pass needed *//* All keys of a UNIQUE index used *//* An index is used *//* Allowed values for WhereLoopBuider.bldFlags *//* Search limiter *//* Second set of SQLITE_BLDF_* flags *//* First set of SQLITE_BLDF_* flags *//* Number of valid fields currently in pRec *//* Probe for stat4 (if required) *//* Record best loops here, if not NULL *//* Template WhereLoop *//* WHERE clause terms *//* Information about this WHERE *//*
** This object is a convenience wrapper holding all information needed
** to construct WhereLoop objects for a particular query.
*//* Cursor assigned to each bit *//* Number of assigned cursor values *//* Used by sqlite3WhereExprUsage() *//*
** An instance of the following structure keeps track of a mapping
** between VDBE cursor numbers and bits of the bitmasks in WhereTerm.
**
** The VDBE cursor numbers are small integers contained in
** SrcItem.iCursor and Expr.iTable fields.  For any given WHERE
** clause, the cursor numbers might not begin with 0 and they might
** contain gaps in the numbering sequence.  But we want to make maximum
** use of the bits in our bitmasks.  This structure provides a mapping
** from the sparse cursor numbers into consecutive integers beginning
** with 0.
**
** If WhereMaskSet.ix[A]==B it means that The A-th bit of a Bitmask
** corresponds VDBE cursor number B.  The A-th bit of a bitmask is 1<<A.
**
** For example, if the WHERE clause expression used these VDBE
** cursors:  4, 5, 8, 29, 57, 73.  Then the  WhereMaskSet structure
** would map those cursor numbers into bits 0 through 5.
**
** Note that the mapping is not necessarily ordered.  In the example
** above, the mapping might go like this:  4->3, 5->1, 8->2, 29->0,
** 57->5, 73->4.  Or one of 719 other combinations might be used. It
** does not really matter.  What is important is that sparse cursor
** numbers all get mapped into bit numbers that begin with 0 and contain
** no gaps.
*//* The subexpression broken out *//*
** A WhereTerm with eOperator==WO_AND has its u.pAndInfo pointer set to
** a dynamically allocated instance of the following structure.
*//* Bitmask of all indexable tables in the clause *//* Decomposition into subterms *//*
** A WhereTerm with eOperator==WO_OR has its u.pOrInfo pointer set to
** a dynamically allocated instance of the following structure.
*//* Initial static space for a[] *//* Each a[] describes a term of the WHERE clause *//* Number of terms through the last non-Virtual *//* Number of entries in a[] *//* True if any a[].eOperator is WO_OR *//* Split operator.  TK_AND or TK_OR *//* Outer conjunction *//*
** An instance of the following structure holds all information about a
** WHERE clause.  Mostly this is a container for one or more WhereTerms.
**
** Explanation of pOuter:  For a WHERE clause of the form
**
**           a AND ((b AND c) OR (d AND e)) AND f
**
** There are separate WhereClause objects for the whole clause and for
** the subclauses "(b AND c)" and "(d AND e)".  The pOuter field of the
** subclauses points to the WhereClause object for the whole clause.
*//* Corresponding column number in the eq-class *//* Cursors in the equivalence class *//* Number of entries in aiCur[] and aiColumn[] *//* Current slot in aiCur[] and aiColumn[] *//* Must match this affinity, if zCollName!=NULL *//* Acceptable operators *//* Resume scanning at this->pWC->a[this->k] *//* Search for this index expression *//* Required collating sequence, if not NULL *//* WhereClause currently being scanned *//* Original, innermost WhereClause *//*
** An instance of the WhereScan object is used as an iterator for locating
** terms in the WHERE clause that are useful to the query planner.
*//* One slice of a row-value/vector comparison *//* Only used with STAT4 *//* Term excludes few rows *//* Heuristic truthProb used *//* Term.pExpr contains a correlated sub-query *//* Term.pExpr is an IS operator *//* The original LIKE operator *//* Conditionally this LIKE operator term *//* Virtual terms from the LIKE optimization *//* Manufactured x>NULL or x<=NULL term *//* Used during OR-clause processing *//* Need to free the WhereTerm.u.pAndInfo obj *//* Need to free the WhereTerm.u.pOrInfo object *//* Has a child *//* This term is already coded *//* Added by the optimizer.  Do not code *//* Need to call sqlite3ExprDelete(db, pExpr) *//*
** Allowed values of WhereTerm.wtFlags
*//* Bitmask of tables referenced by pExpr *//* Bitmask of tables used by pExpr->pRight *//* Extra information if (eOperator& WO_AND)!=0 *//* Extra information if (eOperator & WO_OR)!=0 *//* Opcode other than OP_OR or OP_AND *//* Field in (?,?,?) IN (SELECT...) vector *//* Column number of X in "X <op> <expr>" *//* Cursor number of X in "X <op> <expr>" *//* Disable pWC->a[iParent] when this term disabled *//* Op for vtab MATCH/LIKE/GLOB/REGEXP terms *//* Number of children that must disable us *//* A WO_xx value describing <op> *//* TERM_xxx bit flags.  See below *//* Probability of truth for this expression *//* The clause this term is part of *//* Pointer to the subexpression that is this term *//*
** The query generator uses an array of instances of this structure to
** help it analyze the subexpressions of the WHERE clause.  Each WHERE
** clause subexpression is separated from the others by AND operators,
** usually, or sometimes subexpressions separated by OR.
**
** All WhereTerms are collected into a single WhereClause structure.
** The following identity holds:
**
**        WhereTerm.pWC->a[WhereTerm.idx] == WhereTerm
**
** When a term is of the form:
**
**              X <op> <expr>
**
** where X is a column name and <op> is one of certain operators,
** then WhereTerm.leftCursor and WhereTerm.u.leftColumn record the
** cursor number and column number for X.  WhereTerm.eOperator records
** the <op> using a bitmask encoding defined by WO_xxx below.  The
** use of a bitmask encoding for the operator allows us to search
** quickly for terms that match any of several different operators.
**
** A WhereTerm might also be two or more subterms connected by OR:
**
**         (t1.X <op> <expr>) OR (t1.Y <op> <expr>) OR ....
**
** In this second case, wtFlag has the TERM_ORINFO bit set and eOperator==WO_OR
** and the WhereTerm.u.pOrInfo field points to auxiliary information that
** is collected about the OR clause.
**
** If a term in the WHERE clause does not match either of the two previous
** categories, then eOperator==0.  The WhereTerm.pExpr field is still set
** to the original subexpression content and wtFlags is set up appropriately
** but no other fields in the WhereTerm object are meaningful.
**
** When eOperator!=0, prereqRight and prereqAll record sets of cursor numbers,
** but they do so indirectly.  A single WhereMaskSet structure translates
** cursor number into bits and the translated bit is stored in the prereq
** fields.  The translation is used in order to maximize the number of
** bits that will fit in a Bitmask.  The VDBE cursor numbers might be
** spread out over the non-negative integers.  For example, the cursor
** numbers might be 3, 8, 9, 10, 20, 23, 41, and 45.  The WhereMaskSet
** translates these sparse cursor numbers into consecutive integers
** beginning with 0 in order to make the best possible use of the available
** bits in the Bitmask.  So, in the example above, the cursor numbers
** would be mapped into integers 0 through 7.
**
** The number of terms in a join is limited by the number of bits
** in prereqRight and prereqAll.  The default is 64 bits, hence SQLite
** is only able to process joins with 64 or fewer tables.
*//* Array of WhereLoop objects implementing this path *//* No. of ORDER BY terms satisfied. -1 for unknown *//* Total cost of this path ignoring sorting costs *//* Total cost of this path *//* Estimated number of rows generated by this path *//* aLoop[]s that should be reversed for ORDER BY *//* Bitmask of all WhereLoop objects in this path *//*
** Each instance of this object holds a sequence of WhereLoop objects
** that implement some or all of a query plan.
**
** Think of each WhereLoop object as a node in a graph with arcs
** showing dependencies and costs for travelling between nodes.  (That is
** not a completely accurate description because WhereLoop costs are a
** vector, not a scalar, and because dependencies are many-to-one, not
** one-to-one as are graph nodes.  But it is a useful visualization aid.)
** Then a WherePath object is a path through the graph that visits some
** or all of the WhereLoop objects once.
**
** The "solver" works by creating the N best WherePath objects of length
** 1.  Then using those as a basis to compute the N best WherePath objects
** of length 2.  And so forth until the length of WherePaths equals the
** number of nodes in the FROM clause.  The best (lowest cost) WherePath
** at the end is the chosen query plan.
*//* Set of best costs *//* Number of valid a[] entries *//* The WhereOrSet object holds a set of possible WhereOrCosts that
** correspond to the subquery(s) of OR-clause processing.  Only the
** best N_OR_COST elements are retained.
*//* Number of outputs for this subquery *//* Cost of running this subquery *//* Prerequisites *//* This object holds the prerequisites and the cost of running a
** subquery on one operand of an OR operator in the WHERE clause.
** See WhereOrSet for additional information
*//* Initial aLTerm[] space *//* Next WhereLoop object in the WhereClause *//* WhereTerms used *//* Cost delta due to star-schema heuristic.  Not
                        ** initialized unless pWInfo->bStarUsed *//* Number of slots allocated for aLTerm[] *//**** whereLoopXfer() copies fields above ***********************//* Number of NULL aLTerm[] entries *//* Number of entries in aLTerm[] *//* WHERE_* flags describing the plan *//* Terms to handle as IN(...) instead of == *//* Index identifier string *//* Terms that may be omitted *//* True if satisfies ORDER BY *//* Show idxNum as hex in EXPLAIN QUERY PLAN *//* True to let virtual table handle offset *//* True if sqlite3_free(idxStr) is needed *//* Information for virtual tables *//* ORDER BY clause if this is really a subquery *//* Index used, or NULL *//* Index columns used to sort for DISTINCT *//* Size of TOP vector *//* Size of BTM vector *//* Number of equality constraints *//* Information for internal btree tables *//* Cost of running each loop *//* One-time setup cost (ex: create transient index) *//* Sorting index number.  0==None *//* Position in FROM clause of table for this loop *//* Symbolic ID of this loop for debugging use *//* Bitmask identifying table iTab *//* Bitmask of other loops that must run first *//*
** Each instance of this object represents an algorithm for evaluating one
** term of a join.  Every term of the FROM clause will have at least
** one corresponding WhereLoop object (unless INDEXED BY constraints
** prevent a query solution - which is an error) and many terms of the
** FROM clause will have multiple WhereLoop objects, each describing a
** potential way of implementing that FROM-clause term, together with
** dependencies and cost estimates for using the chosen algorithm.
**
** Query planning consists of building up a collection of these WhereLoop
** objects, then computing a particular sequence of WhereLoop objects, with
** one WhereLoop object per FROM clause term, that satisfy all dependencies
** and that minimize the overall cost.
*//* Address at which row is visited *//* FROM entries not usable at this level *//* The selected WhereLoop object *//* Possible covering index for WHERE_MULTI_OR *//* Used when pWLoop->wsFlags&WHERE_IN_ABLE *//* Information about each nested IN operator *//* IN Loop terminator. OP_Next or OP_Prev *//* Number of prior entries in the key *//* Base register of multi-key index record *//* Top of the IN loop *//* The VDBE cursor used by this IN operator *//* Number of entries in aInLoop[] *//* Information that depends on pWLoop->wsFlags *//* Operands of the opcode used to end the loop *//* Opcode, P3 & P5 of the opcode that ends the loop *//* Which entry in the FROM clause *//* Extra information for RIGHT JOIN *//* Bloom filter *//* LIKE range processing address *//* LIKE range processing counter register (times 2) *//* Jump here for next part of big-null scan *//* big-null flag reg. True if a NULL-scan is needed *//* Beginning of the body of this loop *//* First instruction of interior of the loop *//* Jump here to continue with the next loop cycle *//* Jump here for next iteration of skip-scan *//* Jump here to start the next IN combination *//* The VDBE cursor used to access pIdx *//* The VDBE cursor used to access the table *//* Memory cell used to implement LEFT OUTER JOIN *//*
** This object contains information needed to implement a single nested
** loop in WHERE clause.
**
** Contrast this object with WhereLoop.  This object describes the
** implementation of the loop.  WhereLoop describes the algorithm.
** This object contains a pointer to the WhereLoop algorithm as one of
** its elements.
**
** The WhereInfo object contains a single instance of this object for
** each term in the FROM clause (which is to say, for each of the
** nested loops as implemented).  The order of WhereLevel objects determines
** the loop nested order, with WhereInfo.a[0] being the outer loop and
** WhereInfo.a[WhereInfo.nLevel-1] being the inner loop.
*//* The last opcode in the interior subroutine *//* Starting address for the interior subroutine *//* Return register for the interior subroutine *//* Bloom filter for iRJMatch *//* Cursor used to determine prior matched rows *//*
** Extra information attached to a WhereLevel that is a RIGHT JOIN.
*//* Bytes of space *//* Next block in the chain *//*
** This object is a header on a block of allocated memory that will be
** automatically freed when its WInfo object is destructed.
*//* Forward references
*//*
** 2013-11-12
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
**
** This file contains structure and macro definitions for the query
** planner logic in "where.c".  These definitions are broken out into
** a separate source file for easier editing.
*//************** Begin file whereInt.h ****************************************//************** Include whereInt.h in the middle of wherecode.c **************//*
** 2015-06-06
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This module contains C code that generates VDBE code used to process
** the WHERE clause of SQL statements.
**
** This file was split off from where.c on 2015-06-06 in order to reduce the
** size of where.c and make it easier to edit.  This file contains the routines
** that actually generate the bulk of the WHERE loop code.  The original where.c
** file retains the code that does query planning and analysis.
*//************** Begin file wherecode.c ***************************************//************** End of vtab.c ************************************************//*
** Call from within the xCreate() or xConnect() methods to provide
** the SQLite core with additional information about the behavior
** of the virtual table being implemented.
*//*
** Return the ON CONFLICT resolution mode in effect for the virtual
** table update operation currently in progress.
**
** The results of this routine are undefined unless it is called from
** within an xUpdate method.
*//* Mark the table as Ephemeral prior to deleting it, so that the
    ** sqlite3DeleteTable() routine will know that it is not stored in
    ** the schema. *//*
** Erase the eponymous virtual table instance associated with
** virtual table module pMod, if it exists.
*//*
** Check to see if virtual table module pMod can be have an eponymous
** virtual table instance.  If it can, create one if one does not already
** exist. Return non-zero if either the eponymous virtual table instance
** exists when this routine returns or if an attempt to create it failed
** and an error message was left in pParse.
**
** An eponymous virtual table instance is one that is named after its
** module, and more importantly, does not require a CREATE VIRTUAL TABLE
** statement in order to come into existence.  Eponymous virtual table
** instances always exist.  They cannot be DROP-ed.
**
** Any virtual table module for which xConnect and xCreate are the same
** method can have an eponymous virtual table instance.
*//*
** Make sure virtual table pTab is contained in the pParse->apVirtualLock[]
** array so that an OP_VBegin will get generated for it.  Add pTab to the
** array if it is missing.  If pTab is already in the array, this routine
** is a no-op.
*//* Create a new ephemeral function definition for the overloaded
  ** function *//* Call the xFindFunction method on the virtual table implementation
  ** to see if the implementation wants to overload this function.
  **
  ** Though undocumented, we have historically always invoked xFindFunction
  ** with an all lower-case function name.  Continue in this tradition to
  ** avoid any chance of an incompatibility.
  *//* Check to see the left operand is a column in a virtual table *//* First argument to the function *//* Function to possibly overload *//* Database connection for reporting malloc problems *//*
** The first parameter (pDef) is a function implementation.  The
** second parameter (pExpr) is the first argument to this function.
** If pExpr is a column in a virtual table, then let the virtual
** table implementation have an opportunity to overload the function.
**
** This routine is used to allow virtual table implementations to
** overload MATCH, LIKE, GLOB, and REGEXP operators.
**
** Return either the pDef argument (indicating no change) or a
** new FuncDef structure that is marked as ephemeral using the
** SQLITE_FUNC_EPHEM flag.
*//*
** Invoke either the xSavepoint, xRollbackTo or xRelease method of all
** virtual tables that currently have an open transaction. Pass iSavepoint
** as the second argument to the virtual table method invoked.
**
** If op is SAVEPOINT_BEGIN, the xSavepoint method is invoked. If it is
** SAVEPOINT_ROLLBACK, the xRollbackTo method. Otherwise, if op is
** SAVEPOINT_RELEASE, then the xRelease method of each virtual table with
** an open transaction is invoked.
**
** If any virtual table method returns an error code other than SQLITE_OK,
** processing is abandoned and the error returned to the caller of this
** function immediately. If all calls to virtual table methods are successful,
** SQLITE_OK is returned.
*//* Invoke the xBegin method. If successful, add the vtab to the
    ** sqlite3.aVTrans[] array. *//* If pVtab is already in the aVTrans array, return early *//* Special case: If db->aVTrans is NULL and db->nVTrans is greater
  ** than zero, then this function is being called from within a
  ** virtual module xSync() callback. It is illegal to write to
  ** virtual module tables in this case, so return SQLITE_LOCKED.
  *//*
** If the virtual table pVtab supports the transaction interface
** (xBegin/xRollback/xCommit and optionally xSync) and a transaction is
** not currently open, invoke the xBegin method now.
**
** If the xBegin call is successful, place the sqlite3_vtab pointer
** in the sqlite3.aVTrans array.
*//*
** Invoke the xCommit method of all virtual tables in the
** sqlite3.aVTrans array. Then clear the array itself.
*//*
** Invoke the xRollback method of all virtual tables in the
** sqlite3.aVTrans array. Then clear the array itself.
*//*
** Invoke the xSync method of all virtual tables in the sqlite3.aVTrans
** array. Return the error code for the first error that occurs, or
** SQLITE_OK if all xSync operations are successful.
**
** If an error message is available, leave it in p->zErrMsg.
*//*
** This function invokes either the xRollback or xCommit method
** of each of the virtual tables in the sqlite3.aVTrans array. The method
** called is identified by the second argument, "offset", which is
** the offset of the method to call in the sqlite3_module structure.
**
** The array is cleared after invoking the callbacks.
*//* Remove the sqlite3_vtab* from the aVTrans[] array, if applicable *//*
** This function is invoked by the vdbe to call the xDestroy method
** of the virtual table named zTab in database iDb. This occurs
** when a DROP TABLE is mentioned.
**
** This call is a no-op if zTab is not a virtual table.
*//* WITHOUT ROWID virtual tables must either be read-only (xUpdate==0)
        ** or else must have a single-column PRIMARY KEY *//* We should never be able to reach this point while loading the
  ** schema.  Nevertheless, defend against that (turn off db->init.busy)
  ** in case a bug arises. *//* Verify that the first two keywords in the CREATE TABLE statement
  ** really are "CREATE" and "TABLE".  If this is not the case, then
  ** sqlite3_declare_vtab() is being misused.
  *//*
** This function is used to set the schema of a virtual table.  It is only
** valid to call this function from within the xCreate() or xConnect() of a
** virtual table module.
*//* Justification of ALWAYS():  The xConstructor method is required to
  ** create a valid sqlite3_vtab if it returns SQLITE_OK. *//* If the module has been registered and includes a Create method,
  ** invoke it now. If the module has not been registered, return an
  ** error. Otherwise, do nothing.
  *//* Locate the required virtual table module *//*
** This function is invoked by the vdbe to call the xCreate method
** of the virtual table named zTab in database iDb.
**
** If an error occurs, *pzErr is set to point to an English language
** description of the error and an SQLITE_XXX error code is returned.
** In this case the caller must call sqlite3DbFree(db, ) on *pzErr.
*//* Add pVtab to the end of sqlite3.aVTrans *//*
** Add the virtual table pVTab to the array sqlite3.aVTrans[]. Space should
** have already been reserved using growVTrans().
*//* Grow the sqlite3.aVTrans array if required *//*
** Grow the db->aVTrans[] array so that there is room for at least one
** more v-table. Return SQLITE_NOMEM if a malloc fails, or SQLITE_OK otherwise.
*//*
** This function is invoked by the parser to call the xConnect() method
** of the virtual table pTab. If an error occurs, an error code is returned
** and an error left in pParse.
**
** This call is a no-op if table pTab is not a virtual table.
*//* If everything went according to plan, link the new VTable structure
      ** into the linked list headed by pTab->u.vtab.p. Then loop through the
      ** columns of the table to see if any of them contain the token "hidden".
      ** If so, set the Column COLFLAG_HIDDEN flag and remove the token from
      ** the type string.  *//* Justification of ALWAYS():  A correct vtab constructor must allocate
    ** the sqlite3_vtab object if successful.  *//* Invoke the virtual table constructor *//* Check that the virtual-table is not already being initialized *//*
** Invoke a virtual table constructor (either xCreate or xConnect). The
** pointer to the function to invoke is passed as the fourth parameter
** to this procedure.
*//*
** The parser calls this routine for each token after the first token
** in an argument to the module name in a CREATE VIRTUAL TABLE statement.
*//*
** The parser calls this routine when it sees the first token
** of an argument to the module name in a CREATE VIRTUAL TABLE statement.
*//* Malloc must have failed inside HashInsert() *//* If we are rereading the sqlite_schema table create the in-memory
    ** record of the table. *//* A slot for the record has already been allocated in the
    ** schema table.  We just need to update that slot with all
    ** the information we've collected.
    **
    ** The VM register number pParse->u1.cr.regRowid holds the rowid of an
    ** entry in the sqlite_schema table that was created for this vtab
    ** by sqlite3StartTable().
    *//* Compute the complete text of the CREATE VIRTUAL TABLE statement *//* If the CREATE VIRTUAL TABLE statement is being entered for the
  ** first time (in other words if the virtual table is actually being
  ** created now instead of just being read out of sqlite_schema) then
  ** do additional initialization work and store the statement text
  ** in the sqlite_schema table.
  *//* The table being constructed *//*
** The parser calls this routine after the CREATE VIRTUAL TABLE statement
** has been completely parsed.
*//*
** This routine takes the module argument that has been accumulating
** in pParse->zArg[] and appends it to the list of arguments on the
** virtual table currently under construction in pParse->pTable.
*//* The database the table is being created in *//* Creating a virtual table invokes the authorization callback twice.
  ** The first invocation, to obtain permission to INSERT a row into the
  ** sqlite_schema table, has already been made by sqlite3StartTable().
  ** The second call, to obtain permission to create the table, is made now.
  *//* The new virtual table *//* No error if the table already exists *//* Name of the module for the virtual table *//* Name of new table or NULL *//* Name of new table, or database name *//*
** The parser calls this routine when it first sees a CREATE VIRTUAL TABLE
** statement.  The module name has been parsed, but the optional list
** of parameters that follow the module name are still pending.
*//*
** Add a new module argument to pTable->u.vtab.azArg[].
** The string is not copied - the pointer is stored.  The
** string will be freed automatically when the table is
** deleted.
*//*
** Clear any and all virtual-table information from the Table record.
** This routine is called, for example, just before deleting the Table
** record.
**
** Since it is a virtual-table, the Table structure contains a pointer
** to the head of a linked list of VTable structures. Each VTable
** structure is associated with a single sqlite3* user of the schema.
** The reference count of the VTable structure associated with database
** connection db is decremented immediately (which may lead to the
** structure being xDisconnected and free). Any other VTable structures
** in the list are moved to the sqlite3.pDisconnect list of the associated
** database connection.
*//*
** Disconnect all the virtual table objects in the sqlite3.pDisconnect list.
**
** This function may only be called when the mutexes associated with all
** shared b-tree databases opened using connection db are held by the
** caller. This is done to protect the sqlite3.pDisconnect list. The
** sqlite3.pDisconnect list is accessed only as follows:
**
**   1) By this function. In this case, all BtShared mutexes and the mutex
**      associated with the database handle itself must be held.
**
**   2) By function vtabDisconnectAll(), when it adds a VTable entry to
**      the sqlite3.pDisconnect list. In this case either the BtShared mutex
**      associated with the database the virtual table is stored in is held
**      or, if the virtual table is stored in a non-sharable database, then
**      the database handle mutex is held.
**
** As a result, a sqlite3.pDisconnect cannot be accessed simultaneously
** by multiple threads. It is thread-safe.
*//*
** Table *p is a virtual table. This function removes the VTable object
** for table *p associated with database connection db from the linked
** list in p->pVTab. It also decrements the VTable ref count. This is
** used when closing database connection db to free all of its VTable
** objects without disturbing the rest of the Schema object (which may
** be being used by other shared-cache connections).
*//* Assert that the mutex (if any) associated with the BtShared database
  ** that contains table p is held by the caller. See header comments
  ** above function sqlite3VtabUnlockList() for an explanation of why
  ** this makes it safe to access the sqlite3.pDisconnect list of any
  ** database connection that may have an entry in the p->u.vtab.p list.
  *//*
** Table p is a virtual table. This function moves all elements in the
** p->u.vtab.p list to the sqlite3.pDisconnect lists of their associated
** database connections to be disconnected at the next opportunity.
** Except, if argument db is not NULL, then the entry associated with
** connection db is left in the p->u.vtab.p list.
*//*
** Decrement the ref-count on a virtual table object. When the ref-count
** reaches zero, call the xDisconnect() method to delete the object.
*//*
** pTab is a pointer to a Table structure representing a virtual-table.
** Return a pointer to the VTable object used by connection db to access
** this virtual-table, if one has been created, or NULL otherwise.
*//*
** Lock the virtual table so that it cannot be disconnected.
** Locks nest.  Every lock should have a corresponding unlock.
** If an unlock is omitted, resources leaks will occur.
**
** If a disconnect is attempted while a virtual table is locked,
** the disconnect is deferred until all locks have been removed.
*//*
** Decrement the reference count on a Module object.  Destroy the
** module when the reference count reaches zero.
*//*
** External API to drop all virtual-table modules, except those named
** on the azNames list.
*//* Context pointer for xCreate/xConnect *//* The definition of the module *//* Name assigned to this module *//* Database in which module is registered *//*
** External API function used to create a new virtual-table module.
*//*
** The actual function that does the work of creating a new module.
** This function implements the sqlite3_create_module() and
** sqlite3_create_module_v2() interfaces.
*//*
** Construct and install a Module object for a virtual table.  When this
** routine is called, it is guaranteed that all appropriate locks are held
** and the module is not already part of the connection.
**
** If there already exists a module with zName, replace it with the new one.
** If pModule==0, then delete the module zName if it exists.
*//* True after sqlite3_declare_vtab() is called *//* Parent context (if any) *//* The Table object to which the virtual table belongs *//* The virtual table being constructed *//*
** Before a virtual table xCreate() or xConnect() method is invoked, the
** sqlite3.pVtabCtx member variable is set to point to an instance of
** this struct allocated on the stack. It is used by the implementation of
** the sqlite3_declare_vtab() and sqlite3_vtab_config() APIs, both of which
** are invoked only from within xCreate and xConnect methods.
*//*
** 2006 June 10
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains code used to help implement virtual tables.
*//************** Begin file vtab.c ********************************************//************** End of vacuum.c **********************************************//* SQLITE_OMIT_VACUUM && SQLITE_OMIT_ATTACH *//* This both clears the schemas and reduces the size of the db->aDb[]
  ** array. *//* Currently there is an SQL level transaction open on the vacuum
  ** database. No locks are held on any other files (since the main file
  ** was committed at the btree level). So it safe to end the transaction
  ** by manually setting the autoCommit flag to true and detaching the
  ** vacuum database. The vacuum_db journal file is deleted when the pager
  ** is closed by the DETACH.
  *//* Restore the original value of db->flags *//* GetMeta() and UpdateMeta() cannot fail in this context because
      ** we already have page 1 loaded into cache and marked dirty. *//* Copy Btree meta values *//* Preserve the application id *//* Preserve the user version *//* Preserve the text encoding *//* Preserve the default page cache size *//* Add one to the old schema cookie *//* This array determines which meta meta values are preserved in the
    ** vacuum.  Even entries are the meta value number and odd entries
    ** are an increment to apply to the meta value after the vacuum.
    ** The increment is used to increase the schema cookie so that other
    ** connections to the same database will know to reread the schema.
    *//* At this point, there is a write transaction open on both the
  ** vacuum database and the main database. Assuming no error occurs,
  ** both transactions are closed by this block - the main database
  ** transaction by sqlite3BtreeCopyFile() and the other by an explicit
  ** call to sqlite3BtreeCommit().
  *//* Copy the triggers, views, and virtual tables from the main database
  ** over to the temporary database.  None of these objects has any
  ** associated storage, so all we have to do is copy their entries
  ** from the schema table.
  *//* Loop through the tables in the main database. For each, do
  ** an "INSERT INTO vacuum_db.xxx SELECT * FROM main.xxx;" to copy
  ** the contents to the temporary database.
  *//* force new CREATE statements into vacuum_db *//* Query the schema of the main database. Create a mirror schema
  ** in the temporary database.
  *//* Do not attempt to change the page size for a WAL database *//* Begin a transaction and take an exclusive lock on the main database
  ** file. This is done before the sqlite3BtreeGetPageSize(pMain) call below,
  ** to ensure that we do not try to change the page-size on a WAL database.
  *//* For a VACUUM INTO, the pager-flags are set to the same values as
    ** they are for the database being vacuumed, except that PAGER_CACHESPILL
    ** is always set. *//* Attach the temporary database as 'vacuum_XXXXXX'. The synchronous pragma
  ** can be set to 'off' for this file, as it is not recovered if a crash
  ** occurs anyway. The integrity of the database is maintained by a
  ** (possibly synchronous) transaction opened on the main database before
  ** sqlite3BtreeCopyFile() is called.
  **
  ** An optimization would be to use a non-journaled pager.
  ** (Later:) I tried setting "PRAGMA vacuum_XXXXXX.journal_mode=OFF" but
  ** that actually made the VACUUM run slower.  Very little journalling
  ** actually occurs when doing a vacuum since the vacuum_db is initially
  ** empty.  Only the journal header is written.  Apparently it takes more
  ** time to parse and run the PRAGMA to turn journalling off than it does
  ** to write the journal header file.
  *//* Save the current value of the database flags so that it can be
  ** restored before returning. Then set the writable-schema flag, and
  ** disable CHECK and foreign key constraints.  *//* IMP: R-15610-35227 *//* IMP: R-12218-18073 *//* Name of the ATTACH-ed database used for vacuum *//* Random value used for zDbVacuum[] *//* sync flags for output db *//* Name of output file *//* Schema name of database to vacuum *//* Number of attached databases *//* Bytes of reserved space at the end of each page *//* True if vacuuming a :memory: database *//* Database to detach at end of vacuum *//* Saved trace settings *//* Saved value of db->openFlags *//* Saved value of db->nTotalChange *//* Saved value of db->nChange *//* Saved value of db->flags *//* Saved value of db->mDbFlags *//* The temporary database we vacuum into *//* The database being vacuumed *//* Return code from service routines *//* Write results here, if not NULL. VACUUM INTO *//* Which attached DB to vacuum *//*
** This routine implements the OP_Vacuum opcode of the VDBE.
*//* When SQLITE_BUG_COMPATIBLE_20160819 is defined, unrecognized arguments
    ** to VACUUM are silently ignored.  This is a back-out of a bug fix that
    ** occurred on 2016-08-19 (https://www.sqlite.org/src/info/083f9e6270).
    ** The buggy behavior is required for binary compatibility with some
    ** legacy applications. *//* Default behavior:  Report an error if the argument to VACUUM is
    ** not recognized *//*
** The VACUUM command is used to clean up the database,
** collapse free space, etc.  It is modelled after the VACUUM command
** in PostgreSQL.  The VACUUM command works as follows:
**
**   (1)  Create a new transient database file
**   (2)  Copy all content from the database being vacuumed into
**        the new transient database file
**   (3)  Copy content from the transient database back into the
**        original database.
**
** The transient database requires temporary disk space approximately
** equal to the size of the original database.  The copy operation of
** step (3) requires additional temporary disk space approximately equal
** to the size of the original database for the rollback journal.
** Hence, temporary disk space that is approximately 2x the size of the
** original database is required.  Every page of the database is written
** approximately 3 times:  Once for step (2) and twice for step (3).
** Two writes per page are required in step (3) because the original
** database content must be written into the rollback journal prior to
** overwriting the database with the vacuumed content.
**
** Only 1x temporary space and only 1x writes would be required if
** the copy of step (3) were replaced by deleting the original database
** and renaming the transient database as the original.  But that will
** not work if other processes are attached to the original database.
** And a power loss in between deleting the original and renaming the
** transient would cause the database file to appear to be deleted
** following reboot.
*//* The secondary SQL must be one of CREATE TABLE, CREATE INDEX,
    ** or INSERT.  Historically there have been attacks that first
    ** corrupt the sqlite_schema.sql field with other kinds of statements
    ** then run VACUUM to get those statements to execute at inappropriate
    ** times. *//* printf("SQL: [%s]\n", zSql); fflush(stdout); *//*
** Execute zSql on database db.
**
** If zSql returns rows, then each row will have exactly one
** column.  (This will only happen if zSql begins with "SELECT".)
** Take each row of result and call execSql() again recursively.
**
** The execSqlF() routine does the same thing, except it accepts
** a format string as its third argument
*//* #include "vdbeInt.h" *//*
** 2003 April 6
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains code used to implement the VACUUM command.
**
** Most of the code in this file may be omitted by defining the
** SQLITE_OMIT_VACUUM macro.
*//************** Begin file vacuum.c ******************************************//************** End of upsert.c **********************************************//* SQLITE_OMIT_UPSERT *//* excluded.* columns of type REAL need to be converted to a hard real *//* pUpsert does not own pTop->pUpsertSrc - the outer INSERT statement does.
  ** So we have to make a copy before passing it down into sqlite3Update() *//* FROM clause for the UPDATE *//* Cursor for pIdx (or pTab if pIdx==NULL) *//* The UNIQUE constraint that failed *//* The table being updated *//* The ON CONFLICT clause for the upsert *//* The parsing and code-generating context *//*
** Generate bytecode that does an UPDATE as part of an upsert.
**
** If pIdx is NULL, then the UNIQUE constraint that failed was the IPK.
** In this case parameter iCur is a cursor open on the table b-tree that
** currently points to the conflicting table row. Otherwise, if pIdx
** is not NULL, then pIdx is the constraint that failed and iCur is a
** cursor points to the conflicting row.
*//*
** Given the list of ON CONFLICT clauses described by pUpsert, and
** a particular index pIdx, return a pointer to the particular ON CONFLICT
** clause that applies to the index.  Or, if the index is not subject to
** any ON CONFLICT clause, return NULL.
*//*
** Return true if pUpsert is the last ON CONFLICT clause with a
** conflict target, or if pUpsert is followed by another ON CONFLICT
** clause that targets the INTEGER PRIMARY KEY.
*//* Really this should be an error.  The isDup ON CONFLICT clause will
        ** never fire.  But this problem was not discovered until three years
        ** after multi-CONFLICT upsert was added, and so we silently ignore
        ** the problem to prevent breaking applications that might actually
        ** have redundant ON CONFLICT clauses. *//* Column ii of the index did not match any term of the conflict target.
        ** Continue the search with the next index. *//* The target contains no match for column jj of the index *//* Column ii of the index matches column jj of target *//* Check for matches against other indexes *//* Initialize sCol[0..1] to be an expression parse tree for a
    ** single column of an index.  The sCol[0] node will be the TK_COLLATE
    ** operator and sCol[1] will be the TK_COLUMN operator.  Code below
    ** will populate the specific collation and column number values
    ** prior to comparing against the conflict-target expression.
    *//* The conflict-target is the rowid of the primary table *//* Check to see if the conflict target matches the rowid. *//* Resolve all symbolic names in the conflict-target clause, which
  ** includes both the list of columns and the optional partial-index
  ** WHERE clause.
  *//* Counter of ON CONFLICT clauses *//* Index column converted into an Expr *//* Context for resolving symbolic names *//* One term of the conflict-target clause *//* The conflict-target clause *//* One of the indexes of pTab *//* Cursor used by pTab *//* That table into which we are inserting *//* Complete list of all ON CONFLICT clauses *//* The ON CONFLICT clauses *//* Table into which we are inserting *//*
** Analyze the ON CONFLICT clause described by pUpsert.  Resolve all
** symbols in the conflict-target.
**
** Return SQLITE_OK if everything works, or an error code is something
** is wrong.
*//* Next ON CONFLICT clause in the list *//* WHERE clause for the ON CONFLICT UPDATE *//* UPDATE columns, or NULL for a DO NOTHING *//* Optional WHERE clause on the target *//* Target argument to ON CONFLICT, or NULL *//* Determines which memory allocator to use *//*
** Create a new Upsert object.
*//*
** Duplicate an Upsert object.
*//*
** Free a list of Upsert objects
*//*
** 2018-04-12
**
** The author disclaims copyright to this source code.  In place of
** a legal notice, here is a blessing:
**
**    May you do good and not evil.
**    May you find forgiveness for yourself and forgive others.
**    May you share freely, never taking more than you give.
**
*************************************************************************
** This file contains code to implement various aspects of UPSERT
** processing and handling of the Upsert object.
*//************** Begin file upsert.c ******************************************//************** End of update.c **********************************************//* End of the ephemeral table scan. Or, if using the onepass strategy,
  ** jump to here if the scan visited zero rows. *//* Extract arguments from the current row of the ephemeral table and
    ** invoke the VUpdate method.  *//* Begin scanning through the ephemeral table. *//* End the virtual table scan *//* Signal an assert() within OP_MakeRecord that it is allowed to
      ** accept no-change records with serial_type 10 *//* Create a record from the argument register contents and insert it into
      ** the ephemeral table. *//* If using the onepass strategy, no-op out the OP_OpenEphemeral coded
      ** above. *//* There is no ONEPASS_MULTI on virtual tables *//* PRIMARY KEY column *//* PRIMARY KEY index *//* For sqlite3_vtab_nochange() *//* Populate the argument registers. *//* Start scanning the virtual table *//* Allocate nArg registers in which to gather the arguments for VUpdate. Then
  ** create and open the ephemeral table in which the records created from
  ** these arguments will be temporarily stored. *//* Address of OP_OpenEphemeral *//* True to use onepass strategy *//* Unused arg for sqlite3WhereOkOnePass() *//* Cursor used for virtual table scan *//* Register for ephemeral table rowid *//* Register in which to assemble record *//* First register in VUpdate arg array *//* Number of arguments to VUpdate *//* Table holding the result of the SELECT *//* Virtual machine under construction *//* ON CONFLICT strategy *//* WHERE clause of the UPDATE statement *//* Mapping from columns of pTab to entries in pChanges *//* Expression used to recompute the rowid *//* The columns to change in the UPDATE statement *//* The virtual table *//* The virtual table to be modified *//*
** Generate code for an UPDATE of a virtual table.
**
** There are two possible strategies - the default and the special
** "onepass" strategy. Onepass is only used if the virtual table
** implementation indicates that pWhere may match at most one row.
**
** The default strategy is to create an ephemeral table that contains
** for each row to be changed:
**
**   (A)  The original rowid of that row.
**   (B)  The revised rowid for the row.
**   (C)  The content of every column in the row.
**
** Then loop through the contents of this ephemeral table executing a
** VUpdate for each row. When finished, drop the ephemeral table.
**
** The "onepass" strategy does not use an ephemeral table. Instead, it
** stores the same values (A, B and C above) in a register array and
** makes a single invocation of VUpdate.
*//* Make sure "isView" and other macros defined above are undefined. Otherwise
** they may interfere with compilation of other functions in this file
** (or in another file, if this file becomes part of the amalgamation).  *//* Also frees aRegIdx[] and aToOpen[] *//*
  ** Return the number of rows that were changed, if we are tracking
  ** that information.
  *//* Update the sqlite_sequence table by storing the content of the
  ** maximum rowid counter values recorded while inserting into
  ** autoincrement tables.
  *//* Nothing to do at end-of-loop for a single-pass *//* Repeat the above with the next record to be updated, until
  ** all record selected by the WHERE clause have been updated.
  *//* Increment the row counter
  *//* Do any ON CASCADE, SET NULL or SET DEFAULT operations required to
    ** handle rows (possibly in other tables) that refer via a foreign key
    ** to the row just updated. *//* Insert the new index entries and the new record. *//* If changing the rowid value, or if there are foreign key constraints
    ** to process, delete the old record. Otherwise, add a noop OP_Delete
    ** to invoke the pre-update hook.
    **
    ** That (regNew==regnewRowid+1) is true is also important for the
    ** pre-update hook. If the caller invokes preupdate_new(), the returned
    ** value is copied from memory cell (regNewRowid+1+iCol), where iCol
    ** is the column index supplied by the user.
    *//* We must run the OP_FinishSeek opcode to resolve a prior
    ** OP_DeferredSeek if there is any possibility that there have been
    ** no OP_Column opcodes since the OP_DeferredSeek was issued.  But
    ** we want to avoid the OP_FinishSeek if possible, as running it
    ** costs CPU cycles. *//* Delete the index entries associated with the current record.  *//* Do FK constraint checks. *//* If REPLACE conflict handling may have been used, or if the PK of the
    ** row is changing, then the GenerateConstraintChecks() above may have
    ** moved cursor iDataCur. Reseek it. *//* Do constraint checks. *//* After-BEFORE-trigger-reload-loop:
      ** If it did not delete it, the BEFORE trigger may still have modified
      ** some of the columns of the row being updated. Load the values for
      ** all columns not modified by the update statement into their registers
      ** in case this has happened. Only unmodified columns are reloaded.
      ** The values computed for modified columns use the values before the
      ** BEFORE trigger runs.  See test case trigger1-18.0 (added 2018-04-26)
      ** for an example.
      *//* The row-trigger may have deleted the row being updated. In this
      ** case, jump to the next row. No updates or AFTER triggers are
      ** required. This behavior - what happens when the row being updated
      ** is deleted or renamed by a BEFORE trigger - is left undefined in the
      ** documentation.
      *//* Fire any BEFORE UPDATE triggers. This happens before constraints are
  ** verified. One could argue that this is wrong.
  *//* This branch loads the value of a column that will not be changed
        ** into a register. This is done if there are no BEFORE triggers, or
        ** if there are one or more BEFORE triggers that use this value via
        ** a new.* reference in a trigger program.
        *//* Populate the array of registers beginning at regNew with the new
  ** row data. This array is used to check constants, create the new
  ** table and index records, and as the values for any new.* references
  ** made by triggers.
  **
  ** If there are one or more BEFORE triggers, then do not populate the
  ** registers associated with columns that are (a) not modified by
  ** this UPDATE statement and (b) not accessed by new.* references. The
  ** values for registers not modified by the UPDATE must be reloaded from
  ** the database after the BEFORE triggers are fired anyway (as the trigger
  ** may have modified them). So not loading those that are not going to
  ** be used eliminates some redundant opcodes.
  *//* Compute the old pre-UPDATE content of the row being changed, if that
  ** information is needed *//* If the rowid value will change, set register regNewRowid to
  ** contain the new value. If the rowid is not being modified,
  ** then regNewRowid is the same register as regOldRowid, which is
  ** already populated.  *//* Top of the update loop *//* Open every index that needs updating. *//* Read the PK of the current row into an array of registers. In
      ** ONEPASS_OFF mode, serialize the array into a record and store it in
      ** the ephemeral table. Or, in ONEPASS_SINGLE or MULTI mode, change
      ** the OP_OpenEphemeral instruction to a Noop (the ephemeral table
      ** is not required) and leave the PK fields in the array of registers.  *//* Read the rowid of the current row of the WHERE scan. In ONEPASS_OFF
      ** mode, write the rowid into the FIFO. In either of the one-pass modes,
      ** leave it in register regOldRowid.  *//* A one-pass strategy that might update more than one row may not
      ** be used if any column of the index used for the scan is being
      ** updated. Otherwise, if there is an index on "b", statements like
      ** the following could create an infinite loop:
      **
      **   UPDATE t1 SET b=b+1 WHERE b>?
      **
      ** Fall back to ONEPASS_OFF if where.c has selected a ONEPASS_MULTI
      ** strategy that uses an index for which one or more columns are being
      ** updated.  *//* Begin the database scan.
      **
      ** Do not consider a single-pass strategy for a multi-row update if
      ** there is anything that might disrupt the cursor being used to do
      ** the UPDATE:
      **   (1) This is a nested UPDATE
      **   (2) There are triggers
      **   (3) There are FOREIGN KEY constraints
      **   (4) There are REPLACE conflict handlers
      **   (5) There are subqueries in the WHERE clause
      *//* If this is an UPSERT, then all cursors have already been opened by
      ** the outer INSERT and the data cursor should be pointing at the row
      ** that is to be updated.  So bypass the code that searches for the
      ** row(s) to be updated.
      *//* Not an UPSERT.  Normal processing.  Begin by
  ** initialize the count of updated rows *//* Jump to labelBreak to abandon further processing of this UPDATE *//* Virtual tables must be handled separately *//* Resolve the column names in all the expressions in the
  ** WHERE clause.
  *//* If we are trying to update a view, realize that view into
  ** an ephemeral table.
  *//* Start the view context. *//* For now, regRowSet and aRegIdx[nAllIdx] share the same register.
    ** If regRowSet turns out to be needed, then aRegIdx[nAllIdx] will be
    ** reallocated.  aRegIdx[nAllIdx] is the register in which the main
    ** table record is written.  regRowSet holds the RowSet for the
    ** two-pass update algorithm. *//* Allocate required registers. *//* If REPLACE conflict resolution might be invoked, open cursors on all
    ** indexes in case they are needed to delete records.  *//* Register storing the table record *//* There is one entry in the aRegIdx[] array for each index on the table
  ** being updated.  Fill in aRegIdx[] with a register number that will hold
  ** the key for accessing each index.
  *//* The SET expressions are not actually used inside the WHERE loop.
  ** So reset the colUsed mask. Unless this is a virtual table. In that
  ** case, set all bits of the colUsed mask (to ensure that the virtual
  ** table implementation makes all columns available).
  *//* Mark generated columns as changing if their generator expressions
  ** reference any changing column.  The actual aXRef[] value for
  ** generated expressions is not used, other than to check to see that it
  ** is non-negative, so the value of aXRef[] for generated columns can be
  ** set to any non-negative number.  We use 99999 so that the value is
  ** obvious when looking at aXRef[] in a symbolic debugger.
  *//* If this is an UPDATE with a FROM clause, do not resolve expressions
    ** here. The call to sqlite3Select() below will do that. *//* Resolve the column names in all the expressions of the
  ** of the UPDATE statement.  Also find the column index
  ** for each column to be updated in the pChanges array.  For each
  ** column to be updated, make sure we have authorization to change
  ** that column.
  *//* Begin generating code. *//* Initialize the name-context *//* Allocate space for aXRef[], aRegIdx[], and aToOpen[].
  ** Initialize aXRef[] and aToOpen[] to their default values.
  *//* On an UPSERT, reuse the same cursors already opened by INSERT *//* Allocate a cursors for the main database table and for all indices.
  ** The index cursors might not be used, but if they are used they
  ** need to occur right after the database cursor.  So go ahead and
  ** allocate enough space, just in case.
  *//* If there was a FROM clause, set nChangeFrom to the number of expressions
  ** in the change-list. Otherwise, set it to 0. There cannot be a FROM
  ** clause if this function is being called to generate code for part of
  ** an UPSERT statement.  *//* Figure out if we have any triggers and if the table being
  ** updated is a view.
  *//* Locate the table which we want to update.
  *//* composite PRIMARY KEY value *//* Rowset of rows to be updated *//* Content of OLD.* table in triggers *//* Content of the NEW.* table in triggers *//* A count of rows changed *//* Register Allocations *//* If there is a FROM, pChanges->nExpr, else 0 *//* The OP_FinishSeek opcode is needed *//* True if REPLACE conflict resolution might happen *//* Number of components of the PRIMARY KEY *//* First of nPk cells holding PRIMARY KEY value *//* The write cursors opened by WHERE_ONEPASS *//* Number of elements in regKey for WITHOUT ROWID *//* Ephemeral table holding all primary key values *//* Mask of NEW.* columns accessed by BEFORE triggers *//* Mask of TRIGGER_BEFORE|TRIGGER_AFTER *//* List of triggers on pTab, if required *//* True when updating a view (INSTEAD OF trigger) *//* Flags for sqlite3WhereBegin() *//* Jump here to continue next step of UPDATE loop *//* Jump here to break out of UPDATE loop *//* True if foreign key processing is required *//* ONEPASS_XXX value from where.c *//* Database containing the table being updated *//* The name-context to resolve expressions in *//* The authorization context *//* Index of "rowid=" (or IPK) assignment in pChanges *//* Expression defining the new record number *//* Either chngPk or chngRowid *//* Rowid changed in a normal table *//* PRIMARY KEY changed in a WITHOUT ROWID table *//* 1 for tables and indices to be opened *//* aXRef[i] is the index in pChanges->a[] of the
                         ** an expression for the i-th column of the table.
                         ** aXRef[i]==-1 if the i-th column is not changed. *//* Registers for to each index and the main table *//* The database structure *//* Cursor for the first index *//* Cursor for the canonical data btree *//* Base cursor number *//* Total number of indexes *//* Number of indices that need updating *//* The PRIMARY KEY index for WITHOUT ROWID tables *//* For looping over indices *//* Information about the WHERE clause *//* VDBE instruction address of the start of the loop *//* The table to be updated *//* ON CONFLICT clause, or null *//* LIMIT clause. May be null *//* ORDER BY clause. May be null *//* How to handle constraint errors *//* The WHERE clause.  May be null *//* Things to be changed *//* The table in which we should change things *//*
** Process an UPDATE statement.
**
**   UPDATE OR IGNORE tbl SET a=b, c=d FROM tbl2... WHERE e<5 AND f NOT NULL;
**          \_______/ \_/     \______/      \_____/       \________________/
**           onError   |      pChanges         |                pWhere
**                     \_______________________/
**                               pTabList
*//* LIMIT clause *//* ORDER BY clause *//* WHERE clause for query *//* List of tables to select from *//* List of expressions to return *//* PK if table 0 is WITHOUT ROWID *//* Cursor for open eph. table *//*
** Assuming both the pLimit and pOrderBy parameters are NULL, this function
** generates VM code to run the query:
**
**   SELECT <other-columns>, pChanges FROM pTabList WHERE pWhere
**
** and write the results to the ephemeral table already opened as cursor
** iEph. None of pChanges, pTabList or pWhere are modified or consumed by
** this function, they must be deleted by the caller.
**
** Or, if pLimit and pOrderBy are not NULL, and pTab is not a view:
**
**   SELECT <other-columns>, pChanges FROM pTabList
**   WHERE pWhere
**   GROUP BY <other-columns>
**   ORDER BY pOrderBy LIMIT pLimit
**
** If pTab is a view, the GROUP BY clause is omitted.
**
** Exactly how results are written to table iEph, and exactly what
** the <other-columns> in the query above are is determined by the type
** of table pTabList->a[0].pTab.
**
** If the table is a WITHOUT ROWID table, then argument pPk must be its
** PRIMARY KEY. In this case <other-columns> are the primary key columns
** of the table, in order. The results of the query are written to ephemeral
** table iEph as index keys, using OP_IdxInsert.
**
** If the table is actually a view, then <other-columns> are all columns of
** the view. The results are written to the ephemeral table iEph as records
** with automatically assigned integer keys.
**
** If the table is a virtual or ordinary intkey table, then <other-columns>
** is its rowid. For a virtual table, the results are written to iEph as
** records with automatically assigned integer keys For intkey tables, the
** rowid value in <other-columns> is used as the integer key, and the
** remaining fields make up the table record.
*//*
** Allocate and return a pointer to an expression of type TK_ROW with
** Expr.iColumn set to value (iCol+1). The resolver will modify the
** expression to be a TK_COLUMN reading column iCol of the first
** table in the source-list (pSrc->a[0]).
*//* true if the rowid is being updated *//* aXRef[j]>=0 if column j is being updated *//* The index to check *//*
** Check to see if index pIdx is a partial index whose conditional
** expression might change values due to an UPDATE.  Return true if
** the index is subject to change and false if the index is guaranteed
** to be unchanged.  This is an optimization.  False-positives are a
** performance degradation, but false-negatives can result in a corrupt
** index and incorrect answers.
**
** aXRef[j] will be non-negative if column j of the original table is
** being updated.  chngRowid will be true if the rowid of the table is
** being updated.
*//* Cannot index rowid *//* Which column of the index to check *//*
** Check to see if column iCol of index pIdx references any of the
** columns defined by aXRef and chngRowid.  Return true if it does
** and false if not.  This is an optimization.  False-positives are a
** performance degradation, but false-negatives can result in a corrupt
** index and incorrect answers.
**
** aXRef[j] will be non-negative if column j of the original table is
** being updated.  chngRowid will be true if the rowid of the table is
** being updated.
*//*
** The most recently coded instruction was an OP_Column to retrieve the
** i-th column of table pTab. This routine sets the P4 parameter of the
** OP_Column to the default value, if any.
**
** The default value of a column is specified by a DEFAULT clause in the
** column definition. This was either supplied by the user when the table
** was created, or added later to the table definition by an ALTER TABLE
** command. If the latter, then the row-records in the table btree on disk
** may not contain a value for the column and the default value, taken
** from the P4 parameter of the OP_Column instruction, is returned instead.
** If the former, then all row-records are guaranteed to include a value
** for the column and the P4 value is not required.
**
** Column definitions created by an ALTER TABLE command may only have
** liter r.  Z&    